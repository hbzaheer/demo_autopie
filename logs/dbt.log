

============================== 2022-02-20 04:35:45.649791 | a4be2ece-b5fa-40da-9e9f-7ca0ef05da29 ==============================
04:35:45.649791 [info ] [MainThread]: Running with dbt=1.0.1
04:35:45.650123 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/hassanzaheer/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, parse_only=False, threads=None, select=None, exclude=None, selector_name=None, state=None, full_refresh=False, defer=None, cls=<class 'dbt.task.compile.CompileTask'>, which='compile', rpc_method='compile')
04:35:45.650251 [debug] [MainThread]: Tracking: do not track
04:35:45.664275 [info ] [MainThread]: Partial parse save file not found. Starting full parse.
04:35:45.672379 [debug] [MainThread]: Parsing macros/catalog.sql
04:35:45.674448 [debug] [MainThread]: Parsing macros/relations.sql
04:35:45.675182 [debug] [MainThread]: Parsing macros/adapters.sql
04:35:45.686781 [debug] [MainThread]: Parsing macros/materializations/snapshot_merge.sql
04:35:45.687713 [debug] [MainThread]: Parsing macros/materializations/hooks.sql
04:35:45.689488 [debug] [MainThread]: Parsing macros/materializations/configs.sql
04:35:45.690522 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot_merge.sql
04:35:45.691353 [debug] [MainThread]: Parsing macros/materializations/snapshots/strategies.sql
04:35:45.699216 [debug] [MainThread]: Parsing macros/materializations/snapshots/helpers.sql
04:35:45.704732 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot.sql
04:35:45.710537 [debug] [MainThread]: Parsing macros/materializations/tests/test.sql
04:35:45.712581 [debug] [MainThread]: Parsing macros/materializations/tests/helpers.sql
04:35:45.713384 [debug] [MainThread]: Parsing macros/materializations/tests/where_subquery.sql
04:35:45.714178 [debug] [MainThread]: Parsing macros/materializations/models/incremental/column_helpers.sql
04:35:45.716158 [debug] [MainThread]: Parsing macros/materializations/models/incremental/merge.sql
04:35:45.721507 [debug] [MainThread]: Parsing macros/materializations/models/incremental/is_incremental.sql
04:35:45.722189 [debug] [MainThread]: Parsing macros/materializations/models/incremental/incremental.sql
04:35:45.727010 [debug] [MainThread]: Parsing macros/materializations/models/incremental/on_schema_change.sql
04:35:45.734667 [debug] [MainThread]: Parsing macros/materializations/models/table/table.sql
04:35:45.738307 [debug] [MainThread]: Parsing macros/materializations/models/table/create_table_as.sql
04:35:45.739567 [debug] [MainThread]: Parsing macros/materializations/models/view/view.sql
04:35:45.743057 [debug] [MainThread]: Parsing macros/materializations/models/view/helpers.sql
04:35:45.743622 [debug] [MainThread]: Parsing macros/materializations/models/view/create_or_replace_view.sql
04:35:45.744840 [debug] [MainThread]: Parsing macros/materializations/models/view/create_view_as.sql
04:35:45.745830 [debug] [MainThread]: Parsing macros/materializations/seeds/seed.sql
04:35:45.748618 [debug] [MainThread]: Parsing macros/materializations/seeds/helpers.sql
04:35:45.756769 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_alias.sql
04:35:45.757434 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_schema.sql
04:35:45.758541 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_database.sql
04:35:45.759239 [debug] [MainThread]: Parsing macros/generic_test_sql/relationships.sql
04:35:45.759634 [debug] [MainThread]: Parsing macros/generic_test_sql/not_null.sql
04:35:45.759863 [debug] [MainThread]: Parsing macros/generic_test_sql/unique.sql
04:35:45.760161 [debug] [MainThread]: Parsing macros/generic_test_sql/accepted_values.sql
04:35:45.760763 [debug] [MainThread]: Parsing macros/etc/statement.sql
04:35:45.762760 [debug] [MainThread]: Parsing macros/etc/datetime.sql
04:35:45.766681 [debug] [MainThread]: Parsing macros/adapters/schema.sql
04:35:45.767621 [debug] [MainThread]: Parsing macros/adapters/indexes.sql
04:35:45.768796 [debug] [MainThread]: Parsing macros/adapters/relation.sql
04:35:45.773127 [debug] [MainThread]: Parsing macros/adapters/freshness.sql
04:35:45.774413 [debug] [MainThread]: Parsing macros/adapters/persist_docs.sql
04:35:45.776370 [debug] [MainThread]: Parsing macros/adapters/metadata.sql
04:35:45.779662 [debug] [MainThread]: Parsing macros/adapters/columns.sql
04:35:45.784176 [debug] [MainThread]: Parsing tests/generic/builtin.sql
04:35:45.865001 [debug] [MainThread]: 1699: static parser successfully parsed example/my_first_dbt_model.sql
04:35:45.870353 [debug] [MainThread]: 1699: static parser successfully parsed example/my_second_dbt_model.sql
04:35:45.894821 [info ] [MainThread]: Found 2 models, 4 tests, 0 snapshots, 0 analyses, 165 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
04:35:45.895462 [info ] [MainThread]: 
04:35:45.895680 [debug] [MainThread]: Acquiring new postgres connection "master"
04:35:45.896019 [debug] [ThreadPool]: Acquiring new postgres connection "list_postgres_testsatmap"
04:35:45.900504 [debug] [ThreadPool]: Using postgres connection "list_postgres_testsatmap"
04:35:45.900587 [debug] [ThreadPool]: On list_postgres_testsatmap: BEGIN
04:35:45.900650 [debug] [ThreadPool]: Opening a new connection, currently in state init
04:35:45.934042 [debug] [ThreadPool]: SQL status: BEGIN in 0.03 seconds
04:35:45.934217 [debug] [ThreadPool]: Using postgres connection "list_postgres_testsatmap"
04:35:45.934282 [debug] [ThreadPool]: On list_postgres_testsatmap: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "list_postgres_testsatmap"} */
select
      'postgres' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'testsatmap'
    union all
    select
      'postgres' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'testsatmap'
  
04:35:45.943201 [debug] [ThreadPool]: SQL status: SELECT 5 in 0.01 seconds
04:35:45.944203 [debug] [ThreadPool]: On list_postgres_testsatmap: ROLLBACK
04:35:45.944484 [debug] [ThreadPool]: On list_postgres_testsatmap: Close
04:35:45.946695 [debug] [MainThread]: Using postgres connection "master"
04:35:45.946792 [debug] [MainThread]: On master: BEGIN
04:35:45.946860 [debug] [MainThread]: Opening a new connection, currently in state init
04:35:45.951925 [debug] [MainThread]: SQL status: BEGIN in 0.01 seconds
04:35:45.952004 [debug] [MainThread]: Using postgres connection "master"
04:35:45.952065 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
04:35:45.972376 [debug] [MainThread]: SQL status: SELECT 0 in 0.02 seconds
04:35:45.973092 [debug] [MainThread]: On master: ROLLBACK
04:35:45.973314 [debug] [MainThread]: On master: Close
04:35:45.973480 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
04:35:45.973595 [info ] [MainThread]: 
04:35:45.975581 [debug] [Thread-1  ]: Began running node model.demo_autopie.my_first_dbt_model
04:35:45.975774 [debug] [Thread-1  ]: Acquiring new postgres connection "model.demo_autopie.my_first_dbt_model"
04:35:45.975856 [debug] [Thread-1  ]: Began compiling node model.demo_autopie.my_first_dbt_model
04:35:45.975928 [debug] [Thread-1  ]: Compiling model.demo_autopie.my_first_dbt_model
04:35:45.977182 [debug] [Thread-1  ]: Writing injected SQL for node "model.demo_autopie.my_first_dbt_model"
04:35:45.977604 [debug] [Thread-1  ]: finished collecting timing info
04:35:45.977682 [debug] [Thread-1  ]: Began executing node model.demo_autopie.my_first_dbt_model
04:35:45.977751 [debug] [Thread-1  ]: finished collecting timing info
04:35:45.977895 [debug] [Thread-1  ]: Finished running node model.demo_autopie.my_first_dbt_model
04:35:45.978134 [debug] [Thread-1  ]: Began running node model.demo_autopie.my_second_dbt_model
04:35:45.978362 [debug] [Thread-1  ]: Acquiring new postgres connection "model.demo_autopie.my_second_dbt_model"
04:35:45.978427 [debug] [Thread-1  ]: Began compiling node model.demo_autopie.my_second_dbt_model
04:35:45.978486 [debug] [Thread-1  ]: Compiling model.demo_autopie.my_second_dbt_model
04:35:45.979490 [debug] [Thread-1  ]: Writing injected SQL for node "model.demo_autopie.my_second_dbt_model"
04:35:45.979779 [debug] [Thread-1  ]: finished collecting timing info
04:35:45.979849 [debug] [Thread-1  ]: Began executing node model.demo_autopie.my_second_dbt_model
04:35:45.979912 [debug] [Thread-1  ]: finished collecting timing info
04:35:45.980065 [debug] [Thread-1  ]: Finished running node model.demo_autopie.my_second_dbt_model
04:35:45.980146 [debug] [Thread-1  ]: Began running node test.demo_autopie.not_null_my_first_dbt_model_id.5fb22c2710
04:35:45.980352 [debug] [Thread-1  ]: Acquiring new postgres connection "test.demo_autopie.not_null_my_first_dbt_model_id.5fb22c2710"
04:35:45.980411 [debug] [Thread-1  ]: Began compiling node test.demo_autopie.not_null_my_first_dbt_model_id.5fb22c2710
04:35:45.980469 [debug] [Thread-1  ]: Compiling test.demo_autopie.not_null_my_first_dbt_model_id.5fb22c2710
04:35:45.985559 [debug] [Thread-1  ]: Writing injected SQL for node "test.demo_autopie.not_null_my_first_dbt_model_id.5fb22c2710"
04:35:45.985889 [debug] [Thread-1  ]: finished collecting timing info
04:35:45.985966 [debug] [Thread-1  ]: Began executing node test.demo_autopie.not_null_my_first_dbt_model_id.5fb22c2710
04:35:45.986031 [debug] [Thread-1  ]: finished collecting timing info
04:35:45.986185 [debug] [Thread-1  ]: Finished running node test.demo_autopie.not_null_my_first_dbt_model_id.5fb22c2710
04:35:45.986273 [debug] [Thread-1  ]: Began running node test.demo_autopie.unique_my_first_dbt_model_id.16e066b321
04:35:45.986553 [debug] [Thread-1  ]: Acquiring new postgres connection "test.demo_autopie.unique_my_first_dbt_model_id.16e066b321"
04:35:45.986706 [debug] [Thread-1  ]: Began compiling node test.demo_autopie.unique_my_first_dbt_model_id.16e066b321
04:35:45.986784 [debug] [Thread-1  ]: Compiling test.demo_autopie.unique_my_first_dbt_model_id.16e066b321
04:35:45.989960 [debug] [Thread-1  ]: Writing injected SQL for node "test.demo_autopie.unique_my_first_dbt_model_id.16e066b321"
04:35:45.990264 [debug] [Thread-1  ]: finished collecting timing info
04:35:45.990338 [debug] [Thread-1  ]: Began executing node test.demo_autopie.unique_my_first_dbt_model_id.16e066b321
04:35:45.990403 [debug] [Thread-1  ]: finished collecting timing info
04:35:45.990544 [debug] [Thread-1  ]: Finished running node test.demo_autopie.unique_my_first_dbt_model_id.16e066b321
04:35:45.990625 [debug] [Thread-1  ]: Began running node test.demo_autopie.not_null_my_second_dbt_model_id.151b76d778
04:35:45.990796 [debug] [Thread-1  ]: Acquiring new postgres connection "test.demo_autopie.not_null_my_second_dbt_model_id.151b76d778"
04:35:45.990872 [debug] [Thread-1  ]: Began compiling node test.demo_autopie.not_null_my_second_dbt_model_id.151b76d778
04:35:45.990933 [debug] [Thread-1  ]: Compiling test.demo_autopie.not_null_my_second_dbt_model_id.151b76d778
04:35:45.992483 [debug] [Thread-1  ]: Writing injected SQL for node "test.demo_autopie.not_null_my_second_dbt_model_id.151b76d778"
04:35:45.992664 [debug] [Thread-1  ]: finished collecting timing info
04:35:45.992727 [debug] [Thread-1  ]: Began executing node test.demo_autopie.not_null_my_second_dbt_model_id.151b76d778
04:35:45.992785 [debug] [Thread-1  ]: finished collecting timing info
04:35:45.992910 [debug] [Thread-1  ]: Finished running node test.demo_autopie.not_null_my_second_dbt_model_id.151b76d778
04:35:45.992983 [debug] [Thread-1  ]: Began running node test.demo_autopie.unique_my_second_dbt_model_id.57a0f8c493
04:35:45.993118 [debug] [Thread-1  ]: Acquiring new postgres connection "test.demo_autopie.unique_my_second_dbt_model_id.57a0f8c493"
04:35:45.993173 [debug] [Thread-1  ]: Began compiling node test.demo_autopie.unique_my_second_dbt_model_id.57a0f8c493
04:35:45.993227 [debug] [Thread-1  ]: Compiling test.demo_autopie.unique_my_second_dbt_model_id.57a0f8c493
04:35:45.994961 [debug] [Thread-1  ]: Writing injected SQL for node "test.demo_autopie.unique_my_second_dbt_model_id.57a0f8c493"
04:35:45.995316 [debug] [Thread-1  ]: finished collecting timing info
04:35:45.995392 [debug] [Thread-1  ]: Began executing node test.demo_autopie.unique_my_second_dbt_model_id.57a0f8c493
04:35:45.995459 [debug] [Thread-1  ]: finished collecting timing info
04:35:45.995614 [debug] [Thread-1  ]: Finished running node test.demo_autopie.unique_my_second_dbt_model_id.57a0f8c493
04:35:45.996012 [debug] [MainThread]: Connection 'master' was properly closed.
04:35:45.996083 [debug] [MainThread]: Connection 'test.demo_autopie.unique_my_second_dbt_model_id.57a0f8c493' was properly closed.
04:35:45.998229 [info ] [MainThread]: Done.


============================== 2022-02-20 04:38:46.552940 | 2615faeb-9138-414a-9764-d9f137e6d2c0 ==============================
04:38:46.552940 [info ] [MainThread]: Running with dbt=1.0.1
04:38:46.553610 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/hassanzaheer/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, parse_only=False, threads=None, select=None, exclude=None, selector_name=None, state=None, full_refresh=False, defer=None, cls=<class 'dbt.task.compile.CompileTask'>, which='compile', rpc_method='compile')
04:38:46.553737 [debug] [MainThread]: Tracking: do not track
04:38:46.576798 [debug] [MainThread]: Partial parsing enabled: 3 files deleted, 7 files added, 0 files changed.
04:38:46.577092 [debug] [MainThread]: Partial parsing: added file: demo_autopie://macros/compile_recipe_collect_fact.sql
04:38:46.577193 [debug] [MainThread]: Partial parsing: added file: demo_autopie://models/demo_ebp_flow/prepared_scripts/prepared_fact_calls.sql
04:38:46.577275 [debug] [MainThread]: Partial parsing: added file: demo_autopie://macros/core/run_recipe.sql
04:38:46.577352 [debug] [MainThread]: Partial parsing: added file: demo_autopie://models/demo_ebp_flow/demo_data_prep.sql
04:38:46.577427 [debug] [MainThread]: Partial parsing: added file: demo_autopie://models/demo_ebp_flow/prepared_scripts/prepared_facts.sql
04:38:46.577500 [debug] [MainThread]: Partial parsing: added file: demo_autopie://macros/core/run_directory.sql
04:38:46.577571 [debug] [MainThread]: Partial parsing: added file: demo_autopie://models/demo_ebp_flow/prepared_scripts/prepared_fact_outcomes.sql
04:38:46.577670 [debug] [MainThread]: Partial parsing: deleted file: demo_autopie://models/example/my_first_dbt_model.sql
04:38:46.577764 [debug] [MainThread]: Partial parsing: deleted file: demo_autopie://models/example/my_second_dbt_model.sql
04:38:46.577852 [debug] [MainThread]: Parsing macros/compile_recipe_collect_fact.sql
04:38:46.606696 [debug] [MainThread]: Parsing macros/core/run_recipe.sql
04:38:46.608121 [debug] [MainThread]: Parsing macros/core/run_directory.sql
04:38:46.625801 [debug] [MainThread]: 1699: static parser successfully parsed demo_ebp_flow/prepared_scripts/prepared_fact_calls.sql
04:38:46.631021 [debug] [MainThread]: 1699: static parser successfully parsed demo_ebp_flow/demo_data_prep.sql
04:38:46.631980 [debug] [MainThread]: 1699: static parser successfully parsed demo_ebp_flow/prepared_scripts/prepared_facts.sql
04:38:46.632790 [debug] [MainThread]: 1699: static parser successfully parsed demo_ebp_flow/prepared_scripts/prepared_fact_outcomes.sql
04:38:46.635094 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.demo_autopie.example

04:38:46.640336 [info ] [MainThread]: Found 4 models, 0 tests, 0 snapshots, 0 analyses, 168 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
04:38:46.641029 [info ] [MainThread]: 
04:38:46.641255 [debug] [MainThread]: Acquiring new postgres connection "master"
04:38:46.641644 [debug] [ThreadPool]: Acquiring new postgres connection "list_postgres_testsatmap"
04:38:46.646428 [debug] [ThreadPool]: Using postgres connection "list_postgres_testsatmap"
04:38:46.646627 [debug] [ThreadPool]: On list_postgres_testsatmap: BEGIN
04:38:46.646806 [debug] [ThreadPool]: Opening a new connection, currently in state init
04:38:46.669864 [debug] [ThreadPool]: SQL status: BEGIN in 0.02 seconds
04:38:46.670056 [debug] [ThreadPool]: Using postgres connection "list_postgres_testsatmap"
04:38:46.670123 [debug] [ThreadPool]: On list_postgres_testsatmap: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "list_postgres_testsatmap"} */
select
      'postgres' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'testsatmap'
    union all
    select
      'postgres' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'testsatmap'
  
04:38:46.675593 [debug] [ThreadPool]: SQL status: SELECT 5 in 0.01 seconds
04:38:46.676655 [debug] [ThreadPool]: On list_postgres_testsatmap: ROLLBACK
04:38:46.677040 [debug] [ThreadPool]: On list_postgres_testsatmap: Close
04:38:46.679156 [debug] [MainThread]: Using postgres connection "master"
04:38:46.679248 [debug] [MainThread]: On master: BEGIN
04:38:46.679308 [debug] [MainThread]: Opening a new connection, currently in state init
04:38:46.683440 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
04:38:46.683513 [debug] [MainThread]: Using postgres connection "master"
04:38:46.683568 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
04:38:46.698858 [debug] [MainThread]: SQL status: SELECT 0 in 0.02 seconds
04:38:46.699609 [debug] [MainThread]: On master: ROLLBACK
04:38:46.699827 [debug] [MainThread]: On master: Close
04:38:46.699999 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
04:38:46.700120 [info ] [MainThread]: 
04:38:46.701661 [debug] [Thread-1  ]: Began running node model.demo_autopie.demo_data_prep
04:38:46.701962 [debug] [Thread-1  ]: Acquiring new postgres connection "model.demo_autopie.demo_data_prep"
04:38:46.702059 [debug] [Thread-1  ]: Began compiling node model.demo_autopie.demo_data_prep
04:38:46.702140 [debug] [Thread-1  ]: Compiling model.demo_autopie.demo_data_prep
04:38:46.702922 [debug] [Thread-1  ]: Writing injected SQL for node "model.demo_autopie.demo_data_prep"
04:38:46.703343 [debug] [Thread-1  ]: finished collecting timing info
04:38:46.703430 [debug] [Thread-1  ]: Began executing node model.demo_autopie.demo_data_prep
04:38:46.703503 [debug] [Thread-1  ]: finished collecting timing info
04:38:46.703681 [debug] [Thread-1  ]: Finished running node model.demo_autopie.demo_data_prep
04:38:46.703777 [debug] [Thread-1  ]: Began running node model.demo_autopie.prepared_fact_calls
04:38:46.704065 [debug] [Thread-1  ]: Acquiring new postgres connection "model.demo_autopie.prepared_fact_calls"
04:38:46.704233 [debug] [Thread-1  ]: Began compiling node model.demo_autopie.prepared_fact_calls
04:38:46.704308 [debug] [Thread-1  ]: Compiling model.demo_autopie.prepared_fact_calls
04:38:46.705006 [debug] [Thread-1  ]: Writing injected SQL for node "model.demo_autopie.prepared_fact_calls"
04:38:46.705354 [debug] [Thread-1  ]: finished collecting timing info
04:38:46.705426 [debug] [Thread-1  ]: Began executing node model.demo_autopie.prepared_fact_calls
04:38:46.705508 [debug] [Thread-1  ]: finished collecting timing info
04:38:46.705680 [debug] [Thread-1  ]: Finished running node model.demo_autopie.prepared_fact_calls
04:38:46.705763 [debug] [Thread-1  ]: Began running node model.demo_autopie.prepared_fact_outcomes
04:38:46.705901 [debug] [Thread-1  ]: Acquiring new postgres connection "model.demo_autopie.prepared_fact_outcomes"
04:38:46.706022 [debug] [Thread-1  ]: Began compiling node model.demo_autopie.prepared_fact_outcomes
04:38:46.706145 [debug] [Thread-1  ]: Compiling model.demo_autopie.prepared_fact_outcomes
04:38:46.707010 [debug] [Thread-1  ]: Writing injected SQL for node "model.demo_autopie.prepared_fact_outcomes"
04:38:46.707276 [debug] [Thread-1  ]: finished collecting timing info
04:38:46.707351 [debug] [Thread-1  ]: Began executing node model.demo_autopie.prepared_fact_outcomes
04:38:46.707414 [debug] [Thread-1  ]: finished collecting timing info
04:38:46.707585 [debug] [Thread-1  ]: Finished running node model.demo_autopie.prepared_fact_outcomes
04:38:46.707674 [debug] [Thread-1  ]: Began running node model.demo_autopie.prepared_facts
04:38:46.707836 [debug] [Thread-1  ]: Acquiring new postgres connection "model.demo_autopie.prepared_facts"
04:38:46.707902 [debug] [Thread-1  ]: Began compiling node model.demo_autopie.prepared_facts
04:38:46.707961 [debug] [Thread-1  ]: Compiling model.demo_autopie.prepared_facts
04:38:46.708643 [debug] [Thread-1  ]: Writing injected SQL for node "model.demo_autopie.prepared_facts"
04:38:46.708889 [debug] [Thread-1  ]: finished collecting timing info
04:38:46.708953 [debug] [Thread-1  ]: Began executing node model.demo_autopie.prepared_facts
04:38:46.709013 [debug] [Thread-1  ]: finished collecting timing info
04:38:46.709172 [debug] [Thread-1  ]: Finished running node model.demo_autopie.prepared_facts
04:38:46.709564 [debug] [MainThread]: Connection 'master' was properly closed.
04:38:46.709638 [debug] [MainThread]: Connection 'model.demo_autopie.prepared_facts' was properly closed.
04:38:46.712018 [info ] [MainThread]: Done.


============================== 2022-02-20 04:40:14.454742 | f37c66e0-b81e-4149-b601-ab02d104ca04 ==============================
04:40:14.454742 [info ] [MainThread]: Running with dbt=1.0.1
04:40:14.455067 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/hassanzaheer/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, parse_only=False, threads=None, select=None, exclude=None, selector_name=None, state=None, full_refresh=False, defer=None, cls=<class 'dbt.task.compile.CompileTask'>, which='compile', rpc_method='compile')
04:40:14.455174 [debug] [MainThread]: Tracking: do not track
04:40:14.472192 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
04:40:14.478101 [debug] [MainThread]: Parsing macros/compile_recipe_collect_fact.sql
04:40:14.507746 [debug] [MainThread]: Parsing macros/core/run_recipe.sql
04:40:14.509243 [debug] [MainThread]: Parsing macros/core/run_directory.sql
04:40:14.510651 [debug] [MainThread]: Parsing macros/catalog.sql
04:40:14.511807 [debug] [MainThread]: Parsing macros/relations.sql
04:40:14.512505 [debug] [MainThread]: Parsing macros/adapters.sql
04:40:14.523133 [debug] [MainThread]: Parsing macros/materializations/snapshot_merge.sql
04:40:14.523909 [debug] [MainThread]: Parsing macros/materializations/hooks.sql
04:40:14.525633 [debug] [MainThread]: Parsing macros/materializations/configs.sql
04:40:14.526649 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot_merge.sql
04:40:14.527406 [debug] [MainThread]: Parsing macros/materializations/snapshots/strategies.sql
04:40:14.535182 [debug] [MainThread]: Parsing macros/materializations/snapshots/helpers.sql
04:40:14.540703 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot.sql
04:40:14.546459 [debug] [MainThread]: Parsing macros/materializations/tests/test.sql
04:40:14.548506 [debug] [MainThread]: Parsing macros/materializations/tests/helpers.sql
04:40:14.549294 [debug] [MainThread]: Parsing macros/materializations/tests/where_subquery.sql
04:40:14.550086 [debug] [MainThread]: Parsing macros/materializations/models/incremental/column_helpers.sql
04:40:14.552078 [debug] [MainThread]: Parsing macros/materializations/models/incremental/merge.sql
04:40:14.557418 [debug] [MainThread]: Parsing macros/materializations/models/incremental/is_incremental.sql
04:40:14.558090 [debug] [MainThread]: Parsing macros/materializations/models/incremental/incremental.sql
04:40:14.562939 [debug] [MainThread]: Parsing macros/materializations/models/incremental/on_schema_change.sql
04:40:14.570586 [debug] [MainThread]: Parsing macros/materializations/models/table/table.sql
04:40:14.574216 [debug] [MainThread]: Parsing macros/materializations/models/table/create_table_as.sql
04:40:14.575479 [debug] [MainThread]: Parsing macros/materializations/models/view/view.sql
04:40:14.579169 [debug] [MainThread]: Parsing macros/materializations/models/view/helpers.sql
04:40:14.579768 [debug] [MainThread]: Parsing macros/materializations/models/view/create_or_replace_view.sql
04:40:14.581058 [debug] [MainThread]: Parsing macros/materializations/models/view/create_view_as.sql
04:40:14.582117 [debug] [MainThread]: Parsing macros/materializations/seeds/seed.sql
04:40:14.585081 [debug] [MainThread]: Parsing macros/materializations/seeds/helpers.sql
04:40:14.593479 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_alias.sql
04:40:14.594175 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_schema.sql
04:40:14.595302 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_database.sql
04:40:14.596002 [debug] [MainThread]: Parsing macros/generic_test_sql/relationships.sql
04:40:14.596411 [debug] [MainThread]: Parsing macros/generic_test_sql/not_null.sql
04:40:14.596644 [debug] [MainThread]: Parsing macros/generic_test_sql/unique.sql
04:40:14.596952 [debug] [MainThread]: Parsing macros/generic_test_sql/accepted_values.sql
04:40:14.597553 [debug] [MainThread]: Parsing macros/etc/statement.sql
04:40:14.599554 [debug] [MainThread]: Parsing macros/etc/datetime.sql
04:40:14.603493 [debug] [MainThread]: Parsing macros/adapters/schema.sql
04:40:14.604455 [debug] [MainThread]: Parsing macros/adapters/indexes.sql
04:40:14.605645 [debug] [MainThread]: Parsing macros/adapters/relation.sql
04:40:14.610043 [debug] [MainThread]: Parsing macros/adapters/freshness.sql
04:40:14.611348 [debug] [MainThread]: Parsing macros/adapters/persist_docs.sql
04:40:14.613323 [debug] [MainThread]: Parsing macros/adapters/metadata.sql
04:40:14.616645 [debug] [MainThread]: Parsing macros/adapters/columns.sql
04:40:14.621201 [debug] [MainThread]: Parsing tests/generic/builtin.sql
04:40:14.709503 [debug] [MainThread]: 1699: static parser successfully parsed demo_ebp_flow/demo_data_prep.sql
04:40:14.714708 [debug] [MainThread]: 1699: static parser successfully parsed demo_ebp_flow/prepared_scripts/prepared_fact_outcomes.sql
04:40:14.715593 [debug] [MainThread]: 1699: static parser successfully parsed demo_ebp_flow/prepared_scripts/prepared_facts.sql
04:40:14.716483 [debug] [MainThread]: 1699: static parser successfully parsed demo_ebp_flow/prepared_scripts/prepared_fact_calls.sql
04:40:14.729425 [info ] [MainThread]: Found 4 models, 0 tests, 0 snapshots, 0 analyses, 168 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
04:40:14.730070 [info ] [MainThread]: 
04:40:14.730291 [debug] [MainThread]: Acquiring new postgres connection "master"
04:40:14.730684 [debug] [ThreadPool]: Acquiring new postgres connection "list_postgres_testsatmap"
04:40:14.735533 [debug] [ThreadPool]: Using postgres connection "list_postgres_testsatmap"
04:40:14.735715 [debug] [ThreadPool]: On list_postgres_testsatmap: BEGIN
04:40:14.735787 [debug] [ThreadPool]: Opening a new connection, currently in state init
04:40:14.764947 [debug] [ThreadPool]: SQL status: BEGIN in 0.03 seconds
04:40:14.765118 [debug] [ThreadPool]: Using postgres connection "list_postgres_testsatmap"
04:40:14.765182 [debug] [ThreadPool]: On list_postgres_testsatmap: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "list_postgres_testsatmap"} */
select
      'postgres' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'testsatmap'
    union all
    select
      'postgres' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'testsatmap'
  
04:40:14.768422 [debug] [ThreadPool]: SQL status: SELECT 5 in 0.0 seconds
04:40:14.769380 [debug] [ThreadPool]: On list_postgres_testsatmap: ROLLBACK
04:40:14.769566 [debug] [ThreadPool]: On list_postgres_testsatmap: Close
04:40:14.771703 [debug] [MainThread]: Using postgres connection "master"
04:40:14.771809 [debug] [MainThread]: On master: BEGIN
04:40:14.771873 [debug] [MainThread]: Opening a new connection, currently in state init
04:40:14.775255 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
04:40:14.775349 [debug] [MainThread]: Using postgres connection "master"
04:40:14.775411 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
04:40:14.788564 [debug] [MainThread]: SQL status: SELECT 0 in 0.01 seconds
04:40:14.789244 [debug] [MainThread]: On master: ROLLBACK
04:40:14.789449 [debug] [MainThread]: On master: Close
04:40:14.789632 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
04:40:14.789753 [info ] [MainThread]: 
04:40:14.791278 [debug] [Thread-1  ]: Began running node model.demo_autopie.demo_data_prep
04:40:14.791565 [debug] [Thread-1  ]: Acquiring new postgres connection "model.demo_autopie.demo_data_prep"
04:40:14.791656 [debug] [Thread-1  ]: Began compiling node model.demo_autopie.demo_data_prep
04:40:14.791740 [debug] [Thread-1  ]: Compiling model.demo_autopie.demo_data_prep
04:40:14.792532 [debug] [Thread-1  ]: Writing injected SQL for node "model.demo_autopie.demo_data_prep"
04:40:14.792942 [debug] [Thread-1  ]: finished collecting timing info
04:40:14.793035 [debug] [Thread-1  ]: Began executing node model.demo_autopie.demo_data_prep
04:40:14.793115 [debug] [Thread-1  ]: finished collecting timing info
04:40:14.793286 [debug] [Thread-1  ]: Finished running node model.demo_autopie.demo_data_prep
04:40:14.793370 [debug] [Thread-1  ]: Began running node model.demo_autopie.prepared_fact_calls
04:40:14.793510 [debug] [Thread-1  ]: Acquiring new postgres connection "model.demo_autopie.prepared_fact_calls"
04:40:14.793584 [debug] [Thread-1  ]: Began compiling node model.demo_autopie.prepared_fact_calls
04:40:14.793663 [debug] [Thread-1  ]: Compiling model.demo_autopie.prepared_fact_calls
04:40:14.795009 [debug] [Thread-1  ]: Writing injected SQL for node "model.demo_autopie.prepared_fact_calls"
04:40:14.795395 [debug] [Thread-1  ]: finished collecting timing info
04:40:14.795476 [debug] [Thread-1  ]: Began executing node model.demo_autopie.prepared_fact_calls
04:40:14.795549 [debug] [Thread-1  ]: finished collecting timing info
04:40:14.795735 [debug] [Thread-1  ]: Finished running node model.demo_autopie.prepared_fact_calls
04:40:14.795825 [debug] [Thread-1  ]: Began running node model.demo_autopie.prepared_fact_outcomes
04:40:14.795990 [debug] [Thread-1  ]: Acquiring new postgres connection "model.demo_autopie.prepared_fact_outcomes"
04:40:14.796064 [debug] [Thread-1  ]: Began compiling node model.demo_autopie.prepared_fact_outcomes
04:40:14.796129 [debug] [Thread-1  ]: Compiling model.demo_autopie.prepared_fact_outcomes
04:40:14.796813 [debug] [Thread-1  ]: Writing injected SQL for node "model.demo_autopie.prepared_fact_outcomes"
04:40:14.797017 [debug] [Thread-1  ]: finished collecting timing info
04:40:14.797085 [debug] [Thread-1  ]: Began executing node model.demo_autopie.prepared_fact_outcomes
04:40:14.797148 [debug] [Thread-1  ]: finished collecting timing info
04:40:14.797284 [debug] [Thread-1  ]: Finished running node model.demo_autopie.prepared_fact_outcomes
04:40:14.797362 [debug] [Thread-1  ]: Began running node model.demo_autopie.prepared_facts
04:40:14.797506 [debug] [Thread-1  ]: Acquiring new postgres connection "model.demo_autopie.prepared_facts"
04:40:14.797566 [debug] [Thread-1  ]: Began compiling node model.demo_autopie.prepared_facts
04:40:14.797632 [debug] [Thread-1  ]: Compiling model.demo_autopie.prepared_facts
04:40:14.798327 [debug] [Thread-1  ]: Writing injected SQL for node "model.demo_autopie.prepared_facts"
04:40:14.798521 [debug] [Thread-1  ]: finished collecting timing info
04:40:14.798585 [debug] [Thread-1  ]: Began executing node model.demo_autopie.prepared_facts
04:40:14.798645 [debug] [Thread-1  ]: finished collecting timing info
04:40:14.798773 [debug] [Thread-1  ]: Finished running node model.demo_autopie.prepared_facts
04:40:14.799160 [debug] [MainThread]: Connection 'master' was properly closed.
04:40:14.799252 [debug] [MainThread]: Connection 'model.demo_autopie.prepared_facts' was properly closed.
04:40:14.801476 [info ] [MainThread]: Done.


============================== 2022-02-20 04:40:29.101638 | f1766b9f-be3a-40f3-b75d-abc49feb8843 ==============================
04:40:29.101638 [info ] [MainThread]: Running with dbt=1.0.1
04:40:29.101966 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/hassanzaheer/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, macro='run_directory', args='{}', defer=None, state=None, cls=<class 'dbt.task.run_operation.RunOperationTask'>, which='run-operation', rpc_method='run-operation')
04:40:29.102082 [debug] [MainThread]: Tracking: do not track
04:40:29.121906 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
04:40:29.122150 [debug] [MainThread]: Partial parsing: updated file: demo_autopie://models/demo_ebp_flow/prepared_scripts/prepared_facts.sql
04:40:29.127558 [debug] [MainThread]: 1699: static parser successfully parsed demo_ebp_flow/prepared_scripts/prepared_facts.sql
04:40:29.137959 [debug] [MainThread]: Acquiring new postgres connection "macro_run_directory"
04:40:29.138104 [debug] [MainThread]: Using postgres connection "macro_run_directory"
04:40:29.138167 [debug] [MainThread]: On macro_run_directory: BEGIN
04:40:29.138224 [debug] [MainThread]: Opening a new connection, currently in state init
04:40:29.142382 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
04:40:29.142491 [debug] [MainThread]: On macro_run_directory: COMMIT
04:40:29.142553 [debug] [MainThread]: Using postgres connection "macro_run_directory"
04:40:29.142606 [debug] [MainThread]: On macro_run_directory: COMMIT
04:40:29.142755 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
04:40:29.148925 [debug] [MainThread]: Using postgres connection "macro_run_directory"
04:40:29.149021 [debug] [MainThread]: On macro_run_directory: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_directory"} */

    
with read_directory as (select * from (select * from pg_ls_dir('./autopie_workdir') pg) iq where pg like '%.json'),
file_content as (select pg file_name, cast(pg_read_file(E'./autopie_workdir/'||pg, 0, 100000000) as json) json_content from read_directory)
select file_name, 
       json_content->>'recipe_type' recipe_type,
       json_content->>'ingredients' ingredients,
       json_content->>'target_fact' target_fact,
       json_content->>'source_fact' source_fact
  from file_content
order by file_name;

  
04:40:29.153066 [debug] [MainThread]: SQL status: SELECT 2 in 0.0 seconds
04:40:29.153787 [info ] [MainThread]: 
--PARAM ROW ---> <agate.Row: ('collect_fact_calls.json', 'collect_fact', '{\n        "expression_extract": {  \n            "source_raw": "testsatmap.calltable",\n            "expression_list": [\n                {"expression": "call_id", "alias": "call_id"},\n                {"expression": "to_timestamp(call_start_epoch)", "alias": "time_call_start"},\n                {"expression": "to_timestamp(call_start_epoch + call_duration)", "alias": "time_call_end"},\n                {"expression": "call_duration", "alias": "num_duration_seconds"},\n                {"expression": "trim(customer_id)",  "alias": "customer_id"},\n                {"expression": "lower(trim(agent_id))",  "alias": "agent_id"}\n            ]\n        },\n        "expression_extract_outer": {  \n            "expression_list": [\n                {"expression": "round(num_duration_seconds/60,2)", "alias": "num_duration_minutes"}\n            ]\n        },\n        "filter_conjunctions": [\n            "agent_id is not null",\n            "customer_id is not null",\n            "num_duration_seconds > 10"\n        ],\n        "incremental_update_on": "time_call_start",\n        "deduplication": {\n            "grouping_key": "call_id",\n            "preference": "arbitrary"\n        }\n    }', '{\n        "id": "calls", \n        "entity_and_dims": "call_id",\n        "date":"time_call_end"\n    }', None)>
04:40:29.153974 [info ] [MainThread]: 
--RUNNING FILE ---> collect_fact_calls.json
04:40:29.154076 [info ] [MainThread]: 
--TARGET FACT ---> {
        "id": "calls", 
        "entity_and_dims": "call_id",
        "date":"time_call_end"
    }
04:40:29.191424 [debug] [MainThread]: Using postgres connection "macro_run_directory"
04:40:29.191585 [debug] [MainThread]: On macro_run_directory: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_directory"} */

    
select 
    column_name||'::'||
        case when replace(udt_name, '_','') = 'bit' then 'int'
            when replace(udt_name, '_','') like 'int8%' then 'bigint'
            when replace(udt_name, '_','') like 'int4%' then 'int'
            when replace(udt_name, '_','') like 'int%' then 'smallint'
            when replace(udt_name, '_','') like 'bool%' then 'int'
            when replace(udt_name, '_','') like 'float%' then 'numeric'
            when replace(udt_name, '_','') like 'float%' then 'numeric'
            when replace(udt_name, '_','') like 'byte%' then 'text'
            when replace(udt_name, '_','') like 'varchar%' then 'text'
            when replace(udt_name, '_','') like 'timestamp%' then 'timestamp'
            else replace(udt_name, '_','') end ||
       ' as "'||column_name||'"' select_text
from information_schema.columns 
where table_schema||'.'||table_name = 'testsatmap.calltable'
order by ordinal_position
;
  
04:40:29.206273 [debug] [MainThread]: SQL status: SELECT 5 in 0.01 seconds
04:40:29.207125 [debug] [MainThread]: Using postgres connection "macro_run_directory"
04:40:29.207223 [debug] [MainThread]: On macro_run_directory: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_directory"} */

    
create or replace view autopie_ebpdemo.tmp_staging_view_source_extract_0 as
select
    call_id::text as "call_id", 
    call_start_epoch::bigint as "call_start_epoch", 
    call_duration::int as "call_duration", 
    customer_id::text as "customer_id", 
    agent_id::text as "agent_id" 
from testsatmap.calltable
;
  
04:40:29.209589 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
04:40:29.210279 [debug] [MainThread]: Using postgres connection "macro_run_directory"
04:40:29.210360 [debug] [MainThread]: On macro_run_directory: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_directory"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type cascade;
  
04:40:29.210649 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
04:40:29.211203 [debug] [MainThread]: Using postgres connection "macro_run_directory"
04:40:29.211277 [debug] [MainThread]: On macro_run_directory: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_directory"} */

    create or replace view autopie_ebpdemo.tmp_exp_type as select call_id as exp from autopie_ebpdemo.tmp_staging_view_source_extract_0 limit 1;
  
04:40:29.216347 [debug] [MainThread]: SQL status: CREATE VIEW in 0.01 seconds
04:40:29.216914 [debug] [MainThread]: Using postgres connection "macro_run_directory"
04:40:29.216986 [debug] [MainThread]: On macro_run_directory: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_directory"} */

    select replace(udt_name, '_','') as dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type' and column_name = 'exp';
  
04:40:29.227016 [debug] [MainThread]: SQL status: SELECT 1 in 0.01 seconds
04:40:29.227607 [debug] [MainThread]: Using postgres connection "macro_run_directory"
04:40:29.227684 [debug] [MainThread]: On macro_run_directory: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_directory"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type cascade;
  
04:40:29.228715 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
04:40:29.229252 [debug] [MainThread]: Using postgres connection "macro_run_directory"
04:40:29.229321 [debug] [MainThread]: On macro_run_directory: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_directory"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type cascade;
  
04:40:29.231027 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
04:40:29.231569 [debug] [MainThread]: Using postgres connection "macro_run_directory"
04:40:29.231639 [debug] [MainThread]: On macro_run_directory: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_directory"} */

    create or replace view autopie_ebpdemo.tmp_exp_type as select to_timestamp(call_start_epoch) as exp from autopie_ebpdemo.tmp_staging_view_source_extract_0 limit 1;
  
04:40:29.232503 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
04:40:29.233043 [debug] [MainThread]: Using postgres connection "macro_run_directory"
04:40:29.233120 [debug] [MainThread]: On macro_run_directory: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_directory"} */

    select replace(udt_name, '_','') as dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type' and column_name = 'exp';
  
04:40:29.235322 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
04:40:29.236077 [debug] [MainThread]: Using postgres connection "macro_run_directory"
04:40:29.236167 [debug] [MainThread]: On macro_run_directory: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_directory"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type cascade;
  
04:40:29.236722 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
04:40:29.237483 [debug] [MainThread]: Using postgres connection "macro_run_directory"
04:40:29.237566 [debug] [MainThread]: On macro_run_directory: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_directory"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type cascade;
  
04:40:29.237769 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
04:40:29.238342 [debug] [MainThread]: Using postgres connection "macro_run_directory"
04:40:29.238416 [debug] [MainThread]: On macro_run_directory: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_directory"} */

    create or replace view autopie_ebpdemo.tmp_exp_type as select to_timestamp(call_start_epoch + call_duration) as exp from autopie_ebpdemo.tmp_staging_view_source_extract_0 limit 1;
  
04:40:29.239200 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
04:40:29.239935 [debug] [MainThread]: Using postgres connection "macro_run_directory"
04:40:29.240032 [debug] [MainThread]: On macro_run_directory: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_directory"} */

    select replace(udt_name, '_','') as dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type' and column_name = 'exp';
  
04:40:29.242697 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
04:40:29.243372 [debug] [MainThread]: Using postgres connection "macro_run_directory"
04:40:29.243453 [debug] [MainThread]: On macro_run_directory: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_directory"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type cascade;
  
04:40:29.244083 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
04:40:29.244724 [debug] [MainThread]: Using postgres connection "macro_run_directory"
04:40:29.244805 [debug] [MainThread]: On macro_run_directory: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_directory"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type cascade;
  
04:40:29.245004 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
04:40:29.245583 [debug] [MainThread]: Using postgres connection "macro_run_directory"
04:40:29.245656 [debug] [MainThread]: On macro_run_directory: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_directory"} */

    create or replace view autopie_ebpdemo.tmp_exp_type as select call_duration as exp from autopie_ebpdemo.tmp_staging_view_source_extract_0 limit 1;
  
04:40:29.246730 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
04:40:29.247347 [debug] [MainThread]: Using postgres connection "macro_run_directory"
04:40:29.247431 [debug] [MainThread]: On macro_run_directory: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_directory"} */

    select replace(udt_name, '_','') as dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type' and column_name = 'exp';
  
04:40:29.250018 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
04:40:29.250616 [debug] [MainThread]: Using postgres connection "macro_run_directory"
04:40:29.250692 [debug] [MainThread]: On macro_run_directory: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_directory"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type cascade;
  
04:40:29.251288 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
04:40:29.251842 [debug] [MainThread]: Using postgres connection "macro_run_directory"
04:40:29.251912 [debug] [MainThread]: On macro_run_directory: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_directory"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type cascade;
  
04:40:29.252086 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
04:40:29.252624 [debug] [MainThread]: Using postgres connection "macro_run_directory"
04:40:29.252695 [debug] [MainThread]: On macro_run_directory: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_directory"} */

    create or replace view autopie_ebpdemo.tmp_exp_type as select trim(customer_id) as exp from autopie_ebpdemo.tmp_staging_view_source_extract_0 limit 1;
  
04:40:29.253433 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
04:40:29.253988 [debug] [MainThread]: Using postgres connection "macro_run_directory"
04:40:29.254059 [debug] [MainThread]: On macro_run_directory: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_directory"} */

    select replace(udt_name, '_','') as dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type' and column_name = 'exp';
  
04:40:29.256577 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
04:40:29.257423 [debug] [MainThread]: Using postgres connection "macro_run_directory"
04:40:29.257514 [debug] [MainThread]: On macro_run_directory: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_directory"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type cascade;
  
04:40:29.258099 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
04:40:29.258718 [debug] [MainThread]: Using postgres connection "macro_run_directory"
04:40:29.258793 [debug] [MainThread]: On macro_run_directory: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_directory"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type cascade;
  
04:40:29.259027 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
04:40:29.259787 [debug] [MainThread]: Using postgres connection "macro_run_directory"
04:40:29.259878 [debug] [MainThread]: On macro_run_directory: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_directory"} */

    create or replace view autopie_ebpdemo.tmp_exp_type as select lower(trim(agent_id)) as exp from autopie_ebpdemo.tmp_staging_view_source_extract_0 limit 1;
  
04:40:29.260726 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
04:40:29.261402 [debug] [MainThread]: Using postgres connection "macro_run_directory"
04:40:29.261485 [debug] [MainThread]: On macro_run_directory: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_directory"} */

    select replace(udt_name, '_','') as dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type' and column_name = 'exp';
  
04:40:29.265094 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
04:40:29.265901 [debug] [MainThread]: Using postgres connection "macro_run_directory"
04:40:29.266001 [debug] [MainThread]: On macro_run_directory: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_directory"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type cascade;
  
04:40:29.266727 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
04:40:29.267500 [debug] [MainThread]: Using postgres connection "macro_run_directory"
04:40:29.267596 [debug] [MainThread]: On macro_run_directory: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_directory"} */

    
create or replace view autopie_ebpdemo.tmp_staging_view_expression_extract_1 as
select
    (call_id)::text as call_id, 
    (to_timestamp(call_start_epoch))::timestamptz as time_call_start, 
    (to_timestamp(call_start_epoch + call_duration))::timestamptz as time_call_end, 
    (call_duration)::int4 as num_duration_seconds, 
    (trim(customer_id))::text as customer_id, 
    (lower(trim(agent_id)))::text as agent_id 
from autopie_ebpdemo.tmp_staging_view_source_extract_0
;
  
04:40:29.269039 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
04:40:29.269781 [debug] [MainThread]: Using postgres connection "macro_run_directory"
04:40:29.269869 [debug] [MainThread]: On macro_run_directory: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_directory"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type cascade;
  
04:40:29.270052 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
04:40:29.270736 [debug] [MainThread]: Using postgres connection "macro_run_directory"
04:40:29.270823 [debug] [MainThread]: On macro_run_directory: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_directory"} */

    create or replace view autopie_ebpdemo.tmp_exp_type as select round(num_duration_seconds/60,2) as exp from autopie_ebpdemo.tmp_staging_view_expression_extract_1 limit 1;
  
04:40:29.272140 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
04:40:29.272732 [debug] [MainThread]: Using postgres connection "macro_run_directory"
04:40:29.272807 [debug] [MainThread]: On macro_run_directory: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_directory"} */

    select replace(udt_name, '_','') as dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type' and column_name = 'exp';
  
04:40:29.274973 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
04:40:29.275653 [debug] [MainThread]: Using postgres connection "macro_run_directory"
04:40:29.275735 [debug] [MainThread]: On macro_run_directory: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_directory"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type cascade;
  
04:40:29.276370 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
04:40:29.278487 [debug] [MainThread]: Using postgres connection "macro_run_directory"
04:40:29.278589 [debug] [MainThread]: On macro_run_directory: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_directory"} */

    
drop view if exists autopie_ebpdemo.tmp_staging_view_source_extract_0 cascade;
drop view if exists autopie_ebpdemo.tmp_staging_view_expression_extract_1 cascade;
  
04:40:29.279469 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
04:40:29.280096 [info ] [MainThread]: 





create or replace view autopie_ebpdemo.tmp_staging_view_source_extract_0 as
select
    call_id::text as "call_id", 
    call_start_epoch::bigint as "call_start_epoch", 
    call_duration::int as "call_duration", 
    customer_id::text as "customer_id", 
    agent_id::text as "agent_id" 
from testsatmap.calltable
;


create or replace view autopie_ebpdemo.tmp_staging_view_expression_extract_1 as
select
    (call_id)::text as call_id, 
    (to_timestamp(call_start_epoch))::timestamptz as time_call_start, 
    (to_timestamp(call_start_epoch + call_duration))::timestamptz as time_call_end, 
    (call_duration)::int4 as num_duration_seconds, 
    (trim(customer_id))::text as customer_id, 
    (lower(trim(agent_id)))::text as agent_id 
from autopie_ebpdemo.tmp_staging_view_source_extract_0
;

drop table if exists autopie_ebpdemo.tmp_staging_fact_calls;
create table autopie_ebpdemo.tmp_staging_fact_calls as
(
    with expression_extract_1 as
    (
        select * from autopie_ebpdemo.tmp_staging_view_expression_extract_1
    ),
    expression_extract_2 as
    (
        select  t.*,
                (round(num_duration_seconds/60,2))::numeric as num_duration_minutes
        from expression_extract_1 t
    ),
    filter_3 as
    (
        select /* filtering irrelevant records out */ *
        from expression_extract_2
        where 1=1
        and agent_id is not null
        and customer_id is not null
        and num_duration_seconds > 10
    ),
    incremental_extract_4 as
    (
        select /* retrieving incremental data - by date range only */ *
        from filter_3
        where time_call_start >= to_date('1900-01-01', 'YYYY-MM-DD')
          and time_call_start  < to_date('2100-01-01', 'YYYY-MM-DD')
    ),
    deduplication_5 as
    (
        select /* deduplicate by strategy */
            call_id
            , max(time_call_start) as time_call_start
            , max(time_call_end) as time_call_end
            , max(num_duration_seconds) as num_duration_seconds
            , max(customer_id) as customer_id
            , max(agent_id) as agent_id
            , max(num_duration_minutes) as num_duration_minutes
        from incremental_extract_4
        group by call_id 
    ),
    coarsening_6 as
    (
        select * from deduplication_5
    )
    select * from coarsening_6
)
;

drop view if exists autopie_ebpdemo.tmp_staging_view_source_extract_0 cascade;
drop view if exists autopie_ebpdemo.tmp_staging_view_expression_extract_1 cascade;

-- check if not exists already, this should run once
do $$                  
begin
if not exists
( 
    select 1 from information_schema.tables 
    where table_schema||'.'|| table_name = 'autopie_ebpdemo.obj_fact_calls'
)
then
    create table autopie_ebpdemo.obj_fact_calls as (select * from autopie_ebpdemo.tmp_staging_fact_calls where 1=0);
    alter  table autopie_ebpdemo.obj_fact_calls add column row_id bigserial not null;
    alter  table autopie_ebpdemo.obj_fact_calls add primary key (call_id, time_call_end);
    --
    create index ixrid_obj_fact_calls on autopie_ebpdemo.obj_fact_calls(row_id);
end if;
end
$$;

-- upsert staging additions into the permanent fact object
delete from autopie_ebpdemo.obj_fact_calls where (call_id, time_call_end) in (select call_id, time_call_end from autopie_ebpdemo.tmp_staging_fact_calls);
insert into autopie_ebpdemo.obj_fact_calls select * from autopie_ebpdemo.tmp_staging_fact_calls;
drop table autopie_ebpdemo.tmp_staging_fact_calls;


04:40:29.280446 [info ] [MainThread]: 
--PARAM ROW ---> <agate.Row: ('collect_fact_outcomes.json', 'collect_fact', '{\n        "expression_extract": {  \n            "source_raw": "testsatmap.outcomes",\n            "expression_list": [\n                {"expression": "outcome_date", "alias": "date_outcome"},\n                {"expression": "trim(customer_id)", "alias": "customer_id"},             \n                {"expression": "outcome_code::numeric", "alias": "num_outcome_amount"}\n            ]\n        },\n        "filter_conjunctions": [\n            "num_outcome_amount > 0",\n            "customer_id is not null"\n        ],\n        "incremental_update_on": "date_outcome",\n        "deduplication": {\n            "grouping_key": "customer_id, date_outcome, num_outcome_amount",\n            "preference": "arbitrary"\n        },\n        "coarsening": {\n            "entity_and_dims": "customer_id",\n            "date_expression":"date_outcome",\n            "aggregations": [\n                {"expression": "sum(num_outcome_amount)", "alias": "sum_outcome_amount"}\n            ]\n        }\n    }', '{\n        "id": "outcomes", \n        "entity_and_dims": "customer_id",\n        "date":"date_outcome"\n    }', None)>
04:40:29.280654 [info ] [MainThread]: 
--RUNNING FILE ---> collect_fact_outcomes.json
04:40:29.280783 [info ] [MainThread]: 
--TARGET FACT ---> {
        "id": "outcomes", 
        "entity_and_dims": "customer_id",
        "date":"date_outcome"
    }
04:40:29.281114 [debug] [MainThread]: Using postgres connection "macro_run_directory"
04:40:29.281191 [debug] [MainThread]: On macro_run_directory: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_directory"} */

    
select 
    column_name||'::'||
        case when replace(udt_name, '_','') = 'bit' then 'int'
            when replace(udt_name, '_','') like 'int8%' then 'bigint'
            when replace(udt_name, '_','') like 'int4%' then 'int'
            when replace(udt_name, '_','') like 'int%' then 'smallint'
            when replace(udt_name, '_','') like 'bool%' then 'int'
            when replace(udt_name, '_','') like 'float%' then 'numeric'
            when replace(udt_name, '_','') like 'float%' then 'numeric'
            when replace(udt_name, '_','') like 'byte%' then 'text'
            when replace(udt_name, '_','') like 'varchar%' then 'text'
            when replace(udt_name, '_','') like 'timestamp%' then 'timestamp'
            else replace(udt_name, '_','') end ||
       ' as "'||column_name||'"' select_text
from information_schema.columns 
where table_schema||'.'||table_name = 'testsatmap.outcomes'
order by ordinal_position
;
  
04:40:29.283954 [debug] [MainThread]: SQL status: SELECT 3 in 0.0 seconds
04:40:29.284778 [debug] [MainThread]: Using postgres connection "macro_run_directory"
04:40:29.284883 [debug] [MainThread]: On macro_run_directory: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_directory"} */

    
create or replace view autopie_ebpdemo.tmp_staging_view_source_extract_0 as
select
    outcome_date::date as "outcome_date", 
    customer_id::text as "customer_id", 
    outcome_code::text as "outcome_code" 
from testsatmap.outcomes
;
  
04:40:29.285980 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
04:40:29.286702 [debug] [MainThread]: Using postgres connection "macro_run_directory"
04:40:29.286788 [debug] [MainThread]: On macro_run_directory: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_directory"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type cascade;
  
04:40:29.287226 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
04:40:29.287964 [debug] [MainThread]: Using postgres connection "macro_run_directory"
04:40:29.288059 [debug] [MainThread]: On macro_run_directory: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_directory"} */

    create or replace view autopie_ebpdemo.tmp_exp_type as select outcome_date as exp from autopie_ebpdemo.tmp_staging_view_source_extract_0 limit 1;
  
04:40:29.288849 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
04:40:29.289466 [debug] [MainThread]: Using postgres connection "macro_run_directory"
04:40:29.289546 [debug] [MainThread]: On macro_run_directory: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_directory"} */

    select replace(udt_name, '_','') as dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type' and column_name = 'exp';
  
04:40:29.292691 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
04:40:29.293278 [debug] [MainThread]: Using postgres connection "macro_run_directory"
04:40:29.293348 [debug] [MainThread]: On macro_run_directory: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_directory"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type cascade;
  
04:40:29.294195 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
04:40:29.294728 [debug] [MainThread]: Using postgres connection "macro_run_directory"
04:40:29.294799 [debug] [MainThread]: On macro_run_directory: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_directory"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type cascade;
  
04:40:29.295024 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
04:40:29.295560 [debug] [MainThread]: Using postgres connection "macro_run_directory"
04:40:29.295629 [debug] [MainThread]: On macro_run_directory: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_directory"} */

    create or replace view autopie_ebpdemo.tmp_exp_type as select trim(customer_id) as exp from autopie_ebpdemo.tmp_staging_view_source_extract_0 limit 1;
  
04:40:29.297918 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
04:40:29.298599 [debug] [MainThread]: Using postgres connection "macro_run_directory"
04:40:29.298668 [debug] [MainThread]: On macro_run_directory: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_directory"} */

    select replace(udt_name, '_','') as dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type' and column_name = 'exp';
  
04:40:29.304216 [debug] [MainThread]: SQL status: SELECT 1 in 0.01 seconds
04:40:29.304748 [debug] [MainThread]: Using postgres connection "macro_run_directory"
04:40:29.304826 [debug] [MainThread]: On macro_run_directory: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_directory"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type cascade;
  
04:40:29.305594 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
04:40:29.306089 [debug] [MainThread]: Using postgres connection "macro_run_directory"
04:40:29.306153 [debug] [MainThread]: On macro_run_directory: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_directory"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type cascade;
  
04:40:29.306435 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
04:40:29.306894 [debug] [MainThread]: Using postgres connection "macro_run_directory"
04:40:29.306954 [debug] [MainThread]: On macro_run_directory: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_directory"} */

    create or replace view autopie_ebpdemo.tmp_exp_type as select outcome_code::numeric as exp from autopie_ebpdemo.tmp_staging_view_source_extract_0 limit 1;
  
04:40:29.307843 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
04:40:29.308304 [debug] [MainThread]: Using postgres connection "macro_run_directory"
04:40:29.308363 [debug] [MainThread]: On macro_run_directory: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_directory"} */

    select replace(udt_name, '_','') as dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type' and column_name = 'exp';
  
04:40:29.312176 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
04:40:29.312681 [debug] [MainThread]: Using postgres connection "macro_run_directory"
04:40:29.312745 [debug] [MainThread]: On macro_run_directory: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_directory"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type cascade;
  
04:40:29.314033 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
04:40:29.314499 [debug] [MainThread]: Using postgres connection "macro_run_directory"
04:40:29.314556 [debug] [MainThread]: On macro_run_directory: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_directory"} */

    
create or replace view autopie_ebpdemo.tmp_staging_view_expression_extract_1 as
select
    (outcome_date)::date as date_outcome, 
    (trim(customer_id))::text as customer_id, 
    (outcome_code::numeric)::numeric as num_outcome_amount 
from autopie_ebpdemo.tmp_staging_view_source_extract_0
;
  
04:40:29.315620 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
04:40:29.316341 [debug] [MainThread]: Using postgres connection "macro_run_directory"
04:40:29.316400 [debug] [MainThread]: On macro_run_directory: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_directory"} */

    
drop view if exists autopie_ebpdemo.tmp_staging_view_source_extract_0 cascade;
drop view if exists autopie_ebpdemo.tmp_staging_view_expression_extract_1 cascade;
  
04:40:29.317241 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
04:40:29.317736 [info ] [MainThread]: 





create or replace view autopie_ebpdemo.tmp_staging_view_source_extract_0 as
select
    outcome_date::date as "outcome_date", 
    customer_id::text as "customer_id", 
    outcome_code::text as "outcome_code" 
from testsatmap.outcomes
;


create or replace view autopie_ebpdemo.tmp_staging_view_expression_extract_1 as
select
    (outcome_date)::date as date_outcome, 
    (trim(customer_id))::text as customer_id, 
    (outcome_code::numeric)::numeric as num_outcome_amount 
from autopie_ebpdemo.tmp_staging_view_source_extract_0
;

drop table if exists autopie_ebpdemo.tmp_staging_fact_outcomes;
create table autopie_ebpdemo.tmp_staging_fact_outcomes as
(
    with expression_extract_1 as
    (
        select * from autopie_ebpdemo.tmp_staging_view_expression_extract_1
    ),
    expression_extract_2 as
    (
        select * from expression_extract_1
    ),
    filter_3 as
    (
        select /* filtering irrelevant records out */ *
        from expression_extract_2
        where 1=1
        and num_outcome_amount > 0
        and customer_id is not null
    ),
    incremental_extract_4 as
    (
        select /* retrieving incremental data - by date range only */ *
        from filter_3
        where date_outcome >= to_date('1900-01-01', 'YYYY-MM-DD')
          and date_outcome  < to_date('2100-01-01', 'YYYY-MM-DD')
    ),
    deduplication_5 as
    (
        select /* deduplicate by strategy */
            customer_id, date_outcome, num_outcome_amount
        from incremental_extract_4
        group by customer_id, date_outcome, num_outcome_amount 
    ),
    coarsening_6 as
    (
        select /* flatten all dimensions, fit into EAVT format */
            customer_id
            , date_outcome
            
            , sum(num_outcome_amount) as sum_outcome_amount
            from deduplication_5
        group by customer_id, date_outcome
    )
    select * from coarsening_6
)
;

drop view if exists autopie_ebpdemo.tmp_staging_view_source_extract_0 cascade;
drop view if exists autopie_ebpdemo.tmp_staging_view_expression_extract_1 cascade;

-- check if not exists already, this should run once
do $$                  
begin
if not exists
( 
    select 1 from information_schema.tables 
    where table_schema||'.'|| table_name = 'autopie_ebpdemo.obj_fact_outcomes'
)
then
    create table autopie_ebpdemo.obj_fact_outcomes as (select * from autopie_ebpdemo.tmp_staging_fact_outcomes where 1=0);
    alter  table autopie_ebpdemo.obj_fact_outcomes add column row_id bigserial not null;
    alter  table autopie_ebpdemo.obj_fact_outcomes add primary key (customer_id, date_outcome);
    --
    create index ixrid_obj_fact_outcomes on autopie_ebpdemo.obj_fact_outcomes(row_id);
end if;
end
$$;

-- upsert staging additions into the permanent fact object
delete from autopie_ebpdemo.obj_fact_outcomes where (customer_id, date_outcome) in (select customer_id, date_outcome from autopie_ebpdemo.tmp_staging_fact_outcomes);
insert into autopie_ebpdemo.obj_fact_outcomes select * from autopie_ebpdemo.tmp_staging_fact_outcomes;
drop table autopie_ebpdemo.tmp_staging_fact_outcomes;


04:40:29.318020 [debug] [MainThread]: On macro_run_directory: Close
04:40:29.318718 [debug] [MainThread]: Connection 'macro_run_directory' was properly closed.


============================== 2022-02-20 04:40:49.802100 | 3dee1ce8-4eba-49fb-b636-ba72e9edc760 ==============================
04:40:49.802100 [info ] [MainThread]: Running with dbt=1.0.1
04:40:49.802546 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/hassanzaheer/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, macro='run_directory', args='{}', defer=None, state=None, cls=<class 'dbt.task.run_operation.RunOperationTask'>, which='run-operation', rpc_method='run-operation')
04:40:49.802661 [debug] [MainThread]: Tracking: do not track
04:40:49.823029 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
04:40:49.823227 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
04:40:49.828380 [debug] [MainThread]: Acquiring new postgres connection "macro_run_directory"
04:40:49.828492 [debug] [MainThread]: Using postgres connection "macro_run_directory"
04:40:49.828561 [debug] [MainThread]: On macro_run_directory: BEGIN
04:40:49.828626 [debug] [MainThread]: Opening a new connection, currently in state init
04:40:49.859468 [debug] [MainThread]: SQL status: BEGIN in 0.03 seconds
04:40:49.859642 [debug] [MainThread]: On macro_run_directory: COMMIT
04:40:49.859708 [debug] [MainThread]: Using postgres connection "macro_run_directory"
04:40:49.859766 [debug] [MainThread]: On macro_run_directory: COMMIT
04:40:49.859897 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
04:40:49.867263 [debug] [MainThread]: Using postgres connection "macro_run_directory"
04:40:49.867398 [debug] [MainThread]: On macro_run_directory: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_directory"} */

    
with read_directory as (select * from (select * from pg_ls_dir('./autopie_workdir') pg) iq where pg like '%.json'),
file_content as (select pg file_name, cast(pg_read_file(E'./autopie_workdir/'||pg, 0, 100000000) as json) json_content from read_directory)
select file_name, 
       json_content->>'recipe_type' recipe_type,
       json_content->>'ingredients' ingredients,
       json_content->>'target_fact' target_fact,
       json_content->>'source_fact' source_fact
  from file_content
order by file_name;

  
04:40:49.869327 [debug] [MainThread]: SQL status: SELECT 2 in 0.0 seconds
04:40:49.870224 [info ] [MainThread]: 
--PARAM ROW ---> <agate.Row: ('collect_fact_calls.json', 'collect_fact', '{\n        "expression_extract": {  \n            "source_raw": "testsatmap.calltable",\n            "expression_list": [\n                {"expression": "call_id", "alias": "call_id"},\n                {"expression": "to_timestamp(call_start_epoch)", "alias": "time_call_start"},\n                {"expression": "to_timestamp(call_start_epoch + call_duration)", "alias": "time_call_end"},\n                {"expression": "call_duration", "alias": "num_duration_seconds"},\n                {"expression": "trim(customer_id)",  "alias": "customer_id"},\n                {"expression": "lower(trim(agent_id))",  "alias": "agent_id"}\n            ]\n        },\n        "expression_extract_outer": {  \n            "expression_list": [\n                {"expression": "round(num_duration_seconds/60,2)", "alias": "num_duration_minutes"}\n            ]\n        },\n        "filter_conjunctions": [\n            "agent_id is not null",\n            "customer_id is not null",\n            "num_duration_seconds > 10"\n        ],\n        "incremental_update_on": "time_call_start",\n        "deduplication": {\n            "grouping_key": "call_id",\n            "preference": "arbitrary"\n        }\n    }', '{\n        "id": "calls", \n        "entity_and_dims": "call_id",\n        "date":"time_call_end"\n    }', None)>
04:40:49.870447 [info ] [MainThread]: 
--RUNNING FILE ---> collect_fact_calls.json
04:40:49.870566 [info ] [MainThread]: 
--TARGET FACT ---> {
        "id": "calls", 
        "entity_and_dims": "call_id",
        "date":"time_call_end"
    }
04:40:49.908043 [debug] [MainThread]: Using postgres connection "macro_run_directory"
04:40:49.908193 [debug] [MainThread]: On macro_run_directory: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_directory"} */

    
select 
    column_name||'::'||
        case when replace(udt_name, '_','') = 'bit' then 'int'
            when replace(udt_name, '_','') like 'int8%' then 'bigint'
            when replace(udt_name, '_','') like 'int4%' then 'int'
            when replace(udt_name, '_','') like 'int%' then 'smallint'
            when replace(udt_name, '_','') like 'bool%' then 'int'
            when replace(udt_name, '_','') like 'float%' then 'numeric'
            when replace(udt_name, '_','') like 'float%' then 'numeric'
            when replace(udt_name, '_','') like 'byte%' then 'text'
            when replace(udt_name, '_','') like 'varchar%' then 'text'
            when replace(udt_name, '_','') like 'timestamp%' then 'timestamp'
            else replace(udt_name, '_','') end ||
       ' as "'||column_name||'"' select_text
from information_schema.columns 
where table_schema||'.'||table_name = 'testsatmap.calltable'
order by ordinal_position
;
  
04:40:49.922325 [debug] [MainThread]: SQL status: SELECT 5 in 0.01 seconds
04:40:49.922979 [debug] [MainThread]: Using postgres connection "macro_run_directory"
04:40:49.923052 [debug] [MainThread]: On macro_run_directory: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_directory"} */

    
create or replace view autopie_ebpdemo.tmp_staging_view_source_extract_0 as
select
    call_id::text as "call_id", 
    call_start_epoch::bigint as "call_start_epoch", 
    call_duration::int as "call_duration", 
    customer_id::text as "customer_id", 
    agent_id::text as "agent_id" 
from testsatmap.calltable
;
  
04:40:49.926417 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
04:40:49.926957 [debug] [MainThread]: Using postgres connection "macro_run_directory"
04:40:49.927026 [debug] [MainThread]: On macro_run_directory: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_directory"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type cascade;
  
04:40:49.927254 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
04:40:49.927749 [debug] [MainThread]: Using postgres connection "macro_run_directory"
04:40:49.927813 [debug] [MainThread]: On macro_run_directory: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_directory"} */

    create or replace view autopie_ebpdemo.tmp_exp_type as select call_id as exp from autopie_ebpdemo.tmp_staging_view_source_extract_0 limit 1;
  
04:40:49.928687 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
04:40:49.929175 [debug] [MainThread]: Using postgres connection "macro_run_directory"
04:40:49.929241 [debug] [MainThread]: On macro_run_directory: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_directory"} */

    select replace(udt_name, '_','') as dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type' and column_name = 'exp';
  
04:40:49.933444 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
04:40:49.933952 [debug] [MainThread]: Using postgres connection "macro_run_directory"
04:40:49.934019 [debug] [MainThread]: On macro_run_directory: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_directory"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type cascade;
  
04:40:49.938874 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
04:40:49.939387 [debug] [MainThread]: Using postgres connection "macro_run_directory"
04:40:49.939452 [debug] [MainThread]: On macro_run_directory: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_directory"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type cascade;
  
04:40:49.939839 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
04:40:49.940365 [debug] [MainThread]: Using postgres connection "macro_run_directory"
04:40:49.940437 [debug] [MainThread]: On macro_run_directory: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_directory"} */

    create or replace view autopie_ebpdemo.tmp_exp_type as select to_timestamp(call_start_epoch) as exp from autopie_ebpdemo.tmp_staging_view_source_extract_0 limit 1;
  
04:40:49.941729 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
04:40:49.942256 [debug] [MainThread]: Using postgres connection "macro_run_directory"
04:40:49.942324 [debug] [MainThread]: On macro_run_directory: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_directory"} */

    select replace(udt_name, '_','') as dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type' and column_name = 'exp';
  
04:40:49.947004 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
04:40:49.947567 [debug] [MainThread]: Using postgres connection "macro_run_directory"
04:40:49.947635 [debug] [MainThread]: On macro_run_directory: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_directory"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type cascade;
  
04:40:49.948653 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
04:40:49.949307 [debug] [MainThread]: Using postgres connection "macro_run_directory"
04:40:49.949377 [debug] [MainThread]: On macro_run_directory: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_directory"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type cascade;
  
04:40:49.949615 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
04:40:49.950136 [debug] [MainThread]: Using postgres connection "macro_run_directory"
04:40:49.950205 [debug] [MainThread]: On macro_run_directory: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_directory"} */

    create or replace view autopie_ebpdemo.tmp_exp_type as select to_timestamp(call_start_epoch + call_duration) as exp from autopie_ebpdemo.tmp_staging_view_source_extract_0 limit 1;
  
04:40:49.951835 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
04:40:49.952355 [debug] [MainThread]: Using postgres connection "macro_run_directory"
04:40:49.952424 [debug] [MainThread]: On macro_run_directory: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_directory"} */

    select replace(udt_name, '_','') as dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type' and column_name = 'exp';
  
04:40:49.957434 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
04:40:49.957981 [debug] [MainThread]: Using postgres connection "macro_run_directory"
04:40:49.958049 [debug] [MainThread]: On macro_run_directory: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_directory"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type cascade;
  
04:40:49.958936 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
04:40:49.959456 [debug] [MainThread]: Using postgres connection "macro_run_directory"
04:40:49.959526 [debug] [MainThread]: On macro_run_directory: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_directory"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type cascade;
  
04:40:49.959828 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
04:40:49.960369 [debug] [MainThread]: Using postgres connection "macro_run_directory"
04:40:49.960438 [debug] [MainThread]: On macro_run_directory: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_directory"} */

    create or replace view autopie_ebpdemo.tmp_exp_type as select call_duration as exp from autopie_ebpdemo.tmp_staging_view_source_extract_0 limit 1;
  
04:40:49.961540 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
04:40:49.962056 [debug] [MainThread]: Using postgres connection "macro_run_directory"
04:40:49.962125 [debug] [MainThread]: On macro_run_directory: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_directory"} */

    select replace(udt_name, '_','') as dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type' and column_name = 'exp';
  
04:40:49.966457 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
04:40:49.966999 [debug] [MainThread]: Using postgres connection "macro_run_directory"
04:40:49.967067 [debug] [MainThread]: On macro_run_directory: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_directory"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type cascade;
  
04:40:49.968258 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
04:40:49.968781 [debug] [MainThread]: Using postgres connection "macro_run_directory"
04:40:49.968848 [debug] [MainThread]: On macro_run_directory: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_directory"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type cascade;
  
04:40:49.969077 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
04:40:49.969597 [debug] [MainThread]: Using postgres connection "macro_run_directory"
04:40:49.969668 [debug] [MainThread]: On macro_run_directory: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_directory"} */

    create or replace view autopie_ebpdemo.tmp_exp_type as select trim(customer_id) as exp from autopie_ebpdemo.tmp_staging_view_source_extract_0 limit 1;
  
04:40:49.970833 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
04:40:49.971367 [debug] [MainThread]: Using postgres connection "macro_run_directory"
04:40:49.971444 [debug] [MainThread]: On macro_run_directory: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_directory"} */

    select replace(udt_name, '_','') as dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type' and column_name = 'exp';
  
04:40:49.975758 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
04:40:49.976602 [debug] [MainThread]: Using postgres connection "macro_run_directory"
04:40:49.976681 [debug] [MainThread]: On macro_run_directory: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_directory"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type cascade;
  
04:40:49.977546 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
04:40:49.978127 [debug] [MainThread]: Using postgres connection "macro_run_directory"
04:40:49.978204 [debug] [MainThread]: On macro_run_directory: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_directory"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type cascade;
  
04:40:49.978447 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
04:40:49.979014 [debug] [MainThread]: Using postgres connection "macro_run_directory"
04:40:49.979093 [debug] [MainThread]: On macro_run_directory: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_directory"} */

    create or replace view autopie_ebpdemo.tmp_exp_type as select lower(trim(agent_id)) as exp from autopie_ebpdemo.tmp_staging_view_source_extract_0 limit 1;
  
04:40:49.980586 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
04:40:49.981158 [debug] [MainThread]: Using postgres connection "macro_run_directory"
04:40:49.981235 [debug] [MainThread]: On macro_run_directory: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_directory"} */

    select replace(udt_name, '_','') as dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type' and column_name = 'exp';
  
04:40:49.985580 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
04:40:49.986172 [debug] [MainThread]: Using postgres connection "macro_run_directory"
04:40:49.986246 [debug] [MainThread]: On macro_run_directory: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_directory"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type cascade;
  
04:40:49.987346 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
04:40:49.987931 [debug] [MainThread]: Using postgres connection "macro_run_directory"
04:40:49.988005 [debug] [MainThread]: On macro_run_directory: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_directory"} */

    
create or replace view autopie_ebpdemo.tmp_staging_view_expression_extract_1 as
select
    (call_id)::text as call_id, 
    (to_timestamp(call_start_epoch))::timestamptz as time_call_start, 
    (to_timestamp(call_start_epoch + call_duration))::timestamptz as time_call_end, 
    (call_duration)::int4 as num_duration_seconds, 
    (trim(customer_id))::text as customer_id, 
    (lower(trim(agent_id)))::text as agent_id 
from autopie_ebpdemo.tmp_staging_view_source_extract_0
;
  
04:40:49.990403 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
04:40:49.990972 [debug] [MainThread]: Using postgres connection "macro_run_directory"
04:40:49.991045 [debug] [MainThread]: On macro_run_directory: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_directory"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type cascade;
  
04:40:49.991332 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
04:40:49.991896 [debug] [MainThread]: Using postgres connection "macro_run_directory"
04:40:49.991968 [debug] [MainThread]: On macro_run_directory: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_directory"} */

    create or replace view autopie_ebpdemo.tmp_exp_type as select round(num_duration_seconds/60,2) as exp from autopie_ebpdemo.tmp_staging_view_expression_extract_1 limit 1;
  
04:40:49.993672 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
04:40:49.994234 [debug] [MainThread]: Using postgres connection "macro_run_directory"
04:40:49.994309 [debug] [MainThread]: On macro_run_directory: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_directory"} */

    select replace(udt_name, '_','') as dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type' and column_name = 'exp';
  
04:40:49.998742 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
04:40:49.999329 [debug] [MainThread]: Using postgres connection "macro_run_directory"
04:40:49.999403 [debug] [MainThread]: On macro_run_directory: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_directory"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type cascade;
  
04:40:50.000258 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
04:40:50.001972 [debug] [MainThread]: Using postgres connection "macro_run_directory"
04:40:50.002049 [debug] [MainThread]: On macro_run_directory: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_directory"} */

    
drop view if exists autopie_ebpdemo.tmp_staging_view_source_extract_0 cascade;
drop view if exists autopie_ebpdemo.tmp_staging_view_expression_extract_1 cascade;
  
04:40:50.003496 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
04:40:50.004031 [info ] [MainThread]: 





create or replace view autopie_ebpdemo.tmp_staging_view_source_extract_0 as
select
    call_id::text as "call_id", 
    call_start_epoch::bigint as "call_start_epoch", 
    call_duration::int as "call_duration", 
    customer_id::text as "customer_id", 
    agent_id::text as "agent_id" 
from testsatmap.calltable
;


create or replace view autopie_ebpdemo.tmp_staging_view_expression_extract_1 as
select
    (call_id)::text as call_id, 
    (to_timestamp(call_start_epoch))::timestamptz as time_call_start, 
    (to_timestamp(call_start_epoch + call_duration))::timestamptz as time_call_end, 
    (call_duration)::int4 as num_duration_seconds, 
    (trim(customer_id))::text as customer_id, 
    (lower(trim(agent_id)))::text as agent_id 
from autopie_ebpdemo.tmp_staging_view_source_extract_0
;

drop table if exists autopie_ebpdemo.tmp_staging_fact_calls;
create table autopie_ebpdemo.tmp_staging_fact_calls as
(
    with expression_extract_1 as
    (
        select * from autopie_ebpdemo.tmp_staging_view_expression_extract_1
    ),
    expression_extract_2 as
    (
        select  t.*,
                (round(num_duration_seconds/60,2))::numeric as num_duration_minutes
        from expression_extract_1 t
    ),
    filter_3 as
    (
        select /* filtering irrelevant records out */ *
        from expression_extract_2
        where 1=1
        and agent_id is not null
        and customer_id is not null
        and num_duration_seconds > 10
    ),
    incremental_extract_4 as
    (
        select /* retrieving incremental data - by date range only */ *
        from filter_3
        where time_call_start >= to_date('1900-01-01', 'YYYY-MM-DD')
          and time_call_start  < to_date('2100-01-01', 'YYYY-MM-DD')
    ),
    deduplication_5 as
    (
        select /* deduplicate by strategy */
            call_id
            , max(time_call_start) as time_call_start
            , max(time_call_end) as time_call_end
            , max(num_duration_seconds) as num_duration_seconds
            , max(customer_id) as customer_id
            , max(agent_id) as agent_id
            , max(num_duration_minutes) as num_duration_minutes
        from incremental_extract_4
        group by call_id 
    ),
    coarsening_6 as
    (
        select * from deduplication_5
    )
    select * from coarsening_6
)
;

drop view if exists autopie_ebpdemo.tmp_staging_view_source_extract_0 cascade;
drop view if exists autopie_ebpdemo.tmp_staging_view_expression_extract_1 cascade;

-- check if not exists already, this should run once
do $$                  
begin
if not exists
( 
    select 1 from information_schema.tables 
    where table_schema||'.'|| table_name = 'autopie_ebpdemo.obj_fact_calls'
)
then
    create table autopie_ebpdemo.obj_fact_calls as (select * from autopie_ebpdemo.tmp_staging_fact_calls where 1=0);
    alter  table autopie_ebpdemo.obj_fact_calls add column row_id bigserial not null;
    alter  table autopie_ebpdemo.obj_fact_calls add primary key (call_id, time_call_end);
    --
    create index ixrid_obj_fact_calls on autopie_ebpdemo.obj_fact_calls(row_id);
end if;
end
$$;

-- upsert staging additions into the permanent fact object
delete from autopie_ebpdemo.obj_fact_calls where (call_id, time_call_end) in (select call_id, time_call_end from autopie_ebpdemo.tmp_staging_fact_calls);
insert into autopie_ebpdemo.obj_fact_calls select * from autopie_ebpdemo.tmp_staging_fact_calls;
drop table autopie_ebpdemo.tmp_staging_fact_calls;


04:40:50.004425 [debug] [MainThread]: Using postgres connection "macro_run_directory"
04:40:50.004494 [debug] [MainThread]: On macro_run_directory: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_directory"} */

    





create or replace view autopie_ebpdemo.tmp_staging_view_source_extract_0 as
select
    call_id::text as "call_id", 
    call_start_epoch::bigint as "call_start_epoch", 
    call_duration::int as "call_duration", 
    customer_id::text as "customer_id", 
    agent_id::text as "agent_id" 
from testsatmap.calltable
;


create or replace view autopie_ebpdemo.tmp_staging_view_expression_extract_1 as
select
    (call_id)::text as call_id, 
    (to_timestamp(call_start_epoch))::timestamptz as time_call_start, 
    (to_timestamp(call_start_epoch + call_duration))::timestamptz as time_call_end, 
    (call_duration)::int4 as num_duration_seconds, 
    (trim(customer_id))::text as customer_id, 
    (lower(trim(agent_id)))::text as agent_id 
from autopie_ebpdemo.tmp_staging_view_source_extract_0
;

drop table if exists autopie_ebpdemo.tmp_staging_fact_calls;
create table autopie_ebpdemo.tmp_staging_fact_calls as
(
    with expression_extract_1 as
    (
        select * from autopie_ebpdemo.tmp_staging_view_expression_extract_1
    ),
    expression_extract_2 as
    (
        select  t.*,
                (round(num_duration_seconds/60,2))::numeric as num_duration_minutes
        from expression_extract_1 t
    ),
    filter_3 as
    (
        select /* filtering irrelevant records out */ *
        from expression_extract_2
        where 1=1
        and agent_id is not null
        and customer_id is not null
        and num_duration_seconds > 10
    ),
    incremental_extract_4 as
    (
        select /* retrieving incremental data - by date range only */ *
        from filter_3
        where time_call_start >= to_date('1900-01-01', 'YYYY-MM-DD')
          and time_call_start  < to_date('2100-01-01', 'YYYY-MM-DD')
    ),
    deduplication_5 as
    (
        select /* deduplicate by strategy */
            call_id
            , max(time_call_start) as time_call_start
            , max(time_call_end) as time_call_end
            , max(num_duration_seconds) as num_duration_seconds
            , max(customer_id) as customer_id
            , max(agent_id) as agent_id
            , max(num_duration_minutes) as num_duration_minutes
        from incremental_extract_4
        group by call_id 
    ),
    coarsening_6 as
    (
        select * from deduplication_5
    )
    select * from coarsening_6
)
;

drop view if exists autopie_ebpdemo.tmp_staging_view_source_extract_0 cascade;
drop view if exists autopie_ebpdemo.tmp_staging_view_expression_extract_1 cascade;

-- check if not exists already, this should run once
do $$                  
begin
if not exists
( 
    select 1 from information_schema.tables 
    where table_schema||'.'|| table_name = 'autopie_ebpdemo.obj_fact_calls'
)
then
    create table autopie_ebpdemo.obj_fact_calls as (select * from autopie_ebpdemo.tmp_staging_fact_calls where 1=0);
    alter  table autopie_ebpdemo.obj_fact_calls add column row_id bigserial not null;
    alter  table autopie_ebpdemo.obj_fact_calls add primary key (call_id, time_call_end);
    --
    create index ixrid_obj_fact_calls on autopie_ebpdemo.obj_fact_calls(row_id);
end if;
end
$$;

-- upsert staging additions into the permanent fact object
delete from autopie_ebpdemo.obj_fact_calls where (call_id, time_call_end) in (select call_id, time_call_end from autopie_ebpdemo.tmp_staging_fact_calls);
insert into autopie_ebpdemo.obj_fact_calls select * from autopie_ebpdemo.tmp_staging_fact_calls;
drop table autopie_ebpdemo.tmp_staging_fact_calls;


  
04:40:50.034222 [debug] [MainThread]: SQL status: DROP TABLE in 0.03 seconds
04:40:50.034946 [debug] [MainThread]: Using postgres connection "macro_run_directory"
04:40:50.035037 [debug] [MainThread]: On macro_run_directory: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_directory"} */

    None
  
04:40:50.035811 [debug] [MainThread]: Postgres adapter: Postgres error: syntax error at or near "None"
LINE 3:     None
            ^

04:40:50.035979 [debug] [MainThread]: Postgres adapter: Error running SQL: macro run_directory
04:40:50.036062 [debug] [MainThread]: Postgres adapter: Rolling back transaction.
04:40:50.036160 [debug] [MainThread]: On macro_run_directory: Close
04:40:50.036352 [error] [MainThread]: Encountered an error while running operation: Database Error
  syntax error at or near "None"
  LINE 3:     None
              ^
04:40:50.036556 [debug] [MainThread]: 
04:40:50.037205 [debug] [MainThread]: Connection 'macro_run_directory' was properly closed.


============================== 2022-02-20 06:03:57.754456 | 78880eaa-d38a-4071-88a8-6d8cc3910604 ==============================
06:03:57.754456 [info ] [MainThread]: Running with dbt=1.0.1
06:03:57.755959 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/hassanzaheer/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, macro='run_recipe', args='', defer=None, state=None, cls=<class 'dbt.task.run_operation.RunOperationTask'>, which='run-operation', rpc_method='run-operation')
06:03:57.756112 [debug] [MainThread]: Tracking: do not track
06:03:57.771240 [info ] [MainThread]: Unable to do partial parsing because profile has changed
06:03:57.777632 [debug] [MainThread]: Parsing macros/compile_recipe_collect_fact.sql
06:03:57.805539 [debug] [MainThread]: Parsing macros/core/run_recipe.sql
06:03:57.806889 [debug] [MainThread]: Parsing macros/core/run_directory.sql
06:03:57.808052 [debug] [MainThread]: Parsing macros/catalog.sql
06:03:57.809107 [debug] [MainThread]: Parsing macros/relations.sql
06:03:57.809742 [debug] [MainThread]: Parsing macros/adapters.sql
06:03:57.820153 [debug] [MainThread]: Parsing macros/materializations/snapshot_merge.sql
06:03:57.820913 [debug] [MainThread]: Parsing macros/materializations/hooks.sql
06:03:57.822644 [debug] [MainThread]: Parsing macros/materializations/configs.sql
06:03:57.823655 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot_merge.sql
06:03:57.824395 [debug] [MainThread]: Parsing macros/materializations/snapshots/strategies.sql
06:03:57.832110 [debug] [MainThread]: Parsing macros/materializations/snapshots/helpers.sql
06:03:57.837602 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot.sql
06:03:57.843322 [debug] [MainThread]: Parsing macros/materializations/tests/test.sql
06:03:57.845343 [debug] [MainThread]: Parsing macros/materializations/tests/helpers.sql
06:03:57.846125 [debug] [MainThread]: Parsing macros/materializations/tests/where_subquery.sql
06:03:57.846905 [debug] [MainThread]: Parsing macros/materializations/models/incremental/column_helpers.sql
06:03:57.848881 [debug] [MainThread]: Parsing macros/materializations/models/incremental/merge.sql
06:03:57.854201 [debug] [MainThread]: Parsing macros/materializations/models/incremental/is_incremental.sql
06:03:57.854873 [debug] [MainThread]: Parsing macros/materializations/models/incremental/incremental.sql
06:03:57.859670 [debug] [MainThread]: Parsing macros/materializations/models/incremental/on_schema_change.sql
06:03:57.867270 [debug] [MainThread]: Parsing macros/materializations/models/table/table.sql
06:03:57.870868 [debug] [MainThread]: Parsing macros/materializations/models/table/create_table_as.sql
06:03:57.872110 [debug] [MainThread]: Parsing macros/materializations/models/view/view.sql
06:03:57.875578 [debug] [MainThread]: Parsing macros/materializations/models/view/helpers.sql
06:03:57.876136 [debug] [MainThread]: Parsing macros/materializations/models/view/create_or_replace_view.sql
06:03:57.877342 [debug] [MainThread]: Parsing macros/materializations/models/view/create_view_as.sql
06:03:57.878333 [debug] [MainThread]: Parsing macros/materializations/seeds/seed.sql
06:03:57.881092 [debug] [MainThread]: Parsing macros/materializations/seeds/helpers.sql
06:03:57.888901 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_alias.sql
06:03:57.889556 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_schema.sql
06:03:57.890639 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_database.sql
06:03:57.891317 [debug] [MainThread]: Parsing macros/generic_test_sql/relationships.sql
06:03:57.891708 [debug] [MainThread]: Parsing macros/generic_test_sql/not_null.sql
06:03:57.891949 [debug] [MainThread]: Parsing macros/generic_test_sql/unique.sql
06:03:57.892243 [debug] [MainThread]: Parsing macros/generic_test_sql/accepted_values.sql
06:03:57.892848 [debug] [MainThread]: Parsing macros/etc/statement.sql
06:03:57.894819 [debug] [MainThread]: Parsing macros/etc/datetime.sql
06:03:57.898698 [debug] [MainThread]: Parsing macros/adapters/schema.sql
06:03:57.899628 [debug] [MainThread]: Parsing macros/adapters/indexes.sql
06:03:57.900799 [debug] [MainThread]: Parsing macros/adapters/relation.sql
06:03:57.905102 [debug] [MainThread]: Parsing macros/adapters/freshness.sql
06:03:57.906378 [debug] [MainThread]: Parsing macros/adapters/persist_docs.sql
06:03:57.908323 [debug] [MainThread]: Parsing macros/adapters/metadata.sql
06:03:57.911572 [debug] [MainThread]: Parsing macros/adapters/columns.sql
06:03:57.916058 [debug] [MainThread]: Parsing tests/generic/builtin.sql
06:03:58.004265 [debug] [MainThread]: 1699: static parser successfully parsed demo_ebp_flow/demo_data_prep.sql
06:03:58.009320 [debug] [MainThread]: 1699: static parser successfully parsed demo_ebp_flow/prepared_scripts/prepared_fact_outcomes.sql
06:03:58.010156 [debug] [MainThread]: 1699: static parser successfully parsed demo_ebp_flow/prepared_scripts/prepared_fact_calls.sql
06:03:58.022388 [error] [MainThread]: Encountered an error while running operation: Compilation Error
  The --vars argument must be a YAML dictionary, but was of type 'NoneType'
06:03:58.022568 [debug] [MainThread]: 


============================== 2022-02-20 06:04:24.712162 | eb68827b-07af-40e4-a0f5-766607cd6c43 ==============================
06:04:24.712162 [info ] [MainThread]: Running with dbt=1.0.1
06:04:24.712582 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/hassanzaheer/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, macro='run_recipe', args='{\n    "recipe_type" : "collect_fact",\n    "target_fact" : {\n        "id": "calls", \n        "entity_and_dims": "call_id",\n        "date":"time_call_end"\n    },\n    "ingredients": {\n        "expression_extract": {  \n            "source_raw": "testsatmap.calltable",\n            "expression_list": [\n                {"expression": "call_id", "alias": "call_id"},\n                {"expression": "to_timestamp(call_start_epoch)", "alias": "time_call_start"},\n                {"expression": "to_timestamp(call_start_epoch + call_duration)", "alias": "time_call_end"},\n                {"expression": "call_duration", "alias": "num_duration_seconds"},\n                {"expression": "trim(customer_id)",  "alias": "customer_id"},\n                {"expression": "lower(trim(agent_id))",  "alias": "agent_id"}\n            ]\n        },\n        "expression_extract_outer": {  \n            "expression_list": [\n                {"expression": "round(num_duration_seconds/60,2)", "alias": "num_duration_minutes"}\n            ]\n        },\n        "filter_conjunctions": [\n            "agent_id is not null",\n            "customer_id is not null",\n            "num_duration_seconds > 10"\n        ],\n        "incremental_update_on": "time_call_start",\n        "deduplication": {\n            "grouping_key": "call_id",\n            "preference": "arbitrary"\n        }\n    }\n}', defer=None, state=None, cls=<class 'dbt.task.run_operation.RunOperationTask'>, which='run-operation', rpc_method='run-operation')
06:04:24.712697 [debug] [MainThread]: Tracking: do not track
06:04:24.731627 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
06:04:24.731873 [debug] [MainThread]: Partial parsing: updated file: demo_autopie://models/demo_ebp_flow/prepared_scripts/prepared_fact_calls.sql
06:04:24.737427 [debug] [MainThread]: 1699: static parser successfully parsed demo_ebp_flow/prepared_scripts/prepared_fact_calls.sql
06:04:24.748000 [debug] [MainThread]: Acquiring new postgres connection "macro_run_recipe"
06:04:24.748106 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:04:24.748166 [debug] [MainThread]: On macro_run_recipe: BEGIN
06:04:24.748224 [debug] [MainThread]: Opening a new connection, currently in state init
06:04:24.770797 [debug] [MainThread]: SQL status: BEGIN in 0.02 seconds
06:04:24.770918 [debug] [MainThread]: On macro_run_recipe: COMMIT
06:04:24.770991 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:04:24.771051 [debug] [MainThread]: On macro_run_recipe: COMMIT
06:04:24.771186 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
06:04:24.811960 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:04:24.812085 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    
select 
    column_name||'::'||
        case when replace(udt_name, '_','') = 'bit' then 'int'
            when replace(udt_name, '_','') like 'int8%' then 'bigint'
            when replace(udt_name, '_','') like 'int4%' then 'int'
            when replace(udt_name, '_','') like 'int%' then 'smallint'
            when replace(udt_name, '_','') like 'bool%' then 'int'
            when replace(udt_name, '_','') like 'float%' then 'numeric'
            when replace(udt_name, '_','') like 'float%' then 'numeric'
            when replace(udt_name, '_','') like 'byte%' then 'text'
            when replace(udt_name, '_','') like 'varchar%' then 'text'
            when replace(udt_name, '_','') like 'timestamp%' then 'timestamp'
            else replace(udt_name, '_','') end ||
       ' as "'||column_name||'"' select_text
from information_schema.columns 
where table_schema||'.'||table_name = 'testsatmap.calltable'
order by ordinal_position
;
  
06:04:24.825644 [debug] [MainThread]: SQL status: SELECT 5 in 0.01 seconds
06:04:24.826515 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:04:24.826592 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    
create or replace view autopie.tmp_staging_view_source_extract_0 as
select
    call_id::text as "call_id", 
    call_start_epoch::bigint as "call_start_epoch", 
    call_duration::int as "call_duration", 
    customer_id::text as "customer_id", 
    agent_id::text as "agent_id" 
from testsatmap.calltable
;
  
06:04:24.827472 [debug] [MainThread]: Postgres adapter: Postgres error: schema "autopie" does not exist

06:04:24.827591 [debug] [MainThread]: Postgres adapter: Error running SQL: macro run_recipe
06:04:24.827644 [debug] [MainThread]: Postgres adapter: Rolling back transaction.
06:04:24.827706 [debug] [MainThread]: On macro_run_recipe: Close
06:04:24.827841 [error] [MainThread]: Encountered an error while running operation: Database Error
  schema "autopie" does not exist
06:04:24.827983 [debug] [MainThread]: 
06:04:24.828460 [debug] [MainThread]: Connection 'macro_run_recipe' was properly closed.


============================== 2022-02-20 06:06:30.368833 | 68370c6a-af8f-46d5-99bd-f30c9c4d76ac ==============================
06:06:30.368833 [info ] [MainThread]: Running with dbt=1.0.1
06:06:30.369222 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/hassanzaheer/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, macro='run_recipe', args='{\n    "recipe_type" : "collect_fact",\n    "target_fact" : {\n        "id": "calls", \n        "entity_and_dims": "call_id",\n        "date":"time_call_end"\n    },\n    "ingredients": {\n        "expression_extract": {  \n            "source_raw": "testsatmap.calltable",\n            "expression_list": [\n                {"expression": "call_id", "alias": "call_id"},\n                {"expression": "to_timestamp(call_start_epoch)", "alias": "time_call_start"},\n                {"expression": "to_timestamp(call_start_epoch + call_duration)", "alias": "time_call_end"},\n                {"expression": "call_duration", "alias": "num_duration_seconds"},\n                {"expression": "trim(customer_id)",  "alias": "customer_id"},\n                {"expression": "lower(trim(agent_id))",  "alias": "agent_id"}\n            ]\n        },\n        "expression_extract_outer": {  \n            "expression_list": [\n                {"expression": "round(num_duration_seconds/60,2)", "alias": "num_duration_minutes"}\n            ]\n        },\n        "filter_conjunctions": [\n            "agent_id is not null",\n            "customer_id is not null",\n            "num_duration_seconds > 10"\n        ],\n        "incremental_update_on": "time_call_start",\n        "deduplication": {\n            "grouping_key": "call_id",\n            "preference": "arbitrary"\n        }\n    }\n}', defer=None, state=None, cls=<class 'dbt.task.run_operation.RunOperationTask'>, which='run-operation', rpc_method='run-operation')
06:06:30.369342 [debug] [MainThread]: Tracking: do not track
06:06:30.389271 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
06:06:30.389433 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
06:06:30.394381 [debug] [MainThread]: Acquiring new postgres connection "macro_run_recipe"
06:06:30.394493 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:06:30.394559 [debug] [MainThread]: On macro_run_recipe: BEGIN
06:06:30.394615 [debug] [MainThread]: Opening a new connection, currently in state init
06:06:30.420481 [debug] [MainThread]: SQL status: BEGIN in 0.03 seconds
06:06:30.420594 [debug] [MainThread]: On macro_run_recipe: COMMIT
06:06:30.420653 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:06:30.420708 [debug] [MainThread]: On macro_run_recipe: COMMIT
06:06:30.421449 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
06:06:30.462477 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:06:30.462597 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    
select 
    column_name||'::'||
        case when replace(udt_name, '_','') = 'bit' then 'int'
            when replace(udt_name, '_','') like 'int8%' then 'bigint'
            when replace(udt_name, '_','') like 'int4%' then 'int'
            when replace(udt_name, '_','') like 'int%' then 'smallint'
            when replace(udt_name, '_','') like 'bool%' then 'int'
            when replace(udt_name, '_','') like 'float%' then 'numeric'
            when replace(udt_name, '_','') like 'float%' then 'numeric'
            when replace(udt_name, '_','') like 'byte%' then 'text'
            when replace(udt_name, '_','') like 'varchar%' then 'text'
            when replace(udt_name, '_','') like 'timestamp%' then 'timestamp'
            else replace(udt_name, '_','') end ||
       ' as "'||column_name||'"' select_text
from information_schema.columns 
where table_schema||'.'||table_name = 'testsatmap.calltable'
order by ordinal_position
;
  
06:06:30.476344 [debug] [MainThread]: SQL status: SELECT 5 in 0.01 seconds
06:06:30.477351 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:06:30.477434 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    
create or replace view autopie_ebpdemo.tmp_staging_view_source_extract_0 as
select
    call_id::text as "call_id", 
    call_start_epoch::bigint as "call_start_epoch", 
    call_duration::int as "call_duration", 
    customer_id::text as "customer_id", 
    agent_id::text as "agent_id" 
from testsatmap.calltable
;
  
06:06:30.480703 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:06:30.481251 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:06:30.481320 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type cascade;
  
06:06:30.481553 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:06:30.482041 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:06:30.482104 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_exp_type as select call_id as exp from autopie_ebpdemo.tmp_staging_view_source_extract_0 limit 1;
  
06:06:30.483219 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:06:30.483696 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:06:30.483760 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select replace(udt_name, '_','') as dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type' and column_name = 'exp';
  
06:06:30.487266 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
06:06:30.487772 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:06:30.487834 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type cascade;
  
06:06:30.488901 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:06:30.489390 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:06:30.489455 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type cascade;
  
06:06:30.489652 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:06:30.490134 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:06:30.490198 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_exp_type as select to_timestamp(call_start_epoch) as exp from autopie_ebpdemo.tmp_staging_view_source_extract_0 limit 1;
  
06:06:30.491135 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:06:30.491740 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:06:30.491808 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select replace(udt_name, '_','') as dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type' and column_name = 'exp';
  
06:06:30.495685 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
06:06:30.496203 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:06:30.496268 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type cascade;
  
06:06:30.497161 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:06:30.497647 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:06:30.497710 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type cascade;
  
06:06:30.497944 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:06:30.498434 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:06:30.498496 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_exp_type as select to_timestamp(call_start_epoch + call_duration) as exp from autopie_ebpdemo.tmp_staging_view_source_extract_0 limit 1;
  
06:06:30.499918 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:06:30.500400 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:06:30.500466 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select replace(udt_name, '_','') as dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type' and column_name = 'exp';
  
06:06:30.504687 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
06:06:30.505203 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:06:30.505272 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type cascade;
  
06:06:30.506117 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:06:30.506640 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:06:30.506708 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type cascade;
  
06:06:30.506935 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:06:30.507454 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:06:30.507525 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_exp_type as select call_duration as exp from autopie_ebpdemo.tmp_staging_view_source_extract_0 limit 1;
  
06:06:30.508590 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:06:30.509112 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:06:30.509181 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select replace(udt_name, '_','') as dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type' and column_name = 'exp';
  
06:06:30.513344 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
06:06:30.513890 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:06:30.513960 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type cascade;
  
06:06:30.514782 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:06:30.515301 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:06:30.515369 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type cascade;
  
06:06:30.515704 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:06:30.516226 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:06:30.516294 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_exp_type as select trim(customer_id) as exp from autopie_ebpdemo.tmp_staging_view_source_extract_0 limit 1;
  
06:06:30.517819 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:06:30.518339 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:06:30.518407 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select replace(udt_name, '_','') as dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type' and column_name = 'exp';
  
06:06:30.522487 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
06:06:30.523025 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:06:30.523094 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type cascade;
  
06:06:30.523929 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:06:30.524453 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:06:30.524521 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type cascade;
  
06:06:30.524764 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:06:30.525277 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:06:30.525347 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_exp_type as select lower(trim(agent_id)) as exp from autopie_ebpdemo.tmp_staging_view_source_extract_0 limit 1;
  
06:06:30.526486 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:06:30.527003 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:06:30.527075 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select replace(udt_name, '_','') as dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type' and column_name = 'exp';
  
06:06:30.531268 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
06:06:30.531849 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:06:30.531922 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type cascade;
  
06:06:30.532796 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:06:30.533359 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:06:30.533431 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    
create or replace view autopie_ebpdemo.tmp_staging_view_expression_extract_1 as
select
    (call_id)::text as call_id, 
    (to_timestamp(call_start_epoch))::timestamptz as time_call_start, 
    (to_timestamp(call_start_epoch + call_duration))::timestamptz as time_call_end, 
    (call_duration)::int4 as num_duration_seconds, 
    (trim(customer_id))::text as customer_id, 
    (lower(trim(agent_id)))::text as agent_id 
from autopie_ebpdemo.tmp_staging_view_source_extract_0
;
  
06:06:30.535077 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:06:30.535644 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:06:30.535716 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type cascade;
  
06:06:30.535952 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:06:30.536506 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:06:30.536578 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_exp_type as select round(num_duration_seconds/60,2) as exp from autopie_ebpdemo.tmp_staging_view_expression_extract_1 limit 1;
  
06:06:30.538208 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:06:30.538767 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:06:30.538841 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select replace(udt_name, '_','') as dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type' and column_name = 'exp';
  
06:06:30.543473 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
06:06:30.544213 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:06:30.544286 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type cascade;
  
06:06:30.545183 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:06:30.546984 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:06:30.547066 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    
drop view if exists autopie_ebpdemo.tmp_staging_view_source_extract_0 cascade;
drop view if exists autopie_ebpdemo.tmp_staging_view_expression_extract_1 cascade;
  
06:06:30.548147 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:06:30.548681 [info ] [MainThread]: 





create or replace view autopie_ebpdemo.tmp_staging_view_source_extract_0 as
select
    call_id::text as "call_id", 
    call_start_epoch::bigint as "call_start_epoch", 
    call_duration::int as "call_duration", 
    customer_id::text as "customer_id", 
    agent_id::text as "agent_id" 
from testsatmap.calltable
;


create or replace view autopie_ebpdemo.tmp_staging_view_expression_extract_1 as
select
    (call_id)::text as call_id, 
    (to_timestamp(call_start_epoch))::timestamptz as time_call_start, 
    (to_timestamp(call_start_epoch + call_duration))::timestamptz as time_call_end, 
    (call_duration)::int4 as num_duration_seconds, 
    (trim(customer_id))::text as customer_id, 
    (lower(trim(agent_id)))::text as agent_id 
from autopie_ebpdemo.tmp_staging_view_source_extract_0
;

drop table if exists autopie_ebpdemo.tmp_staging_fact_calls;
create table autopie_ebpdemo.tmp_staging_fact_calls as
(
    with expression_extract_1 as
    (
        select * from autopie_ebpdemo.tmp_staging_view_expression_extract_1
    ),
    expression_extract_2 as
    (
        select  t.*,
                (round(num_duration_seconds/60,2))::numeric as num_duration_minutes
        from expression_extract_1 t
    ),
    filter_3 as
    (
        select /* filtering irrelevant records out */ *
        from expression_extract_2
        where 1=1
        and agent_id is not null
        and customer_id is not null
        and num_duration_seconds > 10
    ),
    incremental_extract_4 as
    (
        select /* retrieving incremental data - by date range only */ *
        from filter_3
        where time_call_start >= to_date('1900-01-01', 'YYYY-MM-DD')
          and time_call_start  < to_date('2100-01-01', 'YYYY-MM-DD')
    ),
    deduplication_5 as
    (
        select /* deduplicate by strategy */
            call_id
            , max(time_call_start) as time_call_start
            , max(time_call_end) as time_call_end
            , max(num_duration_seconds) as num_duration_seconds
            , max(customer_id) as customer_id
            , max(agent_id) as agent_id
            , max(num_duration_minutes) as num_duration_minutes
        from incremental_extract_4
        group by call_id 
    ),
    coarsening_6 as
    (
        select * from deduplication_5
    )
    select * from coarsening_6
)
;

drop view if exists autopie_ebpdemo.tmp_staging_view_source_extract_0 cascade;
drop view if exists autopie_ebpdemo.tmp_staging_view_expression_extract_1 cascade;

-- check if not exists already, this should run once
do $$                  
begin
if not exists
( 
    select 1 from information_schema.tables 
    where table_schema||'.'|| table_name = 'autopie_ebpdemo.obj_fact_calls'
)
then
    create table autopie_ebpdemo.obj_fact_calls as (select * from autopie_ebpdemo.tmp_staging_fact_calls where 1=0);
    alter  table autopie_ebpdemo.obj_fact_calls add column row_id bigserial not null;
    alter  table autopie_ebpdemo.obj_fact_calls add primary key (call_id, time_call_end);
    --
    create index ixrid_obj_fact_calls on autopie_ebpdemo.obj_fact_calls(row_id);
end if;
end
$$;

-- upsert staging additions into the permanent fact object
delete from autopie_ebpdemo.obj_fact_calls where (call_id, time_call_end) in (select call_id, time_call_end from autopie_ebpdemo.tmp_staging_fact_calls);
insert into autopie_ebpdemo.obj_fact_calls select * from autopie_ebpdemo.tmp_staging_fact_calls;
drop table autopie_ebpdemo.tmp_staging_fact_calls;


06:06:30.549086 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:06:30.549155 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    





create or replace view autopie_ebpdemo.tmp_staging_view_source_extract_0 as
select
    call_id::text as "call_id", 
    call_start_epoch::bigint as "call_start_epoch", 
    call_duration::int as "call_duration", 
    customer_id::text as "customer_id", 
    agent_id::text as "agent_id" 
from testsatmap.calltable
;


create or replace view autopie_ebpdemo.tmp_staging_view_expression_extract_1 as
select
    (call_id)::text as call_id, 
    (to_timestamp(call_start_epoch))::timestamptz as time_call_start, 
    (to_timestamp(call_start_epoch + call_duration))::timestamptz as time_call_end, 
    (call_duration)::int4 as num_duration_seconds, 
    (trim(customer_id))::text as customer_id, 
    (lower(trim(agent_id)))::text as agent_id 
from autopie_ebpdemo.tmp_staging_view_source_extract_0
;

drop table if exists autopie_ebpdemo.tmp_staging_fact_calls;
create table autopie_ebpdemo.tmp_staging_fact_calls as
(
    with expression_extract_1 as
    (
        select * from autopie_ebpdemo.tmp_staging_view_expression_extract_1
    ),
    expression_extract_2 as
    (
        select  t.*,
                (round(num_duration_seconds/60,2))::numeric as num_duration_minutes
        from expression_extract_1 t
    ),
    filter_3 as
    (
        select /* filtering irrelevant records out */ *
        from expression_extract_2
        where 1=1
        and agent_id is not null
        and customer_id is not null
        and num_duration_seconds > 10
    ),
    incremental_extract_4 as
    (
        select /* retrieving incremental data - by date range only */ *
        from filter_3
        where time_call_start >= to_date('1900-01-01', 'YYYY-MM-DD')
          and time_call_start  < to_date('2100-01-01', 'YYYY-MM-DD')
    ),
    deduplication_5 as
    (
        select /* deduplicate by strategy */
            call_id
            , max(time_call_start) as time_call_start
            , max(time_call_end) as time_call_end
            , max(num_duration_seconds) as num_duration_seconds
            , max(customer_id) as customer_id
            , max(agent_id) as agent_id
            , max(num_duration_minutes) as num_duration_minutes
        from incremental_extract_4
        group by call_id 
    ),
    coarsening_6 as
    (
        select * from deduplication_5
    )
    select * from coarsening_6
)
;

drop view if exists autopie_ebpdemo.tmp_staging_view_source_extract_0 cascade;
drop view if exists autopie_ebpdemo.tmp_staging_view_expression_extract_1 cascade;

-- check if not exists already, this should run once
do $$                  
begin
if not exists
( 
    select 1 from information_schema.tables 
    where table_schema||'.'|| table_name = 'autopie_ebpdemo.obj_fact_calls'
)
then
    create table autopie_ebpdemo.obj_fact_calls as (select * from autopie_ebpdemo.tmp_staging_fact_calls where 1=0);
    alter  table autopie_ebpdemo.obj_fact_calls add column row_id bigserial not null;
    alter  table autopie_ebpdemo.obj_fact_calls add primary key (call_id, time_call_end);
    --
    create index ixrid_obj_fact_calls on autopie_ebpdemo.obj_fact_calls(row_id);
end if;
end
$$;

-- upsert staging additions into the permanent fact object
delete from autopie_ebpdemo.obj_fact_calls where (call_id, time_call_end) in (select call_id, time_call_end from autopie_ebpdemo.tmp_staging_fact_calls);
insert into autopie_ebpdemo.obj_fact_calls select * from autopie_ebpdemo.tmp_staging_fact_calls;
drop table autopie_ebpdemo.tmp_staging_fact_calls;


  
06:06:30.577853 [debug] [MainThread]: SQL status: DROP TABLE in 0.03 seconds
06:06:30.578602 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:06:30.578689 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    None
  
06:06:30.579100 [debug] [MainThread]: Postgres adapter: Postgres error: syntax error at or near "None"
LINE 3:     None
            ^

06:06:30.579252 [debug] [MainThread]: Postgres adapter: Error running SQL: macro run_recipe
06:06:30.579326 [debug] [MainThread]: Postgres adapter: Rolling back transaction.
06:06:30.579415 [debug] [MainThread]: On macro_run_recipe: Close
06:06:30.579597 [error] [MainThread]: Encountered an error while running operation: Database Error
  syntax error at or near "None"
  LINE 3:     None
              ^
06:06:30.579782 [debug] [MainThread]: 
06:06:30.580591 [debug] [MainThread]: Connection 'macro_run_recipe' was properly closed.


============================== 2022-02-20 06:07:13.161850 | 93aec54d-bab9-4a82-9cc3-fcb74b88e99f ==============================
06:07:13.161850 [info ] [MainThread]: Running with dbt=1.0.1
06:07:13.162241 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/hassanzaheer/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, macro='run_recipe', args='{\n    "recipe_type" : "collect_fact",\n    "target_fact" : {\n        "id": "calls", \n        "entity_and_dims": "call_id",\n        "date":"time_call_end"\n    },\n    "ingredients": {\n        "expression_extract": {  \n            "source_raw": "testsatmap.calltable",\n            "expression_list": [\n                {"expression": "call_id", "alias": "call_id"},\n                {"expression": "to_timestamp(call_start_epoch)", "alias": "time_call_start"},\n                {"expression": "to_timestamp(call_start_epoch + call_duration)", "alias": "time_call_end"},\n                {"expression": "call_duration", "alias": "num_duration_seconds"},\n                {"expression": "trim(customer_id)",  "alias": "customer_id"},\n                {"expression": "lower(trim(agent_id))",  "alias": "agent_id"}\n            ]\n        },\n        "expression_extract_outer": {  \n            "expression_list": [\n                {"expression": "round(num_duration_seconds/60,2)", "alias": "num_duration_minutes"}\n            ]\n        },\n        "filter_conjunctions": [\n            "agent_id is not null",\n            "customer_id is not null",\n            "num_duration_seconds > 10"\n        ],\n        "incremental_update_on": "time_call_start",\n        "deduplication": {\n            "grouping_key": "call_id",\n            "preference": "arbitrary"\n        }\n    }\n}', defer=None, state=None, cls=<class 'dbt.task.run_operation.RunOperationTask'>, which='run-operation', rpc_method='run-operation')
06:07:13.162372 [debug] [MainThread]: Tracking: do not track
06:07:13.181299 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
06:07:13.181453 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
06:07:13.186445 [debug] [MainThread]: Acquiring new postgres connection "macro_run_recipe"
06:07:13.186556 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:07:13.186617 [debug] [MainThread]: On macro_run_recipe: BEGIN
06:07:13.186673 [debug] [MainThread]: Opening a new connection, currently in state init
06:07:13.211746 [debug] [MainThread]: SQL status: BEGIN in 0.03 seconds
06:07:13.211864 [debug] [MainThread]: On macro_run_recipe: COMMIT
06:07:13.211934 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:07:13.211994 [debug] [MainThread]: On macro_run_recipe: COMMIT
06:07:13.212135 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
06:07:13.253275 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:07:13.253382 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    
select 
    column_name||'::'||
        case when replace(udt_name, '_','') = 'bit' then 'int'
            when replace(udt_name, '_','') like 'int8%' then 'bigint'
            when replace(udt_name, '_','') like 'int4%' then 'int'
            when replace(udt_name, '_','') like 'int%' then 'smallint'
            when replace(udt_name, '_','') like 'bool%' then 'int'
            when replace(udt_name, '_','') like 'float%' then 'numeric'
            when replace(udt_name, '_','') like 'float%' then 'numeric'
            when replace(udt_name, '_','') like 'byte%' then 'text'
            when replace(udt_name, '_','') like 'varchar%' then 'text'
            when replace(udt_name, '_','') like 'timestamp%' then 'timestamp'
            else replace(udt_name, '_','') end ||
       ' as "'||column_name||'"' select_text
from information_schema.columns 
where table_schema||'.'||table_name = 'testsatmap.calltable'
order by ordinal_position
;
  
06:07:13.266935 [debug] [MainThread]: SQL status: SELECT 5 in 0.01 seconds
06:07:13.267798 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:07:13.267870 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    
create or replace view autopie_ebpdemo.tmp_staging_view_source_extract_0 as
select
    call_id::text as "call_id", 
    call_start_epoch::bigint as "call_start_epoch", 
    call_duration::int as "call_duration", 
    customer_id::text as "customer_id", 
    agent_id::text as "agent_id" 
from testsatmap.calltable
;
  
06:07:13.270626 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:07:13.271116 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:07:13.271178 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type cascade;
  
06:07:13.271406 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:07:13.271877 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:07:13.271943 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_exp_type as select call_id as exp from autopie_ebpdemo.tmp_staging_view_source_extract_0 limit 1;
  
06:07:13.273225 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:07:13.273729 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:07:13.273793 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select replace(udt_name, '_','') as dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type' and column_name = 'exp';
  
06:07:13.277502 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
06:07:13.278024 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:07:13.278096 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type cascade;
  
06:07:13.279199 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:07:13.279691 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:07:13.279759 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type cascade;
  
06:07:13.279966 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:07:13.280441 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:07:13.280504 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_exp_type as select to_timestamp(call_start_epoch) as exp from autopie_ebpdemo.tmp_staging_view_source_extract_0 limit 1;
  
06:07:13.281449 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:07:13.282043 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:07:13.282107 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select replace(udt_name, '_','') as dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type' and column_name = 'exp';
  
06:07:13.285306 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
06:07:13.285817 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:07:13.285880 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type cascade;
  
06:07:13.286572 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:07:13.287057 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:07:13.287120 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type cascade;
  
06:07:13.287321 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:07:13.287792 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:07:13.287857 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_exp_type as select to_timestamp(call_start_epoch + call_duration) as exp from autopie_ebpdemo.tmp_staging_view_source_extract_0 limit 1;
  
06:07:13.289084 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:07:13.289571 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:07:13.289643 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select replace(udt_name, '_','') as dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type' and column_name = 'exp';
  
06:07:13.293969 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
06:07:13.294516 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:07:13.294584 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type cascade;
  
06:07:13.295784 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:07:13.296294 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:07:13.296387 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type cascade;
  
06:07:13.296639 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:07:13.297150 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:07:13.297218 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_exp_type as select call_duration as exp from autopie_ebpdemo.tmp_staging_view_source_extract_0 limit 1;
  
06:07:13.298387 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:07:13.298909 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:07:13.298980 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select replace(udt_name, '_','') as dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type' and column_name = 'exp';
  
06:07:13.303185 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
06:07:13.303723 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:07:13.303793 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type cascade;
  
06:07:13.304659 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:07:13.305175 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:07:13.305242 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type cascade;
  
06:07:13.305597 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:07:13.306113 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:07:13.306181 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_exp_type as select trim(customer_id) as exp from autopie_ebpdemo.tmp_staging_view_source_extract_0 limit 1;
  
06:07:13.307829 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:07:13.308348 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:07:13.308416 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select replace(udt_name, '_','') as dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type' and column_name = 'exp';
  
06:07:13.312688 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
06:07:13.313224 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:07:13.313294 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type cascade;
  
06:07:13.314168 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:07:13.314685 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:07:13.314752 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type cascade;
  
06:07:13.314994 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:07:13.315504 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:07:13.315574 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_exp_type as select lower(trim(agent_id)) as exp from autopie_ebpdemo.tmp_staging_view_source_extract_0 limit 1;
  
06:07:13.316742 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:07:13.317256 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:07:13.317323 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select replace(udt_name, '_','') as dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type' and column_name = 'exp';
  
06:07:13.321631 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
06:07:13.322218 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:07:13.322294 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type cascade;
  
06:07:13.323169 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:07:13.323731 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:07:13.323804 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    
create or replace view autopie_ebpdemo.tmp_staging_view_expression_extract_1 as
select
    (call_id)::text as call_id, 
    (to_timestamp(call_start_epoch))::timestamptz as time_call_start, 
    (to_timestamp(call_start_epoch + call_duration))::timestamptz as time_call_end, 
    (call_duration)::int4 as num_duration_seconds, 
    (trim(customer_id))::text as customer_id, 
    (lower(trim(agent_id)))::text as agent_id 
from autopie_ebpdemo.tmp_staging_view_source_extract_0
;
  
06:07:13.325580 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:07:13.326145 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:07:13.326217 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type cascade;
  
06:07:13.326469 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:07:13.327020 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:07:13.327093 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_exp_type as select round(num_duration_seconds/60,2) as exp from autopie_ebpdemo.tmp_staging_view_expression_extract_1 limit 1;
  
06:07:13.328428 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:07:13.328986 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:07:13.329059 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select replace(udt_name, '_','') as dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type' and column_name = 'exp';
  
06:07:13.333250 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
06:07:13.333964 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:07:13.334038 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type cascade;
  
06:07:13.334907 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:07:13.336491 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:07:13.336569 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    
drop view if exists autopie_ebpdemo.tmp_staging_view_source_extract_0 cascade;
drop view if exists autopie_ebpdemo.tmp_staging_view_expression_extract_1 cascade;
  
06:07:13.337928 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:07:13.338460 [info ] [MainThread]: 





create or replace view autopie_ebpdemo.tmp_staging_view_source_extract_0 as
select
    call_id::text as "call_id", 
    call_start_epoch::bigint as "call_start_epoch", 
    call_duration::int as "call_duration", 
    customer_id::text as "customer_id", 
    agent_id::text as "agent_id" 
from testsatmap.calltable
;


create or replace view autopie_ebpdemo.tmp_staging_view_expression_extract_1 as
select
    (call_id)::text as call_id, 
    (to_timestamp(call_start_epoch))::timestamptz as time_call_start, 
    (to_timestamp(call_start_epoch + call_duration))::timestamptz as time_call_end, 
    (call_duration)::int4 as num_duration_seconds, 
    (trim(customer_id))::text as customer_id, 
    (lower(trim(agent_id)))::text as agent_id 
from autopie_ebpdemo.tmp_staging_view_source_extract_0
;

drop table if exists autopie_ebpdemo.tmp_staging_fact_calls;
create table autopie_ebpdemo.tmp_staging_fact_calls as
(
    with expression_extract_1 as
    (
        select * from autopie_ebpdemo.tmp_staging_view_expression_extract_1
    ),
    expression_extract_2 as
    (
        select  t.*,
                (round(num_duration_seconds/60,2))::numeric as num_duration_minutes
        from expression_extract_1 t
    ),
    filter_3 as
    (
        select /* filtering irrelevant records out */ *
        from expression_extract_2
        where 1=1
        and agent_id is not null
        and customer_id is not null
        and num_duration_seconds > 10
    ),
    incremental_extract_4 as
    (
        select /* retrieving incremental data - by date range only */ *
        from filter_3
        where time_call_start >= to_date('1900-01-01', 'YYYY-MM-DD')
          and time_call_start  < to_date('2100-01-01', 'YYYY-MM-DD')
    ),
    deduplication_5 as
    (
        select /* deduplicate by strategy */
            call_id
            , max(time_call_start) as time_call_start
            , max(time_call_end) as time_call_end
            , max(num_duration_seconds) as num_duration_seconds
            , max(customer_id) as customer_id
            , max(agent_id) as agent_id
            , max(num_duration_minutes) as num_duration_minutes
        from incremental_extract_4
        group by call_id 
    ),
    coarsening_6 as
    (
        select * from deduplication_5
    )
    select * from coarsening_6
)
;

drop view if exists autopie_ebpdemo.tmp_staging_view_source_extract_0 cascade;
drop view if exists autopie_ebpdemo.tmp_staging_view_expression_extract_1 cascade;

-- check if not exists already, this should run once
do $$                  
begin
if not exists
( 
    select 1 from information_schema.tables 
    where table_schema||'.'|| table_name = 'autopie_ebpdemo.obj_fact_calls'
)
then
    create table autopie_ebpdemo.obj_fact_calls as (select * from autopie_ebpdemo.tmp_staging_fact_calls where 1=0);
    alter  table autopie_ebpdemo.obj_fact_calls add column row_id bigserial not null;
    alter  table autopie_ebpdemo.obj_fact_calls add primary key (call_id, time_call_end);
    --
    create index ixrid_obj_fact_calls on autopie_ebpdemo.obj_fact_calls(row_id);
end if;
end
$$;

-- upsert staging additions into the permanent fact object
delete from autopie_ebpdemo.obj_fact_calls where (call_id, time_call_end) in (select call_id, time_call_end from autopie_ebpdemo.tmp_staging_fact_calls);
insert into autopie_ebpdemo.obj_fact_calls select * from autopie_ebpdemo.tmp_staging_fact_calls;
drop table autopie_ebpdemo.tmp_staging_fact_calls;


06:07:13.338865 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:07:13.338937 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    





create or replace view autopie_ebpdemo.tmp_staging_view_source_extract_0 as
select
    call_id::text as "call_id", 
    call_start_epoch::bigint as "call_start_epoch", 
    call_duration::int as "call_duration", 
    customer_id::text as "customer_id", 
    agent_id::text as "agent_id" 
from testsatmap.calltable
;


create or replace view autopie_ebpdemo.tmp_staging_view_expression_extract_1 as
select
    (call_id)::text as call_id, 
    (to_timestamp(call_start_epoch))::timestamptz as time_call_start, 
    (to_timestamp(call_start_epoch + call_duration))::timestamptz as time_call_end, 
    (call_duration)::int4 as num_duration_seconds, 
    (trim(customer_id))::text as customer_id, 
    (lower(trim(agent_id)))::text as agent_id 
from autopie_ebpdemo.tmp_staging_view_source_extract_0
;

drop table if exists autopie_ebpdemo.tmp_staging_fact_calls;
create table autopie_ebpdemo.tmp_staging_fact_calls as
(
    with expression_extract_1 as
    (
        select * from autopie_ebpdemo.tmp_staging_view_expression_extract_1
    ),
    expression_extract_2 as
    (
        select  t.*,
                (round(num_duration_seconds/60,2))::numeric as num_duration_minutes
        from expression_extract_1 t
    ),
    filter_3 as
    (
        select /* filtering irrelevant records out */ *
        from expression_extract_2
        where 1=1
        and agent_id is not null
        and customer_id is not null
        and num_duration_seconds > 10
    ),
    incremental_extract_4 as
    (
        select /* retrieving incremental data - by date range only */ *
        from filter_3
        where time_call_start >= to_date('1900-01-01', 'YYYY-MM-DD')
          and time_call_start  < to_date('2100-01-01', 'YYYY-MM-DD')
    ),
    deduplication_5 as
    (
        select /* deduplicate by strategy */
            call_id
            , max(time_call_start) as time_call_start
            , max(time_call_end) as time_call_end
            , max(num_duration_seconds) as num_duration_seconds
            , max(customer_id) as customer_id
            , max(agent_id) as agent_id
            , max(num_duration_minutes) as num_duration_minutes
        from incremental_extract_4
        group by call_id 
    ),
    coarsening_6 as
    (
        select * from deduplication_5
    )
    select * from coarsening_6
)
;

drop view if exists autopie_ebpdemo.tmp_staging_view_source_extract_0 cascade;
drop view if exists autopie_ebpdemo.tmp_staging_view_expression_extract_1 cascade;

-- check if not exists already, this should run once
do $$                  
begin
if not exists
( 
    select 1 from information_schema.tables 
    where table_schema||'.'|| table_name = 'autopie_ebpdemo.obj_fact_calls'
)
then
    create table autopie_ebpdemo.obj_fact_calls as (select * from autopie_ebpdemo.tmp_staging_fact_calls where 1=0);
    alter  table autopie_ebpdemo.obj_fact_calls add column row_id bigserial not null;
    alter  table autopie_ebpdemo.obj_fact_calls add primary key (call_id, time_call_end);
    --
    create index ixrid_obj_fact_calls on autopie_ebpdemo.obj_fact_calls(row_id);
end if;
end
$$;

-- upsert staging additions into the permanent fact object
delete from autopie_ebpdemo.obj_fact_calls where (call_id, time_call_end) in (select call_id, time_call_end from autopie_ebpdemo.tmp_staging_fact_calls);
insert into autopie_ebpdemo.obj_fact_calls select * from autopie_ebpdemo.tmp_staging_fact_calls;
drop table autopie_ebpdemo.tmp_staging_fact_calls;


  
06:07:13.369467 [debug] [MainThread]: SQL status: DROP TABLE in 0.03 seconds
06:07:13.370237 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:07:13.370330 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    None
  
06:07:13.370759 [debug] [MainThread]: Postgres adapter: Postgres error: syntax error at or near "None"
LINE 3:     None
            ^

06:07:13.370925 [debug] [MainThread]: Postgres adapter: Error running SQL: macro run_recipe
06:07:13.371003 [debug] [MainThread]: Postgres adapter: Rolling back transaction.
06:07:13.371098 [debug] [MainThread]: On macro_run_recipe: Close
06:07:13.371282 [error] [MainThread]: Encountered an error while running operation: Database Error
  syntax error at or near "None"
  LINE 3:     None
              ^
06:07:13.371474 [debug] [MainThread]: 
06:07:13.372304 [debug] [MainThread]: Connection 'macro_run_recipe' was properly closed.


============================== 2022-02-20 06:08:17.159306 | 06508289-8e88-4189-b0ef-c03cbaf0960f ==============================
06:08:17.159306 [info ] [MainThread]: Running with dbt=1.0.1
06:08:17.159817 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/hassanzaheer/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, macro='run_recipe', args='{\n    "recipe_type" : "collect_fact",\n    "target_fact" : {\n        "id": "calls", \n        "entity_and_dims": "call_id",\n        "date":"time_call_end"\n    },\n    "ingredients": {\n        "expression_extract": {  \n            "source_raw": "testsatmap.calltable",\n            "expression_list": [\n                {"expression": "call_id", "alias": "call_id"},\n                {"expression": "to_timestamp(call_start_epoch)", "alias": "time_call_start"},\n                {"expression": "to_timestamp(call_start_epoch + call_duration)", "alias": "time_call_end"},\n                {"expression": "call_duration", "alias": "num_duration_seconds"},\n                {"expression": "trim(customer_id)",  "alias": "customer_id"},\n                {"expression": "lower(trim(agent_id))",  "alias": "agent_id"}\n            ]\n        },\n        "expression_extract_outer": {  \n            "expression_list": [\n                {"expression": "round(num_duration_seconds/60,2)", "alias": "num_duration_minutes"}\n            ]\n        },\n        "filter_conjunctions": [\n            "agent_id is not null",\n            "customer_id is not null",\n            "num_duration_seconds > 10"\n        ],\n        "incremental_update_on": "time_call_start",\n        "deduplication": {\n            "grouping_key": "call_id",\n            "preference": "arbitrary"\n        }\n    }\n}', defer=None, state=None, cls=<class 'dbt.task.run_operation.RunOperationTask'>, which='run-operation', rpc_method='run-operation')
06:08:17.159929 [debug] [MainThread]: Tracking: do not track
06:08:17.181265 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
06:08:17.181531 [debug] [MainThread]: Partial parsing: updated file: demo_autopie://macros/core/run_recipe.sql
06:08:17.181623 [debug] [MainThread]: Parsing macros/core/run_directory.sql
06:08:17.183479 [debug] [MainThread]: Parsing macros/core/run_recipe.sql
06:08:17.195866 [debug] [MainThread]: Acquiring new postgres connection "macro_run_recipe"
06:08:17.195990 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:08:17.196055 [debug] [MainThread]: On macro_run_recipe: BEGIN
06:08:17.196116 [debug] [MainThread]: Opening a new connection, currently in state init
06:08:17.231862 [debug] [MainThread]: SQL status: BEGIN in 0.04 seconds
06:08:17.231989 [debug] [MainThread]: On macro_run_recipe: COMMIT
06:08:17.232060 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:08:17.232122 [debug] [MainThread]: On macro_run_recipe: COMMIT
06:08:17.232283 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
06:08:17.277674 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:08:17.277789 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    
select 
    column_name||'::'||
        case when replace(udt_name, '_','') = 'bit' then 'int'
            when replace(udt_name, '_','') like 'int8%' then 'bigint'
            when replace(udt_name, '_','') like 'int4%' then 'int'
            when replace(udt_name, '_','') like 'int%' then 'smallint'
            when replace(udt_name, '_','') like 'bool%' then 'int'
            when replace(udt_name, '_','') like 'float%' then 'numeric'
            when replace(udt_name, '_','') like 'float%' then 'numeric'
            when replace(udt_name, '_','') like 'byte%' then 'text'
            when replace(udt_name, '_','') like 'varchar%' then 'text'
            when replace(udt_name, '_','') like 'timestamp%' then 'timestamp'
            else replace(udt_name, '_','') end ||
       ' as "'||column_name||'"' select_text
from information_schema.columns 
where table_schema||'.'||table_name = 'testsatmap.calltable'
order by ordinal_position
;
  
06:08:17.294875 [debug] [MainThread]: SQL status: SELECT 5 in 0.02 seconds
06:08:17.295819 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:08:17.295902 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    
create or replace view autopie_ebpdemo.tmp_staging_view_source_extract_0 as
select
    call_id::text as "call_id", 
    call_start_epoch::bigint as "call_start_epoch", 
    call_duration::int as "call_duration", 
    customer_id::text as "customer_id", 
    agent_id::text as "agent_id" 
from testsatmap.calltable
;
  
06:08:17.299661 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:08:17.300218 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:08:17.300287 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type cascade;
  
06:08:17.300529 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:08:17.301025 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:08:17.301092 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_exp_type as select call_id as exp from autopie_ebpdemo.tmp_staging_view_source_extract_0 limit 1;
  
06:08:17.302034 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:08:17.302525 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:08:17.302591 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select replace(udt_name, '_','') as dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type' and column_name = 'exp';
  
06:08:17.306092 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
06:08:17.306614 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:08:17.306678 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type cascade;
  
06:08:17.307754 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:08:17.308240 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:08:17.308303 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type cascade;
  
06:08:17.308502 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:08:17.308986 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:08:17.309051 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_exp_type as select to_timestamp(call_start_epoch) as exp from autopie_ebpdemo.tmp_staging_view_source_extract_0 limit 1;
  
06:08:17.310361 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:08:17.311015 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:08:17.311085 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select replace(udt_name, '_','') as dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type' and column_name = 'exp';
  
06:08:17.314600 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
06:08:17.315150 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:08:17.315220 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type cascade;
  
06:08:17.315935 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:08:17.316455 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:08:17.316524 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type cascade;
  
06:08:17.316718 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:08:17.317231 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:08:17.317299 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_exp_type as select to_timestamp(call_start_epoch + call_duration) as exp from autopie_ebpdemo.tmp_staging_view_source_extract_0 limit 1;
  
06:08:17.318253 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:08:17.318771 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:08:17.318841 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select replace(udt_name, '_','') as dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type' and column_name = 'exp';
  
06:08:17.322024 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
06:08:17.322564 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:08:17.322635 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type cascade;
  
06:08:17.323343 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:08:17.323872 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:08:17.323941 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type cascade;
  
06:08:17.324205 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:08:17.324723 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:08:17.324793 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_exp_type as select call_duration as exp from autopie_ebpdemo.tmp_staging_view_source_extract_0 limit 1;
  
06:08:17.325669 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:08:17.326188 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:08:17.326255 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select replace(udt_name, '_','') as dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type' and column_name = 'exp';
  
06:08:17.329437 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
06:08:17.329981 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:08:17.330050 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type cascade;
  
06:08:17.330751 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:08:17.331277 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:08:17.331346 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type cascade;
  
06:08:17.331661 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:08:17.332180 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:08:17.332249 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_exp_type as select trim(customer_id) as exp from autopie_ebpdemo.tmp_staging_view_source_extract_0 limit 1;
  
06:08:17.333513 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:08:17.334028 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:08:17.334098 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select replace(udt_name, '_','') as dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type' and column_name = 'exp';
  
06:08:17.340354 [debug] [MainThread]: SQL status: SELECT 1 in 0.01 seconds
06:08:17.340890 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:08:17.340962 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type cascade;
  
06:08:17.341724 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:08:17.342241 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:08:17.342309 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type cascade;
  
06:08:17.342511 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:08:17.343029 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:08:17.343103 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_exp_type as select lower(trim(agent_id)) as exp from autopie_ebpdemo.tmp_staging_view_source_extract_0 limit 1;
  
06:08:17.344041 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:08:17.344609 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:08:17.344685 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select replace(udt_name, '_','') as dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type' and column_name = 'exp';
  
06:08:17.348003 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
06:08:17.348592 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:08:17.348670 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type cascade;
  
06:08:17.349367 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:08:17.349930 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:08:17.350007 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    
create or replace view autopie_ebpdemo.tmp_staging_view_expression_extract_1 as
select
    (call_id)::text as call_id, 
    (to_timestamp(call_start_epoch))::timestamptz as time_call_start, 
    (to_timestamp(call_start_epoch + call_duration))::timestamptz as time_call_end, 
    (call_duration)::int4 as num_duration_seconds, 
    (trim(customer_id))::text as customer_id, 
    (lower(trim(agent_id)))::text as agent_id 
from autopie_ebpdemo.tmp_staging_view_source_extract_0
;
  
06:08:17.351390 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:08:17.351952 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:08:17.352027 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type cascade;
  
06:08:17.352232 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:08:17.352783 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:08:17.352861 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_exp_type as select round(num_duration_seconds/60,2) as exp from autopie_ebpdemo.tmp_staging_view_expression_extract_1 limit 1;
  
06:08:17.353915 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:08:17.354479 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:08:17.354556 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select replace(udt_name, '_','') as dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type' and column_name = 'exp';
  
06:08:17.357669 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
06:08:17.358386 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:08:17.358461 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type cascade;
  
06:08:17.359128 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:08:17.360936 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:08:17.361018 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    
drop view if exists autopie_ebpdemo.tmp_staging_view_source_extract_0 cascade;
drop view if exists autopie_ebpdemo.tmp_staging_view_expression_extract_1 cascade;
  
06:08:17.361821 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:08:17.362359 [info ] [MainThread]: 





create or replace view autopie_ebpdemo.tmp_staging_view_source_extract_0 as
select
    call_id::text as "call_id", 
    call_start_epoch::bigint as "call_start_epoch", 
    call_duration::int as "call_duration", 
    customer_id::text as "customer_id", 
    agent_id::text as "agent_id" 
from testsatmap.calltable
;


create or replace view autopie_ebpdemo.tmp_staging_view_expression_extract_1 as
select
    (call_id)::text as call_id, 
    (to_timestamp(call_start_epoch))::timestamptz as time_call_start, 
    (to_timestamp(call_start_epoch + call_duration))::timestamptz as time_call_end, 
    (call_duration)::int4 as num_duration_seconds, 
    (trim(customer_id))::text as customer_id, 
    (lower(trim(agent_id)))::text as agent_id 
from autopie_ebpdemo.tmp_staging_view_source_extract_0
;

drop table if exists autopie_ebpdemo.tmp_staging_fact_calls;
create table autopie_ebpdemo.tmp_staging_fact_calls as
(
    with expression_extract_1 as
    (
        select * from autopie_ebpdemo.tmp_staging_view_expression_extract_1
    ),
    expression_extract_2 as
    (
        select  t.*,
                (round(num_duration_seconds/60,2))::numeric as num_duration_minutes
        from expression_extract_1 t
    ),
    filter_3 as
    (
        select /* filtering irrelevant records out */ *
        from expression_extract_2
        where 1=1
        and agent_id is not null
        and customer_id is not null
        and num_duration_seconds > 10
    ),
    incremental_extract_4 as
    (
        select /* retrieving incremental data - by date range only */ *
        from filter_3
        where time_call_start >= to_date('1900-01-01', 'YYYY-MM-DD')
          and time_call_start  < to_date('2100-01-01', 'YYYY-MM-DD')
    ),
    deduplication_5 as
    (
        select /* deduplicate by strategy */
            call_id
            , max(time_call_start) as time_call_start
            , max(time_call_end) as time_call_end
            , max(num_duration_seconds) as num_duration_seconds
            , max(customer_id) as customer_id
            , max(agent_id) as agent_id
            , max(num_duration_minutes) as num_duration_minutes
        from incremental_extract_4
        group by call_id 
    ),
    coarsening_6 as
    (
        select * from deduplication_5
    )
    select * from coarsening_6
)
;

drop view if exists autopie_ebpdemo.tmp_staging_view_source_extract_0 cascade;
drop view if exists autopie_ebpdemo.tmp_staging_view_expression_extract_1 cascade;

-- check if not exists already, this should run once
do $$                  
begin
if not exists
( 
    select 1 from information_schema.tables 
    where table_schema||'.'|| table_name = 'autopie_ebpdemo.obj_fact_calls'
)
then
    create table autopie_ebpdemo.obj_fact_calls as (select * from autopie_ebpdemo.tmp_staging_fact_calls where 1=0);
    alter  table autopie_ebpdemo.obj_fact_calls add column row_id bigserial not null;
    alter  table autopie_ebpdemo.obj_fact_calls add primary key (call_id, time_call_end);
    --
    create index ixrid_obj_fact_calls on autopie_ebpdemo.obj_fact_calls(row_id);
end if;
end
$$;

-- upsert staging additions into the permanent fact object
delete from autopie_ebpdemo.obj_fact_calls where (call_id, time_call_end) in (select call_id, time_call_end from autopie_ebpdemo.tmp_staging_fact_calls);
insert into autopie_ebpdemo.obj_fact_calls select * from autopie_ebpdemo.tmp_staging_fact_calls;
drop table autopie_ebpdemo.tmp_staging_fact_calls;


06:08:17.362766 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:08:17.362840 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    





create or replace view autopie_ebpdemo.tmp_staging_view_source_extract_0 as
select
    call_id::text as "call_id", 
    call_start_epoch::bigint as "call_start_epoch", 
    call_duration::int as "call_duration", 
    customer_id::text as "customer_id", 
    agent_id::text as "agent_id" 
from testsatmap.calltable
;


create or replace view autopie_ebpdemo.tmp_staging_view_expression_extract_1 as
select
    (call_id)::text as call_id, 
    (to_timestamp(call_start_epoch))::timestamptz as time_call_start, 
    (to_timestamp(call_start_epoch + call_duration))::timestamptz as time_call_end, 
    (call_duration)::int4 as num_duration_seconds, 
    (trim(customer_id))::text as customer_id, 
    (lower(trim(agent_id)))::text as agent_id 
from autopie_ebpdemo.tmp_staging_view_source_extract_0
;

drop table if exists autopie_ebpdemo.tmp_staging_fact_calls;
create table autopie_ebpdemo.tmp_staging_fact_calls as
(
    with expression_extract_1 as
    (
        select * from autopie_ebpdemo.tmp_staging_view_expression_extract_1
    ),
    expression_extract_2 as
    (
        select  t.*,
                (round(num_duration_seconds/60,2))::numeric as num_duration_minutes
        from expression_extract_1 t
    ),
    filter_3 as
    (
        select /* filtering irrelevant records out */ *
        from expression_extract_2
        where 1=1
        and agent_id is not null
        and customer_id is not null
        and num_duration_seconds > 10
    ),
    incremental_extract_4 as
    (
        select /* retrieving incremental data - by date range only */ *
        from filter_3
        where time_call_start >= to_date('1900-01-01', 'YYYY-MM-DD')
          and time_call_start  < to_date('2100-01-01', 'YYYY-MM-DD')
    ),
    deduplication_5 as
    (
        select /* deduplicate by strategy */
            call_id
            , max(time_call_start) as time_call_start
            , max(time_call_end) as time_call_end
            , max(num_duration_seconds) as num_duration_seconds
            , max(customer_id) as customer_id
            , max(agent_id) as agent_id
            , max(num_duration_minutes) as num_duration_minutes
        from incremental_extract_4
        group by call_id 
    ),
    coarsening_6 as
    (
        select * from deduplication_5
    )
    select * from coarsening_6
)
;

drop view if exists autopie_ebpdemo.tmp_staging_view_source_extract_0 cascade;
drop view if exists autopie_ebpdemo.tmp_staging_view_expression_extract_1 cascade;

-- check if not exists already, this should run once
do $$                  
begin
if not exists
( 
    select 1 from information_schema.tables 
    where table_schema||'.'|| table_name = 'autopie_ebpdemo.obj_fact_calls'
)
then
    create table autopie_ebpdemo.obj_fact_calls as (select * from autopie_ebpdemo.tmp_staging_fact_calls where 1=0);
    alter  table autopie_ebpdemo.obj_fact_calls add column row_id bigserial not null;
    alter  table autopie_ebpdemo.obj_fact_calls add primary key (call_id, time_call_end);
    --
    create index ixrid_obj_fact_calls on autopie_ebpdemo.obj_fact_calls(row_id);
end if;
end
$$;

-- upsert staging additions into the permanent fact object
delete from autopie_ebpdemo.obj_fact_calls where (call_id, time_call_end) in (select call_id, time_call_end from autopie_ebpdemo.tmp_staging_fact_calls);
insert into autopie_ebpdemo.obj_fact_calls select * from autopie_ebpdemo.tmp_staging_fact_calls;
drop table autopie_ebpdemo.tmp_staging_fact_calls;


  
06:08:17.390588 [debug] [MainThread]: SQL status: DROP TABLE in 0.03 seconds
06:08:17.391357 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:08:17.391453 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    
select row_number() over (order by autopie_run_id desc) run_sequence, count(*) count_records 
  from autopie_ebpdemo.obj_fact_calls
group by autopie_run_id
order by 1 
limit 5;

  
06:08:17.391965 [debug] [MainThread]: Postgres adapter: Postgres error: column "autopie_run_id" does not exist
LINE 6: group by autopie_run_id
                 ^

06:08:17.392130 [debug] [MainThread]: Postgres adapter: Error running SQL: macro run_recipe
06:08:17.392208 [debug] [MainThread]: Postgres adapter: Rolling back transaction.
06:08:17.392308 [debug] [MainThread]: On macro_run_recipe: Close
06:08:17.392493 [error] [MainThread]: Encountered an error while running operation: Database Error
  column "autopie_run_id" does not exist
  LINE 6: group by autopie_run_id
                   ^
06:08:17.392683 [debug] [MainThread]: 
06:08:17.393370 [debug] [MainThread]: Connection 'macro_run_recipe' was properly closed.


============================== 2022-02-20 06:09:29.845741 | 1222c76c-0e51-44ed-8c97-88592ab59f07 ==============================
06:09:29.845741 [info ] [MainThread]: Running with dbt=1.0.1
06:09:29.846304 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/hassanzaheer/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, macro='run_recipe', args='{\n    "recipe_type" : "collect_fact",\n    "target_fact" : {\n        "id": "calls", \n        "entity_and_dims": "call_id",\n        "date":"time_call_end"\n    },\n    "ingredients": {\n        "expression_extract": {  \n            "source_raw": "testsatmap.calltable",\n            "expression_list": [\n                {"expression": "call_id", "alias": "call_id"},\n                {"expression": "to_timestamp(call_start_epoch)", "alias": "time_call_start"},\n                {"expression": "to_timestamp(call_start_epoch + call_duration)", "alias": "time_call_end"},\n                {"expression": "call_duration", "alias": "num_duration_seconds"},\n                {"expression": "trim(customer_id)",  "alias": "customer_id"},\n                {"expression": "lower(trim(agent_id))",  "alias": "agent_id"}\n            ]\n        },\n        "expression_extract_outer": {  \n            "expression_list": [\n                {"expression": "round(num_duration_seconds/60,2)", "alias": "num_duration_minutes"}\n            ]\n        },\n        "filter_conjunctions": [\n            "agent_id is not null",\n            "customer_id is not null",\n            "num_duration_seconds > 10"\n        ],\n        "incremental_update_on": "time_call_start",\n        "deduplication": {\n            "grouping_key": "call_id",\n            "preference": "arbitrary"\n        }\n    }\n}', defer=None, state=None, cls=<class 'dbt.task.run_operation.RunOperationTask'>, which='run-operation', rpc_method='run-operation')
06:09:29.846416 [debug] [MainThread]: Tracking: do not track
06:09:29.868925 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
06:09:29.869082 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
06:09:29.874128 [debug] [MainThread]: Acquiring new postgres connection "macro_run_recipe"
06:09:29.874239 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:09:29.874303 [debug] [MainThread]: On macro_run_recipe: BEGIN
06:09:29.874360 [debug] [MainThread]: Opening a new connection, currently in state init
06:09:29.909805 [debug] [MainThread]: SQL status: BEGIN in 0.04 seconds
06:09:29.909949 [debug] [MainThread]: On macro_run_recipe: COMMIT
06:09:29.910018 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:09:29.910081 [debug] [MainThread]: On macro_run_recipe: COMMIT
06:09:29.910289 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
06:09:29.955507 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:09:29.955666 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    
select 
    column_name||'::'||
        case when replace(udt_name, '_','') = 'bit' then 'int'
            when replace(udt_name, '_','') like 'int8%' then 'bigint'
            when replace(udt_name, '_','') like 'int4%' then 'int'
            when replace(udt_name, '_','') like 'int%' then 'smallint'
            when replace(udt_name, '_','') like 'bool%' then 'int'
            when replace(udt_name, '_','') like 'float%' then 'numeric'
            when replace(udt_name, '_','') like 'float%' then 'numeric'
            when replace(udt_name, '_','') like 'byte%' then 'text'
            when replace(udt_name, '_','') like 'varchar%' then 'text'
            when replace(udt_name, '_','') like 'timestamp%' then 'timestamp'
            else replace(udt_name, '_','') end ||
       ' as "'||column_name||'"' select_text
from information_schema.columns 
where table_schema||'.'||table_name = 'testsatmap.calltable'
order by ordinal_position
;
  
06:09:29.969925 [debug] [MainThread]: SQL status: SELECT 5 in 0.01 seconds
06:09:29.970834 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:09:29.970918 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    
create or replace view autopie_ebpdemo.tmp_staging_view_source_extract_0 as
select
    call_id::text as "call_id", 
    call_start_epoch::bigint as "call_start_epoch", 
    call_duration::int as "call_duration", 
    customer_id::text as "customer_id", 
    agent_id::text as "agent_id" 
from testsatmap.calltable
;
  
06:09:29.974248 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:09:29.974777 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:09:29.974849 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type cascade;
  
06:09:29.975078 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:09:29.975567 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:09:29.975634 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_exp_type as select call_id as exp from autopie_ebpdemo.tmp_staging_view_source_extract_0 limit 1;
  
06:09:29.976523 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:09:29.977004 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:09:29.977068 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select replace(udt_name, '_','') as dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type' and column_name = 'exp';
  
06:09:29.980601 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
06:09:29.981095 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:09:29.981159 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type cascade;
  
06:09:29.982214 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:09:29.982687 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:09:29.982752 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type cascade;
  
06:09:29.982952 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:09:29.983417 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:09:29.983483 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_exp_type as select to_timestamp(call_start_epoch) as exp from autopie_ebpdemo.tmp_staging_view_source_extract_0 limit 1;
  
06:09:29.984432 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:09:29.985032 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:09:29.985098 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select replace(udt_name, '_','') as dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type' and column_name = 'exp';
  
06:09:29.988379 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
06:09:29.988931 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:09:29.989003 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type cascade;
  
06:09:29.989776 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:09:29.990302 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:09:29.990374 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type cascade;
  
06:09:29.990580 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:09:29.991097 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:09:29.991168 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_exp_type as select to_timestamp(call_start_epoch + call_duration) as exp from autopie_ebpdemo.tmp_staging_view_source_extract_0 limit 1;
  
06:09:29.992436 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:09:29.992960 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:09:29.993032 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select replace(udt_name, '_','') as dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type' and column_name = 'exp';
  
06:09:29.997235 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
06:09:29.997779 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:09:29.997851 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type cascade;
  
06:09:29.998769 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:09:29.999298 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:09:29.999368 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type cascade;
  
06:09:29.999605 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:09:30.000122 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:09:30.000195 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_exp_type as select call_duration as exp from autopie_ebpdemo.tmp_staging_view_source_extract_0 limit 1;
  
06:09:30.001293 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:09:30.001816 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:09:30.001887 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select replace(udt_name, '_','') as dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type' and column_name = 'exp';
  
06:09:30.006593 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
06:09:30.007142 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:09:30.007216 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type cascade;
  
06:09:30.008129 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:09:30.008657 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:09:30.008728 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type cascade;
  
06:09:30.009070 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:09:30.009594 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:09:30.009665 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_exp_type as select trim(customer_id) as exp from autopie_ebpdemo.tmp_staging_view_source_extract_0 limit 1;
  
06:09:30.011120 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:09:30.011637 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:09:30.011715 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select replace(udt_name, '_','') as dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type' and column_name = 'exp';
  
06:09:30.016108 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
06:09:30.016653 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:09:30.016725 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type cascade;
  
06:09:30.017420 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:09:30.017947 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:09:30.018019 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type cascade;
  
06:09:30.018221 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:09:30.018734 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:09:30.018806 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_exp_type as select lower(trim(agent_id)) as exp from autopie_ebpdemo.tmp_staging_view_source_extract_0 limit 1;
  
06:09:30.019892 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:09:30.020459 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:09:30.020540 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select replace(udt_name, '_','') as dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type' and column_name = 'exp';
  
06:09:30.023691 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
06:09:30.024279 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:09:30.024358 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type cascade;
  
06:09:30.025193 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:09:30.025758 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:09:30.025839 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    
create or replace view autopie_ebpdemo.tmp_staging_view_expression_extract_1 as
select
    (call_id)::text as call_id, 
    (to_timestamp(call_start_epoch))::timestamptz as time_call_start, 
    (to_timestamp(call_start_epoch + call_duration))::timestamptz as time_call_end, 
    (call_duration)::int4 as num_duration_seconds, 
    (trim(customer_id))::text as customer_id, 
    (lower(trim(agent_id)))::text as agent_id 
from autopie_ebpdemo.tmp_staging_view_source_extract_0
;
  
06:09:30.027360 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:09:30.027929 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:09:30.028011 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type cascade;
  
06:09:30.028257 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:09:30.028818 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:09:30.028895 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_exp_type as select round(num_duration_seconds/60,2) as exp from autopie_ebpdemo.tmp_staging_view_expression_extract_1 limit 1;
  
06:09:30.030492 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:09:30.031059 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:09:30.031136 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select replace(udt_name, '_','') as dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type' and column_name = 'exp';
  
06:09:30.035319 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
06:09:30.036158 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:09:30.036237 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type cascade;
  
06:09:30.037096 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:09:30.038982 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:09:30.039065 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    
drop view if exists autopie_ebpdemo.tmp_staging_view_source_extract_0 cascade;
drop view if exists autopie_ebpdemo.tmp_staging_view_expression_extract_1 cascade;
  
06:09:30.040266 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:09:30.040805 [info ] [MainThread]: 





create or replace view autopie_ebpdemo.tmp_staging_view_source_extract_0 as
select
    call_id::text as "call_id", 
    call_start_epoch::bigint as "call_start_epoch", 
    call_duration::int as "call_duration", 
    customer_id::text as "customer_id", 
    agent_id::text as "agent_id" 
from testsatmap.calltable
;


create or replace view autopie_ebpdemo.tmp_staging_view_expression_extract_1 as
select
    (call_id)::text as call_id, 
    (to_timestamp(call_start_epoch))::timestamptz as time_call_start, 
    (to_timestamp(call_start_epoch + call_duration))::timestamptz as time_call_end, 
    (call_duration)::int4 as num_duration_seconds, 
    (trim(customer_id))::text as customer_id, 
    (lower(trim(agent_id)))::text as agent_id 
from autopie_ebpdemo.tmp_staging_view_source_extract_0
;

drop table if exists autopie_ebpdemo.tmp_staging_fact_calls;
create table autopie_ebpdemo.tmp_staging_fact_calls as
(
    with expression_extract_1 as
    (
        select * from autopie_ebpdemo.tmp_staging_view_expression_extract_1
    ),
    expression_extract_2 as
    (
        select  t.*,
                (round(num_duration_seconds/60,2))::numeric as num_duration_minutes
        from expression_extract_1 t
    ),
    filter_3 as
    (
        select /* filtering irrelevant records out */ *
        from expression_extract_2
        where 1=1
        and agent_id is not null
        and customer_id is not null
        and num_duration_seconds > 10
    ),
    incremental_extract_4 as
    (
        select /* retrieving incremental data - by date range only */ *
        from filter_3
        where time_call_start >= to_date('1900-01-01', 'YYYY-MM-DD')
          and time_call_start  < to_date('2100-01-01', 'YYYY-MM-DD')
    ),
    deduplication_5 as
    (
        select /* deduplicate by strategy */
            call_id
            , max(time_call_start) as time_call_start
            , max(time_call_end) as time_call_end
            , max(num_duration_seconds) as num_duration_seconds
            , max(customer_id) as customer_id
            , max(agent_id) as agent_id
            , max(num_duration_minutes) as num_duration_minutes
        from incremental_extract_4
        group by call_id 
    ),
    coarsening_6 as
    (
        select * from deduplication_5
    )
    select * from coarsening_6
)
;

drop view if exists autopie_ebpdemo.tmp_staging_view_source_extract_0 cascade;
drop view if exists autopie_ebpdemo.tmp_staging_view_expression_extract_1 cascade;

-- check if not exists already, this should run once
do $$                  
begin
if not exists
( 
    select 1 from information_schema.tables 
    where table_schema||'.'|| table_name = 'autopie_ebpdemo.obj_fact_calls'
)
then
    create table autopie_ebpdemo.obj_fact_calls as (select * from autopie_ebpdemo.tmp_staging_fact_calls where 1=0);
    alter  table autopie_ebpdemo.obj_fact_calls add column row_id bigserial not null;
    alter  table autopie_ebpdemo.obj_fact_calls add primary key (call_id, time_call_end);
    --
    create index ixrid_obj_fact_calls on autopie_ebpdemo.obj_fact_calls(row_id);
end if;
end
$$;

-- upsert staging additions into the permanent fact object
delete from autopie_ebpdemo.obj_fact_calls where (call_id, time_call_end) in (select call_id, time_call_end from autopie_ebpdemo.tmp_staging_fact_calls);
insert into autopie_ebpdemo.obj_fact_calls select * from autopie_ebpdemo.tmp_staging_fact_calls;
drop table autopie_ebpdemo.tmp_staging_fact_calls;


06:09:30.041221 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:09:30.041293 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    





create or replace view autopie_ebpdemo.tmp_staging_view_source_extract_0 as
select
    call_id::text as "call_id", 
    call_start_epoch::bigint as "call_start_epoch", 
    call_duration::int as "call_duration", 
    customer_id::text as "customer_id", 
    agent_id::text as "agent_id" 
from testsatmap.calltable
;


create or replace view autopie_ebpdemo.tmp_staging_view_expression_extract_1 as
select
    (call_id)::text as call_id, 
    (to_timestamp(call_start_epoch))::timestamptz as time_call_start, 
    (to_timestamp(call_start_epoch + call_duration))::timestamptz as time_call_end, 
    (call_duration)::int4 as num_duration_seconds, 
    (trim(customer_id))::text as customer_id, 
    (lower(trim(agent_id)))::text as agent_id 
from autopie_ebpdemo.tmp_staging_view_source_extract_0
;

drop table if exists autopie_ebpdemo.tmp_staging_fact_calls;
create table autopie_ebpdemo.tmp_staging_fact_calls as
(
    with expression_extract_1 as
    (
        select * from autopie_ebpdemo.tmp_staging_view_expression_extract_1
    ),
    expression_extract_2 as
    (
        select  t.*,
                (round(num_duration_seconds/60,2))::numeric as num_duration_minutes
        from expression_extract_1 t
    ),
    filter_3 as
    (
        select /* filtering irrelevant records out */ *
        from expression_extract_2
        where 1=1
        and agent_id is not null
        and customer_id is not null
        and num_duration_seconds > 10
    ),
    incremental_extract_4 as
    (
        select /* retrieving incremental data - by date range only */ *
        from filter_3
        where time_call_start >= to_date('1900-01-01', 'YYYY-MM-DD')
          and time_call_start  < to_date('2100-01-01', 'YYYY-MM-DD')
    ),
    deduplication_5 as
    (
        select /* deduplicate by strategy */
            call_id
            , max(time_call_start) as time_call_start
            , max(time_call_end) as time_call_end
            , max(num_duration_seconds) as num_duration_seconds
            , max(customer_id) as customer_id
            , max(agent_id) as agent_id
            , max(num_duration_minutes) as num_duration_minutes
        from incremental_extract_4
        group by call_id 
    ),
    coarsening_6 as
    (
        select * from deduplication_5
    )
    select * from coarsening_6
)
;

drop view if exists autopie_ebpdemo.tmp_staging_view_source_extract_0 cascade;
drop view if exists autopie_ebpdemo.tmp_staging_view_expression_extract_1 cascade;

-- check if not exists already, this should run once
do $$                  
begin
if not exists
( 
    select 1 from information_schema.tables 
    where table_schema||'.'|| table_name = 'autopie_ebpdemo.obj_fact_calls'
)
then
    create table autopie_ebpdemo.obj_fact_calls as (select * from autopie_ebpdemo.tmp_staging_fact_calls where 1=0);
    alter  table autopie_ebpdemo.obj_fact_calls add column row_id bigserial not null;
    alter  table autopie_ebpdemo.obj_fact_calls add primary key (call_id, time_call_end);
    --
    create index ixrid_obj_fact_calls on autopie_ebpdemo.obj_fact_calls(row_id);
end if;
end
$$;

-- upsert staging additions into the permanent fact object
delete from autopie_ebpdemo.obj_fact_calls where (call_id, time_call_end) in (select call_id, time_call_end from autopie_ebpdemo.tmp_staging_fact_calls);
insert into autopie_ebpdemo.obj_fact_calls select * from autopie_ebpdemo.tmp_staging_fact_calls;
drop table autopie_ebpdemo.tmp_staging_fact_calls;


  
06:09:30.069390 [debug] [MainThread]: SQL status: DROP TABLE in 0.03 seconds
06:09:30.070137 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:09:30.070231 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    
select row_number() over (order by autopie_run_id desc) run_sequence, count(*) count_records 
  from autopie_ebpdemo.obj_fact_calls
group by autopie_run_id
order by 1 
limit 5;

  
06:09:30.070829 [debug] [MainThread]: Postgres adapter: Postgres error: column "autopie_run_id" does not exist
LINE 6: group by autopie_run_id
                 ^

06:09:30.070992 [debug] [MainThread]: Postgres adapter: Error running SQL: macro run_recipe
06:09:30.071071 [debug] [MainThread]: Postgres adapter: Rolling back transaction.
06:09:30.071165 [debug] [MainThread]: On macro_run_recipe: Close
06:09:30.071345 [error] [MainThread]: Encountered an error while running operation: Database Error
  column "autopie_run_id" does not exist
  LINE 6: group by autopie_run_id
                   ^
06:09:30.071548 [debug] [MainThread]: 
06:09:30.072192 [debug] [MainThread]: Connection 'macro_run_recipe' was properly closed.


============================== 2022-02-20 06:10:09.204219 | 038edacb-8139-4d07-9abc-36a60bd2b94c ==============================
06:10:09.204219 [info ] [MainThread]: Running with dbt=1.0.1
06:10:09.204606 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/hassanzaheer/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, macro='run_recipe', args='{\n    "recipe_type" : "collect_fact",\n    "target_fact" : {\n        "id": "calls", \n        "entity_and_dims": "call_id",\n        "date":"time_call_end"\n    },\n    "ingredients": {\n        "expression_extract": {  \n            "source_raw": "testsatmap.calltable",\n            "expression_list": [\n                {"expression": "call_id", "alias": "call_id"},\n                {"expression": "to_timestamp(call_start_epoch)", "alias": "time_call_start"},\n                {"expression": "to_timestamp(call_start_epoch + call_duration)", "alias": "time_call_end"},\n                {"expression": "call_duration", "alias": "num_duration_seconds"},\n                {"expression": "trim(customer_id)",  "alias": "customer_id"},\n                {"expression": "lower(trim(agent_id))",  "alias": "agent_id"}\n            ]\n        },\n        "expression_extract_outer": {  \n            "expression_list": [\n                {"expression": "round(num_duration_seconds/60,2)", "alias": "num_duration_minutes"}\n            ]\n        },\n        "filter_conjunctions": [\n            "agent_id is not null",\n            "customer_id is not null",\n            "num_duration_seconds > 10"\n        ],\n        "incremental_update_on": "time_call_start",\n        "deduplication": {\n            "grouping_key": "call_id",\n            "preference": "arbitrary"\n        }\n    }\n}', defer=None, state=None, cls=<class 'dbt.task.run_operation.RunOperationTask'>, which='run-operation', rpc_method='run-operation')
06:10:09.204719 [debug] [MainThread]: Tracking: do not track
06:10:09.225728 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
06:10:09.225903 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
06:10:09.230990 [debug] [MainThread]: Acquiring new postgres connection "macro_run_recipe"
06:10:09.231094 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:10:09.231163 [debug] [MainThread]: On macro_run_recipe: BEGIN
06:10:09.231227 [debug] [MainThread]: Opening a new connection, currently in state init
06:10:09.252502 [debug] [MainThread]: SQL status: BEGIN in 0.02 seconds
06:10:09.252637 [debug] [MainThread]: On macro_run_recipe: COMMIT
06:10:09.252708 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:10:09.252789 [debug] [MainThread]: On macro_run_recipe: COMMIT
06:10:09.252957 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
06:10:09.296628 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:10:09.296780 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    
select 
    column_name||'::'||
        case when replace(udt_name, '_','') = 'bit' then 'int'
            when replace(udt_name, '_','') like 'int8%' then 'bigint'
            when replace(udt_name, '_','') like 'int4%' then 'int'
            when replace(udt_name, '_','') like 'int%' then 'smallint'
            when replace(udt_name, '_','') like 'bool%' then 'int'
            when replace(udt_name, '_','') like 'float%' then 'numeric'
            when replace(udt_name, '_','') like 'float%' then 'numeric'
            when replace(udt_name, '_','') like 'byte%' then 'text'
            when replace(udt_name, '_','') like 'varchar%' then 'text'
            when replace(udt_name, '_','') like 'timestamp%' then 'timestamp'
            else replace(udt_name, '_','') end ||
       ' as "'||column_name||'"' select_text
from information_schema.columns 
where table_schema||'.'||table_name = 'testsatmap.calltable'
order by ordinal_position
;
  
06:10:09.308687 [debug] [MainThread]: SQL status: SELECT 5 in 0.01 seconds
06:10:09.309627 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:10:09.309714 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    
create or replace view autopie_ebpdemo.tmp_staging_view_source_extract_0 as
select
    call_id::text as "call_id", 
    call_start_epoch::bigint as "call_start_epoch", 
    call_duration::int as "call_duration", 
    customer_id::text as "customer_id", 
    agent_id::text as "agent_id" 
from testsatmap.calltable
;
  
06:10:09.314056 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:10:09.314577 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:10:09.314646 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type cascade;
  
06:10:09.314995 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:10:09.315601 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:10:09.315682 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_exp_type as select call_id as exp from autopie_ebpdemo.tmp_staging_view_source_extract_0 limit 1;
  
06:10:09.316713 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:10:09.317202 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:10:09.317269 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select replace(udt_name, '_','') as dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type' and column_name = 'exp';
  
06:10:09.322156 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
06:10:09.322652 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:10:09.322717 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type cascade;
  
06:10:09.324105 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:10:09.324606 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:10:09.324671 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type cascade;
  
06:10:09.324858 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:10:09.325336 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:10:09.325404 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_exp_type as select to_timestamp(call_start_epoch) as exp from autopie_ebpdemo.tmp_staging_view_source_extract_0 limit 1;
  
06:10:09.327084 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:10:09.327706 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:10:09.327773 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select replace(udt_name, '_','') as dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type' and column_name = 'exp';
  
06:10:09.332487 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
06:10:09.333026 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:10:09.333097 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type cascade;
  
06:10:09.334101 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:10:09.334592 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:10:09.334660 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type cascade;
  
06:10:09.334897 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:10:09.335376 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:10:09.335442 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_exp_type as select to_timestamp(call_start_epoch + call_duration) as exp from autopie_ebpdemo.tmp_staging_view_source_extract_0 limit 1;
  
06:10:09.336981 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:10:09.337480 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:10:09.337547 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select replace(udt_name, '_','') as dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type' and column_name = 'exp';
  
06:10:09.341424 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
06:10:09.342005 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:10:09.342080 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type cascade;
  
06:10:09.343016 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:10:09.343546 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:10:09.343618 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type cascade;
  
06:10:09.344413 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:10:09.344933 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:10:09.345005 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_exp_type as select call_duration as exp from autopie_ebpdemo.tmp_staging_view_source_extract_0 limit 1;
  
06:10:09.349546 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:10:09.350099 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:10:09.350175 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select replace(udt_name, '_','') as dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type' and column_name = 'exp';
  
06:10:09.355292 [debug] [MainThread]: SQL status: SELECT 1 in 0.01 seconds
06:10:09.355854 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:10:09.355928 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type cascade;
  
06:10:09.356748 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:10:09.357309 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:10:09.357391 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type cascade;
  
06:10:09.357711 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:10:09.358248 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:10:09.358321 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_exp_type as select trim(customer_id) as exp from autopie_ebpdemo.tmp_staging_view_source_extract_0 limit 1;
  
06:10:09.359074 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:10:09.359613 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:10:09.359685 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select replace(udt_name, '_','') as dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type' and column_name = 'exp';
  
06:10:09.363218 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
06:10:09.363767 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:10:09.363842 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type cascade;
  
06:10:09.364919 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:10:09.365440 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:10:09.365513 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type cascade;
  
06:10:09.365776 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:10:09.366298 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:10:09.366374 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_exp_type as select lower(trim(agent_id)) as exp from autopie_ebpdemo.tmp_staging_view_source_extract_0 limit 1;
  
06:10:09.367981 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:10:09.368509 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:10:09.368582 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select replace(udt_name, '_','') as dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type' and column_name = 'exp';
  
06:10:09.374064 [debug] [MainThread]: SQL status: SELECT 1 in 0.01 seconds
06:10:09.374765 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:10:09.374852 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type cascade;
  
06:10:09.375477 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:10:09.376172 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:10:09.376261 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    
create or replace view autopie_ebpdemo.tmp_staging_view_expression_extract_1 as
select
    (call_id)::text as call_id, 
    (to_timestamp(call_start_epoch))::timestamptz as time_call_start, 
    (to_timestamp(call_start_epoch + call_duration))::timestamptz as time_call_end, 
    (call_duration)::int4 as num_duration_seconds, 
    (trim(customer_id))::text as customer_id, 
    (lower(trim(agent_id)))::text as agent_id 
from autopie_ebpdemo.tmp_staging_view_source_extract_0
;
  
06:10:09.378316 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:10:09.378912 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:10:09.378996 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type cascade;
  
06:10:09.379185 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:10:09.379755 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:10:09.379851 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_exp_type as select round(num_duration_seconds/60,2) as exp from autopie_ebpdemo.tmp_staging_view_expression_extract_1 limit 1;
  
06:10:09.381331 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:10:09.381998 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:10:09.382081 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select replace(udt_name, '_','') as dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type' and column_name = 'exp';
  
06:10:09.384331 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
06:10:09.385211 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:10:09.385291 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type cascade;
  
06:10:09.386218 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:10:09.387872 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:10:09.387953 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    
drop view if exists autopie_ebpdemo.tmp_staging_view_source_extract_0 cascade;
drop view if exists autopie_ebpdemo.tmp_staging_view_expression_extract_1 cascade;
  
06:10:09.390263 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:10:09.390831 [info ] [MainThread]: 





create or replace view autopie_ebpdemo.tmp_staging_view_source_extract_0 as
select
    call_id::text as "call_id", 
    call_start_epoch::bigint as "call_start_epoch", 
    call_duration::int as "call_duration", 
    customer_id::text as "customer_id", 
    agent_id::text as "agent_id" 
from testsatmap.calltable
;


create or replace view autopie_ebpdemo.tmp_staging_view_expression_extract_1 as
select
    (call_id)::text as call_id, 
    (to_timestamp(call_start_epoch))::timestamptz as time_call_start, 
    (to_timestamp(call_start_epoch + call_duration))::timestamptz as time_call_end, 
    (call_duration)::int4 as num_duration_seconds, 
    (trim(customer_id))::text as customer_id, 
    (lower(trim(agent_id)))::text as agent_id 
from autopie_ebpdemo.tmp_staging_view_source_extract_0
;

drop table if exists autopie_ebpdemo.tmp_staging_fact_calls;
create table autopie_ebpdemo.tmp_staging_fact_calls as
(
    with expression_extract_1 as
    (
        select * from autopie_ebpdemo.tmp_staging_view_expression_extract_1
    ),
    expression_extract_2 as
    (
        select  t.*,
                (round(num_duration_seconds/60,2))::numeric as num_duration_minutes
        from expression_extract_1 t
    ),
    filter_3 as
    (
        select /* filtering irrelevant records out */ *
        from expression_extract_2
        where 1=1
        and agent_id is not null
        and customer_id is not null
        and num_duration_seconds > 10
    ),
    incremental_extract_4 as
    (
        select /* retrieving incremental data - by date range only */ *
        from filter_3
        where time_call_start >= to_date('1900-01-01', 'YYYY-MM-DD')
          and time_call_start  < to_date('2100-01-01', 'YYYY-MM-DD')
    ),
    deduplication_5 as
    (
        select /* deduplicate by strategy */
            call_id
            , max(time_call_start) as time_call_start
            , max(time_call_end) as time_call_end
            , max(num_duration_seconds) as num_duration_seconds
            , max(customer_id) as customer_id
            , max(agent_id) as agent_id
            , max(num_duration_minutes) as num_duration_minutes
        from incremental_extract_4
        group by call_id 
    ),
    coarsening_6 as
    (
        select * from deduplication_5
    )
    select * from coarsening_6
)
;

drop view if exists autopie_ebpdemo.tmp_staging_view_source_extract_0 cascade;
drop view if exists autopie_ebpdemo.tmp_staging_view_expression_extract_1 cascade;

-- check if not exists already, this should run once
do $$                  
begin
if not exists
( 
    select 1 from information_schema.tables 
    where table_schema||'.'|| table_name = 'autopie_ebpdemo.obj_fact_calls'
)
then
    create table autopie_ebpdemo.obj_fact_calls as (select * from autopie_ebpdemo.tmp_staging_fact_calls where 1=0);
    alter  table autopie_ebpdemo.obj_fact_calls add column row_id bigserial not null;
    alter  table autopie_ebpdemo.obj_fact_calls add primary key (call_id, time_call_end);
    --
    create index ixrid_obj_fact_calls on autopie_ebpdemo.obj_fact_calls(row_id);
end if;
end
$$;

-- upsert staging additions into the permanent fact object
delete from autopie_ebpdemo.obj_fact_calls where (call_id, time_call_end) in (select call_id, time_call_end from autopie_ebpdemo.tmp_staging_fact_calls);
insert into autopie_ebpdemo.obj_fact_calls select * from autopie_ebpdemo.tmp_staging_fact_calls;
drop table autopie_ebpdemo.tmp_staging_fact_calls;


06:10:09.391257 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:10:09.391334 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    





create or replace view autopie_ebpdemo.tmp_staging_view_source_extract_0 as
select
    call_id::text as "call_id", 
    call_start_epoch::bigint as "call_start_epoch", 
    call_duration::int as "call_duration", 
    customer_id::text as "customer_id", 
    agent_id::text as "agent_id" 
from testsatmap.calltable
;


create or replace view autopie_ebpdemo.tmp_staging_view_expression_extract_1 as
select
    (call_id)::text as call_id, 
    (to_timestamp(call_start_epoch))::timestamptz as time_call_start, 
    (to_timestamp(call_start_epoch + call_duration))::timestamptz as time_call_end, 
    (call_duration)::int4 as num_duration_seconds, 
    (trim(customer_id))::text as customer_id, 
    (lower(trim(agent_id)))::text as agent_id 
from autopie_ebpdemo.tmp_staging_view_source_extract_0
;

drop table if exists autopie_ebpdemo.tmp_staging_fact_calls;
create table autopie_ebpdemo.tmp_staging_fact_calls as
(
    with expression_extract_1 as
    (
        select * from autopie_ebpdemo.tmp_staging_view_expression_extract_1
    ),
    expression_extract_2 as
    (
        select  t.*,
                (round(num_duration_seconds/60,2))::numeric as num_duration_minutes
        from expression_extract_1 t
    ),
    filter_3 as
    (
        select /* filtering irrelevant records out */ *
        from expression_extract_2
        where 1=1
        and agent_id is not null
        and customer_id is not null
        and num_duration_seconds > 10
    ),
    incremental_extract_4 as
    (
        select /* retrieving incremental data - by date range only */ *
        from filter_3
        where time_call_start >= to_date('1900-01-01', 'YYYY-MM-DD')
          and time_call_start  < to_date('2100-01-01', 'YYYY-MM-DD')
    ),
    deduplication_5 as
    (
        select /* deduplicate by strategy */
            call_id
            , max(time_call_start) as time_call_start
            , max(time_call_end) as time_call_end
            , max(num_duration_seconds) as num_duration_seconds
            , max(customer_id) as customer_id
            , max(agent_id) as agent_id
            , max(num_duration_minutes) as num_duration_minutes
        from incremental_extract_4
        group by call_id 
    ),
    coarsening_6 as
    (
        select * from deduplication_5
    )
    select * from coarsening_6
)
;

drop view if exists autopie_ebpdemo.tmp_staging_view_source_extract_0 cascade;
drop view if exists autopie_ebpdemo.tmp_staging_view_expression_extract_1 cascade;

-- check if not exists already, this should run once
do $$                  
begin
if not exists
( 
    select 1 from information_schema.tables 
    where table_schema||'.'|| table_name = 'autopie_ebpdemo.obj_fact_calls'
)
then
    create table autopie_ebpdemo.obj_fact_calls as (select * from autopie_ebpdemo.tmp_staging_fact_calls where 1=0);
    alter  table autopie_ebpdemo.obj_fact_calls add column row_id bigserial not null;
    alter  table autopie_ebpdemo.obj_fact_calls add primary key (call_id, time_call_end);
    --
    create index ixrid_obj_fact_calls on autopie_ebpdemo.obj_fact_calls(row_id);
end if;
end
$$;

-- upsert staging additions into the permanent fact object
delete from autopie_ebpdemo.obj_fact_calls where (call_id, time_call_end) in (select call_id, time_call_end from autopie_ebpdemo.tmp_staging_fact_calls);
insert into autopie_ebpdemo.obj_fact_calls select * from autopie_ebpdemo.tmp_staging_fact_calls;
drop table autopie_ebpdemo.tmp_staging_fact_calls;


  
06:10:09.416131 [debug] [MainThread]: SQL status: DROP TABLE in 0.02 seconds
06:10:09.417019 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:10:09.417128 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    
select row_number() over (order by autopie_run_id desc) run_sequence, count(*) count_records 
  from autopie_ebpdemo.obj_fact_calls
group by autopie_run_id
order by 1 
limit 5;

  
06:10:09.417680 [debug] [MainThread]: Postgres adapter: Postgres error: column "autopie_run_id" does not exist
LINE 6: group by autopie_run_id
                 ^

06:10:09.417854 [debug] [MainThread]: Postgres adapter: Error running SQL: macro run_recipe
06:10:09.417943 [debug] [MainThread]: Postgres adapter: Rolling back transaction.
06:10:09.418041 [debug] [MainThread]: On macro_run_recipe: Close
06:10:09.418235 [error] [MainThread]: Encountered an error while running operation: Database Error
  column "autopie_run_id" does not exist
  LINE 6: group by autopie_run_id
                   ^
06:10:09.418441 [debug] [MainThread]: 
06:10:09.419163 [debug] [MainThread]: Connection 'macro_run_recipe' was properly closed.


============================== 2022-02-20 06:11:50.139189 | 8fbc1999-b91b-4d01-8505-6b83e52917ad ==============================
06:11:50.139189 [info ] [MainThread]: Running with dbt=1.0.1
06:11:50.139579 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/hassanzaheer/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, macro='run_recipe', args='{\n    "recipe_type" : "collect_fact",\n    "target_fact" : {\n        "id": "calls", \n        "entity_and_dims": "call_id",\n        "date":"time_call_end"\n    },\n    "ingredients": {\n        "expression_extract": {  \n            "source_raw": "testsatmap.calltable",\n            "expression_list": [\n                {"expression": "call_id", "alias": "call_id"},\n                {"expression": "to_timestamp(call_start_epoch)", "alias": "time_call_start"},\n                {"expression": "to_timestamp(call_start_epoch + call_duration)", "alias": "time_call_end"},\n                {"expression": "call_duration", "alias": "num_duration_seconds"},\n                {"expression": "trim(customer_id)",  "alias": "customer_id"},\n                {"expression": "lower(trim(agent_id))",  "alias": "agent_id"}\n            ]\n        },\n        "expression_extract_outer": {  \n            "expression_list": [\n                {"expression": "round(num_duration_seconds/60,2)", "alias": "num_duration_minutes"}\n            ]\n        },\n        "filter_conjunctions": [\n            "agent_id is not null",\n            "customer_id is not null",\n            "num_duration_seconds > 10"\n        ],\n        "incremental_update_on": "time_call_start",\n        "deduplication": {\n            "grouping_key": "call_id",\n            "preference": "arbitrary"\n        }\n    }\n}', defer=None, state=None, cls=<class 'dbt.task.run_operation.RunOperationTask'>, which='run-operation', rpc_method='run-operation')
06:11:50.139702 [debug] [MainThread]: Tracking: do not track
06:11:50.159537 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
06:11:50.159831 [debug] [MainThread]: Partial parsing: updated file: demo_autopie://macros/core/run_recipe.sql
06:11:50.159933 [debug] [MainThread]: Parsing macros/core/run_directory.sql
06:11:50.161470 [debug] [MainThread]: Parsing macros/core/run_recipe.sql
06:11:50.173962 [debug] [MainThread]: Acquiring new postgres connection "macro_run_recipe"
06:11:50.174065 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:11:50.174128 [debug] [MainThread]: On macro_run_recipe: BEGIN
06:11:50.174185 [debug] [MainThread]: Opening a new connection, currently in state init
06:11:50.196656 [debug] [MainThread]: SQL status: BEGIN in 0.02 seconds
06:11:50.196766 [debug] [MainThread]: On macro_run_recipe: COMMIT
06:11:50.196836 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:11:50.196896 [debug] [MainThread]: On macro_run_recipe: COMMIT
06:11:50.197254 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
06:11:50.240699 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:11:50.240825 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    
select 
    column_name||'::'||
        case when replace(udt_name, '_','') = 'bit' then 'int'
            when replace(udt_name, '_','') like 'int8%' then 'bigint'
            when replace(udt_name, '_','') like 'int4%' then 'int'
            when replace(udt_name, '_','') like 'int%' then 'smallint'
            when replace(udt_name, '_','') like 'bool%' then 'int'
            when replace(udt_name, '_','') like 'float%' then 'numeric'
            when replace(udt_name, '_','') like 'float%' then 'numeric'
            when replace(udt_name, '_','') like 'byte%' then 'text'
            when replace(udt_name, '_','') like 'varchar%' then 'text'
            when replace(udt_name, '_','') like 'timestamp%' then 'timestamp'
            else replace(udt_name, '_','') end ||
       ' as "'||column_name||'"' select_text
from information_schema.columns 
where table_schema||'.'||table_name = 'testsatmap.calltable'
order by ordinal_position
;
  
06:11:50.254791 [debug] [MainThread]: SQL status: SELECT 5 in 0.01 seconds
06:11:50.255616 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:11:50.255686 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    
create or replace view autopie_ebpdemo.tmp_staging_view_source_extract_0 as
select
    call_id::text as "call_id", 
    call_start_epoch::bigint as "call_start_epoch", 
    call_duration::int as "call_duration", 
    customer_id::text as "customer_id", 
    agent_id::text as "agent_id" 
from testsatmap.calltable
;
  
06:11:50.258074 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:11:50.258582 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:11:50.258649 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type cascade;
  
06:11:50.258876 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:11:50.259351 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:11:50.259412 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_exp_type as select call_id as exp from autopie_ebpdemo.tmp_staging_view_source_extract_0 limit 1;
  
06:11:50.260686 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:11:50.261142 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:11:50.261202 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select replace(udt_name, '_','') as dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type' and column_name = 'exp';
  
06:11:50.264478 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
06:11:50.264994 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:11:50.265064 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type cascade;
  
06:11:50.266125 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:11:50.266617 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:11:50.266681 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type cascade;
  
06:11:50.266878 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:11:50.267357 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:11:50.267423 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_exp_type as select to_timestamp(call_start_epoch) as exp from autopie_ebpdemo.tmp_staging_view_source_extract_0 limit 1;
  
06:11:50.268885 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:11:50.269489 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:11:50.269555 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select replace(udt_name, '_','') as dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type' and column_name = 'exp';
  
06:11:50.273614 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
06:11:50.274124 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:11:50.274188 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type cascade;
  
06:11:50.275118 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:11:50.275597 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:11:50.275661 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type cascade;
  
06:11:50.276131 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:11:50.276603 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:11:50.276667 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_exp_type as select to_timestamp(call_start_epoch + call_duration) as exp from autopie_ebpdemo.tmp_staging_view_source_extract_0 limit 1;
  
06:11:50.278197 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:11:50.278671 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:11:50.278736 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select replace(udt_name, '_','') as dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type' and column_name = 'exp';
  
06:11:50.283581 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
06:11:50.284124 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:11:50.284193 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type cascade;
  
06:11:50.285214 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:11:50.285737 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:11:50.285807 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type cascade;
  
06:11:50.286011 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:11:50.286543 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:11:50.286612 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_exp_type as select call_duration as exp from autopie_ebpdemo.tmp_staging_view_source_extract_0 limit 1;
  
06:11:50.287463 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:11:50.287980 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:11:50.288049 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select replace(udt_name, '_','') as dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type' and column_name = 'exp';
  
06:11:50.291240 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
06:11:50.291784 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:11:50.291852 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type cascade;
  
06:11:50.292547 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:11:50.293078 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:11:50.293147 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type cascade;
  
06:11:50.293461 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:11:50.293985 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:11:50.294056 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_exp_type as select trim(customer_id) as exp from autopie_ebpdemo.tmp_staging_view_source_extract_0 limit 1;
  
06:11:50.294991 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:11:50.295516 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:11:50.295586 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select replace(udt_name, '_','') as dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type' and column_name = 'exp';
  
06:11:50.298637 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
06:11:50.299180 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:11:50.299250 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type cascade;
  
06:11:50.299924 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:11:50.300452 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:11:50.300522 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type cascade;
  
06:11:50.300874 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:11:50.301393 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:11:50.301467 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_exp_type as select lower(trim(agent_id)) as exp from autopie_ebpdemo.tmp_staging_view_source_extract_0 limit 1;
  
06:11:50.302610 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:11:50.303127 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:11:50.303198 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select replace(udt_name, '_','') as dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type' and column_name = 'exp';
  
06:11:50.307275 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
06:11:50.307815 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:11:50.307884 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type cascade;
  
06:11:50.308773 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:11:50.309340 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:11:50.309416 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    
create or replace view autopie_ebpdemo.tmp_staging_view_expression_extract_1 as
select
    (call_id)::text as call_id, 
    (to_timestamp(call_start_epoch))::timestamptz as time_call_start, 
    (to_timestamp(call_start_epoch + call_duration))::timestamptz as time_call_end, 
    (call_duration)::int4 as num_duration_seconds, 
    (trim(customer_id))::text as customer_id, 
    (lower(trim(agent_id)))::text as agent_id 
from autopie_ebpdemo.tmp_staging_view_source_extract_0
;
  
06:11:50.311186 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:11:50.311759 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:11:50.311834 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type cascade;
  
06:11:50.312079 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:11:50.312638 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:11:50.312716 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_exp_type as select round(num_duration_seconds/60,2) as exp from autopie_ebpdemo.tmp_staging_view_expression_extract_1 limit 1;
  
06:11:50.314026 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:11:50.314590 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:11:50.314667 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select replace(udt_name, '_','') as dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type' and column_name = 'exp';
  
06:11:50.318932 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
06:11:50.319654 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:11:50.319731 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type cascade;
  
06:11:50.320688 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:11:50.322337 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:11:50.322428 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    
drop view if exists autopie_ebpdemo.tmp_staging_view_source_extract_0 cascade;
drop view if exists autopie_ebpdemo.tmp_staging_view_expression_extract_1 cascade;
  
06:11:50.323921 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:11:50.324464 [info ] [MainThread]: 





create or replace view autopie_ebpdemo.tmp_staging_view_source_extract_0 as
select
    call_id::text as "call_id", 
    call_start_epoch::bigint as "call_start_epoch", 
    call_duration::int as "call_duration", 
    customer_id::text as "customer_id", 
    agent_id::text as "agent_id" 
from testsatmap.calltable
;


create or replace view autopie_ebpdemo.tmp_staging_view_expression_extract_1 as
select
    (call_id)::text as call_id, 
    (to_timestamp(call_start_epoch))::timestamptz as time_call_start, 
    (to_timestamp(call_start_epoch + call_duration))::timestamptz as time_call_end, 
    (call_duration)::int4 as num_duration_seconds, 
    (trim(customer_id))::text as customer_id, 
    (lower(trim(agent_id)))::text as agent_id 
from autopie_ebpdemo.tmp_staging_view_source_extract_0
;

drop table if exists autopie_ebpdemo.tmp_staging_fact_calls;
create table autopie_ebpdemo.tmp_staging_fact_calls as
(
    with expression_extract_1 as
    (
        select * from autopie_ebpdemo.tmp_staging_view_expression_extract_1
    ),
    expression_extract_2 as
    (
        select  t.*,
                (round(num_duration_seconds/60,2))::numeric as num_duration_minutes
        from expression_extract_1 t
    ),
    filter_3 as
    (
        select /* filtering irrelevant records out */ *
        from expression_extract_2
        where 1=1
        and agent_id is not null
        and customer_id is not null
        and num_duration_seconds > 10
    ),
    incremental_extract_4 as
    (
        select /* retrieving incremental data - by date range only */ *
        from filter_3
        where time_call_start >= to_date('1900-01-01', 'YYYY-MM-DD')
          and time_call_start  < to_date('2100-01-01', 'YYYY-MM-DD')
    ),
    deduplication_5 as
    (
        select /* deduplicate by strategy */
            call_id
            , max(time_call_start) as time_call_start
            , max(time_call_end) as time_call_end
            , max(num_duration_seconds) as num_duration_seconds
            , max(customer_id) as customer_id
            , max(agent_id) as agent_id
            , max(num_duration_minutes) as num_duration_minutes
        from incremental_extract_4
        group by call_id 
    ),
    coarsening_6 as
    (
        select * from deduplication_5
    )
    select * from coarsening_6
)
;

drop view if exists autopie_ebpdemo.tmp_staging_view_source_extract_0 cascade;
drop view if exists autopie_ebpdemo.tmp_staging_view_expression_extract_1 cascade;

-- check if not exists already, this should run once
do $$                  
begin
if not exists
( 
    select 1 from information_schema.tables 
    where table_schema||'.'|| table_name = 'autopie_ebpdemo.obj_fact_calls'
)
then
    create table autopie_ebpdemo.obj_fact_calls as (select * from autopie_ebpdemo.tmp_staging_fact_calls where 1=0);
    alter  table autopie_ebpdemo.obj_fact_calls add column row_id bigserial not null;
    alter  table autopie_ebpdemo.obj_fact_calls add primary key (call_id, time_call_end);
    --
    create index ixrid_obj_fact_calls on autopie_ebpdemo.obj_fact_calls(row_id);
end if;
end
$$;

-- upsert staging additions into the permanent fact object
delete from autopie_ebpdemo.obj_fact_calls where (call_id, time_call_end) in (select call_id, time_call_end from autopie_ebpdemo.tmp_staging_fact_calls);
insert into autopie_ebpdemo.obj_fact_calls select * from autopie_ebpdemo.tmp_staging_fact_calls;
drop table autopie_ebpdemo.tmp_staging_fact_calls;


06:11:50.324883 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:11:50.324955 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    





create or replace view autopie_ebpdemo.tmp_staging_view_source_extract_0 as
select
    call_id::text as "call_id", 
    call_start_epoch::bigint as "call_start_epoch", 
    call_duration::int as "call_duration", 
    customer_id::text as "customer_id", 
    agent_id::text as "agent_id" 
from testsatmap.calltable
;


create or replace view autopie_ebpdemo.tmp_staging_view_expression_extract_1 as
select
    (call_id)::text as call_id, 
    (to_timestamp(call_start_epoch))::timestamptz as time_call_start, 
    (to_timestamp(call_start_epoch + call_duration))::timestamptz as time_call_end, 
    (call_duration)::int4 as num_duration_seconds, 
    (trim(customer_id))::text as customer_id, 
    (lower(trim(agent_id)))::text as agent_id 
from autopie_ebpdemo.tmp_staging_view_source_extract_0
;

drop table if exists autopie_ebpdemo.tmp_staging_fact_calls;
create table autopie_ebpdemo.tmp_staging_fact_calls as
(
    with expression_extract_1 as
    (
        select * from autopie_ebpdemo.tmp_staging_view_expression_extract_1
    ),
    expression_extract_2 as
    (
        select  t.*,
                (round(num_duration_seconds/60,2))::numeric as num_duration_minutes
        from expression_extract_1 t
    ),
    filter_3 as
    (
        select /* filtering irrelevant records out */ *
        from expression_extract_2
        where 1=1
        and agent_id is not null
        and customer_id is not null
        and num_duration_seconds > 10
    ),
    incremental_extract_4 as
    (
        select /* retrieving incremental data - by date range only */ *
        from filter_3
        where time_call_start >= to_date('1900-01-01', 'YYYY-MM-DD')
          and time_call_start  < to_date('2100-01-01', 'YYYY-MM-DD')
    ),
    deduplication_5 as
    (
        select /* deduplicate by strategy */
            call_id
            , max(time_call_start) as time_call_start
            , max(time_call_end) as time_call_end
            , max(num_duration_seconds) as num_duration_seconds
            , max(customer_id) as customer_id
            , max(agent_id) as agent_id
            , max(num_duration_minutes) as num_duration_minutes
        from incremental_extract_4
        group by call_id 
    ),
    coarsening_6 as
    (
        select * from deduplication_5
    )
    select * from coarsening_6
)
;

drop view if exists autopie_ebpdemo.tmp_staging_view_source_extract_0 cascade;
drop view if exists autopie_ebpdemo.tmp_staging_view_expression_extract_1 cascade;

-- check if not exists already, this should run once
do $$                  
begin
if not exists
( 
    select 1 from information_schema.tables 
    where table_schema||'.'|| table_name = 'autopie_ebpdemo.obj_fact_calls'
)
then
    create table autopie_ebpdemo.obj_fact_calls as (select * from autopie_ebpdemo.tmp_staging_fact_calls where 1=0);
    alter  table autopie_ebpdemo.obj_fact_calls add column row_id bigserial not null;
    alter  table autopie_ebpdemo.obj_fact_calls add primary key (call_id, time_call_end);
    --
    create index ixrid_obj_fact_calls on autopie_ebpdemo.obj_fact_calls(row_id);
end if;
end
$$;

-- upsert staging additions into the permanent fact object
delete from autopie_ebpdemo.obj_fact_calls where (call_id, time_call_end) in (select call_id, time_call_end from autopie_ebpdemo.tmp_staging_fact_calls);
insert into autopie_ebpdemo.obj_fact_calls select * from autopie_ebpdemo.tmp_staging_fact_calls;
drop table autopie_ebpdemo.tmp_staging_fact_calls;


  
06:11:50.352774 [debug] [MainThread]: SQL status: DROP TABLE in 0.03 seconds
06:11:50.353533 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:11:50.353627 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    
select row_number() over (order by autopie_run_id desc) run_sequence, count(*) count_records 
  from autopie_ebpdemo.obj_fact_{'id': 'calls', 'entity_and_dims': 'call_id', 'date': 'time_call_end'}
group by autopie_run_id
order by 1
limit 5;

  
06:11:50.354061 [debug] [MainThread]: Postgres adapter: Postgres error: syntax error at or near "{"
LINE 5:   from autopie_ebpdemo.obj_fact_{'id': 'calls', 'entity_and_...
                                        ^

06:11:50.354231 [debug] [MainThread]: Postgres adapter: Error running SQL: macro run_recipe
06:11:50.354310 [debug] [MainThread]: Postgres adapter: Rolling back transaction.
06:11:50.354406 [debug] [MainThread]: On macro_run_recipe: Close
06:11:50.354586 [error] [MainThread]: Encountered an error while running operation: Database Error
  syntax error at or near "{"
  LINE 5:   from autopie_ebpdemo.obj_fact_{'id': 'calls', 'entity_and_...
                                          ^
06:11:50.354784 [debug] [MainThread]: 
06:11:50.355654 [debug] [MainThread]: Connection 'macro_run_recipe' was properly closed.


============================== 2022-02-20 06:13:19.063548 | 82559a83-0e6e-4ef1-b947-b8d4b3e1baea ==============================
06:13:19.063548 [info ] [MainThread]: Running with dbt=1.0.1
06:13:19.064083 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/hassanzaheer/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, macro='run_recipe', args='{\n    "recipe_type" : "collect_fact",\n    "target_fact" : {\n        "id": "calls", \n        "entity_and_dims": "call_id",\n        "date":"time_call_end"\n    },\n    "ingredients": {\n        "expression_extract": {  \n            "source_raw": "testsatmap.calltable",\n            "expression_list": [\n                {"expression": "call_id", "alias": "call_id"},\n                {"expression": "to_timestamp(call_start_epoch)", "alias": "time_call_start"},\n                {"expression": "to_timestamp(call_start_epoch + call_duration)", "alias": "time_call_end"},\n                {"expression": "call_duration", "alias": "num_duration_seconds"},\n                {"expression": "trim(customer_id)",  "alias": "customer_id"},\n                {"expression": "lower(trim(agent_id))",  "alias": "agent_id"}\n            ]\n        },\n        "expression_extract_outer": {  \n            "expression_list": [\n                {"expression": "round(num_duration_seconds/60,2)", "alias": "num_duration_minutes"}\n            ]\n        },\n        "filter_conjunctions": [\n            "agent_id is not null",\n            "customer_id is not null",\n            "num_duration_seconds > 10"\n        ],\n        "incremental_update_on": "time_call_start",\n        "deduplication": {\n            "grouping_key": "call_id",\n            "preference": "arbitrary"\n        }\n    }\n}', defer=None, state=None, cls=<class 'dbt.task.run_operation.RunOperationTask'>, which='run-operation', rpc_method='run-operation')
06:13:19.064207 [debug] [MainThread]: Tracking: do not track
06:13:19.083554 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
06:13:19.083857 [debug] [MainThread]: Partial parsing: updated file: demo_autopie://macros/compile_recipe_collect_fact.sql
06:13:19.083954 [debug] [MainThread]: Parsing macros/core/run_recipe.sql
06:13:19.087548 [debug] [MainThread]: Parsing macros/core/run_directory.sql
06:13:19.088747 [debug] [MainThread]: Parsing macros/compile_recipe_collect_fact.sql
06:13:19.138965 [debug] [MainThread]: Acquiring new postgres connection "macro_run_recipe"
06:13:19.139081 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:13:19.139149 [debug] [MainThread]: On macro_run_recipe: BEGIN
06:13:19.139211 [debug] [MainThread]: Opening a new connection, currently in state init
06:13:19.161844 [debug] [MainThread]: SQL status: BEGIN in 0.02 seconds
06:13:19.161943 [debug] [MainThread]: On macro_run_recipe: COMMIT
06:13:19.162009 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:13:19.162068 [debug] [MainThread]: On macro_run_recipe: COMMIT
06:13:19.162384 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
06:13:19.207392 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:13:19.207503 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select '"'||column_name||'"::'||
       case when replace(udt_name, '_','') = 'bit' then 'int'
            when replace(udt_name, '_','') like 'int8%' then 'bigint'
            when replace(udt_name, '_','') like 'int4%' then 'int'
            when replace(udt_name, '_','') like 'int%' then 'smallint'
            when replace(udt_name, '_','') like 'bool%' then 'int'
            when replace(udt_name, '_','') like 'float%' then 'numeric'
            when replace(udt_name, '_','') like 'float%' then 'numeric'
            when replace(udt_name, '_','') like 'byte%' then 'text'
            when replace(udt_name, '_','') like 'varchar%' then 'text'
            when replace(udt_name, '_','') like 'timestamp%' then 'timestamp'
            else replace(udt_name, '_','') end ||
       ' as "'||column_name||'"' select_text
from information_schema.columns 
where table_schema||'.'||table_name = 'testsatmap.calltable'
order by ordinal_position ;

  
06:13:19.221042 [debug] [MainThread]: SQL status: SELECT 5 in 0.01 seconds
06:13:19.221972 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:13:19.222059 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 as
select "call_id"::text as "call_id", 
       "call_start_epoch"::bigint as "call_start_epoch", 
       "call_duration"::int as "call_duration", 
       "customer_id"::text as "customer_id", 
       "agent_id"::text as "agent_id"
       from testsatmap.calltable;

  
06:13:19.224786 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:13:19.225300 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:13:19.225367 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:13:19.225588 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:13:19.226061 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:13:19.226125 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_exp_type_0000000000 as select call_id exp from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 limit 1
  
06:13:19.227068 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:13:19.227533 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:13:19.227596 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select replace(udt_name, '_','') dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type_0000000000' and column_name = 'exp'
  
06:13:19.230866 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
06:13:19.231350 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:13:19.231412 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:13:19.232488 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:13:19.232956 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:13:19.233018 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:13:19.233222 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:13:19.233707 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:13:19.233773 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_exp_type_0000000000 as select to_timestamp(call_start_epoch) exp from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 limit 1
  
06:13:19.235323 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:13:19.235953 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:13:19.236022 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select replace(udt_name, '_','') dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type_0000000000' and column_name = 'exp'
  
06:13:19.240802 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
06:13:19.241327 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:13:19.241393 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:13:19.242276 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:13:19.242769 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:13:19.242841 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:13:19.243080 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:13:19.243564 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:13:19.243630 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_exp_type_0000000000 as select to_timestamp(call_start_epoch + call_duration) exp from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 limit 1
  
06:13:19.245315 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:13:19.245801 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:13:19.245867 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select replace(udt_name, '_','') dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type_0000000000' and column_name = 'exp'
  
06:13:19.250271 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
06:13:19.250820 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:13:19.250892 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:13:19.252104 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:13:19.252635 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:13:19.252707 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:13:19.252959 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:13:19.253483 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:13:19.253558 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_exp_type_0000000000 as select call_duration exp from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 limit 1
  
06:13:19.255209 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:13:19.255744 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:13:19.255815 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select replace(udt_name, '_','') dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type_0000000000' and column_name = 'exp'
  
06:13:19.259951 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
06:13:19.260494 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:13:19.260564 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:13:19.262117 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:13:19.262657 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:13:19.262728 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:13:19.267793 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:13:19.268340 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:13:19.268412 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_exp_type_0000000000 as select trim(customer_id) exp from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 limit 1
  
06:13:19.269926 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:13:19.270456 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:13:19.270528 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select replace(udt_name, '_','') dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type_0000000000' and column_name = 'exp'
  
06:13:19.274730 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
06:13:19.275322 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:13:19.275402 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:13:19.276264 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:13:19.276840 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:13:19.276919 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:13:19.277174 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:13:19.277738 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:13:19.277817 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_exp_type_0000000000 as select lower(trim(agent_id)) exp from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 limit 1
  
06:13:19.279125 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:13:19.279695 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:13:19.279775 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select replace(udt_name, '_','') dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type_0000000000' and column_name = 'exp'
  
06:13:19.283909 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
06:13:19.284502 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:13:19.284580 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:13:19.285507 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:13:19.286077 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:13:19.286156 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 as
select  (call_id)::text as call_id, 
        (to_timestamp(call_start_epoch))::timestamptz as time_call_start, 
        (to_timestamp(call_start_epoch + call_duration))::timestamptz as time_call_end, 
        (call_duration)::int4 as num_duration_seconds, 
        (trim(customer_id))::text as customer_id, 
        (lower(trim(agent_id)))::text as agent_id
        from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000;

  
06:13:19.288057 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:13:19.288630 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:13:19.288707 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:13:19.288967 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:13:19.289528 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:13:19.289606 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_exp_type_0000000000 as select round(num_duration_seconds/60,2) exp from autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 limit 1
  
06:13:19.290939 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:13:19.291514 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:13:19.291591 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select replace(udt_name, '_','') dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type_0000000000' and column_name = 'exp'
  
06:13:19.295860 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
06:13:19.296602 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:13:19.296682 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:13:19.297564 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:13:19.299210 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:13:19.299294 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 cascade;
drop view if exists autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 cascade;

  
06:13:19.300360 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:13:19.300905 [info ] [MainThread]: 



create or replace view autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 as
select "call_id"::text as "call_id", 
       "call_start_epoch"::bigint as "call_start_epoch", 
       "call_duration"::int as "call_duration", 
       "customer_id"::text as "customer_id", 
       "agent_id"::text as "agent_id"
       from testsatmap.calltable;


create or replace view autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 as
select  (call_id)::text as call_id, 
        (to_timestamp(call_start_epoch))::timestamptz as time_call_start, 
        (to_timestamp(call_start_epoch + call_duration))::timestamptz as time_call_end, 
        (call_duration)::int4 as num_duration_seconds, 
        (trim(customer_id))::text as customer_id, 
        (lower(trim(agent_id)))::text as agent_id
        from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000;


drop table if exists autopie_ebpdemo.tmp_staging_fact_0000000000;
create table autopie_ebpdemo.tmp_staging_fact_0000000000 as
(
    with expression_extract_1 as
    (
        select * from autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000
    ),
    expression_extract_2 as
    (
        select  t.*,
                (round(num_duration_seconds/60,2))::numeric as num_duration_minutes
                from expression_extract_1 t
    ),
    filter__3 as
    (
        select /* filtering irrelevant records out */ *
        from expression_extract_2
        where 1=1
        and agent_id is not null
        and customer_id is not null
        and num_duration_seconds > 10
    ),
    incremental_extract__4 as
    (
        select /* retrieving incremental data - by date range only */ *
        from filter__3
        where time_call_start >= to_date('2020-01-01', 'YYYY-MM-DD')
          and time_call_start  < to_date('2021-01-01', 'YYYY-MM-DD')
    ),
    deduplication__5 as
    (
        select /* deduplicate by strategy */
               call_id
               , max(time_call_start) as time_call_start
               , max(time_call_end) as time_call_end
               , max(num_duration_seconds) as num_duration_seconds
               , max(customer_id) as customer_id
               , max(agent_id) as agent_id
               , max(num_duration_minutes) as num_duration_minutes
        from incremental_extract__4
        group by call_id 
    ),
    coarsening_6 as
    (
        select * from deduplication__5
    )
    select  t.*,
            1 autopie_run_id
    from coarsening_6 t
);

drop view if exists autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 cascade;
drop view if exists autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 cascade;


-- check if not exists already, this should run once
do $$                  
begin
if not exists
( 
    select 1 from information_schema.tables 
    where table_schema||'.'|| table_name = 'autopie_ebpdemo.obj_fact_calls'
)
then
    create table autopie_ebpdemo.obj_fact_calls as (select * from autopie_ebpdemo.tmp_staging_fact_0000000000 where 1=0);
    alter  table autopie_ebpdemo.obj_fact_calls add column row_id bigserial not null;
    alter  table autopie_ebpdemo.obj_fact_calls add primary key (call_id, time_call_end);
    --
    create index ixrid_obj_fact_calls on autopie_ebpdemo.obj_fact_calls(row_id);
end if;
end
$$;

-- upsert staging additions into the permanent fact object
delete from autopie_ebpdemo.obj_fact_calls where (call_id, time_call_end) in (select call_id, time_call_end from autopie_ebpdemo.tmp_staging_fact_0000000000);
insert into autopie_ebpdemo.obj_fact_calls select * from autopie_ebpdemo.tmp_staging_fact_0000000000;
drop table autopie_ebpdemo.tmp_staging_fact_0000000000;


06:13:19.301338 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:13:19.301411 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    



create or replace view autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 as
select "call_id"::text as "call_id", 
       "call_start_epoch"::bigint as "call_start_epoch", 
       "call_duration"::int as "call_duration", 
       "customer_id"::text as "customer_id", 
       "agent_id"::text as "agent_id"
       from testsatmap.calltable;


create or replace view autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 as
select  (call_id)::text as call_id, 
        (to_timestamp(call_start_epoch))::timestamptz as time_call_start, 
        (to_timestamp(call_start_epoch + call_duration))::timestamptz as time_call_end, 
        (call_duration)::int4 as num_duration_seconds, 
        (trim(customer_id))::text as customer_id, 
        (lower(trim(agent_id)))::text as agent_id
        from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000;


drop table if exists autopie_ebpdemo.tmp_staging_fact_0000000000;
create table autopie_ebpdemo.tmp_staging_fact_0000000000 as
(
    with expression_extract_1 as
    (
        select * from autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000
    ),
    expression_extract_2 as
    (
        select  t.*,
                (round(num_duration_seconds/60,2))::numeric as num_duration_minutes
                from expression_extract_1 t
    ),
    filter__3 as
    (
        select /* filtering irrelevant records out */ *
        from expression_extract_2
        where 1=1
        and agent_id is not null
        and customer_id is not null
        and num_duration_seconds > 10
    ),
    incremental_extract__4 as
    (
        select /* retrieving incremental data - by date range only */ *
        from filter__3
        where time_call_start >= to_date('2020-01-01', 'YYYY-MM-DD')
          and time_call_start  < to_date('2021-01-01', 'YYYY-MM-DD')
    ),
    deduplication__5 as
    (
        select /* deduplicate by strategy */
               call_id
               , max(time_call_start) as time_call_start
               , max(time_call_end) as time_call_end
               , max(num_duration_seconds) as num_duration_seconds
               , max(customer_id) as customer_id
               , max(agent_id) as agent_id
               , max(num_duration_minutes) as num_duration_minutes
        from incremental_extract__4
        group by call_id 
    ),
    coarsening_6 as
    (
        select * from deduplication__5
    )
    select  t.*,
            1 autopie_run_id
    from coarsening_6 t
);

drop view if exists autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 cascade;
drop view if exists autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 cascade;


-- check if not exists already, this should run once
do $$                  
begin
if not exists
( 
    select 1 from information_schema.tables 
    where table_schema||'.'|| table_name = 'autopie_ebpdemo.obj_fact_calls'
)
then
    create table autopie_ebpdemo.obj_fact_calls as (select * from autopie_ebpdemo.tmp_staging_fact_0000000000 where 1=0);
    alter  table autopie_ebpdemo.obj_fact_calls add column row_id bigserial not null;
    alter  table autopie_ebpdemo.obj_fact_calls add primary key (call_id, time_call_end);
    --
    create index ixrid_obj_fact_calls on autopie_ebpdemo.obj_fact_calls(row_id);
end if;
end
$$;

-- upsert staging additions into the permanent fact object
delete from autopie_ebpdemo.obj_fact_calls where (call_id, time_call_end) in (select call_id, time_call_end from autopie_ebpdemo.tmp_staging_fact_0000000000);
insert into autopie_ebpdemo.obj_fact_calls select * from autopie_ebpdemo.tmp_staging_fact_0000000000;
drop table autopie_ebpdemo.tmp_staging_fact_0000000000;


  
06:13:19.331123 [debug] [MainThread]: SQL status: DROP TABLE in 0.03 seconds
06:13:19.331886 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:13:19.331983 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    
select row_number() over (order by autopie_run_id desc) run_sequence, count(*) count_records 
  from autopie_ebpdemo.obj_fact_{'id': 'calls', 'entity_and_dims': 'call_id', 'date': 'time_call_end'}
group by autopie_run_id
order by 1
limit 5;

  
06:13:19.332416 [debug] [MainThread]: Postgres adapter: Postgres error: syntax error at or near "{"
LINE 5:   from autopie_ebpdemo.obj_fact_{'id': 'calls', 'entity_and_...
                                        ^

06:13:19.332577 [debug] [MainThread]: Postgres adapter: Error running SQL: macro run_recipe
06:13:19.332656 [debug] [MainThread]: Postgres adapter: Rolling back transaction.
06:13:19.332752 [debug] [MainThread]: On macro_run_recipe: Close
06:13:19.332936 [error] [MainThread]: Encountered an error while running operation: Database Error
  syntax error at or near "{"
  LINE 5:   from autopie_ebpdemo.obj_fact_{'id': 'calls', 'entity_and_...
                                          ^
06:13:19.333146 [debug] [MainThread]: 
06:13:19.333854 [debug] [MainThread]: Connection 'macro_run_recipe' was properly closed.


============================== 2022-02-20 06:13:48.479626 | 70719846-30ee-4b4d-a130-d0ab02d19390 ==============================
06:13:48.479626 [info ] [MainThread]: Running with dbt=1.0.1
06:13:48.479999 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/hassanzaheer/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, macro='run_recipe', args='{\n    "recipe_type" : "collect_fact",\n    "target_fact" : {\n        "id": "calls", \n        "entity_and_dims": "call_id",\n        "date":"time_call_end"\n    },\n    "ingredients": {\n        "expression_extract": {  \n            "source_raw": "testsatmap.calltable",\n            "expression_list": [\n                {"expression": "call_id", "alias": "call_id"},\n                {"expression": "to_timestamp(call_start_epoch)", "alias": "time_call_start"},\n                {"expression": "to_timestamp(call_start_epoch + call_duration)", "alias": "time_call_end"},\n                {"expression": "call_duration", "alias": "num_duration_seconds"},\n                {"expression": "trim(customer_id)",  "alias": "customer_id"},\n                {"expression": "lower(trim(agent_id))",  "alias": "agent_id"}\n            ]\n        },\n        "expression_extract_outer": {  \n            "expression_list": [\n                {"expression": "round(num_duration_seconds/60,2)", "alias": "num_duration_minutes"}\n            ]\n        },\n        "filter_conjunctions": [\n            "agent_id is not null",\n            "customer_id is not null",\n            "num_duration_seconds > 10"\n        ],\n        "incremental_update_on": "time_call_start",\n        "deduplication": {\n            "grouping_key": "call_id",\n            "preference": "arbitrary"\n        }\n    }\n}', defer=None, state=None, cls=<class 'dbt.task.run_operation.RunOperationTask'>, which='run-operation', rpc_method='run-operation')
06:13:48.480132 [debug] [MainThread]: Tracking: do not track
06:13:48.500711 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
06:13:48.501009 [debug] [MainThread]: Partial parsing: updated file: demo_autopie://macros/core/run_recipe.sql
06:13:48.501106 [debug] [MainThread]: Parsing macros/core/run_directory.sql
06:13:48.502688 [debug] [MainThread]: Parsing macros/core/run_recipe.sql
06:13:48.515180 [debug] [MainThread]: Acquiring new postgres connection "macro_run_recipe"
06:13:48.515287 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:13:48.515351 [debug] [MainThread]: On macro_run_recipe: BEGIN
06:13:48.515413 [debug] [MainThread]: Opening a new connection, currently in state init
06:13:48.537435 [debug] [MainThread]: SQL status: BEGIN in 0.02 seconds
06:13:48.537568 [debug] [MainThread]: On macro_run_recipe: COMMIT
06:13:48.537637 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:13:48.537698 [debug] [MainThread]: On macro_run_recipe: COMMIT
06:13:48.537884 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
06:13:48.583135 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:13:48.583288 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select '"'||column_name||'"::'||
       case when replace(udt_name, '_','') = 'bit' then 'int'
            when replace(udt_name, '_','') like 'int8%' then 'bigint'
            when replace(udt_name, '_','') like 'int4%' then 'int'
            when replace(udt_name, '_','') like 'int%' then 'smallint'
            when replace(udt_name, '_','') like 'bool%' then 'int'
            when replace(udt_name, '_','') like 'float%' then 'numeric'
            when replace(udt_name, '_','') like 'float%' then 'numeric'
            when replace(udt_name, '_','') like 'byte%' then 'text'
            when replace(udt_name, '_','') like 'varchar%' then 'text'
            when replace(udt_name, '_','') like 'timestamp%' then 'timestamp'
            else replace(udt_name, '_','') end ||
       ' as "'||column_name||'"' select_text
from information_schema.columns 
where table_schema||'.'||table_name = 'testsatmap.calltable'
order by ordinal_position ;

  
06:13:48.593358 [debug] [MainThread]: SQL status: SELECT 5 in 0.01 seconds
06:13:48.594325 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:13:48.594411 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 as
select "call_id"::text as "call_id", 
       "call_start_epoch"::bigint as "call_start_epoch", 
       "call_duration"::int as "call_duration", 
       "customer_id"::text as "customer_id", 
       "agent_id"::text as "agent_id"
       from testsatmap.calltable;

  
06:13:48.597415 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:13:48.597952 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:13:48.598022 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:13:48.598372 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:13:48.598857 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:13:48.598922 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_exp_type_0000000000 as select call_id exp from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 limit 1
  
06:13:48.599741 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:13:48.600202 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:13:48.600266 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select replace(udt_name, '_','') dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type_0000000000' and column_name = 'exp'
  
06:13:48.603826 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
06:13:48.604355 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:13:48.604422 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:13:48.605279 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:13:48.605737 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:13:48.605804 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:13:48.605969 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:13:48.606416 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:13:48.606478 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_exp_type_0000000000 as select to_timestamp(call_start_epoch) exp from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 limit 1
  
06:13:48.607189 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:13:48.607781 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:13:48.607854 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select replace(udt_name, '_','') dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type_0000000000' and column_name = 'exp'
  
06:13:48.610355 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
06:13:48.610865 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:13:48.610932 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:13:48.611636 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:13:48.612113 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:13:48.612179 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:13:48.612417 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:13:48.612902 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:13:48.612968 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_exp_type_0000000000 as select to_timestamp(call_start_epoch + call_duration) exp from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 limit 1
  
06:13:48.614264 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:13:48.614749 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:13:48.614818 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select replace(udt_name, '_','') dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type_0000000000' and column_name = 'exp'
  
06:13:48.617508 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
06:13:48.618045 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:13:48.618112 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:13:48.618700 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:13:48.619188 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:13:48.619254 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:13:48.619466 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:13:48.619941 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:13:48.620005 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_exp_type_0000000000 as select call_duration exp from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 limit 1
  
06:13:48.620978 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:13:48.621456 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:13:48.621521 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select replace(udt_name, '_','') dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type_0000000000' and column_name = 'exp'
  
06:13:48.625565 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
06:13:48.626142 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:13:48.626220 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:13:48.627016 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:13:48.627666 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:13:48.627749 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:13:48.628107 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:13:48.628644 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:13:48.628715 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_exp_type_0000000000 as select trim(customer_id) exp from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 limit 1
  
06:13:48.630083 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:13:48.630609 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:13:48.630680 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select replace(udt_name, '_','') dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type_0000000000' and column_name = 'exp'
  
06:13:48.633361 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
06:13:48.633914 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:13:48.633984 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:13:48.634617 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:13:48.635144 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:13:48.635213 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:13:48.635399 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:13:48.635913 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:13:48.635994 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_exp_type_0000000000 as select lower(trim(agent_id)) exp from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 limit 1
  
06:13:48.637912 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:13:48.638436 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:13:48.638507 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select replace(udt_name, '_','') dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type_0000000000' and column_name = 'exp'
  
06:13:48.641057 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
06:13:48.641628 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:13:48.641702 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:13:48.642265 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:13:48.642795 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:13:48.642864 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 as
select  (call_id)::text as call_id, 
        (to_timestamp(call_start_epoch))::timestamptz as time_call_start, 
        (to_timestamp(call_start_epoch + call_duration))::timestamptz as time_call_end, 
        (call_duration)::int4 as num_duration_seconds, 
        (trim(customer_id))::text as customer_id, 
        (lower(trim(agent_id)))::text as agent_id
        from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000;

  
06:13:48.644053 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:13:48.644594 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:13:48.644663 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:13:48.644929 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:13:48.645459 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:13:48.645528 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_exp_type_0000000000 as select round(num_duration_seconds/60,2) exp from autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 limit 1
  
06:13:48.647027 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:13:48.647536 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:13:48.647611 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select replace(udt_name, '_','') dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type_0000000000' and column_name = 'exp'
  
06:13:48.650936 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
06:13:48.651653 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:13:48.651724 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:13:48.652560 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:13:48.654089 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:13:48.654164 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 cascade;
drop view if exists autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 cascade;

  
06:13:48.655109 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:13:48.655615 [info ] [MainThread]: 



create or replace view autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 as
select "call_id"::text as "call_id", 
       "call_start_epoch"::bigint as "call_start_epoch", 
       "call_duration"::int as "call_duration", 
       "customer_id"::text as "customer_id", 
       "agent_id"::text as "agent_id"
       from testsatmap.calltable;


create or replace view autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 as
select  (call_id)::text as call_id, 
        (to_timestamp(call_start_epoch))::timestamptz as time_call_start, 
        (to_timestamp(call_start_epoch + call_duration))::timestamptz as time_call_end, 
        (call_duration)::int4 as num_duration_seconds, 
        (trim(customer_id))::text as customer_id, 
        (lower(trim(agent_id)))::text as agent_id
        from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000;


drop table if exists autopie_ebpdemo.tmp_staging_fact_0000000000;
create table autopie_ebpdemo.tmp_staging_fact_0000000000 as
(
    with expression_extract_1 as
    (
        select * from autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000
    ),
    expression_extract_2 as
    (
        select  t.*,
                (round(num_duration_seconds/60,2))::numeric as num_duration_minutes
                from expression_extract_1 t
    ),
    filter__3 as
    (
        select /* filtering irrelevant records out */ *
        from expression_extract_2
        where 1=1
        and agent_id is not null
        and customer_id is not null
        and num_duration_seconds > 10
    ),
    incremental_extract__4 as
    (
        select /* retrieving incremental data - by date range only */ *
        from filter__3
        where time_call_start >= to_date('2020-01-01', 'YYYY-MM-DD')
          and time_call_start  < to_date('2021-01-01', 'YYYY-MM-DD')
    ),
    deduplication__5 as
    (
        select /* deduplicate by strategy */
               call_id
               , max(time_call_start) as time_call_start
               , max(time_call_end) as time_call_end
               , max(num_duration_seconds) as num_duration_seconds
               , max(customer_id) as customer_id
               , max(agent_id) as agent_id
               , max(num_duration_minutes) as num_duration_minutes
        from incremental_extract__4
        group by call_id 
    ),
    coarsening_6 as
    (
        select * from deduplication__5
    )
    select  t.*,
            1 autopie_run_id
    from coarsening_6 t
);

drop view if exists autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 cascade;
drop view if exists autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 cascade;


-- check if not exists already, this should run once
do $$                  
begin
if not exists
( 
    select 1 from information_schema.tables 
    where table_schema||'.'|| table_name = 'autopie_ebpdemo.obj_fact_calls'
)
then
    create table autopie_ebpdemo.obj_fact_calls as (select * from autopie_ebpdemo.tmp_staging_fact_0000000000 where 1=0);
    alter  table autopie_ebpdemo.obj_fact_calls add column row_id bigserial not null;
    alter  table autopie_ebpdemo.obj_fact_calls add primary key (call_id, time_call_end);
    --
    create index ixrid_obj_fact_calls on autopie_ebpdemo.obj_fact_calls(row_id);
end if;
end
$$;

-- upsert staging additions into the permanent fact object
delete from autopie_ebpdemo.obj_fact_calls where (call_id, time_call_end) in (select call_id, time_call_end from autopie_ebpdemo.tmp_staging_fact_0000000000);
insert into autopie_ebpdemo.obj_fact_calls select * from autopie_ebpdemo.tmp_staging_fact_0000000000;
drop table autopie_ebpdemo.tmp_staging_fact_0000000000;


06:13:48.656013 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:13:48.656080 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    



create or replace view autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 as
select "call_id"::text as "call_id", 
       "call_start_epoch"::bigint as "call_start_epoch", 
       "call_duration"::int as "call_duration", 
       "customer_id"::text as "customer_id", 
       "agent_id"::text as "agent_id"
       from testsatmap.calltable;


create or replace view autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 as
select  (call_id)::text as call_id, 
        (to_timestamp(call_start_epoch))::timestamptz as time_call_start, 
        (to_timestamp(call_start_epoch + call_duration))::timestamptz as time_call_end, 
        (call_duration)::int4 as num_duration_seconds, 
        (trim(customer_id))::text as customer_id, 
        (lower(trim(agent_id)))::text as agent_id
        from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000;


drop table if exists autopie_ebpdemo.tmp_staging_fact_0000000000;
create table autopie_ebpdemo.tmp_staging_fact_0000000000 as
(
    with expression_extract_1 as
    (
        select * from autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000
    ),
    expression_extract_2 as
    (
        select  t.*,
                (round(num_duration_seconds/60,2))::numeric as num_duration_minutes
                from expression_extract_1 t
    ),
    filter__3 as
    (
        select /* filtering irrelevant records out */ *
        from expression_extract_2
        where 1=1
        and agent_id is not null
        and customer_id is not null
        and num_duration_seconds > 10
    ),
    incremental_extract__4 as
    (
        select /* retrieving incremental data - by date range only */ *
        from filter__3
        where time_call_start >= to_date('2020-01-01', 'YYYY-MM-DD')
          and time_call_start  < to_date('2021-01-01', 'YYYY-MM-DD')
    ),
    deduplication__5 as
    (
        select /* deduplicate by strategy */
               call_id
               , max(time_call_start) as time_call_start
               , max(time_call_end) as time_call_end
               , max(num_duration_seconds) as num_duration_seconds
               , max(customer_id) as customer_id
               , max(agent_id) as agent_id
               , max(num_duration_minutes) as num_duration_minutes
        from incremental_extract__4
        group by call_id 
    ),
    coarsening_6 as
    (
        select * from deduplication__5
    )
    select  t.*,
            1 autopie_run_id
    from coarsening_6 t
);

drop view if exists autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 cascade;
drop view if exists autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 cascade;


-- check if not exists already, this should run once
do $$                  
begin
if not exists
( 
    select 1 from information_schema.tables 
    where table_schema||'.'|| table_name = 'autopie_ebpdemo.obj_fact_calls'
)
then
    create table autopie_ebpdemo.obj_fact_calls as (select * from autopie_ebpdemo.tmp_staging_fact_0000000000 where 1=0);
    alter  table autopie_ebpdemo.obj_fact_calls add column row_id bigserial not null;
    alter  table autopie_ebpdemo.obj_fact_calls add primary key (call_id, time_call_end);
    --
    create index ixrid_obj_fact_calls on autopie_ebpdemo.obj_fact_calls(row_id);
end if;
end
$$;

-- upsert staging additions into the permanent fact object
delete from autopie_ebpdemo.obj_fact_calls where (call_id, time_call_end) in (select call_id, time_call_end from autopie_ebpdemo.tmp_staging_fact_0000000000);
insert into autopie_ebpdemo.obj_fact_calls select * from autopie_ebpdemo.tmp_staging_fact_0000000000;
drop table autopie_ebpdemo.tmp_staging_fact_0000000000;


  
06:13:48.682192 [debug] [MainThread]: SQL status: DROP TABLE in 0.03 seconds
06:13:48.682977 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:13:48.683071 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    
select row_number() over (order by autopie_run_id desc) run_sequence, count(*) count_records 
  from autopie_ebpdemo.obj_fact_calls
group by autopie_run_id
order by 1 
limit 5;

  
06:13:48.683642 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
06:13:48.686735 [debug] [MainThread]: On macro_run_recipe: Close
06:13:48.687457 [debug] [MainThread]: Connection 'macro_run_recipe' was properly closed.


============================== 2022-02-20 06:16:55.638602 | 95fcaabe-c7e1-4732-b5a8-76957e3b457f ==============================
06:16:55.638602 [info ] [MainThread]: Running with dbt=1.0.1
06:16:55.639063 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/hassanzaheer/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, macro='run_recipe', args='{\n    "recipe_type" : "collect_fact",\n    "target_fact" : {\n        "id": "calls", \n        "entity_and_dims": "call_id",\n        "date":"time_call_end"\n    },\n    "ingredients": {\n        "expression_extract": {  \n            "source_raw": "testsatmap.calltable",\n            "expression_list": [\n                {"expression": "call_id", "alias": "call_id"},\n                {"expression": "to_timestamp(call_start_epoch)", "alias": "time_call_start"},\n                {"expression": "to_timestamp(call_start_epoch + call_duration)", "alias": "time_call_end"},\n                {"expression": "call_duration", "alias": "num_duration_seconds"},\n                {"expression": "trim(customer_id)",  "alias": "customer_id"},\n                {"expression": "lower(trim(agent_id))",  "alias": "agent_id"}\n            ]\n        },\n        "expression_extract_outer": {  \n            "expression_list": [\n                {"expression": "round(num_duration_seconds/60,2)", "alias": "num_duration_minutes"}\n            ]\n        },\n        "filter_conjunctions": [\n            "agent_id is not null",\n            "customer_id is not null",\n            "num_duration_seconds > 10"\n        ],\n        "incremental_update_on": "time_call_start",\n        "deduplication": {\n            "grouping_key": "call_id",\n            "preference": "arbitrary"\n        }\n    }\n}', defer=None, state=None, cls=<class 'dbt.task.run_operation.RunOperationTask'>, which='run-operation', rpc_method='run-operation')
06:16:55.639184 [debug] [MainThread]: Tracking: do not track
06:16:55.661097 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
06:16:55.661265 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
06:16:55.666156 [debug] [MainThread]: Acquiring new postgres connection "macro_run_recipe"
06:16:55.666258 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:16:55.666323 [debug] [MainThread]: On macro_run_recipe: BEGIN
06:16:55.666383 [debug] [MainThread]: Opening a new connection, currently in state init
06:16:55.689787 [debug] [MainThread]: SQL status: BEGIN in 0.02 seconds
06:16:55.689941 [debug] [MainThread]: On macro_run_recipe: COMMIT
06:16:55.690013 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:16:55.690076 [debug] [MainThread]: On macro_run_recipe: COMMIT
06:16:55.690267 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
06:16:55.735513 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:16:55.735652 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select '"'||column_name||'"::'||
       case when replace(udt_name, '_','') = 'bit' then 'int'
            when replace(udt_name, '_','') like 'int8%' then 'bigint'
            when replace(udt_name, '_','') like 'int4%' then 'int'
            when replace(udt_name, '_','') like 'int%' then 'smallint'
            when replace(udt_name, '_','') like 'bool%' then 'int'
            when replace(udt_name, '_','') like 'float%' then 'numeric'
            when replace(udt_name, '_','') like 'float%' then 'numeric'
            when replace(udt_name, '_','') like 'byte%' then 'text'
            when replace(udt_name, '_','') like 'varchar%' then 'text'
            when replace(udt_name, '_','') like 'timestamp%' then 'timestamp'
            else replace(udt_name, '_','') end ||
       ' as "'||column_name||'"' select_text
from information_schema.columns 
where table_schema||'.'||table_name = 'testsatmap.calltable'
order by ordinal_position ;

  
06:16:55.750277 [debug] [MainThread]: SQL status: SELECT 5 in 0.01 seconds
06:16:55.751136 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:16:55.751213 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 as
select "call_id"::text as "call_id", 
       "call_start_epoch"::bigint as "call_start_epoch", 
       "call_duration"::int as "call_duration", 
       "customer_id"::text as "customer_id", 
       "agent_id"::text as "agent_id"
       from testsatmap.calltable;

  
06:16:55.753647 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:16:55.754187 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:16:55.754264 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:16:55.754493 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:16:55.754993 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:16:55.755061 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_exp_type_0000000000 as select call_id exp from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 limit 1
  
06:16:55.756169 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:16:55.756660 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:16:55.756727 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select replace(udt_name, '_','') dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type_0000000000' and column_name = 'exp'
  
06:16:55.759924 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
06:16:55.760440 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:16:55.760507 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:16:55.761578 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:16:55.762073 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:16:55.762141 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:16:55.762339 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:16:55.762815 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:16:55.762882 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_exp_type_0000000000 as select to_timestamp(call_start_epoch) exp from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 limit 1
  
06:16:55.763830 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:16:55.764436 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:16:55.764505 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select replace(udt_name, '_','') dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type_0000000000' and column_name = 'exp'
  
06:16:55.767990 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
06:16:55.768503 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:16:55.768570 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:16:55.769253 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:16:55.769742 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:16:55.769809 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:16:55.770004 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:16:55.770488 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:16:55.770554 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_exp_type_0000000000 as select to_timestamp(call_start_epoch + call_duration) exp from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 limit 1
  
06:16:55.771961 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:16:55.772481 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:16:55.772552 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select replace(udt_name, '_','') dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type_0000000000' and column_name = 'exp'
  
06:16:55.775777 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
06:16:55.776326 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:16:55.776399 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:16:55.777291 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:16:55.777820 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:16:55.777892 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:16:55.778130 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:16:55.778648 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:16:55.778719 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_exp_type_0000000000 as select call_duration exp from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 limit 1
  
06:16:55.780048 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:16:55.780573 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:16:55.780644 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select replace(udt_name, '_','') dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type_0000000000' and column_name = 'exp'
  
06:16:55.785385 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
06:16:55.785940 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:16:55.786012 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:16:55.787226 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:16:55.787760 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:16:55.787832 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:16:55.788180 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:16:55.788706 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:16:55.788778 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_exp_type_0000000000 as select trim(customer_id) exp from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 limit 1
  
06:16:55.789970 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:16:55.790496 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:16:55.790568 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select replace(udt_name, '_','') dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type_0000000000' and column_name = 'exp'
  
06:16:55.795148 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
06:16:55.795724 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:16:55.795797 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:16:55.796814 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:16:55.797337 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:16:55.797408 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:16:55.797647 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:16:55.798160 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:16:55.798235 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_exp_type_0000000000 as select lower(trim(agent_id)) exp from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 limit 1
  
06:16:55.799449 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:16:55.799966 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:16:55.800037 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select replace(udt_name, '_','') dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type_0000000000' and column_name = 'exp'
  
06:16:55.804180 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
06:16:55.804774 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:16:55.804856 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:16:55.805783 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:16:55.806358 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:16:55.806436 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 as
select  (call_id)::text as call_id, 
        (to_timestamp(call_start_epoch))::timestamptz as time_call_start, 
        (to_timestamp(call_start_epoch + call_duration))::timestamptz as time_call_end, 
        (call_duration)::int4 as num_duration_seconds, 
        (trim(customer_id))::text as customer_id, 
        (lower(trim(agent_id)))::text as agent_id
        from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000;

  
06:16:55.808690 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:16:55.809261 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:16:55.809344 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:16:55.809595 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:16:55.810166 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:16:55.810243 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_exp_type_0000000000 as select round(num_duration_seconds/60,2) exp from autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 limit 1
  
06:16:55.811961 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:16:55.812534 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:16:55.812612 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select replace(udt_name, '_','') dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type_0000000000' and column_name = 'exp'
  
06:16:55.817000 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
06:16:55.817849 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:16:55.817930 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:16:55.818839 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:16:55.820491 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:16:55.820572 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 cascade;
drop view if exists autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 cascade;

  
06:16:55.821795 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:16:55.822326 [info ] [MainThread]: 



create or replace view autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 as
select "call_id"::text as "call_id", 
       "call_start_epoch"::bigint as "call_start_epoch", 
       "call_duration"::int as "call_duration", 
       "customer_id"::text as "customer_id", 
       "agent_id"::text as "agent_id"
       from testsatmap.calltable;


create or replace view autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 as
select  (call_id)::text as call_id, 
        (to_timestamp(call_start_epoch))::timestamptz as time_call_start, 
        (to_timestamp(call_start_epoch + call_duration))::timestamptz as time_call_end, 
        (call_duration)::int4 as num_duration_seconds, 
        (trim(customer_id))::text as customer_id, 
        (lower(trim(agent_id)))::text as agent_id
        from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000;


drop table if exists autopie_ebpdemo.tmp_staging_fact_0000000000;
create table autopie_ebpdemo.tmp_staging_fact_0000000000 as
(
    with expression_extract_1 as
    (
        select * from autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000
    ),
    expression_extract_2 as
    (
        select  t.*,
                (round(num_duration_seconds/60,2))::numeric as num_duration_minutes
                from expression_extract_1 t
    ),
    filter__3 as
    (
        select /* filtering irrelevant records out */ *
        from expression_extract_2
        where 1=1
        and agent_id is not null
        and customer_id is not null
        and num_duration_seconds > 10
    ),
    incremental_extract__4 as
    (
        select /* retrieving incremental data - by date range only */ *
        from filter__3
        where time_call_start >= to_date('2020-01-01', 'YYYY-MM-DD')
          and time_call_start  < to_date('2021-01-01', 'YYYY-MM-DD')
    ),
    deduplication__5 as
    (
        select /* deduplicate by strategy */
               call_id
               , max(time_call_start) as time_call_start
               , max(time_call_end) as time_call_end
               , max(num_duration_seconds) as num_duration_seconds
               , max(customer_id) as customer_id
               , max(agent_id) as agent_id
               , max(num_duration_minutes) as num_duration_minutes
        from incremental_extract__4
        group by call_id 
    ),
    coarsening_6 as
    (
        select * from deduplication__5
    )
    select  t.*,
            1 autopie_run_id
    from coarsening_6 t
);

drop view if exists autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 cascade;
drop view if exists autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 cascade;


-- check if not exists already, this should run once
do $$                  
begin
if not exists
( 
    select 1 from information_schema.tables 
    where table_schema||'.'|| table_name = 'autopie_ebpdemo.obj_fact_calls'
)
then
    create table autopie_ebpdemo.obj_fact_calls as (select * from autopie_ebpdemo.tmp_staging_fact_0000000000 where 1=0);
    alter  table autopie_ebpdemo.obj_fact_calls add column row_id bigserial not null;
    alter  table autopie_ebpdemo.obj_fact_calls add primary key (call_id, time_call_end);
    --
    create index ixrid_obj_fact_calls on autopie_ebpdemo.obj_fact_calls(row_id);
end if;
end
$$;

-- upsert staging additions into the permanent fact object
delete from autopie_ebpdemo.obj_fact_calls where (call_id, time_call_end) in (select call_id, time_call_end from autopie_ebpdemo.tmp_staging_fact_0000000000);
insert into autopie_ebpdemo.obj_fact_calls select * from autopie_ebpdemo.tmp_staging_fact_0000000000;
drop table autopie_ebpdemo.tmp_staging_fact_0000000000;


06:16:55.822749 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:16:55.822822 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    



create or replace view autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 as
select "call_id"::text as "call_id", 
       "call_start_epoch"::bigint as "call_start_epoch", 
       "call_duration"::int as "call_duration", 
       "customer_id"::text as "customer_id", 
       "agent_id"::text as "agent_id"
       from testsatmap.calltable;


create or replace view autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 as
select  (call_id)::text as call_id, 
        (to_timestamp(call_start_epoch))::timestamptz as time_call_start, 
        (to_timestamp(call_start_epoch + call_duration))::timestamptz as time_call_end, 
        (call_duration)::int4 as num_duration_seconds, 
        (trim(customer_id))::text as customer_id, 
        (lower(trim(agent_id)))::text as agent_id
        from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000;


drop table if exists autopie_ebpdemo.tmp_staging_fact_0000000000;
create table autopie_ebpdemo.tmp_staging_fact_0000000000 as
(
    with expression_extract_1 as
    (
        select * from autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000
    ),
    expression_extract_2 as
    (
        select  t.*,
                (round(num_duration_seconds/60,2))::numeric as num_duration_minutes
                from expression_extract_1 t
    ),
    filter__3 as
    (
        select /* filtering irrelevant records out */ *
        from expression_extract_2
        where 1=1
        and agent_id is not null
        and customer_id is not null
        and num_duration_seconds > 10
    ),
    incremental_extract__4 as
    (
        select /* retrieving incremental data - by date range only */ *
        from filter__3
        where time_call_start >= to_date('2020-01-01', 'YYYY-MM-DD')
          and time_call_start  < to_date('2021-01-01', 'YYYY-MM-DD')
    ),
    deduplication__5 as
    (
        select /* deduplicate by strategy */
               call_id
               , max(time_call_start) as time_call_start
               , max(time_call_end) as time_call_end
               , max(num_duration_seconds) as num_duration_seconds
               , max(customer_id) as customer_id
               , max(agent_id) as agent_id
               , max(num_duration_minutes) as num_duration_minutes
        from incremental_extract__4
        group by call_id 
    ),
    coarsening_6 as
    (
        select * from deduplication__5
    )
    select  t.*,
            1 autopie_run_id
    from coarsening_6 t
);

drop view if exists autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 cascade;
drop view if exists autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 cascade;


-- check if not exists already, this should run once
do $$                  
begin
if not exists
( 
    select 1 from information_schema.tables 
    where table_schema||'.'|| table_name = 'autopie_ebpdemo.obj_fact_calls'
)
then
    create table autopie_ebpdemo.obj_fact_calls as (select * from autopie_ebpdemo.tmp_staging_fact_0000000000 where 1=0);
    alter  table autopie_ebpdemo.obj_fact_calls add column row_id bigserial not null;
    alter  table autopie_ebpdemo.obj_fact_calls add primary key (call_id, time_call_end);
    --
    create index ixrid_obj_fact_calls on autopie_ebpdemo.obj_fact_calls(row_id);
end if;
end
$$;

-- upsert staging additions into the permanent fact object
delete from autopie_ebpdemo.obj_fact_calls where (call_id, time_call_end) in (select call_id, time_call_end from autopie_ebpdemo.tmp_staging_fact_0000000000);
insert into autopie_ebpdemo.obj_fact_calls select * from autopie_ebpdemo.tmp_staging_fact_0000000000;
drop table autopie_ebpdemo.tmp_staging_fact_0000000000;


  
06:16:55.852332 [debug] [MainThread]: SQL status: DROP TABLE in 0.03 seconds
06:16:55.853114 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:16:55.853216 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    
select row_number() over (order by autopie_run_id desc) run_sequence, count(*) count_records 
  from autopie_ebpdemo.obj_fact_calls
group by autopie_run_id
order by 1 
limit 5;

  
06:16:55.853889 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
06:16:55.856144 [debug] [MainThread]: On macro_run_recipe: Close
06:16:55.856852 [debug] [MainThread]: Connection 'macro_run_recipe' was properly closed.


============================== 2022-02-20 06:16:56.934818 | 6e08b7c4-0e24-4e02-b32e-db65c52b9929 ==============================
06:16:56.934818 [info ] [MainThread]: Running with dbt=1.0.1
06:16:56.935204 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/hassanzaheer/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, macro='compile_recipe_collect_fact', args='{\n    "recipe_type" : "collect_fact",\n    "target_fact" : {\n        "id": "outcomes", \n        "entity_and_dims": "customer_id",\n        "date":"date_outcome"\n    },\n    "ingredients": {\n        "expression_extract": {  \n            "source_raw": "testsatmap.outcomes",\n            "expression_list": [\n                {"expression": "outcome_date", "alias": "date_outcome"},\n                {"expression": "trim(customer_id)", "alias": "customer_id"},             \n                {"expression": "outcome_code::numeric", "alias": "num_outcome_amount"}\n            ]\n        },\n        "filter_conjunctions": [\n            "num_outcome_amount > 0",\n            "customer_id is not null"\n        ],\n        "incremental_update_on": "date_outcome",\n        "deduplication": {\n            "grouping_key": "customer_id, date_outcome, num_outcome_amount",\n            "preference": "arbitrary"\n        },\n        "coarsening": {\n            "entity_and_dims": "customer_id",\n            "date_expression":"date_outcome",\n            "aggregations": [\n                {"expression": "sum(num_outcome_amount)", "alias": "sum_outcome_amount"}\n            ]\n        }\n    }\n}', defer=None, state=None, cls=<class 'dbt.task.run_operation.RunOperationTask'>, which='run-operation', rpc_method='run-operation')
06:16:56.935314 [debug] [MainThread]: Tracking: do not track
06:16:56.954557 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
06:16:56.954815 [debug] [MainThread]: Partial parsing: updated file: demo_autopie://models/demo_ebp_flow/prepared_scripts/prepared_fact_calls.sql
06:16:56.962022 [debug] [MainThread]: 1699: static parser successfully parsed demo_ebp_flow/prepared_scripts/prepared_fact_calls.sql
06:16:56.972626 [debug] [MainThread]: Acquiring new postgres connection "macro_compile_recipe_collect_fact"
06:16:56.972743 [debug] [MainThread]: Using postgres connection "macro_compile_recipe_collect_fact"
06:16:56.972809 [debug] [MainThread]: On macro_compile_recipe_collect_fact: BEGIN
06:16:56.972875 [debug] [MainThread]: Opening a new connection, currently in state init
06:16:56.979016 [debug] [MainThread]: SQL status: BEGIN in 0.01 seconds
06:16:56.979110 [debug] [MainThread]: On macro_compile_recipe_collect_fact: COMMIT
06:16:56.979173 [debug] [MainThread]: Using postgres connection "macro_compile_recipe_collect_fact"
06:16:56.979226 [debug] [MainThread]: On macro_compile_recipe_collect_fact: COMMIT
06:16:56.979396 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
06:16:57.014532 [debug] [MainThread]: Postgres adapter: Error running SQL: macro compile_recipe_collect_fact
06:16:57.014634 [debug] [MainThread]: Postgres adapter: Rolling back transaction.
06:16:57.014713 [debug] [MainThread]: On macro_compile_recipe_collect_fact: Close
06:16:57.014846 [error] [MainThread]: Encountered an error while running operation: Compilation Error in macro compile_recipe_collect_fact (macros/compile_recipe_collect_fact.sql)
  macro 'dbt_macro__compile_recipe_collect_fact' takes no keyword argument 'recipe_type'
06:16:57.015009 [debug] [MainThread]: 
06:16:57.015405 [debug] [MainThread]: Connection 'macro_compile_recipe_collect_fact' was properly closed.


============================== 2022-02-20 06:18:18.597748 | d225349c-9979-4572-90b5-87128cd1d2dd ==============================
06:18:18.597748 [info ] [MainThread]: Running with dbt=1.0.1
06:18:18.598116 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/hassanzaheer/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, macro='run_recipe', args='{\n    "recipe_type" : "collect_fact",\n    "target_fact" : {\n        "id": "calls", \n        "entity_and_dims": "call_id",\n        "date":"time_call_end"\n    },\n    "ingredients": {\n        "expression_extract": {  \n            "source_raw": "testsatmap.calltable",\n            "expression_list": [\n                {"expression": "call_id", "alias": "call_id"},\n                {"expression": "to_timestamp(call_start_epoch)", "alias": "time_call_start"},\n                {"expression": "to_timestamp(call_start_epoch + call_duration)", "alias": "time_call_end"},\n                {"expression": "call_duration", "alias": "num_duration_seconds"},\n                {"expression": "trim(customer_id)",  "alias": "customer_id"},\n                {"expression": "lower(trim(agent_id))",  "alias": "agent_id"}\n            ]\n        },\n        "expression_extract_outer": {  \n            "expression_list": [\n                {"expression": "round(num_duration_seconds/60,2)", "alias": "num_duration_minutes"}\n            ]\n        },\n        "filter_conjunctions": [\n            "agent_id is not null",\n            "customer_id is not null",\n            "num_duration_seconds > 10"\n        ],\n        "incremental_update_on": "time_call_start",\n        "deduplication": {\n            "grouping_key": "call_id",\n            "preference": "arbitrary"\n        }\n    }\n}', defer=None, state=None, cls=<class 'dbt.task.run_operation.RunOperationTask'>, which='run-operation', rpc_method='run-operation')
06:18:18.598243 [debug] [MainThread]: Tracking: do not track
06:18:18.618999 [debug] [MainThread]: Partial parsing enabled: 1 files deleted, 0 files added, 1 files changed.
06:18:18.619195 [debug] [MainThread]: Partial parsing: deleted file: demo_autopie://models/demo_ebp_flow/prepared_scripts/prepared_fact_outcomes.sql
06:18:18.619370 [debug] [MainThread]: Partial parsing: updated file: demo_autopie://models/demo_ebp_flow/prepared_scripts/prepared_fact_calls.sql
06:18:18.625145 [debug] [MainThread]: 1699: static parser successfully parsed demo_ebp_flow/prepared_scripts/prepared_fact_calls.sql
06:18:18.635871 [debug] [MainThread]: Acquiring new postgres connection "macro_run_recipe"
06:18:18.635986 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:18:18.636061 [debug] [MainThread]: On macro_run_recipe: BEGIN
06:18:18.636127 [debug] [MainThread]: Opening a new connection, currently in state init
06:18:18.664169 [debug] [MainThread]: SQL status: BEGIN in 0.03 seconds
06:18:18.664316 [debug] [MainThread]: On macro_run_recipe: COMMIT
06:18:18.664387 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:18:18.664450 [debug] [MainThread]: On macro_run_recipe: COMMIT
06:18:18.664647 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
06:18:18.710860 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:18:18.711014 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select '"'||column_name||'"::'||
       case when replace(udt_name, '_','') = 'bit' then 'int'
            when replace(udt_name, '_','') like 'int8%' then 'bigint'
            when replace(udt_name, '_','') like 'int4%' then 'int'
            when replace(udt_name, '_','') like 'int%' then 'smallint'
            when replace(udt_name, '_','') like 'bool%' then 'int'
            when replace(udt_name, '_','') like 'float%' then 'numeric'
            when replace(udt_name, '_','') like 'float%' then 'numeric'
            when replace(udt_name, '_','') like 'byte%' then 'text'
            when replace(udt_name, '_','') like 'varchar%' then 'text'
            when replace(udt_name, '_','') like 'timestamp%' then 'timestamp'
            else replace(udt_name, '_','') end ||
       ' as "'||column_name||'"' select_text
from information_schema.columns 
where table_schema||'.'||table_name = 'testsatmap.calltable'
order by ordinal_position ;

  
06:18:18.724583 [debug] [MainThread]: SQL status: SELECT 5 in 0.01 seconds
06:18:18.725538 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:18:18.725620 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 as
select "call_id"::text as "call_id", 
       "call_start_epoch"::bigint as "call_start_epoch", 
       "call_duration"::int as "call_duration", 
       "customer_id"::text as "customer_id", 
       "agent_id"::text as "agent_id"
       from testsatmap.calltable;

  
06:18:18.728353 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:18:18.728856 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:18:18.728922 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:18:18.729147 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:18:18.729604 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:18:18.729666 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_exp_type_0000000000 as select call_id exp from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 limit 1
  
06:18:18.730924 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:18:18.731375 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:18:18.731437 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select replace(udt_name, '_','') dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type_0000000000' and column_name = 'exp'
  
06:18:18.734780 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
06:18:18.735294 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:18:18.735361 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:18:18.736452 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:18:18.736944 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:18:18.737012 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:18:18.737214 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:18:18.737698 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:18:18.737768 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_exp_type_0000000000 as select to_timestamp(call_start_epoch) exp from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 limit 1
  
06:18:18.738836 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:18:18.739442 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:18:18.739512 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select replace(udt_name, '_','') dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type_0000000000' and column_name = 'exp'
  
06:18:18.742758 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
06:18:18.743263 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:18:18.743328 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:18:18.743993 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:18:18.744475 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:18:18.744541 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:18:18.744737 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:18:18.745211 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:18:18.745278 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_exp_type_0000000000 as select to_timestamp(call_start_epoch + call_duration) exp from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 limit 1
  
06:18:18.746348 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:18:18.746828 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:18:18.746897 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select replace(udt_name, '_','') dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type_0000000000' and column_name = 'exp'
  
06:18:18.750297 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
06:18:18.750839 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:18:18.750914 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:18:18.751701 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:18:18.752231 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:18:18.752303 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:18:18.752510 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:18:18.753029 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:18:18.753100 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_exp_type_0000000000 as select call_duration exp from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 limit 1
  
06:18:18.754171 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:18:18.754691 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:18:18.754765 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select replace(udt_name, '_','') dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type_0000000000' and column_name = 'exp'
  
06:18:18.757955 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
06:18:18.758496 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:18:18.758567 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:18:18.759235 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:18:18.759761 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:18:18.759831 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:18:18.760146 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:18:18.760672 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:18:18.760747 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_exp_type_0000000000 as select trim(customer_id) exp from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 limit 1
  
06:18:18.761700 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:18:18.762217 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:18:18.762287 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select replace(udt_name, '_','') dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type_0000000000' and column_name = 'exp'
  
06:18:18.766084 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
06:18:18.766631 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:18:18.766704 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:18:18.767528 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:18:18.768046 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:18:18.768117 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:18:18.768369 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:18:18.768879 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:18:18.768948 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_exp_type_0000000000 as select lower(trim(agent_id)) exp from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 limit 1
  
06:18:18.770653 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:18:18.771166 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:18:18.771238 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select replace(udt_name, '_','') dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type_0000000000' and column_name = 'exp'
  
06:18:18.775580 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
06:18:18.776122 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:18:18.776190 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:18:18.777114 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:18:18.777629 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:18:18.777699 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 as
select  (call_id)::text as call_id, 
        (to_timestamp(call_start_epoch))::timestamptz as time_call_start, 
        (to_timestamp(call_start_epoch + call_duration))::timestamptz as time_call_end, 
        (call_duration)::int4 as num_duration_seconds, 
        (trim(customer_id))::text as customer_id, 
        (lower(trim(agent_id)))::text as agent_id
        from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000;

  
06:18:18.778849 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:18:18.779364 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:18:18.779439 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:18:18.779650 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:18:18.780203 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:18:18.780279 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_exp_type_0000000000 as select round(num_duration_seconds/60,2) exp from autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 limit 1
  
06:18:18.781387 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:18:18.781954 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:18:18.782030 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select replace(udt_name, '_','') dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type_0000000000' and column_name = 'exp'
  
06:18:18.785188 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
06:18:18.785903 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:18:18.785979 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:18:18.786728 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:18:18.788356 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:18:18.788434 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 cascade;
drop view if exists autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 cascade;

  
06:18:18.789556 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:18:18.790103 [info ] [MainThread]: 



create or replace view autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 as
select "call_id"::text as "call_id", 
       "call_start_epoch"::bigint as "call_start_epoch", 
       "call_duration"::int as "call_duration", 
       "customer_id"::text as "customer_id", 
       "agent_id"::text as "agent_id"
       from testsatmap.calltable;


create or replace view autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 as
select  (call_id)::text as call_id, 
        (to_timestamp(call_start_epoch))::timestamptz as time_call_start, 
        (to_timestamp(call_start_epoch + call_duration))::timestamptz as time_call_end, 
        (call_duration)::int4 as num_duration_seconds, 
        (trim(customer_id))::text as customer_id, 
        (lower(trim(agent_id)))::text as agent_id
        from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000;


drop table if exists autopie_ebpdemo.tmp_staging_fact_0000000000;
create table autopie_ebpdemo.tmp_staging_fact_0000000000 as
(
    with expression_extract_1 as
    (
        select * from autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000
    ),
    expression_extract_2 as
    (
        select  t.*,
                (round(num_duration_seconds/60,2))::numeric as num_duration_minutes
                from expression_extract_1 t
    ),
    filter__3 as
    (
        select /* filtering irrelevant records out */ *
        from expression_extract_2
        where 1=1
        and agent_id is not null
        and customer_id is not null
        and num_duration_seconds > 10
    ),
    incremental_extract__4 as
    (
        select /* retrieving incremental data - by date range only */ *
        from filter__3
        where time_call_start >= to_date('2020-01-01', 'YYYY-MM-DD')
          and time_call_start  < to_date('2021-01-01', 'YYYY-MM-DD')
    ),
    deduplication__5 as
    (
        select /* deduplicate by strategy */
               call_id
               , max(time_call_start) as time_call_start
               , max(time_call_end) as time_call_end
               , max(num_duration_seconds) as num_duration_seconds
               , max(customer_id) as customer_id
               , max(agent_id) as agent_id
               , max(num_duration_minutes) as num_duration_minutes
        from incremental_extract__4
        group by call_id 
    ),
    coarsening_6 as
    (
        select * from deduplication__5
    )
    select  t.*,
            1 autopie_run_id
    from coarsening_6 t
);

drop view if exists autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 cascade;
drop view if exists autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 cascade;


-- check if not exists already, this should run once
do $$                  
begin
if not exists
( 
    select 1 from information_schema.tables 
    where table_schema||'.'|| table_name = 'autopie_ebpdemo.obj_fact_calls'
)
then
    create table autopie_ebpdemo.obj_fact_calls as (select * from autopie_ebpdemo.tmp_staging_fact_0000000000 where 1=0);
    alter  table autopie_ebpdemo.obj_fact_calls add column row_id bigserial not null;
    alter  table autopie_ebpdemo.obj_fact_calls add primary key (call_id, time_call_end);
    --
    create index ixrid_obj_fact_calls on autopie_ebpdemo.obj_fact_calls(row_id);
end if;
end
$$;

-- upsert staging additions into the permanent fact object
delete from autopie_ebpdemo.obj_fact_calls where (call_id, time_call_end) in (select call_id, time_call_end from autopie_ebpdemo.tmp_staging_fact_0000000000);
insert into autopie_ebpdemo.obj_fact_calls select * from autopie_ebpdemo.tmp_staging_fact_0000000000;
drop table autopie_ebpdemo.tmp_staging_fact_0000000000;


06:18:18.790531 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:18:18.790605 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    



create or replace view autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 as
select "call_id"::text as "call_id", 
       "call_start_epoch"::bigint as "call_start_epoch", 
       "call_duration"::int as "call_duration", 
       "customer_id"::text as "customer_id", 
       "agent_id"::text as "agent_id"
       from testsatmap.calltable;


create or replace view autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 as
select  (call_id)::text as call_id, 
        (to_timestamp(call_start_epoch))::timestamptz as time_call_start, 
        (to_timestamp(call_start_epoch + call_duration))::timestamptz as time_call_end, 
        (call_duration)::int4 as num_duration_seconds, 
        (trim(customer_id))::text as customer_id, 
        (lower(trim(agent_id)))::text as agent_id
        from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000;


drop table if exists autopie_ebpdemo.tmp_staging_fact_0000000000;
create table autopie_ebpdemo.tmp_staging_fact_0000000000 as
(
    with expression_extract_1 as
    (
        select * from autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000
    ),
    expression_extract_2 as
    (
        select  t.*,
                (round(num_duration_seconds/60,2))::numeric as num_duration_minutes
                from expression_extract_1 t
    ),
    filter__3 as
    (
        select /* filtering irrelevant records out */ *
        from expression_extract_2
        where 1=1
        and agent_id is not null
        and customer_id is not null
        and num_duration_seconds > 10
    ),
    incremental_extract__4 as
    (
        select /* retrieving incremental data - by date range only */ *
        from filter__3
        where time_call_start >= to_date('2020-01-01', 'YYYY-MM-DD')
          and time_call_start  < to_date('2021-01-01', 'YYYY-MM-DD')
    ),
    deduplication__5 as
    (
        select /* deduplicate by strategy */
               call_id
               , max(time_call_start) as time_call_start
               , max(time_call_end) as time_call_end
               , max(num_duration_seconds) as num_duration_seconds
               , max(customer_id) as customer_id
               , max(agent_id) as agent_id
               , max(num_duration_minutes) as num_duration_minutes
        from incremental_extract__4
        group by call_id 
    ),
    coarsening_6 as
    (
        select * from deduplication__5
    )
    select  t.*,
            1 autopie_run_id
    from coarsening_6 t
);

drop view if exists autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 cascade;
drop view if exists autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 cascade;


-- check if not exists already, this should run once
do $$                  
begin
if not exists
( 
    select 1 from information_schema.tables 
    where table_schema||'.'|| table_name = 'autopie_ebpdemo.obj_fact_calls'
)
then
    create table autopie_ebpdemo.obj_fact_calls as (select * from autopie_ebpdemo.tmp_staging_fact_0000000000 where 1=0);
    alter  table autopie_ebpdemo.obj_fact_calls add column row_id bigserial not null;
    alter  table autopie_ebpdemo.obj_fact_calls add primary key (call_id, time_call_end);
    --
    create index ixrid_obj_fact_calls on autopie_ebpdemo.obj_fact_calls(row_id);
end if;
end
$$;

-- upsert staging additions into the permanent fact object
delete from autopie_ebpdemo.obj_fact_calls where (call_id, time_call_end) in (select call_id, time_call_end from autopie_ebpdemo.tmp_staging_fact_0000000000);
insert into autopie_ebpdemo.obj_fact_calls select * from autopie_ebpdemo.tmp_staging_fact_0000000000;
drop table autopie_ebpdemo.tmp_staging_fact_0000000000;


  
06:18:18.815609 [debug] [MainThread]: SQL status: DROP TABLE in 0.02 seconds
06:18:18.816423 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:18:18.816524 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    
select row_number() over (order by autopie_run_id desc) run_sequence, count(*) count_records 
  from autopie_ebpdemo.obj_fact_calls
group by autopie_run_id
order by 1 
limit 5;

  
06:18:18.817184 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
06:18:18.819471 [debug] [MainThread]: On macro_run_recipe: Close
06:18:18.820251 [debug] [MainThread]: Connection 'macro_run_recipe' was properly closed.


============================== 2022-02-20 06:18:19.899467 | 1a4bb9b4-f2dd-4681-a140-302306ca04ee ==============================
06:18:19.899467 [info ] [MainThread]: Running with dbt=1.0.1
06:18:19.899831 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/hassanzaheer/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, macro='run_recipe', args='{\n    "recipe_type" : "collect_fact",\n    "target_fact" : {\n        "id": "outcomes", \n        "entity_and_dims": "customer_id",\n        "date":"date_outcome"\n    },\n    "ingredients": {\n        "expression_extract": {  \n            "source_raw": "testsatmap.outcomes",\n            "expression_list": [\n                {"expression": "outcome_date", "alias": "date_outcome"},\n                {"expression": "trim(customer_id)", "alias": "customer_id"},             \n                {"expression": "outcome_code::numeric", "alias": "num_outcome_amount"}\n            ]\n        },\n        "filter_conjunctions": [\n            "num_outcome_amount > 0",\n            "customer_id is not null"\n        ],\n        "incremental_update_on": "date_outcome",\n        "deduplication": {\n            "grouping_key": "customer_id, date_outcome, num_outcome_amount",\n            "preference": "arbitrary"\n        },\n        "coarsening": {\n            "entity_and_dims": "customer_id",\n            "date_expression":"date_outcome",\n            "aggregations": [\n                {"expression": "sum(num_outcome_amount)", "alias": "sum_outcome_amount"}\n            ]\n        }\n    }\n}', defer=None, state=None, cls=<class 'dbt.task.run_operation.RunOperationTask'>, which='run-operation', rpc_method='run-operation')
06:18:19.899942 [debug] [MainThread]: Tracking: do not track
06:18:19.919131 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 1 files added, 1 files changed.
06:18:19.919349 [debug] [MainThread]: Partial parsing: added file: demo_autopie://models/demo_ebp_flow/prepared_scripts/prepared_fact_outcomes.sql
06:18:19.919486 [debug] [MainThread]: Partial parsing: updated file: demo_autopie://models/demo_ebp_flow/prepared_scripts/prepared_fact_calls.sql
06:18:19.925012 [debug] [MainThread]: 1699: static parser successfully parsed demo_ebp_flow/prepared_scripts/prepared_fact_outcomes.sql
06:18:19.930376 [debug] [MainThread]: 1699: static parser successfully parsed demo_ebp_flow/prepared_scripts/prepared_fact_calls.sql
06:18:19.936331 [debug] [MainThread]: Acquiring new postgres connection "macro_run_recipe"
06:18:19.936431 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:18:19.936494 [debug] [MainThread]: On macro_run_recipe: BEGIN
06:18:19.936554 [debug] [MainThread]: Opening a new connection, currently in state init
06:18:19.940435 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
06:18:19.940523 [debug] [MainThread]: On macro_run_recipe: COMMIT
06:18:19.940579 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:18:19.940633 [debug] [MainThread]: On macro_run_recipe: COMMIT
06:18:19.940807 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
06:18:19.984405 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:18:19.984525 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select '"'||column_name||'"::'||
       case when replace(udt_name, '_','') = 'bit' then 'int'
            when replace(udt_name, '_','') like 'int8%' then 'bigint'
            when replace(udt_name, '_','') like 'int4%' then 'int'
            when replace(udt_name, '_','') like 'int%' then 'smallint'
            when replace(udt_name, '_','') like 'bool%' then 'int'
            when replace(udt_name, '_','') like 'float%' then 'numeric'
            when replace(udt_name, '_','') like 'float%' then 'numeric'
            when replace(udt_name, '_','') like 'byte%' then 'text'
            when replace(udt_name, '_','') like 'varchar%' then 'text'
            when replace(udt_name, '_','') like 'timestamp%' then 'timestamp'
            else replace(udt_name, '_','') end ||
       ' as "'||column_name||'"' select_text
from information_schema.columns 
where table_schema||'.'||table_name = 'testsatmap.outcomes'
order by ordinal_position ;

  
06:18:19.998788 [debug] [MainThread]: SQL status: SELECT 3 in 0.01 seconds
06:18:19.999623 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:18:19.999694 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 as
select "outcome_date"::date as "outcome_date", 
       "customer_id"::text as "customer_id", 
       "outcome_code"::text as "outcome_code"
       from testsatmap.outcomes;

  
06:18:20.006354 [debug] [MainThread]: SQL status: CREATE VIEW in 0.01 seconds
06:18:20.006890 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:18:20.006963 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:18:20.007192 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:18:20.007666 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:18:20.007730 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_exp_type_0000000000 as select outcome_date exp from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 limit 1
  
06:18:20.008749 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:18:20.009241 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:18:20.009307 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select replace(udt_name, '_','') dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type_0000000000' and column_name = 'exp'
  
06:18:20.012702 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
06:18:20.013423 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:18:20.013507 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:18:20.014582 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:18:20.015138 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:18:20.015213 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:18:20.015425 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:18:20.016017 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:18:20.016097 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_exp_type_0000000000 as select trim(customer_id) exp from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 limit 1
  
06:18:20.017252 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:18:20.017893 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:18:20.017966 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select replace(udt_name, '_','') dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type_0000000000' and column_name = 'exp'
  
06:18:20.021083 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
06:18:20.021612 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:18:20.021680 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:18:20.022394 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:18:20.022885 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:18:20.022952 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:18:20.023148 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:18:20.023634 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:18:20.023700 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_exp_type_0000000000 as select outcome_code::numeric exp from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 limit 1
  
06:18:20.024563 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:18:20.025087 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:18:20.025158 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select replace(udt_name, '_','') dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type_0000000000' and column_name = 'exp'
  
06:18:20.028511 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
06:18:20.029061 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:18:20.029132 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:18:20.029849 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:18:20.030384 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:18:20.030458 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 as
select  (outcome_date)::date as date_outcome, 
        (trim(customer_id))::text as customer_id, 
        (outcome_code::numeric)::numeric as num_outcome_amount
        from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000;

  
06:18:20.031430 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:18:20.032402 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:18:20.032476 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 cascade;
drop view if exists autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 cascade;

  
06:18:20.033549 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:18:20.034036 [info ] [MainThread]: 



create or replace view autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 as
select "outcome_date"::date as "outcome_date", 
       "customer_id"::text as "customer_id", 
       "outcome_code"::text as "outcome_code"
       from testsatmap.outcomes;


create or replace view autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 as
select  (outcome_date)::date as date_outcome, 
        (trim(customer_id))::text as customer_id, 
        (outcome_code::numeric)::numeric as num_outcome_amount
        from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000;


drop table if exists autopie_ebpdemo.tmp_staging_fact_0000000000;
create table autopie_ebpdemo.tmp_staging_fact_0000000000 as
(
    with expression_extract_1 as
    (
        select * from autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000
    ),
    expression_extract_2 as
    (
        select * from expression_extract_1
    ),
    filter__3 as
    (
        select /* filtering irrelevant records out */ *
        from expression_extract_2
        where 1=1
        and num_outcome_amount > 0
        and customer_id is not null
    ),
    incremental_extract__4 as
    (
        select /* retrieving incremental data - by date range only */ *
        from filter__3
        where date_outcome >= to_date('2020-01-01', 'YYYY-MM-DD')
          and date_outcome  < to_date('2021-01-01', 'YYYY-MM-DD')
    ),
    deduplication__5 as
    (
        select /* deduplicate by strategy */
               customer_id, date_outcome, num_outcome_amount
        from incremental_extract__4
        group by customer_id, date_outcome, num_outcome_amount 
    ),
    coarsening_6 as
    (
        select /* flatten all dimensions, fit into EAVT format */
              customer_id
              , date_outcome
              
              , sum(num_outcome_amount) as sum_outcome_amount
              from deduplication__5
        group by customer_id, date_outcome
    )
    select  t.*,
            1 autopie_run_id
    from coarsening_6 t
);

drop view if exists autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 cascade;
drop view if exists autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 cascade;


-- check if not exists already, this should run once
do $$                  
begin
if not exists
( 
    select 1 from information_schema.tables 
    where table_schema||'.'|| table_name = 'autopie_ebpdemo.obj_fact_outcomes'
)
then
    create table autopie_ebpdemo.obj_fact_outcomes as (select * from autopie_ebpdemo.tmp_staging_fact_0000000000 where 1=0);
    alter  table autopie_ebpdemo.obj_fact_outcomes add column row_id bigserial not null;
    alter  table autopie_ebpdemo.obj_fact_outcomes add primary key (customer_id, date_outcome);
    --
    create index ixrid_obj_fact_outcomes on autopie_ebpdemo.obj_fact_outcomes(row_id);
end if;
end
$$;

-- upsert staging additions into the permanent fact object
delete from autopie_ebpdemo.obj_fact_outcomes where (customer_id, date_outcome) in (select customer_id, date_outcome from autopie_ebpdemo.tmp_staging_fact_0000000000);
insert into autopie_ebpdemo.obj_fact_outcomes select * from autopie_ebpdemo.tmp_staging_fact_0000000000;
drop table autopie_ebpdemo.tmp_staging_fact_0000000000;


06:18:20.034409 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:18:20.034478 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    



create or replace view autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 as
select "outcome_date"::date as "outcome_date", 
       "customer_id"::text as "customer_id", 
       "outcome_code"::text as "outcome_code"
       from testsatmap.outcomes;


create or replace view autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 as
select  (outcome_date)::date as date_outcome, 
        (trim(customer_id))::text as customer_id, 
        (outcome_code::numeric)::numeric as num_outcome_amount
        from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000;


drop table if exists autopie_ebpdemo.tmp_staging_fact_0000000000;
create table autopie_ebpdemo.tmp_staging_fact_0000000000 as
(
    with expression_extract_1 as
    (
        select * from autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000
    ),
    expression_extract_2 as
    (
        select * from expression_extract_1
    ),
    filter__3 as
    (
        select /* filtering irrelevant records out */ *
        from expression_extract_2
        where 1=1
        and num_outcome_amount > 0
        and customer_id is not null
    ),
    incremental_extract__4 as
    (
        select /* retrieving incremental data - by date range only */ *
        from filter__3
        where date_outcome >= to_date('2020-01-01', 'YYYY-MM-DD')
          and date_outcome  < to_date('2021-01-01', 'YYYY-MM-DD')
    ),
    deduplication__5 as
    (
        select /* deduplicate by strategy */
               customer_id, date_outcome, num_outcome_amount
        from incremental_extract__4
        group by customer_id, date_outcome, num_outcome_amount 
    ),
    coarsening_6 as
    (
        select /* flatten all dimensions, fit into EAVT format */
              customer_id
              , date_outcome
              
              , sum(num_outcome_amount) as sum_outcome_amount
              from deduplication__5
        group by customer_id, date_outcome
    )
    select  t.*,
            1 autopie_run_id
    from coarsening_6 t
);

drop view if exists autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 cascade;
drop view if exists autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 cascade;


-- check if not exists already, this should run once
do $$                  
begin
if not exists
( 
    select 1 from information_schema.tables 
    where table_schema||'.'|| table_name = 'autopie_ebpdemo.obj_fact_outcomes'
)
then
    create table autopie_ebpdemo.obj_fact_outcomes as (select * from autopie_ebpdemo.tmp_staging_fact_0000000000 where 1=0);
    alter  table autopie_ebpdemo.obj_fact_outcomes add column row_id bigserial not null;
    alter  table autopie_ebpdemo.obj_fact_outcomes add primary key (customer_id, date_outcome);
    --
    create index ixrid_obj_fact_outcomes on autopie_ebpdemo.obj_fact_outcomes(row_id);
end if;
end
$$;

-- upsert staging additions into the permanent fact object
delete from autopie_ebpdemo.obj_fact_outcomes where (customer_id, date_outcome) in (select customer_id, date_outcome from autopie_ebpdemo.tmp_staging_fact_0000000000);
insert into autopie_ebpdemo.obj_fact_outcomes select * from autopie_ebpdemo.tmp_staging_fact_0000000000;
drop table autopie_ebpdemo.tmp_staging_fact_0000000000;


  
06:18:20.059216 [debug] [MainThread]: SQL status: DROP TABLE in 0.02 seconds
06:18:20.059934 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:18:20.060027 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    
select row_number() over (order by autopie_run_id desc) run_sequence, count(*) count_records 
  from autopie_ebpdemo.obj_fact_outcomes
group by autopie_run_id
order by 1 
limit 5;

  
06:18:20.060638 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
06:18:20.062796 [debug] [MainThread]: On macro_run_recipe: Close
06:18:20.063483 [debug] [MainThread]: Connection 'macro_run_recipe' was properly closed.


============================== 2022-02-20 06:20:15.185579 | c8b4e623-3c17-43f2-840b-72f0f6eb51ea ==============================
06:20:15.185579 [info ] [MainThread]: Running with dbt=1.0.1
06:20:15.186006 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/hassanzaheer/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, macro='run_recipe', args='{\n    "recipe_type" : "collect_fact",\n    "target_fact" : {\n        "id": "calls", \n        "entity_and_dims": "call_id",\n        "date":"time_call_end"\n    },\n    "ingredients": {\n        "expression_extract": {  \n            "source_raw": "testsatmap.calltable",\n            "expression_list": [\n                {"expression": "call_id", "alias": "call_id"},\n                {"expression": "to_timestamp(call_start_epoch)", "alias": "time_call_start"},\n                {"expression": "to_timestamp(call_start_epoch + call_duration)", "alias": "time_call_end"},\n                {"expression": "call_duration", "alias": "num_duration_seconds"},\n                {"expression": "trim(customer_id)",  "alias": "customer_id"},\n                {"expression": "lower(trim(agent_id))",  "alias": "agent_id"}\n            ]\n        },\n        "expression_extract_outer": {  \n            "expression_list": [\n                {"expression": "round(num_duration_seconds/60,2)", "alias": "num_duration_minutes"}\n            ]\n        },\n        "filter_conjunctions": [\n            "agent_id is not null",\n            "customer_id is not null",\n            "num_duration_seconds > 10"\n        ],\n        "incremental_update_on": "time_call_start",\n        "deduplication": {\n            "grouping_key": "call_id",\n            "preference": "arbitrary"\n        }\n    }\n}', defer=None, state=None, cls=<class 'dbt.task.run_operation.RunOperationTask'>, which='run-operation', rpc_method='run-operation')
06:20:15.186131 [debug] [MainThread]: Tracking: do not track
06:20:15.205464 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 3 files changed.
06:20:15.205708 [debug] [MainThread]: Partial parsing: updated file: demo_autopie://models/demo_ebp_flow/prepared_scripts/prepared_fact_calls.sql
06:20:15.205868 [debug] [MainThread]: Partial parsing: updated file: demo_autopie://macros/core/run_recipe.sql
06:20:15.205979 [debug] [MainThread]: Partial parsing: updated file: demo_autopie://models/demo_ebp_flow/prepared_scripts/prepared_fact_outcomes.sql
06:20:15.206068 [debug] [MainThread]: Parsing macros/core/run_directory.sql
06:20:15.207625 [debug] [MainThread]: Parsing macros/core/run_recipe.sql
06:20:15.219100 [debug] [MainThread]: 1699: static parser successfully parsed demo_ebp_flow/prepared_scripts/prepared_fact_calls.sql
06:20:15.224249 [debug] [MainThread]: 1699: static parser successfully parsed demo_ebp_flow/prepared_scripts/prepared_fact_outcomes.sql
06:20:15.230235 [debug] [MainThread]: Acquiring new postgres connection "macro_run_recipe"
06:20:15.230341 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:20:15.230405 [debug] [MainThread]: On macro_run_recipe: BEGIN
06:20:15.230467 [debug] [MainThread]: Opening a new connection, currently in state init
06:20:15.252554 [debug] [MainThread]: SQL status: BEGIN in 0.02 seconds
06:20:15.252664 [debug] [MainThread]: On macro_run_recipe: COMMIT
06:20:15.252732 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:20:15.252791 [debug] [MainThread]: On macro_run_recipe: COMMIT
06:20:15.252943 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
06:20:15.297560 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:20:15.297693 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select '"'||column_name||'"::'||
       case when replace(udt_name, '_','') = 'bit' then 'int'
            when replace(udt_name, '_','') like 'int8%' then 'bigint'
            when replace(udt_name, '_','') like 'int4%' then 'int'
            when replace(udt_name, '_','') like 'int%' then 'smallint'
            when replace(udt_name, '_','') like 'bool%' then 'int'
            when replace(udt_name, '_','') like 'float%' then 'numeric'
            when replace(udt_name, '_','') like 'float%' then 'numeric'
            when replace(udt_name, '_','') like 'byte%' then 'text'
            when replace(udt_name, '_','') like 'varchar%' then 'text'
            when replace(udt_name, '_','') like 'timestamp%' then 'timestamp'
            else replace(udt_name, '_','') end ||
       ' as "'||column_name||'"' select_text
from information_schema.columns 
where table_schema||'.'||table_name = 'testsatmap.calltable'
order by ordinal_position ;

  
06:20:15.316071 [debug] [MainThread]: SQL status: SELECT 5 in 0.02 seconds
06:20:15.316956 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:20:15.317033 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 as
select "call_id"::text as "call_id", 
       "call_start_epoch"::bigint as "call_start_epoch", 
       "call_duration"::int as "call_duration", 
       "customer_id"::text as "customer_id", 
       "agent_id"::text as "agent_id"
       from testsatmap.calltable;

  
06:20:15.320515 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:20:15.321061 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:20:15.321131 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:20:15.321367 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:20:15.321874 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:20:15.321941 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_exp_type_0000000000 as select call_id exp from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 limit 1
  
06:20:15.322886 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:20:15.323378 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:20:15.323444 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select replace(udt_name, '_','') dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type_0000000000' and column_name = 'exp'
  
06:20:15.327060 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
06:20:15.327582 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:20:15.327648 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:20:15.328717 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:20:15.329216 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:20:15.329289 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:20:15.329489 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:20:15.329967 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:20:15.330032 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_exp_type_0000000000 as select to_timestamp(call_start_epoch) exp from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 limit 1
  
06:20:15.331230 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:20:15.331838 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:20:15.331911 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select replace(udt_name, '_','') dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type_0000000000' and column_name = 'exp'
  
06:20:15.335083 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
06:20:15.335639 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:20:15.335712 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:20:15.336403 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:20:15.336930 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:20:15.337003 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:20:15.337199 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:20:15.337716 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:20:15.337788 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_exp_type_0000000000 as select to_timestamp(call_start_epoch + call_duration) exp from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 limit 1
  
06:20:15.338783 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:20:15.339311 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:20:15.339384 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select replace(udt_name, '_','') dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type_0000000000' and column_name = 'exp'
  
06:20:15.342448 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
06:20:15.342996 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:20:15.343066 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:20:15.343745 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:20:15.344271 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:20:15.344341 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:20:15.344546 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:20:15.345067 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:20:15.345140 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_exp_type_0000000000 as select call_duration exp from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 limit 1
  
06:20:15.345972 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:20:15.346489 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:20:15.346559 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select replace(udt_name, '_','') dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type_0000000000' and column_name = 'exp'
  
06:20:15.349673 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
06:20:15.350228 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:20:15.350298 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:20:15.351018 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:20:15.351551 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:20:15.351621 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:20:15.351935 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:20:15.352459 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:20:15.352530 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_exp_type_0000000000 as select trim(customer_id) exp from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 limit 1
  
06:20:15.353953 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:20:15.354473 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:20:15.354544 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select replace(udt_name, '_','') dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type_0000000000' and column_name = 'exp'
  
06:20:15.358787 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
06:20:15.359341 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:20:15.359412 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:20:15.360279 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:20:15.360800 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:20:15.360870 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:20:15.361163 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:20:15.361676 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:20:15.361746 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_exp_type_0000000000 as select lower(trim(agent_id)) exp from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 limit 1
  
06:20:15.363389 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:20:15.363902 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:20:15.363972 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select replace(udt_name, '_','') dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type_0000000000' and column_name = 'exp'
  
06:20:15.368629 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
06:20:15.369223 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:20:15.369299 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:20:15.370040 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:20:15.370616 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:20:15.370692 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 as
select  (call_id)::text as call_id, 
        (to_timestamp(call_start_epoch))::timestamptz as time_call_start, 
        (to_timestamp(call_start_epoch + call_duration))::timestamptz as time_call_end, 
        (call_duration)::int4 as num_duration_seconds, 
        (trim(customer_id))::text as customer_id, 
        (lower(trim(agent_id)))::text as agent_id
        from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000;

  
06:20:15.372206 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:20:15.372783 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:20:15.372863 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:20:15.373078 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:20:15.373641 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:20:15.373717 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_exp_type_0000000000 as select round(num_duration_seconds/60,2) exp from autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 limit 1
  
06:20:15.374756 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:20:15.375313 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:20:15.375389 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select replace(udt_name, '_','') dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type_0000000000' and column_name = 'exp'
  
06:20:15.378544 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
06:20:15.379261 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:20:15.379338 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:20:15.380177 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:20:15.381832 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:20:15.381912 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 cascade;
drop view if exists autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 cascade;

  
06:20:15.383090 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:20:15.383634 [info ] [MainThread]: 



create or replace view autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 as
select "call_id"::text as "call_id", 
       "call_start_epoch"::bigint as "call_start_epoch", 
       "call_duration"::int as "call_duration", 
       "customer_id"::text as "customer_id", 
       "agent_id"::text as "agent_id"
       from testsatmap.calltable;


create or replace view autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 as
select  (call_id)::text as call_id, 
        (to_timestamp(call_start_epoch))::timestamptz as time_call_start, 
        (to_timestamp(call_start_epoch + call_duration))::timestamptz as time_call_end, 
        (call_duration)::int4 as num_duration_seconds, 
        (trim(customer_id))::text as customer_id, 
        (lower(trim(agent_id)))::text as agent_id
        from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000;


drop table if exists autopie_ebpdemo.tmp_staging_fact_0000000000;
create table autopie_ebpdemo.tmp_staging_fact_0000000000 as
(
    with expression_extract_1 as
    (
        select * from autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000
    ),
    expression_extract_2 as
    (
        select  t.*,
                (round(num_duration_seconds/60,2))::numeric as num_duration_minutes
                from expression_extract_1 t
    ),
    filter__3 as
    (
        select /* filtering irrelevant records out */ *
        from expression_extract_2
        where 1=1
        and agent_id is not null
        and customer_id is not null
        and num_duration_seconds > 10
    ),
    incremental_extract__4 as
    (
        select /* retrieving incremental data - by date range only */ *
        from filter__3
        where time_call_start >= to_date('2020-01-01', 'YYYY-MM-DD')
          and time_call_start  < to_date('2021-01-01', 'YYYY-MM-DD')
    ),
    deduplication__5 as
    (
        select /* deduplicate by strategy */
               call_id
               , max(time_call_start) as time_call_start
               , max(time_call_end) as time_call_end
               , max(num_duration_seconds) as num_duration_seconds
               , max(customer_id) as customer_id
               , max(agent_id) as agent_id
               , max(num_duration_minutes) as num_duration_minutes
        from incremental_extract__4
        group by call_id 
    ),
    coarsening_6 as
    (
        select * from deduplication__5
    )
    select  t.*,
            1 autopie_run_id
    from coarsening_6 t
);

drop view if exists autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 cascade;
drop view if exists autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 cascade;


-- check if not exists already, this should run once
do $$                  
begin
if not exists
( 
    select 1 from information_schema.tables 
    where table_schema||'.'|| table_name = 'autopie_ebpdemo.obj_fact_calls'
)
then
    create table autopie_ebpdemo.obj_fact_calls as (select * from autopie_ebpdemo.tmp_staging_fact_0000000000 where 1=0);
    alter  table autopie_ebpdemo.obj_fact_calls add column row_id bigserial not null;
    alter  table autopie_ebpdemo.obj_fact_calls add primary key (call_id, time_call_end);
    --
    create index ixrid_obj_fact_calls on autopie_ebpdemo.obj_fact_calls(row_id);
end if;
end
$$;

-- upsert staging additions into the permanent fact object
delete from autopie_ebpdemo.obj_fact_calls where (call_id, time_call_end) in (select call_id, time_call_end from autopie_ebpdemo.tmp_staging_fact_0000000000);
insert into autopie_ebpdemo.obj_fact_calls select * from autopie_ebpdemo.tmp_staging_fact_0000000000;
drop table autopie_ebpdemo.tmp_staging_fact_0000000000;


06:20:15.384056 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:20:15.384128 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    



create or replace view autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 as
select "call_id"::text as "call_id", 
       "call_start_epoch"::bigint as "call_start_epoch", 
       "call_duration"::int as "call_duration", 
       "customer_id"::text as "customer_id", 
       "agent_id"::text as "agent_id"
       from testsatmap.calltable;


create or replace view autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 as
select  (call_id)::text as call_id, 
        (to_timestamp(call_start_epoch))::timestamptz as time_call_start, 
        (to_timestamp(call_start_epoch + call_duration))::timestamptz as time_call_end, 
        (call_duration)::int4 as num_duration_seconds, 
        (trim(customer_id))::text as customer_id, 
        (lower(trim(agent_id)))::text as agent_id
        from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000;


drop table if exists autopie_ebpdemo.tmp_staging_fact_0000000000;
create table autopie_ebpdemo.tmp_staging_fact_0000000000 as
(
    with expression_extract_1 as
    (
        select * from autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000
    ),
    expression_extract_2 as
    (
        select  t.*,
                (round(num_duration_seconds/60,2))::numeric as num_duration_minutes
                from expression_extract_1 t
    ),
    filter__3 as
    (
        select /* filtering irrelevant records out */ *
        from expression_extract_2
        where 1=1
        and agent_id is not null
        and customer_id is not null
        and num_duration_seconds > 10
    ),
    incremental_extract__4 as
    (
        select /* retrieving incremental data - by date range only */ *
        from filter__3
        where time_call_start >= to_date('2020-01-01', 'YYYY-MM-DD')
          and time_call_start  < to_date('2021-01-01', 'YYYY-MM-DD')
    ),
    deduplication__5 as
    (
        select /* deduplicate by strategy */
               call_id
               , max(time_call_start) as time_call_start
               , max(time_call_end) as time_call_end
               , max(num_duration_seconds) as num_duration_seconds
               , max(customer_id) as customer_id
               , max(agent_id) as agent_id
               , max(num_duration_minutes) as num_duration_minutes
        from incremental_extract__4
        group by call_id 
    ),
    coarsening_6 as
    (
        select * from deduplication__5
    )
    select  t.*,
            1 autopie_run_id
    from coarsening_6 t
);

drop view if exists autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 cascade;
drop view if exists autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 cascade;


-- check if not exists already, this should run once
do $$                  
begin
if not exists
( 
    select 1 from information_schema.tables 
    where table_schema||'.'|| table_name = 'autopie_ebpdemo.obj_fact_calls'
)
then
    create table autopie_ebpdemo.obj_fact_calls as (select * from autopie_ebpdemo.tmp_staging_fact_0000000000 where 1=0);
    alter  table autopie_ebpdemo.obj_fact_calls add column row_id bigserial not null;
    alter  table autopie_ebpdemo.obj_fact_calls add primary key (call_id, time_call_end);
    --
    create index ixrid_obj_fact_calls on autopie_ebpdemo.obj_fact_calls(row_id);
end if;
end
$$;

-- upsert staging additions into the permanent fact object
delete from autopie_ebpdemo.obj_fact_calls where (call_id, time_call_end) in (select call_id, time_call_end from autopie_ebpdemo.tmp_staging_fact_0000000000);
insert into autopie_ebpdemo.obj_fact_calls select * from autopie_ebpdemo.tmp_staging_fact_0000000000;
drop table autopie_ebpdemo.tmp_staging_fact_0000000000;


  
06:20:15.410416 [debug] [MainThread]: SQL status: DROP TABLE in 0.03 seconds
06:20:15.411248 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:20:15.411367 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    
select row_number() over (order by autopie_run_id desc) run_sequence, count(*) count_records 
  from autopie_ebpdemo.obj_fact_calls
group by autopie_run_id
order by 1 
limit 5;

  
06:20:15.412027 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
06:20:15.414281 [debug] [MainThread]: On macro_run_recipe: Close
06:20:15.415039 [debug] [MainThread]: Connection 'macro_run_recipe' was properly closed.


============================== 2022-02-20 06:20:16.490531 | 81e9d518-7129-45bf-aa0b-a5f5f9ffdd36 ==============================
06:20:16.490531 [info ] [MainThread]: Running with dbt=1.0.1
06:20:16.490965 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/hassanzaheer/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, macro='run_recipe', args='{\n    "recipe_type" : "collect_fact",\n    "target_fact" : {\n        "id": "outcomes", \n        "entity_and_dims": "customer_id",\n        "date":"date_outcome"\n    },\n    "ingredients": {\n        "expression_extract": {  \n            "source_raw": "testsatmap.outcomes",\n            "expression_list": [\n                {"expression": "outcome_date", "alias": "date_outcome"},\n                {"expression": "trim(customer_id)", "alias": "customer_id"},             \n                {"expression": "outcome_code::numeric", "alias": "num_outcome_amount"}\n            ]\n        },\n        "filter_conjunctions": [\n            "num_outcome_amount > 0",\n            "customer_id is not null"\n        ],\n        "incremental_update_on": "date_outcome",\n        "deduplication": {\n            "grouping_key": "customer_id, date_outcome, num_outcome_amount",\n            "preference": "arbitrary"\n        },\n        "coarsening": {\n            "entity_and_dims": "customer_id",\n            "date_expression":"date_outcome",\n            "aggregations": [\n                {"expression": "sum(num_outcome_amount)", "alias": "sum_outcome_amount"}\n            ]\n        }\n    }\n}', defer=None, state=None, cls=<class 'dbt.task.run_operation.RunOperationTask'>, which='run-operation', rpc_method='run-operation')
06:20:16.491077 [debug] [MainThread]: Tracking: do not track
06:20:16.511870 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
06:20:16.512134 [debug] [MainThread]: Partial parsing: updated file: demo_autopie://models/demo_ebp_flow/prepared_scripts/prepared_fact_calls.sql
06:20:16.517652 [debug] [MainThread]: 1699: static parser successfully parsed demo_ebp_flow/prepared_scripts/prepared_fact_calls.sql
06:20:16.528114 [debug] [MainThread]: Acquiring new postgres connection "macro_run_recipe"
06:20:16.528223 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:20:16.528284 [debug] [MainThread]: On macro_run_recipe: BEGIN
06:20:16.528345 [debug] [MainThread]: Opening a new connection, currently in state init
06:20:16.532715 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
06:20:16.532834 [debug] [MainThread]: On macro_run_recipe: COMMIT
06:20:16.532897 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:20:16.532955 [debug] [MainThread]: On macro_run_recipe: COMMIT
06:20:16.533126 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
06:20:16.576638 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:20:16.576761 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select '"'||column_name||'"::'||
       case when replace(udt_name, '_','') = 'bit' then 'int'
            when replace(udt_name, '_','') like 'int8%' then 'bigint'
            when replace(udt_name, '_','') like 'int4%' then 'int'
            when replace(udt_name, '_','') like 'int%' then 'smallint'
            when replace(udt_name, '_','') like 'bool%' then 'int'
            when replace(udt_name, '_','') like 'float%' then 'numeric'
            when replace(udt_name, '_','') like 'float%' then 'numeric'
            when replace(udt_name, '_','') like 'byte%' then 'text'
            when replace(udt_name, '_','') like 'varchar%' then 'text'
            when replace(udt_name, '_','') like 'timestamp%' then 'timestamp'
            else replace(udt_name, '_','') end ||
       ' as "'||column_name||'"' select_text
from information_schema.columns 
where table_schema||'.'||table_name = 'testsatmap.outcomes'
order by ordinal_position ;

  
06:20:16.591160 [debug] [MainThread]: SQL status: SELECT 3 in 0.01 seconds
06:20:16.591969 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:20:16.592035 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 as
select "outcome_date"::date as "outcome_date", 
       "customer_id"::text as "customer_id", 
       "outcome_code"::text as "outcome_code"
       from testsatmap.outcomes;

  
06:20:16.594807 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:20:16.595308 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:20:16.595372 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:20:16.595594 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:20:16.596055 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:20:16.596116 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_exp_type_0000000000 as select outcome_date exp from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 limit 1
  
06:20:16.597535 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:20:16.598026 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:20:16.598091 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select replace(udt_name, '_','') dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type_0000000000' and column_name = 'exp'
  
06:20:16.601279 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
06:20:16.601791 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:20:16.601858 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:20:16.602900 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:20:16.603404 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:20:16.603468 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:20:16.603662 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:20:16.604145 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:20:16.604209 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_exp_type_0000000000 as select trim(customer_id) exp from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 limit 1
  
06:20:16.605105 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:20:16.605724 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:20:16.605790 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select replace(udt_name, '_','') dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type_0000000000' and column_name = 'exp'
  
06:20:16.610096 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
06:20:16.610612 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:20:16.610676 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:20:16.611509 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:20:16.611999 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:20:16.612065 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:20:16.612266 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:20:16.612755 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:20:16.612824 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_exp_type_0000000000 as select outcome_code::numeric exp from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 limit 1
  
06:20:16.613946 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:20:16.614465 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:20:16.614533 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select replace(udt_name, '_','') dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type_0000000000' and column_name = 'exp'
  
06:20:16.617652 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
06:20:16.618201 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:20:16.618276 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:20:16.618967 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:20:16.619489 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:20:16.619557 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 as
select  (outcome_date)::date as date_outcome, 
        (trim(customer_id))::text as customer_id, 
        (outcome_code::numeric)::numeric as num_outcome_amount
        from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000;

  
06:20:16.620768 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:20:16.621716 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:20:16.621789 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 cascade;
drop view if exists autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 cascade;

  
06:20:16.622748 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:20:16.623234 [info ] [MainThread]: 



create or replace view autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 as
select "outcome_date"::date as "outcome_date", 
       "customer_id"::text as "customer_id", 
       "outcome_code"::text as "outcome_code"
       from testsatmap.outcomes;


create or replace view autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 as
select  (outcome_date)::date as date_outcome, 
        (trim(customer_id))::text as customer_id, 
        (outcome_code::numeric)::numeric as num_outcome_amount
        from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000;


drop table if exists autopie_ebpdemo.tmp_staging_fact_0000000000;
create table autopie_ebpdemo.tmp_staging_fact_0000000000 as
(
    with expression_extract_1 as
    (
        select * from autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000
    ),
    expression_extract_2 as
    (
        select * from expression_extract_1
    ),
    filter__3 as
    (
        select /* filtering irrelevant records out */ *
        from expression_extract_2
        where 1=1
        and num_outcome_amount > 0
        and customer_id is not null
    ),
    incremental_extract__4 as
    (
        select /* retrieving incremental data - by date range only */ *
        from filter__3
        where date_outcome >= to_date('2020-01-01', 'YYYY-MM-DD')
          and date_outcome  < to_date('2021-01-01', 'YYYY-MM-DD')
    ),
    deduplication__5 as
    (
        select /* deduplicate by strategy */
               customer_id, date_outcome, num_outcome_amount
        from incremental_extract__4
        group by customer_id, date_outcome, num_outcome_amount 
    ),
    coarsening_6 as
    (
        select /* flatten all dimensions, fit into EAVT format */
              customer_id
              , date_outcome
              
              , sum(num_outcome_amount) as sum_outcome_amount
              from deduplication__5
        group by customer_id, date_outcome
    )
    select  t.*,
            1 autopie_run_id
    from coarsening_6 t
);

drop view if exists autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 cascade;
drop view if exists autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 cascade;


-- check if not exists already, this should run once
do $$                  
begin
if not exists
( 
    select 1 from information_schema.tables 
    where table_schema||'.'|| table_name = 'autopie_ebpdemo.obj_fact_outcomes'
)
then
    create table autopie_ebpdemo.obj_fact_outcomes as (select * from autopie_ebpdemo.tmp_staging_fact_0000000000 where 1=0);
    alter  table autopie_ebpdemo.obj_fact_outcomes add column row_id bigserial not null;
    alter  table autopie_ebpdemo.obj_fact_outcomes add primary key (customer_id, date_outcome);
    --
    create index ixrid_obj_fact_outcomes on autopie_ebpdemo.obj_fact_outcomes(row_id);
end if;
end
$$;

-- upsert staging additions into the permanent fact object
delete from autopie_ebpdemo.obj_fact_outcomes where (customer_id, date_outcome) in (select customer_id, date_outcome from autopie_ebpdemo.tmp_staging_fact_0000000000);
insert into autopie_ebpdemo.obj_fact_outcomes select * from autopie_ebpdemo.tmp_staging_fact_0000000000;
drop table autopie_ebpdemo.tmp_staging_fact_0000000000;


06:20:16.623612 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:20:16.623676 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    



create or replace view autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 as
select "outcome_date"::date as "outcome_date", 
       "customer_id"::text as "customer_id", 
       "outcome_code"::text as "outcome_code"
       from testsatmap.outcomes;


create or replace view autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 as
select  (outcome_date)::date as date_outcome, 
        (trim(customer_id))::text as customer_id, 
        (outcome_code::numeric)::numeric as num_outcome_amount
        from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000;


drop table if exists autopie_ebpdemo.tmp_staging_fact_0000000000;
create table autopie_ebpdemo.tmp_staging_fact_0000000000 as
(
    with expression_extract_1 as
    (
        select * from autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000
    ),
    expression_extract_2 as
    (
        select * from expression_extract_1
    ),
    filter__3 as
    (
        select /* filtering irrelevant records out */ *
        from expression_extract_2
        where 1=1
        and num_outcome_amount > 0
        and customer_id is not null
    ),
    incremental_extract__4 as
    (
        select /* retrieving incremental data - by date range only */ *
        from filter__3
        where date_outcome >= to_date('2020-01-01', 'YYYY-MM-DD')
          and date_outcome  < to_date('2021-01-01', 'YYYY-MM-DD')
    ),
    deduplication__5 as
    (
        select /* deduplicate by strategy */
               customer_id, date_outcome, num_outcome_amount
        from incremental_extract__4
        group by customer_id, date_outcome, num_outcome_amount 
    ),
    coarsening_6 as
    (
        select /* flatten all dimensions, fit into EAVT format */
              customer_id
              , date_outcome
              
              , sum(num_outcome_amount) as sum_outcome_amount
              from deduplication__5
        group by customer_id, date_outcome
    )
    select  t.*,
            1 autopie_run_id
    from coarsening_6 t
);

drop view if exists autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 cascade;
drop view if exists autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 cascade;


-- check if not exists already, this should run once
do $$                  
begin
if not exists
( 
    select 1 from information_schema.tables 
    where table_schema||'.'|| table_name = 'autopie_ebpdemo.obj_fact_outcomes'
)
then
    create table autopie_ebpdemo.obj_fact_outcomes as (select * from autopie_ebpdemo.tmp_staging_fact_0000000000 where 1=0);
    alter  table autopie_ebpdemo.obj_fact_outcomes add column row_id bigserial not null;
    alter  table autopie_ebpdemo.obj_fact_outcomes add primary key (customer_id, date_outcome);
    --
    create index ixrid_obj_fact_outcomes on autopie_ebpdemo.obj_fact_outcomes(row_id);
end if;
end
$$;

-- upsert staging additions into the permanent fact object
delete from autopie_ebpdemo.obj_fact_outcomes where (customer_id, date_outcome) in (select customer_id, date_outcome from autopie_ebpdemo.tmp_staging_fact_0000000000);
insert into autopie_ebpdemo.obj_fact_outcomes select * from autopie_ebpdemo.tmp_staging_fact_0000000000;
drop table autopie_ebpdemo.tmp_staging_fact_0000000000;


  
06:20:16.648244 [debug] [MainThread]: SQL status: DROP TABLE in 0.02 seconds
06:20:16.648970 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:20:16.649056 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    
select row_number() over (order by autopie_run_id desc) run_sequence, count(*) count_records 
  from autopie_ebpdemo.obj_fact_outcomes
group by autopie_run_id
order by 1 
limit 5;

  
06:20:16.649660 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
06:20:16.651819 [debug] [MainThread]: On macro_run_recipe: Close
06:20:16.652524 [debug] [MainThread]: Connection 'macro_run_recipe' was properly closed.


============================== 2022-02-20 06:22:47.389839 | 4400e707-702e-4092-bc1d-2b3e64d9adfd ==============================
06:22:47.389839 [info ] [MainThread]: Running with dbt=1.0.1
06:22:47.390228 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/hassanzaheer/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, macro='run_recipe', args='{\n    "recipe_type" : "collect_fact",\n    "target_fact" : {\n        "id": "calls", \n        "entity_and_dims": "call_id",\n        "date":"time_call_end"\n    },\n    "ingredients": {\n        "expression_extract": {  \n            "source_raw": "testsatmap.calltable",\n            "expression_list": [\n                {"expression": "call_id", "alias": "call_id"},\n                {"expression": "to_timestamp(call_start_epoch)", "alias": "time_call_start"},\n                {"expression": "to_timestamp(call_start_epoch + call_duration)", "alias": "time_call_end"},\n                {"expression": "call_duration", "alias": "num_duration_seconds"},\n                {"expression": "trim(customer_id)",  "alias": "customer_id"},\n                {"expression": "lower(trim(agent_id))",  "alias": "agent_id"}\n            ]\n        },\n        "expression_extract_outer": {  \n            "expression_list": [\n                {"expression": "round(num_duration_seconds/60,2)", "alias": "num_duration_minutes"}\n            ]\n        },\n        "filter_conjunctions": [\n            "agent_id is not null",\n            "customer_id is not null",\n            "num_duration_seconds > 10"\n        ],\n        "incremental_update_on": "time_call_start",\n        "deduplication": {\n            "grouping_key": "call_id",\n            "preference": "arbitrary"\n        }\n    }\n}', defer=None, state=None, cls=<class 'dbt.task.run_operation.RunOperationTask'>, which='run-operation', rpc_method='run-operation')
06:22:47.390343 [debug] [MainThread]: Tracking: do not track
06:22:47.409491 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 2 files changed.
06:22:47.409741 [debug] [MainThread]: Partial parsing: updated file: demo_autopie://models/demo_ebp_flow/prepared_scripts/prepared_fact_calls.sql
06:22:47.409863 [debug] [MainThread]: Partial parsing: updated file: demo_autopie://models/demo_ebp_flow/prepared_scripts/prepared_fact_outcomes.sql
06:22:47.415301 [debug] [MainThread]: 1699: static parser successfully parsed demo_ebp_flow/prepared_scripts/prepared_fact_calls.sql
06:22:47.420897 [debug] [MainThread]: 1699: static parser successfully parsed demo_ebp_flow/prepared_scripts/prepared_fact_outcomes.sql
06:22:47.426936 [debug] [MainThread]: Acquiring new postgres connection "macro_run_recipe"
06:22:47.427043 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:22:47.427109 [debug] [MainThread]: On macro_run_recipe: BEGIN
06:22:47.427169 [debug] [MainThread]: Opening a new connection, currently in state init
06:22:47.450335 [debug] [MainThread]: SQL status: BEGIN in 0.02 seconds
06:22:47.450444 [debug] [MainThread]: On macro_run_recipe: COMMIT
06:22:47.450514 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:22:47.450575 [debug] [MainThread]: On macro_run_recipe: COMMIT
06:22:47.450713 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
06:22:47.495461 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:22:47.495588 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select '"'||column_name||'"::'||
       case when replace(udt_name, '_','') = 'bit' then 'int'
            when replace(udt_name, '_','') like 'int8%' then 'bigint'
            when replace(udt_name, '_','') like 'int4%' then 'int'
            when replace(udt_name, '_','') like 'int%' then 'smallint'
            when replace(udt_name, '_','') like 'bool%' then 'int'
            when replace(udt_name, '_','') like 'float%' then 'numeric'
            when replace(udt_name, '_','') like 'float%' then 'numeric'
            when replace(udt_name, '_','') like 'byte%' then 'text'
            when replace(udt_name, '_','') like 'varchar%' then 'text'
            when replace(udt_name, '_','') like 'timestamp%' then 'timestamp'
            else replace(udt_name, '_','') end ||
       ' as "'||column_name||'"' select_text
from information_schema.columns 
where table_schema||'.'||table_name = 'testsatmap.calltable'
order by ordinal_position ;

  
06:22:47.509217 [debug] [MainThread]: SQL status: SELECT 5 in 0.01 seconds
06:22:47.510177 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:22:47.510260 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 as
select "call_id"::text as "call_id", 
       "call_start_epoch"::bigint as "call_start_epoch", 
       "call_duration"::int as "call_duration", 
       "customer_id"::text as "customer_id", 
       "agent_id"::text as "agent_id"
       from testsatmap.calltable;

  
06:22:47.513295 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:22:47.513855 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:22:47.513935 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:22:47.514170 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:22:47.514687 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:22:47.514757 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_exp_type_0000000000 as select call_id exp from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 limit 1
  
06:22:47.515984 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:22:47.516496 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:22:47.516565 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select replace(udt_name, '_','') dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type_0000000000' and column_name = 'exp'
  
06:22:47.519862 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
06:22:47.520383 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:22:47.520452 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:22:47.521695 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:22:47.522197 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:22:47.522264 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:22:47.522500 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:22:47.522987 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:22:47.523057 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_exp_type_0000000000 as select to_timestamp(call_start_epoch) exp from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 limit 1
  
06:22:47.524273 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:22:47.524879 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:22:47.524950 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select replace(udt_name, '_','') dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type_0000000000' and column_name = 'exp'
  
06:22:47.529202 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
06:22:47.529756 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:22:47.529835 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:22:47.530523 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:22:47.531051 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:22:47.531123 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:22:47.531409 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:22:47.531933 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:22:47.532005 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_exp_type_0000000000 as select to_timestamp(call_start_epoch + call_duration) exp from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 limit 1
  
06:22:47.533185 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:22:47.533708 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:22:47.533779 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select replace(udt_name, '_','') dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type_0000000000' and column_name = 'exp'
  
06:22:47.536925 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
06:22:47.537479 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:22:47.537557 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:22:47.538284 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:22:47.538813 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:22:47.538884 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:22:47.539092 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:22:47.539610 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:22:47.539682 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_exp_type_0000000000 as select call_duration exp from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 limit 1
  
06:22:47.540507 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:22:47.541036 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:22:47.541107 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select replace(udt_name, '_','') dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type_0000000000' and column_name = 'exp'
  
06:22:47.544159 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
06:22:47.544710 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:22:47.544784 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:22:47.545454 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:22:47.545975 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:22:47.546046 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:22:47.546361 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:22:47.546889 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:22:47.546960 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_exp_type_0000000000 as select trim(customer_id) exp from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 limit 1
  
06:22:47.547873 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:22:47.548399 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:22:47.548470 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select replace(udt_name, '_','') dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type_0000000000' and column_name = 'exp'
  
06:22:47.553628 [debug] [MainThread]: SQL status: SELECT 1 in 0.01 seconds
06:22:47.554192 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:22:47.554263 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:22:47.555002 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:22:47.555525 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:22:47.555597 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:22:47.555805 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:22:47.556323 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:22:47.556394 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_exp_type_0000000000 as select lower(trim(agent_id)) exp from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 limit 1
  
06:22:47.557550 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:22:47.558077 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:22:47.558149 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select replace(udt_name, '_','') dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type_0000000000' and column_name = 'exp'
  
06:22:47.561456 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
06:22:47.562006 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:22:47.562077 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:22:47.562749 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:22:47.563270 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:22:47.563342 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 as
select  (call_id)::text as call_id, 
        (to_timestamp(call_start_epoch))::timestamptz as time_call_start, 
        (to_timestamp(call_start_epoch + call_duration))::timestamptz as time_call_end, 
        (call_duration)::int4 as num_duration_seconds, 
        (trim(customer_id))::text as customer_id, 
        (lower(trim(agent_id)))::text as agent_id
        from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000;

  
06:22:47.564511 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:22:47.565055 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:22:47.565137 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:22:47.565351 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:22:47.565912 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:22:47.565989 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_exp_type_0000000000 as select round(num_duration_seconds/60,2) exp from autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 limit 1
  
06:22:47.567017 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:22:47.567589 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:22:47.567669 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select replace(udt_name, '_','') dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type_0000000000' and column_name = 'exp'
  
06:22:47.570863 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
06:22:47.571585 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:22:47.571663 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:22:47.572633 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:22:47.574247 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:22:47.574329 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 cascade;
drop view if exists autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 cascade;

  
06:22:47.575197 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:22:47.575733 [info ] [MainThread]: 



create or replace view autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 as
select "call_id"::text as "call_id", 
       "call_start_epoch"::bigint as "call_start_epoch", 
       "call_duration"::int as "call_duration", 
       "customer_id"::text as "customer_id", 
       "agent_id"::text as "agent_id"
       from testsatmap.calltable;


create or replace view autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 as
select  (call_id)::text as call_id, 
        (to_timestamp(call_start_epoch))::timestamptz as time_call_start, 
        (to_timestamp(call_start_epoch + call_duration))::timestamptz as time_call_end, 
        (call_duration)::int4 as num_duration_seconds, 
        (trim(customer_id))::text as customer_id, 
        (lower(trim(agent_id)))::text as agent_id
        from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000;


drop table if exists autopie_ebpdemo.tmp_staging_fact_0000000000;
create table autopie_ebpdemo.tmp_staging_fact_0000000000 as
(
    with expression_extract_1 as
    (
        select * from autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000
    ),
    expression_extract_2 as
    (
        select  t.*,
                (round(num_duration_seconds/60,2))::numeric as num_duration_minutes
                from expression_extract_1 t
    ),
    filter__3 as
    (
        select /* filtering irrelevant records out */ *
        from expression_extract_2
        where 1=1
        and agent_id is not null
        and customer_id is not null
        and num_duration_seconds > 10
    ),
    incremental_extract__4 as
    (
        select /* retrieving incremental data - by date range only */ *
        from filter__3
        where time_call_start >= to_date('2020-01-01', 'YYYY-MM-DD')
          and time_call_start  < to_date('2021-01-01', 'YYYY-MM-DD')
    ),
    deduplication__5 as
    (
        select /* deduplicate by strategy */
               call_id
               , max(time_call_start) as time_call_start
               , max(time_call_end) as time_call_end
               , max(num_duration_seconds) as num_duration_seconds
               , max(customer_id) as customer_id
               , max(agent_id) as agent_id
               , max(num_duration_minutes) as num_duration_minutes
        from incremental_extract__4
        group by call_id 
    ),
    coarsening_6 as
    (
        select * from deduplication__5
    )
    select  t.*,
            1 autopie_run_id
    from coarsening_6 t
);

drop view if exists autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 cascade;
drop view if exists autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 cascade;


-- check if not exists already, this should run once
do $$                  
begin
if not exists
( 
    select 1 from information_schema.tables 
    where table_schema||'.'|| table_name = 'autopie_ebpdemo.obj_fact_calls'
)
then
    create table autopie_ebpdemo.obj_fact_calls as (select * from autopie_ebpdemo.tmp_staging_fact_0000000000 where 1=0);
    alter  table autopie_ebpdemo.obj_fact_calls add column row_id bigserial not null;
    alter  table autopie_ebpdemo.obj_fact_calls add primary key (call_id, time_call_end);
    --
    create index ixrid_obj_fact_calls on autopie_ebpdemo.obj_fact_calls(row_id);
end if;
end
$$;

-- upsert staging additions into the permanent fact object
delete from autopie_ebpdemo.obj_fact_calls where (call_id, time_call_end) in (select call_id, time_call_end from autopie_ebpdemo.tmp_staging_fact_0000000000);
insert into autopie_ebpdemo.obj_fact_calls select * from autopie_ebpdemo.tmp_staging_fact_0000000000;
drop table autopie_ebpdemo.tmp_staging_fact_0000000000;


06:22:47.576158 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:22:47.576231 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    



create or replace view autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 as
select "call_id"::text as "call_id", 
       "call_start_epoch"::bigint as "call_start_epoch", 
       "call_duration"::int as "call_duration", 
       "customer_id"::text as "customer_id", 
       "agent_id"::text as "agent_id"
       from testsatmap.calltable;


create or replace view autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 as
select  (call_id)::text as call_id, 
        (to_timestamp(call_start_epoch))::timestamptz as time_call_start, 
        (to_timestamp(call_start_epoch + call_duration))::timestamptz as time_call_end, 
        (call_duration)::int4 as num_duration_seconds, 
        (trim(customer_id))::text as customer_id, 
        (lower(trim(agent_id)))::text as agent_id
        from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000;


drop table if exists autopie_ebpdemo.tmp_staging_fact_0000000000;
create table autopie_ebpdemo.tmp_staging_fact_0000000000 as
(
    with expression_extract_1 as
    (
        select * from autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000
    ),
    expression_extract_2 as
    (
        select  t.*,
                (round(num_duration_seconds/60,2))::numeric as num_duration_minutes
                from expression_extract_1 t
    ),
    filter__3 as
    (
        select /* filtering irrelevant records out */ *
        from expression_extract_2
        where 1=1
        and agent_id is not null
        and customer_id is not null
        and num_duration_seconds > 10
    ),
    incremental_extract__4 as
    (
        select /* retrieving incremental data - by date range only */ *
        from filter__3
        where time_call_start >= to_date('2020-01-01', 'YYYY-MM-DD')
          and time_call_start  < to_date('2021-01-01', 'YYYY-MM-DD')
    ),
    deduplication__5 as
    (
        select /* deduplicate by strategy */
               call_id
               , max(time_call_start) as time_call_start
               , max(time_call_end) as time_call_end
               , max(num_duration_seconds) as num_duration_seconds
               , max(customer_id) as customer_id
               , max(agent_id) as agent_id
               , max(num_duration_minutes) as num_duration_minutes
        from incremental_extract__4
        group by call_id 
    ),
    coarsening_6 as
    (
        select * from deduplication__5
    )
    select  t.*,
            1 autopie_run_id
    from coarsening_6 t
);

drop view if exists autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 cascade;
drop view if exists autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 cascade;


-- check if not exists already, this should run once
do $$                  
begin
if not exists
( 
    select 1 from information_schema.tables 
    where table_schema||'.'|| table_name = 'autopie_ebpdemo.obj_fact_calls'
)
then
    create table autopie_ebpdemo.obj_fact_calls as (select * from autopie_ebpdemo.tmp_staging_fact_0000000000 where 1=0);
    alter  table autopie_ebpdemo.obj_fact_calls add column row_id bigserial not null;
    alter  table autopie_ebpdemo.obj_fact_calls add primary key (call_id, time_call_end);
    --
    create index ixrid_obj_fact_calls on autopie_ebpdemo.obj_fact_calls(row_id);
end if;
end
$$;

-- upsert staging additions into the permanent fact object
delete from autopie_ebpdemo.obj_fact_calls where (call_id, time_call_end) in (select call_id, time_call_end from autopie_ebpdemo.tmp_staging_fact_0000000000);
insert into autopie_ebpdemo.obj_fact_calls select * from autopie_ebpdemo.tmp_staging_fact_0000000000;
drop table autopie_ebpdemo.tmp_staging_fact_0000000000;


  
06:22:47.602141 [debug] [MainThread]: SQL status: DROP TABLE in 0.03 seconds
06:22:47.602944 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:22:47.603048 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    
select row_number() over (order by autopie_run_id desc) run_sequence, count(*) count_records 
  from autopie_ebpdemo.obj_fact_calls
group by autopie_run_id
order by 1 
limit 5;

  
06:22:47.603725 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
06:22:47.605972 [debug] [MainThread]: On macro_run_recipe: Close
06:22:47.606696 [debug] [MainThread]: Connection 'macro_run_recipe' was properly closed.


============================== 2022-02-20 06:22:48.685142 | 2758ccbc-f9a1-4179-bdf3-96019b3af725 ==============================
06:22:48.685142 [info ] [MainThread]: Running with dbt=1.0.1
06:22:48.685574 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/hassanzaheer/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, macro='run_recipe', args='{\n    "recipe_type" : "collect_fact",\n    "target_fact" : {\n        "id": "outcomes", \n        "entity_and_dims": "customer_id",\n        "date":"date_outcome"\n    },\n    "ingredients": {\n        "expression_extract": {  \n            "source_raw": "testsatmap.outcomes",\n            "expression_list": [\n                {"expression": "outcome_date", "alias": "date_outcome"},\n                {"expression": "trim(customer_id)", "alias": "customer_id"},             \n                {"expression": "outcome_code::numeric", "alias": "num_outcome_amount"}\n            ]\n        },\n        "filter_conjunctions": [\n            "num_outcome_amount > 0",\n            "customer_id is not null"\n        ],\n        "incremental_update_on": "date_outcome",\n        "deduplication": {\n            "grouping_key": "customer_id, date_outcome, num_outcome_amount",\n            "preference": "arbitrary"\n        },\n        "coarsening": {\n            "entity_and_dims": "customer_id",\n            "date_expression":"date_outcome",\n            "aggregations": [\n                {"expression": "sum(num_outcome_amount)", "alias": "sum_outcome_amount"}\n            ]\n        }\n    }\n}', defer=None, state=None, cls=<class 'dbt.task.run_operation.RunOperationTask'>, which='run-operation', rpc_method='run-operation')
06:22:48.685714 [debug] [MainThread]: Tracking: do not track
06:22:48.706409 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 2 files changed.
06:22:48.706684 [debug] [MainThread]: Partial parsing: updated file: demo_autopie://models/demo_ebp_flow/prepared_scripts/prepared_fact_outcomes.sql
06:22:48.706806 [debug] [MainThread]: Partial parsing: updated file: demo_autopie://models/demo_ebp_flow/prepared_scripts/prepared_fact_calls.sql
06:22:48.712407 [debug] [MainThread]: 1699: static parser successfully parsed demo_ebp_flow/prepared_scripts/prepared_fact_outcomes.sql
06:22:48.718343 [debug] [MainThread]: 1699: static parser successfully parsed demo_ebp_flow/prepared_scripts/prepared_fact_calls.sql
06:22:48.725082 [debug] [MainThread]: Acquiring new postgres connection "macro_run_recipe"
06:22:48.725215 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:22:48.725280 [debug] [MainThread]: On macro_run_recipe: BEGIN
06:22:48.725341 [debug] [MainThread]: Opening a new connection, currently in state init
06:22:48.735400 [debug] [MainThread]: SQL status: BEGIN in 0.01 seconds
06:22:48.735500 [debug] [MainThread]: On macro_run_recipe: COMMIT
06:22:48.735562 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:22:48.735616 [debug] [MainThread]: On macro_run_recipe: COMMIT
06:22:48.735816 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
06:22:48.779976 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:22:48.780143 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select '"'||column_name||'"::'||
       case when replace(udt_name, '_','') = 'bit' then 'int'
            when replace(udt_name, '_','') like 'int8%' then 'bigint'
            when replace(udt_name, '_','') like 'int4%' then 'int'
            when replace(udt_name, '_','') like 'int%' then 'smallint'
            when replace(udt_name, '_','') like 'bool%' then 'int'
            when replace(udt_name, '_','') like 'float%' then 'numeric'
            when replace(udt_name, '_','') like 'float%' then 'numeric'
            when replace(udt_name, '_','') like 'byte%' then 'text'
            when replace(udt_name, '_','') like 'varchar%' then 'text'
            when replace(udt_name, '_','') like 'timestamp%' then 'timestamp'
            else replace(udt_name, '_','') end ||
       ' as "'||column_name||'"' select_text
from information_schema.columns 
where table_schema||'.'||table_name = 'testsatmap.outcomes'
order by ordinal_position ;

  
06:22:48.793912 [debug] [MainThread]: SQL status: SELECT 3 in 0.01 seconds
06:22:48.794817 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:22:48.794901 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 as
select "outcome_date"::date as "outcome_date", 
       "customer_id"::text as "customer_id", 
       "outcome_code"::text as "outcome_code"
       from testsatmap.outcomes;

  
06:22:48.797643 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:22:48.798194 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:22:48.798275 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:22:48.798519 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:22:48.799027 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:22:48.799095 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_exp_type_0000000000 as select outcome_date exp from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 limit 1
  
06:22:48.800303 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:22:48.800828 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:22:48.800895 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select replace(udt_name, '_','') dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type_0000000000' and column_name = 'exp'
  
06:22:48.804320 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
06:22:48.804852 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:22:48.804924 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:22:48.806010 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:22:48.806517 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:22:48.806583 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:22:48.806772 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:22:48.807256 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:22:48.807322 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_exp_type_0000000000 as select trim(customer_id) exp from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 limit 1
  
06:22:48.808216 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:22:48.808826 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:22:48.808897 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select replace(udt_name, '_','') dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type_0000000000' and column_name = 'exp'
  
06:22:48.812308 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
06:22:48.812825 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:22:48.812891 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:22:48.813602 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:22:48.814088 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:22:48.814153 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:22:48.814346 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:22:48.814827 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:22:48.814892 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_exp_type_0000000000 as select outcome_code::numeric exp from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 limit 1
  
06:22:48.815781 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:22:48.816303 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:22:48.816373 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select replace(udt_name, '_','') dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type_0000000000' and column_name = 'exp'
  
06:22:48.819714 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
06:22:48.820264 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:22:48.820335 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:22:48.821053 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:22:48.821585 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:22:48.821655 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 as
select  (outcome_date)::date as date_outcome, 
        (trim(customer_id))::text as customer_id, 
        (outcome_code::numeric)::numeric as num_outcome_amount
        from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000;

  
06:22:48.822853 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:22:48.823818 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:22:48.823891 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 cascade;
drop view if exists autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 cascade;

  
06:22:48.824839 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:22:48.825324 [info ] [MainThread]: 



create or replace view autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 as
select "outcome_date"::date as "outcome_date", 
       "customer_id"::text as "customer_id", 
       "outcome_code"::text as "outcome_code"
       from testsatmap.outcomes;


create or replace view autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 as
select  (outcome_date)::date as date_outcome, 
        (trim(customer_id))::text as customer_id, 
        (outcome_code::numeric)::numeric as num_outcome_amount
        from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000;


drop table if exists autopie_ebpdemo.tmp_staging_fact_0000000000;
create table autopie_ebpdemo.tmp_staging_fact_0000000000 as
(
    with expression_extract_1 as
    (
        select * from autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000
    ),
    expression_extract_2 as
    (
        select * from expression_extract_1
    ),
    filter__3 as
    (
        select /* filtering irrelevant records out */ *
        from expression_extract_2
        where 1=1
        and num_outcome_amount > 0
        and customer_id is not null
    ),
    incremental_extract__4 as
    (
        select /* retrieving incremental data - by date range only */ *
        from filter__3
        where date_outcome >= to_date('2020-01-01', 'YYYY-MM-DD')
          and date_outcome  < to_date('2021-01-01', 'YYYY-MM-DD')
    ),
    deduplication__5 as
    (
        select /* deduplicate by strategy */
               customer_id, date_outcome, num_outcome_amount
        from incremental_extract__4
        group by customer_id, date_outcome, num_outcome_amount 
    ),
    coarsening_6 as
    (
        select /* flatten all dimensions, fit into EAVT format */
              customer_id
              , date_outcome
              
              , sum(num_outcome_amount) as sum_outcome_amount
              from deduplication__5
        group by customer_id, date_outcome
    )
    select  t.*,
            1 autopie_run_id
    from coarsening_6 t
);

drop view if exists autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 cascade;
drop view if exists autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 cascade;


-- check if not exists already, this should run once
do $$                  
begin
if not exists
( 
    select 1 from information_schema.tables 
    where table_schema||'.'|| table_name = 'autopie_ebpdemo.obj_fact_outcomes'
)
then
    create table autopie_ebpdemo.obj_fact_outcomes as (select * from autopie_ebpdemo.tmp_staging_fact_0000000000 where 1=0);
    alter  table autopie_ebpdemo.obj_fact_outcomes add column row_id bigserial not null;
    alter  table autopie_ebpdemo.obj_fact_outcomes add primary key (customer_id, date_outcome);
    --
    create index ixrid_obj_fact_outcomes on autopie_ebpdemo.obj_fact_outcomes(row_id);
end if;
end
$$;

-- upsert staging additions into the permanent fact object
delete from autopie_ebpdemo.obj_fact_outcomes where (customer_id, date_outcome) in (select customer_id, date_outcome from autopie_ebpdemo.tmp_staging_fact_0000000000);
insert into autopie_ebpdemo.obj_fact_outcomes select * from autopie_ebpdemo.tmp_staging_fact_0000000000;
drop table autopie_ebpdemo.tmp_staging_fact_0000000000;


06:22:48.825705 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:22:48.825774 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    



create or replace view autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 as
select "outcome_date"::date as "outcome_date", 
       "customer_id"::text as "customer_id", 
       "outcome_code"::text as "outcome_code"
       from testsatmap.outcomes;


create or replace view autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 as
select  (outcome_date)::date as date_outcome, 
        (trim(customer_id))::text as customer_id, 
        (outcome_code::numeric)::numeric as num_outcome_amount
        from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000;


drop table if exists autopie_ebpdemo.tmp_staging_fact_0000000000;
create table autopie_ebpdemo.tmp_staging_fact_0000000000 as
(
    with expression_extract_1 as
    (
        select * from autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000
    ),
    expression_extract_2 as
    (
        select * from expression_extract_1
    ),
    filter__3 as
    (
        select /* filtering irrelevant records out */ *
        from expression_extract_2
        where 1=1
        and num_outcome_amount > 0
        and customer_id is not null
    ),
    incremental_extract__4 as
    (
        select /* retrieving incremental data - by date range only */ *
        from filter__3
        where date_outcome >= to_date('2020-01-01', 'YYYY-MM-DD')
          and date_outcome  < to_date('2021-01-01', 'YYYY-MM-DD')
    ),
    deduplication__5 as
    (
        select /* deduplicate by strategy */
               customer_id, date_outcome, num_outcome_amount
        from incremental_extract__4
        group by customer_id, date_outcome, num_outcome_amount 
    ),
    coarsening_6 as
    (
        select /* flatten all dimensions, fit into EAVT format */
              customer_id
              , date_outcome
              
              , sum(num_outcome_amount) as sum_outcome_amount
              from deduplication__5
        group by customer_id, date_outcome
    )
    select  t.*,
            1 autopie_run_id
    from coarsening_6 t
);

drop view if exists autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 cascade;
drop view if exists autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 cascade;


-- check if not exists already, this should run once
do $$                  
begin
if not exists
( 
    select 1 from information_schema.tables 
    where table_schema||'.'|| table_name = 'autopie_ebpdemo.obj_fact_outcomes'
)
then
    create table autopie_ebpdemo.obj_fact_outcomes as (select * from autopie_ebpdemo.tmp_staging_fact_0000000000 where 1=0);
    alter  table autopie_ebpdemo.obj_fact_outcomes add column row_id bigserial not null;
    alter  table autopie_ebpdemo.obj_fact_outcomes add primary key (customer_id, date_outcome);
    --
    create index ixrid_obj_fact_outcomes on autopie_ebpdemo.obj_fact_outcomes(row_id);
end if;
end
$$;

-- upsert staging additions into the permanent fact object
delete from autopie_ebpdemo.obj_fact_outcomes where (customer_id, date_outcome) in (select customer_id, date_outcome from autopie_ebpdemo.tmp_staging_fact_0000000000);
insert into autopie_ebpdemo.obj_fact_outcomes select * from autopie_ebpdemo.tmp_staging_fact_0000000000;
drop table autopie_ebpdemo.tmp_staging_fact_0000000000;


  
06:22:48.851169 [debug] [MainThread]: SQL status: DROP TABLE in 0.03 seconds
06:22:48.851905 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:22:48.851997 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    
select row_number() over (order by autopie_run_id desc) run_sequence, count(*) count_records 
  from autopie_ebpdemo.obj_fact_outcomes
group by autopie_run_id
order by 1 
limit 5;

  
06:22:48.852596 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
06:22:48.854818 [debug] [MainThread]: On macro_run_recipe: Close
06:22:48.855549 [debug] [MainThread]: Connection 'macro_run_recipe' was properly closed.


============================== 2022-02-20 06:24:13.873106 | cb9fc0cd-0dac-48b8-9679-6ce66554a8a3 ==============================
06:24:13.873106 [info ] [MainThread]: Running with dbt=1.0.1
06:24:13.873526 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/hassanzaheer/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, macro='run_recipe', args='{\n    "recipe_type" : "collect_fact",\n    "target_fact" : {\n        "id": "calls", \n        "entity_and_dims": "call_id",\n        "date":"time_call_end"\n    },\n    "ingredients": {\n        "expression_extract": {  \n            "source_raw": "testsatmap.calltable",\n            "expression_list": [\n                {"expression": "call_id", "alias": "call_id"},\n                {"expression": "to_timestamp(call_start_epoch)", "alias": "time_call_start"},\n                {"expression": "to_timestamp(call_start_epoch + call_duration)", "alias": "time_call_end"},\n                {"expression": "call_duration", "alias": "num_duration_seconds"},\n                {"expression": "trim(customer_id)",  "alias": "customer_id"},\n                {"expression": "lower(trim(agent_id))",  "alias": "agent_id"}\n            ]\n        },\n        "expression_extract_outer": {  \n            "expression_list": [\n                {"expression": "round(num_duration_seconds/60,2)", "alias": "num_duration_minutes"}\n            ]\n        },\n        "filter_conjunctions": [\n            "agent_id is not null",\n            "customer_id is not null",\n            "num_duration_seconds > 10"\n        ],\n        "incremental_update_on": "time_call_start",\n        "deduplication": {\n            "grouping_key": "call_id",\n            "preference": "arbitrary"\n        }\n    }\n}', defer=None, state=None, cls=<class 'dbt.task.run_operation.RunOperationTask'>, which='run-operation', rpc_method='run-operation')
06:24:13.873645 [debug] [MainThread]: Tracking: do not track
06:24:13.894796 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 3 files changed.
06:24:13.895691 [debug] [MainThread]: Partial parsing: updated file: demo_autopie://models/demo_ebp_flow/prepared_scripts/prepared_fact_outcomes.sql
06:24:13.896401 [debug] [MainThread]: Partial parsing: updated file: demo_autopie://macros/core/run_recipe.sql
06:24:13.896515 [debug] [MainThread]: Partial parsing: updated file: demo_autopie://models/demo_ebp_flow/prepared_scripts/prepared_fact_calls.sql
06:24:13.896608 [debug] [MainThread]: Parsing macros/core/run_directory.sql
06:24:13.898179 [debug] [MainThread]: Parsing macros/core/run_recipe.sql
06:24:13.909879 [debug] [MainThread]: 1699: static parser successfully parsed demo_ebp_flow/prepared_scripts/prepared_fact_outcomes.sql
06:24:13.915097 [debug] [MainThread]: 1699: static parser successfully parsed demo_ebp_flow/prepared_scripts/prepared_fact_calls.sql
06:24:13.921242 [debug] [MainThread]: Acquiring new postgres connection "macro_run_recipe"
06:24:13.921353 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:24:13.921421 [debug] [MainThread]: On macro_run_recipe: BEGIN
06:24:13.921484 [debug] [MainThread]: Opening a new connection, currently in state init
06:24:13.942160 [debug] [MainThread]: SQL status: BEGIN in 0.02 seconds
06:24:13.942294 [debug] [MainThread]: On macro_run_recipe: COMMIT
06:24:13.942369 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:24:13.942433 [debug] [MainThread]: On macro_run_recipe: COMMIT
06:24:13.942588 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
06:24:13.987924 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:24:13.988089 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select '"'||column_name||'"::'||
       case when replace(udt_name, '_','') = 'bit' then 'int'
            when replace(udt_name, '_','') like 'int8%' then 'bigint'
            when replace(udt_name, '_','') like 'int4%' then 'int'
            when replace(udt_name, '_','') like 'int%' then 'smallint'
            when replace(udt_name, '_','') like 'bool%' then 'int'
            when replace(udt_name, '_','') like 'float%' then 'numeric'
            when replace(udt_name, '_','') like 'float%' then 'numeric'
            when replace(udt_name, '_','') like 'byte%' then 'text'
            when replace(udt_name, '_','') like 'varchar%' then 'text'
            when replace(udt_name, '_','') like 'timestamp%' then 'timestamp'
            else replace(udt_name, '_','') end ||
       ' as "'||column_name||'"' select_text
from information_schema.columns 
where table_schema||'.'||table_name = 'testsatmap.calltable'
order by ordinal_position ;

  
06:24:13.999269 [debug] [MainThread]: SQL status: SELECT 5 in 0.01 seconds
06:24:14.000162 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:24:14.000244 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 as
select "call_id"::text as "call_id", 
       "call_start_epoch"::bigint as "call_start_epoch", 
       "call_duration"::int as "call_duration", 
       "customer_id"::text as "customer_id", 
       "agent_id"::text as "agent_id"
       from testsatmap.calltable;

  
06:24:14.003727 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:24:14.004272 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:24:14.004340 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:24:14.004607 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:24:14.005116 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:24:14.005182 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_exp_type_0000000000 as select call_id exp from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 limit 1
  
06:24:14.006173 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:24:14.006656 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:24:14.006721 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select replace(udt_name, '_','') dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type_0000000000' and column_name = 'exp'
  
06:24:14.010855 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
06:24:14.011349 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:24:14.011417 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:24:14.012795 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:24:14.013268 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:24:14.013332 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:24:14.013708 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:24:14.014165 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:24:14.014236 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_exp_type_0000000000 as select to_timestamp(call_start_epoch) exp from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 limit 1
  
06:24:14.015016 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:24:14.015628 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:24:14.015700 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select replace(udt_name, '_','') dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type_0000000000' and column_name = 'exp'
  
06:24:14.020219 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
06:24:14.020735 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:24:14.020803 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:24:14.021999 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:24:14.022488 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:24:14.022554 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:24:14.022790 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:24:14.023270 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:24:14.023336 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_exp_type_0000000000 as select to_timestamp(call_start_epoch + call_duration) exp from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 limit 1
  
06:24:14.024585 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:24:14.025066 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:24:14.025136 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select replace(udt_name, '_','') dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type_0000000000' and column_name = 'exp'
  
06:24:14.028280 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
06:24:14.028792 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:24:14.028859 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:24:14.029853 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:24:14.030357 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:24:14.030422 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:24:14.030649 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:24:14.031125 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:24:14.031191 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_exp_type_0000000000 as select call_duration exp from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 limit 1
  
06:24:14.032305 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:24:14.032789 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:24:14.032860 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select replace(udt_name, '_','') dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type_0000000000' and column_name = 'exp'
  
06:24:14.037744 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
06:24:14.038343 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:24:14.038415 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:24:14.038979 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:24:14.039499 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:24:14.039570 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:24:14.039925 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:24:14.040450 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:24:14.040522 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_exp_type_0000000000 as select trim(customer_id) exp from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 limit 1
  
06:24:14.041955 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:24:14.042489 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:24:14.042560 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select replace(udt_name, '_','') dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type_0000000000' and column_name = 'exp'
  
06:24:14.050206 [debug] [MainThread]: SQL status: SELECT 1 in 0.01 seconds
06:24:14.050837 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:24:14.050911 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:24:14.051710 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:24:14.052251 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:24:14.052331 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:24:14.053173 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:24:14.053701 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:24:14.053773 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_exp_type_0000000000 as select lower(trim(agent_id)) exp from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 limit 1
  
06:24:14.055105 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:24:14.055633 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:24:14.055704 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select replace(udt_name, '_','') dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type_0000000000' and column_name = 'exp'
  
06:24:14.060099 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
06:24:14.060806 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:24:14.060901 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:24:14.061470 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:24:14.062025 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:24:14.062097 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 as
select  (call_id)::text as call_id, 
        (to_timestamp(call_start_epoch))::timestamptz as time_call_start, 
        (to_timestamp(call_start_epoch + call_duration))::timestamptz as time_call_end, 
        (call_duration)::int4 as num_duration_seconds, 
        (trim(customer_id))::text as customer_id, 
        (lower(trim(agent_id)))::text as agent_id
        from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000;

  
06:24:14.062930 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:24:14.063525 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:24:14.063608 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:24:14.063854 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:24:14.064426 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:24:14.064503 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_exp_type_0000000000 as select round(num_duration_seconds/60,2) exp from autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 limit 1
  
06:24:14.066090 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:24:14.066655 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:24:14.066736 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select replace(udt_name, '_','') dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type_0000000000' and column_name = 'exp'
  
06:24:14.071848 [debug] [MainThread]: SQL status: SELECT 1 in 0.01 seconds
06:24:14.072636 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:24:14.072719 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:24:14.073302 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:24:14.074944 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:24:14.075025 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 cascade;
drop view if exists autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 cascade;

  
06:24:14.076187 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:24:14.076721 [info ] [MainThread]: 



create or replace view autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 as
select "call_id"::text as "call_id", 
       "call_start_epoch"::bigint as "call_start_epoch", 
       "call_duration"::int as "call_duration", 
       "customer_id"::text as "customer_id", 
       "agent_id"::text as "agent_id"
       from testsatmap.calltable;


create or replace view autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 as
select  (call_id)::text as call_id, 
        (to_timestamp(call_start_epoch))::timestamptz as time_call_start, 
        (to_timestamp(call_start_epoch + call_duration))::timestamptz as time_call_end, 
        (call_duration)::int4 as num_duration_seconds, 
        (trim(customer_id))::text as customer_id, 
        (lower(trim(agent_id)))::text as agent_id
        from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000;


drop table if exists autopie_ebpdemo.tmp_staging_fact_0000000000;
create table autopie_ebpdemo.tmp_staging_fact_0000000000 as
(
    with expression_extract_1 as
    (
        select * from autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000
    ),
    expression_extract_2 as
    (
        select  t.*,
                (round(num_duration_seconds/60,2))::numeric as num_duration_minutes
                from expression_extract_1 t
    ),
    filter__3 as
    (
        select /* filtering irrelevant records out */ *
        from expression_extract_2
        where 1=1
        and agent_id is not null
        and customer_id is not null
        and num_duration_seconds > 10
    ),
    incremental_extract__4 as
    (
        select /* retrieving incremental data - by date range only */ *
        from filter__3
        where time_call_start >= to_date('2020-01-01', 'YYYY-MM-DD')
          and time_call_start  < to_date('2021-01-01', 'YYYY-MM-DD')
    ),
    deduplication__5 as
    (
        select /* deduplicate by strategy */
               call_id
               , max(time_call_start) as time_call_start
               , max(time_call_end) as time_call_end
               , max(num_duration_seconds) as num_duration_seconds
               , max(customer_id) as customer_id
               , max(agent_id) as agent_id
               , max(num_duration_minutes) as num_duration_minutes
        from incremental_extract__4
        group by call_id 
    ),
    coarsening_6 as
    (
        select * from deduplication__5
    )
    select  t.*,
            1 autopie_run_id
    from coarsening_6 t
);

drop view if exists autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 cascade;
drop view if exists autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 cascade;


-- check if not exists already, this should run once
do $$                  
begin
if not exists
( 
    select 1 from information_schema.tables 
    where table_schema||'.'|| table_name = 'autopie_ebpdemo.obj_fact_calls'
)
then
    create table autopie_ebpdemo.obj_fact_calls as (select * from autopie_ebpdemo.tmp_staging_fact_0000000000 where 1=0);
    alter  table autopie_ebpdemo.obj_fact_calls add column row_id bigserial not null;
    alter  table autopie_ebpdemo.obj_fact_calls add primary key (call_id, time_call_end);
    --
    create index ixrid_obj_fact_calls on autopie_ebpdemo.obj_fact_calls(row_id);
end if;
end
$$;

-- upsert staging additions into the permanent fact object
delete from autopie_ebpdemo.obj_fact_calls where (call_id, time_call_end) in (select call_id, time_call_end from autopie_ebpdemo.tmp_staging_fact_0000000000);
insert into autopie_ebpdemo.obj_fact_calls select * from autopie_ebpdemo.tmp_staging_fact_0000000000;
drop table autopie_ebpdemo.tmp_staging_fact_0000000000;


06:24:14.077148 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:24:14.077223 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    



create or replace view autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 as
select "call_id"::text as "call_id", 
       "call_start_epoch"::bigint as "call_start_epoch", 
       "call_duration"::int as "call_duration", 
       "customer_id"::text as "customer_id", 
       "agent_id"::text as "agent_id"
       from testsatmap.calltable;


create or replace view autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 as
select  (call_id)::text as call_id, 
        (to_timestamp(call_start_epoch))::timestamptz as time_call_start, 
        (to_timestamp(call_start_epoch + call_duration))::timestamptz as time_call_end, 
        (call_duration)::int4 as num_duration_seconds, 
        (trim(customer_id))::text as customer_id, 
        (lower(trim(agent_id)))::text as agent_id
        from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000;


drop table if exists autopie_ebpdemo.tmp_staging_fact_0000000000;
create table autopie_ebpdemo.tmp_staging_fact_0000000000 as
(
    with expression_extract_1 as
    (
        select * from autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000
    ),
    expression_extract_2 as
    (
        select  t.*,
                (round(num_duration_seconds/60,2))::numeric as num_duration_minutes
                from expression_extract_1 t
    ),
    filter__3 as
    (
        select /* filtering irrelevant records out */ *
        from expression_extract_2
        where 1=1
        and agent_id is not null
        and customer_id is not null
        and num_duration_seconds > 10
    ),
    incremental_extract__4 as
    (
        select /* retrieving incremental data - by date range only */ *
        from filter__3
        where time_call_start >= to_date('2020-01-01', 'YYYY-MM-DD')
          and time_call_start  < to_date('2021-01-01', 'YYYY-MM-DD')
    ),
    deduplication__5 as
    (
        select /* deduplicate by strategy */
               call_id
               , max(time_call_start) as time_call_start
               , max(time_call_end) as time_call_end
               , max(num_duration_seconds) as num_duration_seconds
               , max(customer_id) as customer_id
               , max(agent_id) as agent_id
               , max(num_duration_minutes) as num_duration_minutes
        from incremental_extract__4
        group by call_id 
    ),
    coarsening_6 as
    (
        select * from deduplication__5
    )
    select  t.*,
            1 autopie_run_id
    from coarsening_6 t
);

drop view if exists autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 cascade;
drop view if exists autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 cascade;


-- check if not exists already, this should run once
do $$                  
begin
if not exists
( 
    select 1 from information_schema.tables 
    where table_schema||'.'|| table_name = 'autopie_ebpdemo.obj_fact_calls'
)
then
    create table autopie_ebpdemo.obj_fact_calls as (select * from autopie_ebpdemo.tmp_staging_fact_0000000000 where 1=0);
    alter  table autopie_ebpdemo.obj_fact_calls add column row_id bigserial not null;
    alter  table autopie_ebpdemo.obj_fact_calls add primary key (call_id, time_call_end);
    --
    create index ixrid_obj_fact_calls on autopie_ebpdemo.obj_fact_calls(row_id);
end if;
end
$$;

-- upsert staging additions into the permanent fact object
delete from autopie_ebpdemo.obj_fact_calls where (call_id, time_call_end) in (select call_id, time_call_end from autopie_ebpdemo.tmp_staging_fact_0000000000);
insert into autopie_ebpdemo.obj_fact_calls select * from autopie_ebpdemo.tmp_staging_fact_0000000000;
drop table autopie_ebpdemo.tmp_staging_fact_0000000000;


  
06:24:14.100122 [debug] [MainThread]: SQL status: DROP TABLE in 0.02 seconds
06:24:14.101006 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:24:14.101119 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    
select row_number() over (order by autopie_run_id desc) run_sequence, count(*) count_records 
  from autopie_ebpdemo.obj_fact_calls
group by autopie_run_id
order by 1 
limit 5;

  
06:24:14.101774 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
06:24:14.104047 [debug] [MainThread]: On macro_run_recipe: Close
06:24:14.104880 [debug] [MainThread]: Connection 'macro_run_recipe' was properly closed.


============================== 2022-02-20 06:24:15.237545 | 6f8281cd-e8bf-45fb-a6f7-eb8fdfd26fd6 ==============================
06:24:15.237545 [info ] [MainThread]: Running with dbt=1.0.1
06:24:15.237963 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/hassanzaheer/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, macro='run_recipe', args='{\n    "recipe_type" : "collect_fact",\n    "target_fact" : {\n        "id": "outcomes", \n        "entity_and_dims": "customer_id",\n        "date":"date_outcome"\n    },\n    "ingredients": {\n        "expression_extract": {  \n            "source_raw": "testsatmap.outcomes",\n            "expression_list": [\n                {"expression": "outcome_date", "alias": "date_outcome"},\n                {"expression": "trim(customer_id)", "alias": "customer_id"},             \n                {"expression": "outcome_code::numeric", "alias": "num_outcome_amount"}\n            ]\n        },\n        "filter_conjunctions": [\n            "num_outcome_amount > 0",\n            "customer_id is not null"\n        ],\n        "incremental_update_on": "date_outcome",\n        "deduplication": {\n            "grouping_key": "customer_id, date_outcome, num_outcome_amount",\n            "preference": "arbitrary"\n        },\n        "coarsening": {\n            "entity_and_dims": "customer_id",\n            "date_expression":"date_outcome",\n            "aggregations": [\n                {"expression": "sum(num_outcome_amount)", "alias": "sum_outcome_amount"}\n            ]\n        }\n    }\n}', defer=None, state=None, cls=<class 'dbt.task.run_operation.RunOperationTask'>, which='run-operation', rpc_method='run-operation')
06:24:15.238085 [debug] [MainThread]: Tracking: do not track
06:24:15.258448 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 2 files changed.
06:24:15.258724 [debug] [MainThread]: Partial parsing: updated file: demo_autopie://models/demo_ebp_flow/prepared_scripts/prepared_fact_calls.sql
06:24:15.258859 [debug] [MainThread]: Partial parsing: updated file: demo_autopie://models/demo_ebp_flow/prepared_scripts/prepared_fact_outcomes.sql
06:24:15.264683 [debug] [MainThread]: 1699: static parser successfully parsed demo_ebp_flow/prepared_scripts/prepared_fact_calls.sql
06:24:15.270535 [debug] [MainThread]: 1699: static parser successfully parsed demo_ebp_flow/prepared_scripts/prepared_fact_outcomes.sql
06:24:15.276678 [debug] [MainThread]: Acquiring new postgres connection "macro_run_recipe"
06:24:15.276797 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:24:15.276870 [debug] [MainThread]: On macro_run_recipe: BEGIN
06:24:15.276941 [debug] [MainThread]: Opening a new connection, currently in state init
06:24:15.280711 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
06:24:15.280822 [debug] [MainThread]: On macro_run_recipe: COMMIT
06:24:15.280893 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:24:15.280950 [debug] [MainThread]: On macro_run_recipe: COMMIT
06:24:15.281127 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
06:24:15.325419 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:24:15.325585 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select '"'||column_name||'"::'||
       case when replace(udt_name, '_','') = 'bit' then 'int'
            when replace(udt_name, '_','') like 'int8%' then 'bigint'
            when replace(udt_name, '_','') like 'int4%' then 'int'
            when replace(udt_name, '_','') like 'int%' then 'smallint'
            when replace(udt_name, '_','') like 'bool%' then 'int'
            when replace(udt_name, '_','') like 'float%' then 'numeric'
            when replace(udt_name, '_','') like 'float%' then 'numeric'
            when replace(udt_name, '_','') like 'byte%' then 'text'
            when replace(udt_name, '_','') like 'varchar%' then 'text'
            when replace(udt_name, '_','') like 'timestamp%' then 'timestamp'
            else replace(udt_name, '_','') end ||
       ' as "'||column_name||'"' select_text
from information_schema.columns 
where table_schema||'.'||table_name = 'testsatmap.outcomes'
order by ordinal_position ;

  
06:24:15.336951 [debug] [MainThread]: SQL status: SELECT 3 in 0.01 seconds
06:24:15.337886 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:24:15.337977 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 as
select "outcome_date"::date as "outcome_date", 
       "customer_id"::text as "customer_id", 
       "outcome_code"::text as "outcome_code"
       from testsatmap.outcomes;

  
06:24:15.340721 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:24:15.341206 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:24:15.341275 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:24:15.341550 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:24:15.342179 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:24:15.342270 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_exp_type_0000000000 as select outcome_date exp from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 limit 1
  
06:24:15.343115 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:24:15.343614 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:24:15.343690 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select replace(udt_name, '_','') dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type_0000000000' and column_name = 'exp'
  
06:24:15.348179 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
06:24:15.348681 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:24:15.348746 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:24:15.349851 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:24:15.350338 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:24:15.350403 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:24:15.350832 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:24:15.351358 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:24:15.351435 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_exp_type_0000000000 as select trim(customer_id) exp from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 limit 1
  
06:24:15.353782 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:24:15.354426 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:24:15.354497 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select replace(udt_name, '_','') dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type_0000000000' and column_name = 'exp'
  
06:24:15.357140 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
06:24:15.357641 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:24:15.357706 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:24:15.358396 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:24:15.358879 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:24:15.358943 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:24:15.359192 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:24:15.359651 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:24:15.359719 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_exp_type_0000000000 as select outcome_code::numeric exp from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 limit 1
  
06:24:15.360897 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:24:15.361399 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:24:15.361467 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select replace(udt_name, '_','') dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type_0000000000' and column_name = 'exp'
  
06:24:15.364166 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
06:24:15.364771 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:24:15.364846 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:24:15.365411 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:24:15.365906 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:24:15.365981 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 as
select  (outcome_date)::date as date_outcome, 
        (trim(customer_id))::text as customer_id, 
        (outcome_code::numeric)::numeric as num_outcome_amount
        from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000;

  
06:24:15.366688 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:24:15.367593 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:24:15.367665 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 cascade;
drop view if exists autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 cascade;

  
06:24:15.368814 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:24:15.369308 [info ] [MainThread]: 



create or replace view autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 as
select "outcome_date"::date as "outcome_date", 
       "customer_id"::text as "customer_id", 
       "outcome_code"::text as "outcome_code"
       from testsatmap.outcomes;


create or replace view autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 as
select  (outcome_date)::date as date_outcome, 
        (trim(customer_id))::text as customer_id, 
        (outcome_code::numeric)::numeric as num_outcome_amount
        from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000;


drop table if exists autopie_ebpdemo.tmp_staging_fact_0000000000;
create table autopie_ebpdemo.tmp_staging_fact_0000000000 as
(
    with expression_extract_1 as
    (
        select * from autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000
    ),
    expression_extract_2 as
    (
        select * from expression_extract_1
    ),
    filter__3 as
    (
        select /* filtering irrelevant records out */ *
        from expression_extract_2
        where 1=1
        and num_outcome_amount > 0
        and customer_id is not null
    ),
    incremental_extract__4 as
    (
        select /* retrieving incremental data - by date range only */ *
        from filter__3
        where date_outcome >= to_date('2020-01-01', 'YYYY-MM-DD')
          and date_outcome  < to_date('2021-01-01', 'YYYY-MM-DD')
    ),
    deduplication__5 as
    (
        select /* deduplicate by strategy */
               customer_id, date_outcome, num_outcome_amount
        from incremental_extract__4
        group by customer_id, date_outcome, num_outcome_amount 
    ),
    coarsening_6 as
    (
        select /* flatten all dimensions, fit into EAVT format */
              customer_id
              , date_outcome
              
              , sum(num_outcome_amount) as sum_outcome_amount
              from deduplication__5
        group by customer_id, date_outcome
    )
    select  t.*,
            1 autopie_run_id
    from coarsening_6 t
);

drop view if exists autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 cascade;
drop view if exists autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 cascade;


-- check if not exists already, this should run once
do $$                  
begin
if not exists
( 
    select 1 from information_schema.tables 
    where table_schema||'.'|| table_name = 'autopie_ebpdemo.obj_fact_outcomes'
)
then
    create table autopie_ebpdemo.obj_fact_outcomes as (select * from autopie_ebpdemo.tmp_staging_fact_0000000000 where 1=0);
    alter  table autopie_ebpdemo.obj_fact_outcomes add column row_id bigserial not null;
    alter  table autopie_ebpdemo.obj_fact_outcomes add primary key (customer_id, date_outcome);
    --
    create index ixrid_obj_fact_outcomes on autopie_ebpdemo.obj_fact_outcomes(row_id);
end if;
end
$$;

-- upsert staging additions into the permanent fact object
delete from autopie_ebpdemo.obj_fact_outcomes where (customer_id, date_outcome) in (select customer_id, date_outcome from autopie_ebpdemo.tmp_staging_fact_0000000000);
insert into autopie_ebpdemo.obj_fact_outcomes select * from autopie_ebpdemo.tmp_staging_fact_0000000000;
drop table autopie_ebpdemo.tmp_staging_fact_0000000000;


06:24:15.369666 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:24:15.369729 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    



create or replace view autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 as
select "outcome_date"::date as "outcome_date", 
       "customer_id"::text as "customer_id", 
       "outcome_code"::text as "outcome_code"
       from testsatmap.outcomes;


create or replace view autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 as
select  (outcome_date)::date as date_outcome, 
        (trim(customer_id))::text as customer_id, 
        (outcome_code::numeric)::numeric as num_outcome_amount
        from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000;


drop table if exists autopie_ebpdemo.tmp_staging_fact_0000000000;
create table autopie_ebpdemo.tmp_staging_fact_0000000000 as
(
    with expression_extract_1 as
    (
        select * from autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000
    ),
    expression_extract_2 as
    (
        select * from expression_extract_1
    ),
    filter__3 as
    (
        select /* filtering irrelevant records out */ *
        from expression_extract_2
        where 1=1
        and num_outcome_amount > 0
        and customer_id is not null
    ),
    incremental_extract__4 as
    (
        select /* retrieving incremental data - by date range only */ *
        from filter__3
        where date_outcome >= to_date('2020-01-01', 'YYYY-MM-DD')
          and date_outcome  < to_date('2021-01-01', 'YYYY-MM-DD')
    ),
    deduplication__5 as
    (
        select /* deduplicate by strategy */
               customer_id, date_outcome, num_outcome_amount
        from incremental_extract__4
        group by customer_id, date_outcome, num_outcome_amount 
    ),
    coarsening_6 as
    (
        select /* flatten all dimensions, fit into EAVT format */
              customer_id
              , date_outcome
              
              , sum(num_outcome_amount) as sum_outcome_amount
              from deduplication__5
        group by customer_id, date_outcome
    )
    select  t.*,
            1 autopie_run_id
    from coarsening_6 t
);

drop view if exists autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 cascade;
drop view if exists autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 cascade;


-- check if not exists already, this should run once
do $$                  
begin
if not exists
( 
    select 1 from information_schema.tables 
    where table_schema||'.'|| table_name = 'autopie_ebpdemo.obj_fact_outcomes'
)
then
    create table autopie_ebpdemo.obj_fact_outcomes as (select * from autopie_ebpdemo.tmp_staging_fact_0000000000 where 1=0);
    alter  table autopie_ebpdemo.obj_fact_outcomes add column row_id bigserial not null;
    alter  table autopie_ebpdemo.obj_fact_outcomes add primary key (customer_id, date_outcome);
    --
    create index ixrid_obj_fact_outcomes on autopie_ebpdemo.obj_fact_outcomes(row_id);
end if;
end
$$;

-- upsert staging additions into the permanent fact object
delete from autopie_ebpdemo.obj_fact_outcomes where (customer_id, date_outcome) in (select customer_id, date_outcome from autopie_ebpdemo.tmp_staging_fact_0000000000);
insert into autopie_ebpdemo.obj_fact_outcomes select * from autopie_ebpdemo.tmp_staging_fact_0000000000;
drop table autopie_ebpdemo.tmp_staging_fact_0000000000;


  
06:24:15.391257 [debug] [MainThread]: SQL status: DROP TABLE in 0.02 seconds
06:24:15.392002 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:24:15.392095 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    
select row_number() over (order by autopie_run_id desc) run_sequence, count(*) count_records 
  from autopie_ebpdemo.obj_fact_outcomes
group by autopie_run_id
order by 1 
limit 5;

  
06:24:15.392634 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
06:24:15.394773 [debug] [MainThread]: On macro_run_recipe: Close
06:24:15.395505 [debug] [MainThread]: Connection 'macro_run_recipe' was properly closed.


============================== 2022-02-20 06:24:46.616938 | 2d44d915-0550-4600-8b3b-62f4b3d376b4 ==============================
06:24:46.616938 [info ] [MainThread]: Running with dbt=1.0.1
06:24:46.617375 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/hassanzaheer/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, macro='run_recipe', args='{\n    "recipe_type" : "collect_fact",\n    "target_fact" : {\n        "id": "calls", \n        "entity_and_dims": "call_id",\n        "date":"time_call_end"\n    },\n    "ingredients": {\n        "expression_extract": {  \n            "source_raw": "testsatmap.calltable",\n            "expression_list": [\n                {"expression": "call_id", "alias": "call_id"},\n                {"expression": "to_timestamp(call_start_epoch)", "alias": "time_call_start"},\n                {"expression": "to_timestamp(call_start_epoch + call_duration)", "alias": "time_call_end"},\n                {"expression": "call_duration", "alias": "num_duration_seconds"},\n                {"expression": "trim(customer_id)",  "alias": "customer_id"},\n                {"expression": "lower(trim(agent_id))",  "alias": "agent_id"}\n            ]\n        },\n        "expression_extract_outer": {  \n            "expression_list": [\n                {"expression": "round(num_duration_seconds/60,2)", "alias": "num_duration_minutes"}\n            ]\n        },\n        "filter_conjunctions": [\n            "agent_id is not null",\n            "customer_id is not null",\n            "num_duration_seconds > 10"\n        ],\n        "incremental_update_on": "time_call_start",\n        "deduplication": {\n            "grouping_key": "call_id",\n            "preference": "arbitrary"\n        }\n    }\n}', defer=None, state=None, cls=<class 'dbt.task.run_operation.RunOperationTask'>, which='run-operation', rpc_method='run-operation')
06:24:46.617498 [debug] [MainThread]: Tracking: do not track
06:24:46.637404 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 3 files changed.
06:24:46.637697 [debug] [MainThread]: Partial parsing: updated file: demo_autopie://macros/core/run_recipe.sql
06:24:46.637820 [debug] [MainThread]: Partial parsing: updated file: demo_autopie://models/demo_ebp_flow/prepared_scripts/prepared_fact_outcomes.sql
06:24:46.637928 [debug] [MainThread]: Partial parsing: updated file: demo_autopie://models/demo_ebp_flow/prepared_scripts/prepared_fact_calls.sql
06:24:46.638015 [debug] [MainThread]: Parsing macros/core/run_directory.sql
06:24:46.639553 [debug] [MainThread]: Parsing macros/core/run_recipe.sql
06:24:46.650926 [debug] [MainThread]: 1699: static parser successfully parsed demo_ebp_flow/prepared_scripts/prepared_fact_outcomes.sql
06:24:46.656007 [debug] [MainThread]: 1699: static parser successfully parsed demo_ebp_flow/prepared_scripts/prepared_fact_calls.sql
06:24:46.661979 [debug] [MainThread]: Acquiring new postgres connection "macro_run_recipe"
06:24:46.662086 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:24:46.662149 [debug] [MainThread]: On macro_run_recipe: BEGIN
06:24:46.662208 [debug] [MainThread]: Opening a new connection, currently in state init
06:24:46.685786 [debug] [MainThread]: SQL status: BEGIN in 0.02 seconds
06:24:46.685885 [debug] [MainThread]: On macro_run_recipe: COMMIT
06:24:46.685948 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:24:46.686007 [debug] [MainThread]: On macro_run_recipe: COMMIT
06:24:46.686141 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
06:24:46.731086 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:24:46.731215 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select '"'||column_name||'"::'||
       case when replace(udt_name, '_','') = 'bit' then 'int'
            when replace(udt_name, '_','') like 'int8%' then 'bigint'
            when replace(udt_name, '_','') like 'int4%' then 'int'
            when replace(udt_name, '_','') like 'int%' then 'smallint'
            when replace(udt_name, '_','') like 'bool%' then 'int'
            when replace(udt_name, '_','') like 'float%' then 'numeric'
            when replace(udt_name, '_','') like 'float%' then 'numeric'
            when replace(udt_name, '_','') like 'byte%' then 'text'
            when replace(udt_name, '_','') like 'varchar%' then 'text'
            when replace(udt_name, '_','') like 'timestamp%' then 'timestamp'
            else replace(udt_name, '_','') end ||
       ' as "'||column_name||'"' select_text
from information_schema.columns 
where table_schema||'.'||table_name = 'testsatmap.calltable'
order by ordinal_position ;

  
06:24:46.743366 [debug] [MainThread]: SQL status: SELECT 5 in 0.01 seconds
06:24:46.744259 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:24:46.744338 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 as
select "call_id"::text as "call_id", 
       "call_start_epoch"::bigint as "call_start_epoch", 
       "call_duration"::int as "call_duration", 
       "customer_id"::text as "customer_id", 
       "agent_id"::text as "agent_id"
       from testsatmap.calltable;

  
06:24:46.746545 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:24:46.747057 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:24:46.747123 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:24:46.747349 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:24:46.747820 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:24:46.747884 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_exp_type_0000000000 as select call_id exp from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 limit 1
  
06:24:46.748946 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:24:46.749431 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:24:46.749495 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select replace(udt_name, '_','') dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type_0000000000' and column_name = 'exp'
  
06:24:46.753067 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
06:24:46.753557 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:24:46.753620 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:24:46.754725 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:24:46.755191 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:24:46.755253 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:24:46.755449 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:24:46.755903 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:24:46.755965 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_exp_type_0000000000 as select to_timestamp(call_start_epoch) exp from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 limit 1
  
06:24:46.757431 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:24:46.758011 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:24:46.758075 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select replace(udt_name, '_','') dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type_0000000000' and column_name = 'exp'
  
06:24:46.762362 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
06:24:46.762874 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:24:46.762940 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:24:46.763820 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:24:46.764307 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:24:46.764380 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:24:46.764633 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:24:46.765108 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:24:46.765175 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_exp_type_0000000000 as select to_timestamp(call_start_epoch + call_duration) exp from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 limit 1
  
06:24:46.766417 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:24:46.766898 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:24:46.766962 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select replace(udt_name, '_','') dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type_0000000000' and column_name = 'exp'
  
06:24:46.771301 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
06:24:46.771799 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:24:46.771864 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:24:46.772753 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:24:46.773232 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:24:46.773296 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:24:46.773526 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:24:46.773995 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:24:46.774060 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_exp_type_0000000000 as select call_duration exp from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 limit 1
  
06:24:46.778659 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:24:46.779180 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:24:46.779250 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select replace(udt_name, '_','') dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type_0000000000' and column_name = 'exp'
  
06:24:46.782682 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
06:24:46.783222 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:24:46.783293 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:24:46.784025 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:24:46.784542 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:24:46.784613 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:24:46.784926 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:24:46.785446 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:24:46.785516 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_exp_type_0000000000 as select trim(customer_id) exp from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 limit 1
  
06:24:46.786456 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:24:46.786973 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:24:46.787043 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select replace(udt_name, '_','') dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type_0000000000' and column_name = 'exp'
  
06:24:46.790172 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
06:24:46.790709 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:24:46.790778 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:24:46.791465 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:24:46.791984 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:24:46.792053 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:24:46.792288 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:24:46.792795 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:24:46.792864 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_exp_type_0000000000 as select lower(trim(agent_id)) exp from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 limit 1
  
06:24:46.794214 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:24:46.794890 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:24:46.794979 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select replace(udt_name, '_','') dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type_0000000000' and column_name = 'exp'
  
06:24:46.799473 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
06:24:46.800050 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:24:46.800125 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:24:46.801077 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:24:46.801635 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:24:46.801711 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 as
select  (call_id)::text as call_id, 
        (to_timestamp(call_start_epoch))::timestamptz as time_call_start, 
        (to_timestamp(call_start_epoch + call_duration))::timestamptz as time_call_end, 
        (call_duration)::int4 as num_duration_seconds, 
        (trim(customer_id))::text as customer_id, 
        (lower(trim(agent_id)))::text as agent_id
        from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000;

  
06:24:46.803502 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:24:46.804071 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:24:46.804146 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:24:46.804384 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:24:46.804937 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:24:46.805011 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_exp_type_0000000000 as select round(num_duration_seconds/60,2) exp from autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 limit 1
  
06:24:46.806393 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:24:46.806949 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:24:46.807025 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select replace(udt_name, '_','') dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type_0000000000' and column_name = 'exp'
  
06:24:46.811294 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
06:24:46.812011 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:24:46.812088 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:24:46.812961 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:24:46.814585 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:24:46.814663 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 cascade;
drop view if exists autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 cascade;

  
06:24:46.815733 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:24:46.816262 [info ] [MainThread]: 



create or replace view autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 as
select "call_id"::text as "call_id", 
       "call_start_epoch"::bigint as "call_start_epoch", 
       "call_duration"::int as "call_duration", 
       "customer_id"::text as "customer_id", 
       "agent_id"::text as "agent_id"
       from testsatmap.calltable;


create or replace view autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 as
select  (call_id)::text as call_id, 
        (to_timestamp(call_start_epoch))::timestamptz as time_call_start, 
        (to_timestamp(call_start_epoch + call_duration))::timestamptz as time_call_end, 
        (call_duration)::int4 as num_duration_seconds, 
        (trim(customer_id))::text as customer_id, 
        (lower(trim(agent_id)))::text as agent_id
        from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000;


drop table if exists autopie_ebpdemo.tmp_staging_fact_0000000000;
create table autopie_ebpdemo.tmp_staging_fact_0000000000 as
(
    with expression_extract_1 as
    (
        select * from autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000
    ),
    expression_extract_2 as
    (
        select  t.*,
                (round(num_duration_seconds/60,2))::numeric as num_duration_minutes
                from expression_extract_1 t
    ),
    filter__3 as
    (
        select /* filtering irrelevant records out */ *
        from expression_extract_2
        where 1=1
        and agent_id is not null
        and customer_id is not null
        and num_duration_seconds > 10
    ),
    incremental_extract__4 as
    (
        select /* retrieving incremental data - by date range only */ *
        from filter__3
        where time_call_start >= to_date('2020-01-01', 'YYYY-MM-DD')
          and time_call_start  < to_date('2021-01-01', 'YYYY-MM-DD')
    ),
    deduplication__5 as
    (
        select /* deduplicate by strategy */
               call_id
               , max(time_call_start) as time_call_start
               , max(time_call_end) as time_call_end
               , max(num_duration_seconds) as num_duration_seconds
               , max(customer_id) as customer_id
               , max(agent_id) as agent_id
               , max(num_duration_minutes) as num_duration_minutes
        from incremental_extract__4
        group by call_id 
    ),
    coarsening_6 as
    (
        select * from deduplication__5
    )
    select  t.*,
            1 autopie_run_id
    from coarsening_6 t
);

drop view if exists autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 cascade;
drop view if exists autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 cascade;


-- check if not exists already, this should run once
do $$                  
begin
if not exists
( 
    select 1 from information_schema.tables 
    where table_schema||'.'|| table_name = 'autopie_ebpdemo.obj_fact_calls'
)
then
    create table autopie_ebpdemo.obj_fact_calls as (select * from autopie_ebpdemo.tmp_staging_fact_0000000000 where 1=0);
    alter  table autopie_ebpdemo.obj_fact_calls add column row_id bigserial not null;
    alter  table autopie_ebpdemo.obj_fact_calls add primary key (call_id, time_call_end);
    --
    create index ixrid_obj_fact_calls on autopie_ebpdemo.obj_fact_calls(row_id);
end if;
end
$$;

-- upsert staging additions into the permanent fact object
delete from autopie_ebpdemo.obj_fact_calls where (call_id, time_call_end) in (select call_id, time_call_end from autopie_ebpdemo.tmp_staging_fact_0000000000);
insert into autopie_ebpdemo.obj_fact_calls select * from autopie_ebpdemo.tmp_staging_fact_0000000000;
drop table autopie_ebpdemo.tmp_staging_fact_0000000000;


06:24:46.816688 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:24:46.816761 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    



create or replace view autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 as
select "call_id"::text as "call_id", 
       "call_start_epoch"::bigint as "call_start_epoch", 
       "call_duration"::int as "call_duration", 
       "customer_id"::text as "customer_id", 
       "agent_id"::text as "agent_id"
       from testsatmap.calltable;


create or replace view autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 as
select  (call_id)::text as call_id, 
        (to_timestamp(call_start_epoch))::timestamptz as time_call_start, 
        (to_timestamp(call_start_epoch + call_duration))::timestamptz as time_call_end, 
        (call_duration)::int4 as num_duration_seconds, 
        (trim(customer_id))::text as customer_id, 
        (lower(trim(agent_id)))::text as agent_id
        from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000;


drop table if exists autopie_ebpdemo.tmp_staging_fact_0000000000;
create table autopie_ebpdemo.tmp_staging_fact_0000000000 as
(
    with expression_extract_1 as
    (
        select * from autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000
    ),
    expression_extract_2 as
    (
        select  t.*,
                (round(num_duration_seconds/60,2))::numeric as num_duration_minutes
                from expression_extract_1 t
    ),
    filter__3 as
    (
        select /* filtering irrelevant records out */ *
        from expression_extract_2
        where 1=1
        and agent_id is not null
        and customer_id is not null
        and num_duration_seconds > 10
    ),
    incremental_extract__4 as
    (
        select /* retrieving incremental data - by date range only */ *
        from filter__3
        where time_call_start >= to_date('2020-01-01', 'YYYY-MM-DD')
          and time_call_start  < to_date('2021-01-01', 'YYYY-MM-DD')
    ),
    deduplication__5 as
    (
        select /* deduplicate by strategy */
               call_id
               , max(time_call_start) as time_call_start
               , max(time_call_end) as time_call_end
               , max(num_duration_seconds) as num_duration_seconds
               , max(customer_id) as customer_id
               , max(agent_id) as agent_id
               , max(num_duration_minutes) as num_duration_minutes
        from incremental_extract__4
        group by call_id 
    ),
    coarsening_6 as
    (
        select * from deduplication__5
    )
    select  t.*,
            1 autopie_run_id
    from coarsening_6 t
);

drop view if exists autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 cascade;
drop view if exists autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 cascade;


-- check if not exists already, this should run once
do $$                  
begin
if not exists
( 
    select 1 from information_schema.tables 
    where table_schema||'.'|| table_name = 'autopie_ebpdemo.obj_fact_calls'
)
then
    create table autopie_ebpdemo.obj_fact_calls as (select * from autopie_ebpdemo.tmp_staging_fact_0000000000 where 1=0);
    alter  table autopie_ebpdemo.obj_fact_calls add column row_id bigserial not null;
    alter  table autopie_ebpdemo.obj_fact_calls add primary key (call_id, time_call_end);
    --
    create index ixrid_obj_fact_calls on autopie_ebpdemo.obj_fact_calls(row_id);
end if;
end
$$;

-- upsert staging additions into the permanent fact object
delete from autopie_ebpdemo.obj_fact_calls where (call_id, time_call_end) in (select call_id, time_call_end from autopie_ebpdemo.tmp_staging_fact_0000000000);
insert into autopie_ebpdemo.obj_fact_calls select * from autopie_ebpdemo.tmp_staging_fact_0000000000;
drop table autopie_ebpdemo.tmp_staging_fact_0000000000;


  
06:24:46.847353 [debug] [MainThread]: SQL status: DROP TABLE in 0.03 seconds
06:24:46.848133 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:24:46.848230 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    
select row_number() over (order by autopie_run_id desc) run_sequence, count(*) count_records 
  from autopie_ebpdemo.obj_fact_calls
group by autopie_run_id
order by 1 
limit 5;

  
06:24:46.848899 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
06:24:46.849585 [debug] [MainThread]: On macro_run_recipe: Close
06:24:46.850392 [debug] [MainThread]: Connection 'macro_run_recipe' was properly closed.


============================== 2022-02-20 06:24:47.950046 | 24bf552d-444c-4a2f-832a-e9373a546bc2 ==============================
06:24:47.950046 [info ] [MainThread]: Running with dbt=1.0.1
06:24:47.950481 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/hassanzaheer/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, macro='run_recipe', args='{\n    "recipe_type" : "collect_fact",\n    "target_fact" : {\n        "id": "outcomes", \n        "entity_and_dims": "customer_id",\n        "date":"date_outcome"\n    },\n    "ingredients": {\n        "expression_extract": {  \n            "source_raw": "testsatmap.outcomes",\n            "expression_list": [\n                {"expression": "outcome_date", "alias": "date_outcome"},\n                {"expression": "trim(customer_id)", "alias": "customer_id"},             \n                {"expression": "outcome_code::numeric", "alias": "num_outcome_amount"}\n            ]\n        },\n        "filter_conjunctions": [\n            "num_outcome_amount > 0",\n            "customer_id is not null"\n        ],\n        "incremental_update_on": "date_outcome",\n        "deduplication": {\n            "grouping_key": "customer_id, date_outcome, num_outcome_amount",\n            "preference": "arbitrary"\n        },\n        "coarsening": {\n            "entity_and_dims": "customer_id",\n            "date_expression":"date_outcome",\n            "aggregations": [\n                {"expression": "sum(num_outcome_amount)", "alias": "sum_outcome_amount"}\n            ]\n        }\n    }\n}', defer=None, state=None, cls=<class 'dbt.task.run_operation.RunOperationTask'>, which='run-operation', rpc_method='run-operation')
06:24:47.950636 [debug] [MainThread]: Tracking: do not track
06:24:47.970100 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 2 files changed.
06:24:47.970350 [debug] [MainThread]: Partial parsing: updated file: demo_autopie://models/demo_ebp_flow/prepared_scripts/prepared_fact_calls.sql
06:24:47.970473 [debug] [MainThread]: Partial parsing: updated file: demo_autopie://models/demo_ebp_flow/prepared_scripts/prepared_fact_outcomes.sql
06:24:47.975974 [debug] [MainThread]: 1699: static parser successfully parsed demo_ebp_flow/prepared_scripts/prepared_fact_calls.sql
06:24:47.981360 [debug] [MainThread]: 1699: static parser successfully parsed demo_ebp_flow/prepared_scripts/prepared_fact_outcomes.sql
06:24:47.987258 [debug] [MainThread]: Acquiring new postgres connection "macro_run_recipe"
06:24:47.987360 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:24:47.987427 [debug] [MainThread]: On macro_run_recipe: BEGIN
06:24:47.987485 [debug] [MainThread]: Opening a new connection, currently in state init
06:24:47.991062 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
06:24:47.991150 [debug] [MainThread]: On macro_run_recipe: COMMIT
06:24:47.991207 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:24:47.991259 [debug] [MainThread]: On macro_run_recipe: COMMIT
06:24:47.991380 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
06:24:48.034565 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:24:48.034683 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select '"'||column_name||'"::'||
       case when replace(udt_name, '_','') = 'bit' then 'int'
            when replace(udt_name, '_','') like 'int8%' then 'bigint'
            when replace(udt_name, '_','') like 'int4%' then 'int'
            when replace(udt_name, '_','') like 'int%' then 'smallint'
            when replace(udt_name, '_','') like 'bool%' then 'int'
            when replace(udt_name, '_','') like 'float%' then 'numeric'
            when replace(udt_name, '_','') like 'float%' then 'numeric'
            when replace(udt_name, '_','') like 'byte%' then 'text'
            when replace(udt_name, '_','') like 'varchar%' then 'text'
            when replace(udt_name, '_','') like 'timestamp%' then 'timestamp'
            else replace(udt_name, '_','') end ||
       ' as "'||column_name||'"' select_text
from information_schema.columns 
where table_schema||'.'||table_name = 'testsatmap.outcomes'
order by ordinal_position ;

  
06:24:48.047662 [debug] [MainThread]: SQL status: SELECT 3 in 0.01 seconds
06:24:48.048557 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:24:48.048627 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 as
select "outcome_date"::date as "outcome_date", 
       "customer_id"::text as "customer_id", 
       "outcome_code"::text as "outcome_code"
       from testsatmap.outcomes;

  
06:24:48.051092 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:24:48.051587 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:24:48.051656 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:24:48.051878 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:24:48.052335 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:24:48.052397 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_exp_type_0000000000 as select outcome_date exp from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 limit 1
  
06:24:48.053942 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:24:48.054400 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:24:48.054463 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select replace(udt_name, '_','') dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type_0000000000' and column_name = 'exp'
  
06:24:48.057678 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
06:24:48.058189 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:24:48.058254 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:24:48.060141 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:24:48.060634 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:24:48.060704 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:24:48.060958 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:24:48.061617 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:24:48.061699 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_exp_type_0000000000 as select trim(customer_id) exp from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 limit 1
  
06:24:48.062465 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:24:48.063154 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:24:48.063229 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select replace(udt_name, '_','') dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type_0000000000' and column_name = 'exp'
  
06:24:48.066587 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
06:24:48.067144 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:24:48.067216 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:24:48.067928 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:24:48.068423 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:24:48.068489 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:24:48.068699 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:24:48.069186 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:24:48.069251 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_exp_type_0000000000 as select outcome_code::numeric exp from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 limit 1
  
06:24:48.070145 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:24:48.070628 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:24:48.070694 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select replace(udt_name, '_','') dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type_0000000000' and column_name = 'exp'
  
06:24:48.073812 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
06:24:48.074318 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:24:48.074383 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:24:48.075057 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:24:48.075536 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:24:48.075601 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 as
select  (outcome_date)::date as date_outcome, 
        (trim(customer_id))::text as customer_id, 
        (outcome_code::numeric)::numeric as num_outcome_amount
        from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000;

  
06:24:48.077052 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:24:48.078006 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:24:48.078081 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 cascade;
drop view if exists autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 cascade;

  
06:24:48.078955 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:24:48.079437 [info ] [MainThread]: 



create or replace view autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 as
select "outcome_date"::date as "outcome_date", 
       "customer_id"::text as "customer_id", 
       "outcome_code"::text as "outcome_code"
       from testsatmap.outcomes;


create or replace view autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 as
select  (outcome_date)::date as date_outcome, 
        (trim(customer_id))::text as customer_id, 
        (outcome_code::numeric)::numeric as num_outcome_amount
        from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000;


drop table if exists autopie_ebpdemo.tmp_staging_fact_0000000000;
create table autopie_ebpdemo.tmp_staging_fact_0000000000 as
(
    with expression_extract_1 as
    (
        select * from autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000
    ),
    expression_extract_2 as
    (
        select * from expression_extract_1
    ),
    filter__3 as
    (
        select /* filtering irrelevant records out */ *
        from expression_extract_2
        where 1=1
        and num_outcome_amount > 0
        and customer_id is not null
    ),
    incremental_extract__4 as
    (
        select /* retrieving incremental data - by date range only */ *
        from filter__3
        where date_outcome >= to_date('2020-01-01', 'YYYY-MM-DD')
          and date_outcome  < to_date('2021-01-01', 'YYYY-MM-DD')
    ),
    deduplication__5 as
    (
        select /* deduplicate by strategy */
               customer_id, date_outcome, num_outcome_amount
        from incremental_extract__4
        group by customer_id, date_outcome, num_outcome_amount 
    ),
    coarsening_6 as
    (
        select /* flatten all dimensions, fit into EAVT format */
              customer_id
              , date_outcome
              
              , sum(num_outcome_amount) as sum_outcome_amount
              from deduplication__5
        group by customer_id, date_outcome
    )
    select  t.*,
            1 autopie_run_id
    from coarsening_6 t
);

drop view if exists autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 cascade;
drop view if exists autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 cascade;


-- check if not exists already, this should run once
do $$                  
begin
if not exists
( 
    select 1 from information_schema.tables 
    where table_schema||'.'|| table_name = 'autopie_ebpdemo.obj_fact_outcomes'
)
then
    create table autopie_ebpdemo.obj_fact_outcomes as (select * from autopie_ebpdemo.tmp_staging_fact_0000000000 where 1=0);
    alter  table autopie_ebpdemo.obj_fact_outcomes add column row_id bigserial not null;
    alter  table autopie_ebpdemo.obj_fact_outcomes add primary key (customer_id, date_outcome);
    --
    create index ixrid_obj_fact_outcomes on autopie_ebpdemo.obj_fact_outcomes(row_id);
end if;
end
$$;

-- upsert staging additions into the permanent fact object
delete from autopie_ebpdemo.obj_fact_outcomes where (customer_id, date_outcome) in (select customer_id, date_outcome from autopie_ebpdemo.tmp_staging_fact_0000000000);
insert into autopie_ebpdemo.obj_fact_outcomes select * from autopie_ebpdemo.tmp_staging_fact_0000000000;
drop table autopie_ebpdemo.tmp_staging_fact_0000000000;


06:24:48.079814 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:24:48.079882 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    



create or replace view autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 as
select "outcome_date"::date as "outcome_date", 
       "customer_id"::text as "customer_id", 
       "outcome_code"::text as "outcome_code"
       from testsatmap.outcomes;


create or replace view autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 as
select  (outcome_date)::date as date_outcome, 
        (trim(customer_id))::text as customer_id, 
        (outcome_code::numeric)::numeric as num_outcome_amount
        from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000;


drop table if exists autopie_ebpdemo.tmp_staging_fact_0000000000;
create table autopie_ebpdemo.tmp_staging_fact_0000000000 as
(
    with expression_extract_1 as
    (
        select * from autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000
    ),
    expression_extract_2 as
    (
        select * from expression_extract_1
    ),
    filter__3 as
    (
        select /* filtering irrelevant records out */ *
        from expression_extract_2
        where 1=1
        and num_outcome_amount > 0
        and customer_id is not null
    ),
    incremental_extract__4 as
    (
        select /* retrieving incremental data - by date range only */ *
        from filter__3
        where date_outcome >= to_date('2020-01-01', 'YYYY-MM-DD')
          and date_outcome  < to_date('2021-01-01', 'YYYY-MM-DD')
    ),
    deduplication__5 as
    (
        select /* deduplicate by strategy */
               customer_id, date_outcome, num_outcome_amount
        from incremental_extract__4
        group by customer_id, date_outcome, num_outcome_amount 
    ),
    coarsening_6 as
    (
        select /* flatten all dimensions, fit into EAVT format */
              customer_id
              , date_outcome
              
              , sum(num_outcome_amount) as sum_outcome_amount
              from deduplication__5
        group by customer_id, date_outcome
    )
    select  t.*,
            1 autopie_run_id
    from coarsening_6 t
);

drop view if exists autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 cascade;
drop view if exists autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 cascade;


-- check if not exists already, this should run once
do $$                  
begin
if not exists
( 
    select 1 from information_schema.tables 
    where table_schema||'.'|| table_name = 'autopie_ebpdemo.obj_fact_outcomes'
)
then
    create table autopie_ebpdemo.obj_fact_outcomes as (select * from autopie_ebpdemo.tmp_staging_fact_0000000000 where 1=0);
    alter  table autopie_ebpdemo.obj_fact_outcomes add column row_id bigserial not null;
    alter  table autopie_ebpdemo.obj_fact_outcomes add primary key (customer_id, date_outcome);
    --
    create index ixrid_obj_fact_outcomes on autopie_ebpdemo.obj_fact_outcomes(row_id);
end if;
end
$$;

-- upsert staging additions into the permanent fact object
delete from autopie_ebpdemo.obj_fact_outcomes where (customer_id, date_outcome) in (select customer_id, date_outcome from autopie_ebpdemo.tmp_staging_fact_0000000000);
insert into autopie_ebpdemo.obj_fact_outcomes select * from autopie_ebpdemo.tmp_staging_fact_0000000000;
drop table autopie_ebpdemo.tmp_staging_fact_0000000000;


  
06:24:48.108044 [debug] [MainThread]: SQL status: DROP TABLE in 0.03 seconds
06:24:48.108757 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:24:48.108850 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    
select row_number() over (order by autopie_run_id desc) run_sequence, count(*) count_records 
  from autopie_ebpdemo.obj_fact_outcomes
group by autopie_run_id
order by 1 
limit 5;

  
06:24:48.109465 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
06:24:48.110241 [debug] [MainThread]: On macro_run_recipe: Close
06:24:48.110912 [debug] [MainThread]: Connection 'macro_run_recipe' was properly closed.


============================== 2022-02-20 06:30:58.341684 | 5b956355-823b-48f9-b91c-aa519b856431 ==============================
06:30:58.341684 [info ] [MainThread]: Running with dbt=1.0.1
06:30:58.342108 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/hassanzaheer/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, macro='run_recipe', args='{\n    "recipe_type" : "collect_fact",\n    "target_fact" : {\n        "id": "calls", \n        "entity_and_dims": "call_id",\n        "date":"time_call_end"\n    },\n    "ingredients": {\n        "expression_extract": {  \n            "source_raw": "testsatmap.calltable",\n            "expression_list": [\n                {"expression": "call_id", "alias": "call_id"},\n                {"expression": "to_timestamp(call_start_epoch)", "alias": "time_call_start"},\n                {"expression": "to_timestamp(call_start_epoch + call_duration)", "alias": "time_call_end"},\n                {"expression": "call_duration", "alias": "num_duration_seconds"},\n                {"expression": "trim(customer_id)",  "alias": "customer_id"},\n                {"expression": "lower(trim(agent_id))",  "alias": "agent_id"}\n            ]\n        },\n        "expression_extract_outer": {  \n            "expression_list": [\n                {"expression": "round(num_duration_seconds/60,2)", "alias": "num_duration_minutes"}\n            ]\n        },\n        "filter_conjunctions": [\n            "agent_id is not null",\n            "customer_id is not null",\n            "num_duration_seconds > 10"\n        ],\n        "incremental_update_on": "time_call_start",\n        "deduplication": {\n            "grouping_key": "call_id",\n            "preference": "arbitrary"\n        }\n    }\n}', defer=None, state=None, cls=<class 'dbt.task.run_operation.RunOperationTask'>, which='run-operation', rpc_method='run-operation')
06:30:58.342219 [debug] [MainThread]: Tracking: do not track
06:30:58.362689 [debug] [MainThread]: Partial parsing enabled: 1 files deleted, 4 files added, 2 files changed.
06:30:58.362911 [debug] [MainThread]: Partial parsing: added file: demo_autopie://macros/compile_recipes/compile_recipe_chop_rollup.sql
06:30:58.363007 [debug] [MainThread]: Partial parsing: added file: demo_autopie://macros/compile_recipes/compile_recipe_collect_fact.sql
06:30:58.363090 [debug] [MainThread]: Partial parsing: added file: demo_autopie://macros/compile_recipes/compile_recipe_collect_union.sql
06:30:58.363171 [debug] [MainThread]: Partial parsing: added file: demo_autopie://macros/compile_recipes/compile_recipe_blend_window.sql
06:30:58.363302 [debug] [MainThread]: Partial parsing: deleted file: demo_autopie://macros/compile_recipe_collect_fact.sql
06:30:58.363417 [debug] [MainThread]: Partial parsing: updated file: demo_autopie://models/demo_ebp_flow/prepared_scripts/prepared_fact_calls.sql
06:30:58.363520 [debug] [MainThread]: Partial parsing: updated file: demo_autopie://models/demo_ebp_flow/prepared_scripts/prepared_fact_outcomes.sql
06:30:58.363602 [debug] [MainThread]: Parsing macros/compile_recipes/compile_recipe_chop_rollup.sql
06:30:58.375577 [debug] [MainThread]: Parsing macros/compile_recipes/compile_recipe_collect_fact.sql
06:30:58.407264 [debug] [MainThread]: Parsing macros/compile_recipes/compile_recipe_collect_union.sql
06:30:58.417004 [debug] [MainThread]: Parsing macros/compile_recipes/compile_recipe_blend_window.sql
06:30:58.419983 [debug] [MainThread]: Parsing macros/core/run_recipe.sql
06:30:58.422811 [debug] [MainThread]: Parsing macros/core/run_directory.sql
06:30:58.452167 [debug] [MainThread]: 1699: static parser successfully parsed demo_ebp_flow/prepared_scripts/prepared_fact_calls.sql
06:30:58.457559 [debug] [MainThread]: 1699: static parser successfully parsed demo_ebp_flow/prepared_scripts/prepared_fact_outcomes.sql
06:30:58.463920 [debug] [MainThread]: Acquiring new postgres connection "macro_run_recipe"
06:30:58.464023 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:30:58.464090 [debug] [MainThread]: On macro_run_recipe: BEGIN
06:30:58.464154 [debug] [MainThread]: Opening a new connection, currently in state init
06:30:58.487717 [debug] [MainThread]: SQL status: BEGIN in 0.02 seconds
06:30:58.487891 [debug] [MainThread]: On macro_run_recipe: COMMIT
06:30:58.487965 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:30:58.488025 [debug] [MainThread]: On macro_run_recipe: COMMIT
06:30:58.488212 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
06:30:58.534037 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:30:58.534190 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select '"'||column_name||'"::'||
       case when replace(udt_name, '_','') = 'bit' then 'int'
            when replace(udt_name, '_','') like 'int8%' then 'bigint'
            when replace(udt_name, '_','') like 'int4%' then 'int'
            when replace(udt_name, '_','') like 'int%' then 'smallint'
            when replace(udt_name, '_','') like 'bool%' then 'int'
            when replace(udt_name, '_','') like 'float%' then 'numeric'
            when replace(udt_name, '_','') like 'float%' then 'numeric'
            when replace(udt_name, '_','') like 'byte%' then 'text'
            when replace(udt_name, '_','') like 'varchar%' then 'text'
            when replace(udt_name, '_','') like 'timestamp%' then 'timestamp'
            else replace(udt_name, '_','') end ||
       ' as "'||column_name||'"' select_text
from information_schema.columns 
where table_schema||'.'||table_name = 'testsatmap.calltable'
order by ordinal_position ;

  
06:30:58.542990 [debug] [MainThread]: SQL status: SELECT 5 in 0.01 seconds
06:30:58.544018 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:30:58.544127 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 as
select "call_id"::text as "call_id", 
       "call_start_epoch"::bigint as "call_start_epoch", 
       "call_duration"::int as "call_duration", 
       "customer_id"::text as "customer_id", 
       "agent_id"::text as "agent_id"
       from testsatmap.calltable;

  
06:30:58.548391 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:30:58.548952 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:30:58.549020 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:30:58.549349 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:30:58.549835 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:30:58.549899 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_exp_type_0000000000 as select call_id exp from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 limit 1
  
06:30:58.551160 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:30:58.551628 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:30:58.551691 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select replace(udt_name, '_','') dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type_0000000000' and column_name = 'exp'
  
06:30:58.556464 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
06:30:58.556984 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:30:58.557048 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:30:58.558564 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:30:58.559073 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:30:58.559141 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:30:58.559378 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:30:58.559867 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:30:58.559934 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_exp_type_0000000000 as select to_timestamp(call_start_epoch) exp from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 limit 1
  
06:30:58.561221 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:30:58.561866 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:30:58.561933 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select replace(udt_name, '_','') dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type_0000000000' and column_name = 'exp'
  
06:30:58.564036 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
06:30:58.564553 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:30:58.564619 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:30:58.565175 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:30:58.565659 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:30:58.565726 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:30:58.565958 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:30:58.566440 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:30:58.566507 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_exp_type_0000000000 as select to_timestamp(call_start_epoch + call_duration) exp from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 limit 1
  
06:30:58.568259 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:30:58.568748 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:30:58.568814 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select replace(udt_name, '_','') dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type_0000000000' and column_name = 'exp'
  
06:30:58.571359 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
06:30:58.571867 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:30:58.571934 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:30:58.572545 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:30:58.573030 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:30:58.573098 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:30:58.573272 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:30:58.573751 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:30:58.573815 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_exp_type_0000000000 as select call_duration exp from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 limit 1
  
06:30:58.574528 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:30:58.575132 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:30:58.575216 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select replace(udt_name, '_','') dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type_0000000000' and column_name = 'exp'
  
06:30:58.577860 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
06:30:58.578403 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:30:58.578476 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:30:58.579170 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:30:58.579690 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:30:58.579762 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:30:58.580075 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:30:58.580596 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:30:58.580669 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_exp_type_0000000000 as select trim(customer_id) exp from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 limit 1
  
06:30:58.581791 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:30:58.582315 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:30:58.582390 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select replace(udt_name, '_','') dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type_0000000000' and column_name = 'exp'
  
06:30:58.585644 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
06:30:58.586198 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:30:58.586270 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:30:58.587016 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:30:58.587537 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:30:58.587609 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:30:58.587810 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:30:58.588339 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:30:58.588410 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_exp_type_0000000000 as select lower(trim(agent_id)) exp from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 limit 1
  
06:30:58.590311 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:30:58.590849 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:30:58.590921 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select replace(udt_name, '_','') dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type_0000000000' and column_name = 'exp'
  
06:30:58.593285 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
06:30:58.593838 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:30:58.593909 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:30:58.594695 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:30:58.595219 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:30:58.595289 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 as
select  (call_id)::text as call_id, 
        (to_timestamp(call_start_epoch))::timestamptz as time_call_start, 
        (to_timestamp(call_start_epoch + call_duration))::timestamptz as time_call_end, 
        (call_duration)::int4 as num_duration_seconds, 
        (trim(customer_id))::text as customer_id, 
        (lower(trim(agent_id)))::text as agent_id
        from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000;

  
06:30:58.596738 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:30:58.597266 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:30:58.597335 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:30:58.597573 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:30:58.598083 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:30:58.598153 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_exp_type_0000000000 as select round(num_duration_seconds/60,2) exp from autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 limit 1
  
06:30:58.599550 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:30:58.600067 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:30:58.600139 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select replace(udt_name, '_','') dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type_0000000000' and column_name = 'exp'
  
06:30:58.603339 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
06:30:58.604070 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:30:58.604143 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:30:58.604816 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:30:58.606384 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:30:58.606457 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 cascade;
drop view if exists autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 cascade;

  
06:30:58.607595 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:30:58.608096 [info ] [MainThread]: 



create or replace view autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 as
select "call_id"::text as "call_id", 
       "call_start_epoch"::bigint as "call_start_epoch", 
       "call_duration"::int as "call_duration", 
       "customer_id"::text as "customer_id", 
       "agent_id"::text as "agent_id"
       from testsatmap.calltable;


create or replace view autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 as
select  (call_id)::text as call_id, 
        (to_timestamp(call_start_epoch))::timestamptz as time_call_start, 
        (to_timestamp(call_start_epoch + call_duration))::timestamptz as time_call_end, 
        (call_duration)::int4 as num_duration_seconds, 
        (trim(customer_id))::text as customer_id, 
        (lower(trim(agent_id)))::text as agent_id
        from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000;


drop table if exists autopie_ebpdemo.tmp_staging_fact_0000000000;
create table autopie_ebpdemo.tmp_staging_fact_0000000000 as
(
    with expression_extract_1 as
    (
        select * from autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000
    ),
    expression_extract_2 as
    (
        select  t.*,
                (round(num_duration_seconds/60,2))::numeric as num_duration_minutes
                from expression_extract_1 t
    ),
    filter__3 as
    (
        select /* filtering irrelevant records out */ *
        from expression_extract_2
        where 1=1
        and agent_id is not null
        and customer_id is not null
        and num_duration_seconds > 10
    ),
    incremental_extract__4 as
    (
        select /* retrieving incremental data - by date range only */ *
        from filter__3
        where time_call_start >= to_date('2020-01-01', 'YYYY-MM-DD')
          and time_call_start  < to_date('2021-01-01', 'YYYY-MM-DD')
    ),
    deduplication__5 as
    (
        select /* deduplicate by strategy */
               call_id
               , max(time_call_start) as time_call_start
               , max(time_call_end) as time_call_end
               , max(num_duration_seconds) as num_duration_seconds
               , max(customer_id) as customer_id
               , max(agent_id) as agent_id
               , max(num_duration_minutes) as num_duration_minutes
        from incremental_extract__4
        group by call_id 
    ),
    coarsening_6 as
    (
        select * from deduplication__5
    )
    select  t.*,
            1 autopie_run_id
    from coarsening_6 t
);

drop view if exists autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 cascade;
drop view if exists autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 cascade;


-- check if not exists already, this should run once
do $$                  
begin
if not exists
( 
    select 1 from information_schema.tables 
    where table_schema||'.'|| table_name = 'autopie_ebpdemo.obj_fact_calls'
)
then
    create table autopie_ebpdemo.obj_fact_calls as (select * from autopie_ebpdemo.tmp_staging_fact_0000000000 where 1=0);
    alter  table autopie_ebpdemo.obj_fact_calls add column row_id bigserial not null;
    alter  table autopie_ebpdemo.obj_fact_calls add primary key (call_id, time_call_end);
    --
    create index ixrid_obj_fact_calls on autopie_ebpdemo.obj_fact_calls(row_id);
end if;
end
$$;

-- upsert staging additions into the permanent fact object
delete from autopie_ebpdemo.obj_fact_calls where (call_id, time_call_end) in (select call_id, time_call_end from autopie_ebpdemo.tmp_staging_fact_0000000000);
insert into autopie_ebpdemo.obj_fact_calls select * from autopie_ebpdemo.tmp_staging_fact_0000000000;
drop table autopie_ebpdemo.tmp_staging_fact_0000000000;


06:30:58.608493 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:30:58.608563 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    



create or replace view autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 as
select "call_id"::text as "call_id", 
       "call_start_epoch"::bigint as "call_start_epoch", 
       "call_duration"::int as "call_duration", 
       "customer_id"::text as "customer_id", 
       "agent_id"::text as "agent_id"
       from testsatmap.calltable;


create or replace view autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 as
select  (call_id)::text as call_id, 
        (to_timestamp(call_start_epoch))::timestamptz as time_call_start, 
        (to_timestamp(call_start_epoch + call_duration))::timestamptz as time_call_end, 
        (call_duration)::int4 as num_duration_seconds, 
        (trim(customer_id))::text as customer_id, 
        (lower(trim(agent_id)))::text as agent_id
        from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000;


drop table if exists autopie_ebpdemo.tmp_staging_fact_0000000000;
create table autopie_ebpdemo.tmp_staging_fact_0000000000 as
(
    with expression_extract_1 as
    (
        select * from autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000
    ),
    expression_extract_2 as
    (
        select  t.*,
                (round(num_duration_seconds/60,2))::numeric as num_duration_minutes
                from expression_extract_1 t
    ),
    filter__3 as
    (
        select /* filtering irrelevant records out */ *
        from expression_extract_2
        where 1=1
        and agent_id is not null
        and customer_id is not null
        and num_duration_seconds > 10
    ),
    incremental_extract__4 as
    (
        select /* retrieving incremental data - by date range only */ *
        from filter__3
        where time_call_start >= to_date('2020-01-01', 'YYYY-MM-DD')
          and time_call_start  < to_date('2021-01-01', 'YYYY-MM-DD')
    ),
    deduplication__5 as
    (
        select /* deduplicate by strategy */
               call_id
               , max(time_call_start) as time_call_start
               , max(time_call_end) as time_call_end
               , max(num_duration_seconds) as num_duration_seconds
               , max(customer_id) as customer_id
               , max(agent_id) as agent_id
               , max(num_duration_minutes) as num_duration_minutes
        from incremental_extract__4
        group by call_id 
    ),
    coarsening_6 as
    (
        select * from deduplication__5
    )
    select  t.*,
            1 autopie_run_id
    from coarsening_6 t
);

drop view if exists autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 cascade;
drop view if exists autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 cascade;


-- check if not exists already, this should run once
do $$                  
begin
if not exists
( 
    select 1 from information_schema.tables 
    where table_schema||'.'|| table_name = 'autopie_ebpdemo.obj_fact_calls'
)
then
    create table autopie_ebpdemo.obj_fact_calls as (select * from autopie_ebpdemo.tmp_staging_fact_0000000000 where 1=0);
    alter  table autopie_ebpdemo.obj_fact_calls add column row_id bigserial not null;
    alter  table autopie_ebpdemo.obj_fact_calls add primary key (call_id, time_call_end);
    --
    create index ixrid_obj_fact_calls on autopie_ebpdemo.obj_fact_calls(row_id);
end if;
end
$$;

-- upsert staging additions into the permanent fact object
delete from autopie_ebpdemo.obj_fact_calls where (call_id, time_call_end) in (select call_id, time_call_end from autopie_ebpdemo.tmp_staging_fact_0000000000);
insert into autopie_ebpdemo.obj_fact_calls select * from autopie_ebpdemo.tmp_staging_fact_0000000000;
drop table autopie_ebpdemo.tmp_staging_fact_0000000000;


  
06:30:58.635664 [debug] [MainThread]: SQL status: DROP TABLE in 0.03 seconds
06:30:58.636446 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:30:58.636539 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    
select row_number() over (order by autopie_run_id desc) run_sequence, count(*) count_records 
  from autopie_ebpdemo.obj_fact_calls
group by autopie_run_id
order by 1 
limit 5;

  
06:30:58.637791 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
06:30:58.638390 [debug] [MainThread]: On macro_run_recipe: Close
06:30:58.639158 [debug] [MainThread]: Connection 'macro_run_recipe' was properly closed.


============================== 2022-02-20 06:30:59.720297 | aff23e1a-ad2b-4ff7-8b76-ff54776c3fc1 ==============================
06:30:59.720297 [info ] [MainThread]: Running with dbt=1.0.1
06:30:59.720682 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/hassanzaheer/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, macro='run_recipe', args='{\n    "recipe_type" : "collect_fact",\n    "target_fact" : {\n        "id": "outcomes", \n        "entity_and_dims": "customer_id",\n        "date":"date_outcome"\n    },\n    "ingredients": {\n        "expression_extract": {  \n            "source_raw": "testsatmap.outcomes",\n            "expression_list": [\n                {"expression": "outcome_date", "alias": "date_outcome"},\n                {"expression": "trim(customer_id)", "alias": "customer_id"},             \n                {"expression": "outcome_code::numeric", "alias": "num_outcome_amount"}\n            ]\n        },\n        "filter_conjunctions": [\n            "num_outcome_amount > 0",\n            "customer_id is not null"\n        ],\n        "incremental_update_on": "date_outcome",\n        "deduplication": {\n            "grouping_key": "customer_id, date_outcome, num_outcome_amount",\n            "preference": "arbitrary"\n        },\n        "coarsening": {\n            "entity_and_dims": "customer_id",\n            "date_expression":"date_outcome",\n            "aggregations": [\n                {"expression": "sum(num_outcome_amount)", "alias": "sum_outcome_amount"}\n            ]\n        }\n    }\n}', defer=None, state=None, cls=<class 'dbt.task.run_operation.RunOperationTask'>, which='run-operation', rpc_method='run-operation')
06:30:59.720808 [debug] [MainThread]: Tracking: do not track
06:30:59.740761 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 2 files changed.
06:30:59.741005 [debug] [MainThread]: Partial parsing: updated file: demo_autopie://models/demo_ebp_flow/prepared_scripts/prepared_fact_calls.sql
06:30:59.741127 [debug] [MainThread]: Partial parsing: updated file: demo_autopie://models/demo_ebp_flow/prepared_scripts/prepared_fact_outcomes.sql
06:30:59.746599 [debug] [MainThread]: 1699: static parser successfully parsed demo_ebp_flow/prepared_scripts/prepared_fact_calls.sql
06:30:59.751999 [debug] [MainThread]: 1699: static parser successfully parsed demo_ebp_flow/prepared_scripts/prepared_fact_outcomes.sql
06:30:59.757939 [debug] [MainThread]: Acquiring new postgres connection "macro_run_recipe"
06:30:59.758037 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:30:59.758104 [debug] [MainThread]: On macro_run_recipe: BEGIN
06:30:59.758165 [debug] [MainThread]: Opening a new connection, currently in state init
06:30:59.762250 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
06:30:59.762338 [debug] [MainThread]: On macro_run_recipe: COMMIT
06:30:59.762392 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:30:59.762442 [debug] [MainThread]: On macro_run_recipe: COMMIT
06:30:59.762626 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
06:30:59.805856 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:30:59.805965 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select '"'||column_name||'"::'||
       case when replace(udt_name, '_','') = 'bit' then 'int'
            when replace(udt_name, '_','') like 'int8%' then 'bigint'
            when replace(udt_name, '_','') like 'int4%' then 'int'
            when replace(udt_name, '_','') like 'int%' then 'smallint'
            when replace(udt_name, '_','') like 'bool%' then 'int'
            when replace(udt_name, '_','') like 'float%' then 'numeric'
            when replace(udt_name, '_','') like 'float%' then 'numeric'
            when replace(udt_name, '_','') like 'byte%' then 'text'
            when replace(udt_name, '_','') like 'varchar%' then 'text'
            when replace(udt_name, '_','') like 'timestamp%' then 'timestamp'
            else replace(udt_name, '_','') end ||
       ' as "'||column_name||'"' select_text
from information_schema.columns 
where table_schema||'.'||table_name = 'testsatmap.outcomes'
order by ordinal_position ;

  
06:30:59.820750 [debug] [MainThread]: SQL status: SELECT 3 in 0.01 seconds
06:30:59.821585 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:30:59.821657 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 as
select "outcome_date"::date as "outcome_date", 
       "customer_id"::text as "customer_id", 
       "outcome_code"::text as "outcome_code"
       from testsatmap.outcomes;

  
06:30:59.824652 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:30:59.825195 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:30:59.825263 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:30:59.825490 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:30:59.825985 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:30:59.826049 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_exp_type_0000000000 as select outcome_date exp from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 limit 1
  
06:30:59.826984 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:30:59.827472 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:30:59.827536 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select replace(udt_name, '_','') dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type_0000000000' and column_name = 'exp'
  
06:30:59.830753 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
06:30:59.831261 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:30:59.831325 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:30:59.832364 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:30:59.832863 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:30:59.832929 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:30:59.833285 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:30:59.833765 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:30:59.833829 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_exp_type_0000000000 as select trim(customer_id) exp from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 limit 1
  
06:30:59.835282 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:30:59.835897 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:30:59.835964 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select replace(udt_name, '_','') dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type_0000000000' and column_name = 'exp'
  
06:30:59.840425 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
06:30:59.840988 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:30:59.841060 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:30:59.841928 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:30:59.842455 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:30:59.842527 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:30:59.842769 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:30:59.843286 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:30:59.843355 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_exp_type_0000000000 as select outcome_code::numeric exp from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 limit 1
  
06:30:59.844498 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:30:59.845015 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:30:59.845086 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select replace(udt_name, '_','') dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type_0000000000' and column_name = 'exp'
  
06:30:59.849276 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
06:30:59.849821 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:30:59.849889 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:30:59.850723 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:30:59.851249 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:30:59.851320 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 as
select  (outcome_date)::date as date_outcome, 
        (trim(customer_id))::text as customer_id, 
        (outcome_code::numeric)::numeric as num_outcome_amount
        from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000;

  
06:30:59.853116 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:30:59.854052 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:30:59.854125 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 cascade;
drop view if exists autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 cascade;

  
06:30:59.855255 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:30:59.855733 [info ] [MainThread]: 



create or replace view autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 as
select "outcome_date"::date as "outcome_date", 
       "customer_id"::text as "customer_id", 
       "outcome_code"::text as "outcome_code"
       from testsatmap.outcomes;


create or replace view autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 as
select  (outcome_date)::date as date_outcome, 
        (trim(customer_id))::text as customer_id, 
        (outcome_code::numeric)::numeric as num_outcome_amount
        from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000;


drop table if exists autopie_ebpdemo.tmp_staging_fact_0000000000;
create table autopie_ebpdemo.tmp_staging_fact_0000000000 as
(
    with expression_extract_1 as
    (
        select * from autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000
    ),
    expression_extract_2 as
    (
        select * from expression_extract_1
    ),
    filter__3 as
    (
        select /* filtering irrelevant records out */ *
        from expression_extract_2
        where 1=1
        and num_outcome_amount > 0
        and customer_id is not null
    ),
    incremental_extract__4 as
    (
        select /* retrieving incremental data - by date range only */ *
        from filter__3
        where date_outcome >= to_date('2020-01-01', 'YYYY-MM-DD')
          and date_outcome  < to_date('2021-01-01', 'YYYY-MM-DD')
    ),
    deduplication__5 as
    (
        select /* deduplicate by strategy */
               customer_id, date_outcome, num_outcome_amount
        from incremental_extract__4
        group by customer_id, date_outcome, num_outcome_amount 
    ),
    coarsening_6 as
    (
        select /* flatten all dimensions, fit into EAVT format */
              customer_id
              , date_outcome
              
              , sum(num_outcome_amount) as sum_outcome_amount
              from deduplication__5
        group by customer_id, date_outcome
    )
    select  t.*,
            1 autopie_run_id
    from coarsening_6 t
);

drop view if exists autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 cascade;
drop view if exists autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 cascade;


-- check if not exists already, this should run once
do $$                  
begin
if not exists
( 
    select 1 from information_schema.tables 
    where table_schema||'.'|| table_name = 'autopie_ebpdemo.obj_fact_outcomes'
)
then
    create table autopie_ebpdemo.obj_fact_outcomes as (select * from autopie_ebpdemo.tmp_staging_fact_0000000000 where 1=0);
    alter  table autopie_ebpdemo.obj_fact_outcomes add column row_id bigserial not null;
    alter  table autopie_ebpdemo.obj_fact_outcomes add primary key (customer_id, date_outcome);
    --
    create index ixrid_obj_fact_outcomes on autopie_ebpdemo.obj_fact_outcomes(row_id);
end if;
end
$$;

-- upsert staging additions into the permanent fact object
delete from autopie_ebpdemo.obj_fact_outcomes where (customer_id, date_outcome) in (select customer_id, date_outcome from autopie_ebpdemo.tmp_staging_fact_0000000000);
insert into autopie_ebpdemo.obj_fact_outcomes select * from autopie_ebpdemo.tmp_staging_fact_0000000000;
drop table autopie_ebpdemo.tmp_staging_fact_0000000000;


06:30:59.856107 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:30:59.856170 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    



create or replace view autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 as
select "outcome_date"::date as "outcome_date", 
       "customer_id"::text as "customer_id", 
       "outcome_code"::text as "outcome_code"
       from testsatmap.outcomes;


create or replace view autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 as
select  (outcome_date)::date as date_outcome, 
        (trim(customer_id))::text as customer_id, 
        (outcome_code::numeric)::numeric as num_outcome_amount
        from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000;


drop table if exists autopie_ebpdemo.tmp_staging_fact_0000000000;
create table autopie_ebpdemo.tmp_staging_fact_0000000000 as
(
    with expression_extract_1 as
    (
        select * from autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000
    ),
    expression_extract_2 as
    (
        select * from expression_extract_1
    ),
    filter__3 as
    (
        select /* filtering irrelevant records out */ *
        from expression_extract_2
        where 1=1
        and num_outcome_amount > 0
        and customer_id is not null
    ),
    incremental_extract__4 as
    (
        select /* retrieving incremental data - by date range only */ *
        from filter__3
        where date_outcome >= to_date('2020-01-01', 'YYYY-MM-DD')
          and date_outcome  < to_date('2021-01-01', 'YYYY-MM-DD')
    ),
    deduplication__5 as
    (
        select /* deduplicate by strategy */
               customer_id, date_outcome, num_outcome_amount
        from incremental_extract__4
        group by customer_id, date_outcome, num_outcome_amount 
    ),
    coarsening_6 as
    (
        select /* flatten all dimensions, fit into EAVT format */
              customer_id
              , date_outcome
              
              , sum(num_outcome_amount) as sum_outcome_amount
              from deduplication__5
        group by customer_id, date_outcome
    )
    select  t.*,
            1 autopie_run_id
    from coarsening_6 t
);

drop view if exists autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 cascade;
drop view if exists autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 cascade;


-- check if not exists already, this should run once
do $$                  
begin
if not exists
( 
    select 1 from information_schema.tables 
    where table_schema||'.'|| table_name = 'autopie_ebpdemo.obj_fact_outcomes'
)
then
    create table autopie_ebpdemo.obj_fact_outcomes as (select * from autopie_ebpdemo.tmp_staging_fact_0000000000 where 1=0);
    alter  table autopie_ebpdemo.obj_fact_outcomes add column row_id bigserial not null;
    alter  table autopie_ebpdemo.obj_fact_outcomes add primary key (customer_id, date_outcome);
    --
    create index ixrid_obj_fact_outcomes on autopie_ebpdemo.obj_fact_outcomes(row_id);
end if;
end
$$;

-- upsert staging additions into the permanent fact object
delete from autopie_ebpdemo.obj_fact_outcomes where (customer_id, date_outcome) in (select customer_id, date_outcome from autopie_ebpdemo.tmp_staging_fact_0000000000);
insert into autopie_ebpdemo.obj_fact_outcomes select * from autopie_ebpdemo.tmp_staging_fact_0000000000;
drop table autopie_ebpdemo.tmp_staging_fact_0000000000;


  
06:30:59.882823 [debug] [MainThread]: SQL status: DROP TABLE in 0.03 seconds
06:30:59.883512 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:30:59.883594 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    
select row_number() over (order by autopie_run_id desc) run_sequence, count(*) count_records 
  from autopie_ebpdemo.obj_fact_outcomes
group by autopie_run_id
order by 1 
limit 5;

  
06:30:59.884177 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
06:30:59.884925 [debug] [MainThread]: On macro_run_recipe: Close
06:30:59.885607 [debug] [MainThread]: Connection 'macro_run_recipe' was properly closed.


============================== 2022-02-20 06:32:57.694133 | 3b4fd490-935a-4962-8a07-567b72818ddc ==============================
06:32:57.694133 [info ] [MainThread]: Running with dbt=1.0.1
06:32:57.694498 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/hassanzaheer/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, macro='run_recipe', args='{\n    "recipe_type" : "collect_fact",\n    "target_fact" : {\n        "id": "calls", \n        "entity_and_dims": "call_id",\n        "date":"time_call_end"\n    },\n    "ingredients": {\n        "expression_extract": {  \n            "source_raw": "testsatmap.calltable",\n            "expression_list": [\n                {"expression": "call_id", "alias": "call_id"},\n                {"expression": "to_timestamp(call_start_epoch)", "alias": "time_call_start"},\n                {"expression": "to_timestamp(call_start_epoch + call_duration)", "alias": "time_call_end"},\n                {"expression": "call_duration", "alias": "num_duration_seconds"},\n                {"expression": "trim(customer_id)",  "alias": "customer_id"},\n                {"expression": "lower(trim(agent_id))",  "alias": "agent_id"}\n            ]\n        },\n        "expression_extract_outer": {  \n            "expression_list": [\n                {"expression": "round(num_duration_seconds/60,2)", "alias": "num_duration_minutes"}\n            ]\n        },\n        "filter_conjunctions": [\n            "agent_id is not null",\n            "customer_id is not null",\n            "num_duration_seconds > 10"\n        ],\n        "incremental_update_on": "time_call_start",\n        "deduplication": {\n            "grouping_key": "call_id",\n            "preference": "arbitrary"\n        }\n    }\n}', defer=None, state=None, cls=<class 'dbt.task.run_operation.RunOperationTask'>, which='run-operation', rpc_method='run-operation')
06:32:57.694614 [debug] [MainThread]: Tracking: do not track
06:32:57.715450 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 2 files changed.
06:32:57.715685 [debug] [MainThread]: Partial parsing: updated file: demo_autopie://models/demo_ebp_flow/prepared_scripts/prepared_fact_calls.sql
06:32:57.715813 [debug] [MainThread]: Partial parsing: updated file: demo_autopie://models/demo_ebp_flow/prepared_scripts/prepared_fact_outcomes.sql
06:32:57.721274 [debug] [MainThread]: 1699: static parser successfully parsed demo_ebp_flow/prepared_scripts/prepared_fact_calls.sql
06:32:57.726661 [debug] [MainThread]: 1699: static parser successfully parsed demo_ebp_flow/prepared_scripts/prepared_fact_outcomes.sql
06:32:57.732725 [debug] [MainThread]: Acquiring new postgres connection "macro_run_recipe"
06:32:57.732826 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:32:57.732889 [debug] [MainThread]: On macro_run_recipe: BEGIN
06:32:57.732949 [debug] [MainThread]: Opening a new connection, currently in state init
06:32:57.754746 [debug] [MainThread]: SQL status: BEGIN in 0.02 seconds
06:32:57.754863 [debug] [MainThread]: On macro_run_recipe: COMMIT
06:32:57.754935 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:32:57.754998 [debug] [MainThread]: On macro_run_recipe: COMMIT
06:32:57.755133 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
06:32:57.799604 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:32:57.799732 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select '"'||column_name||'"::'||
       case when replace(udt_name, '_','') = 'bit' then 'int'
            when replace(udt_name, '_','') like 'int8%' then 'bigint'
            when replace(udt_name, '_','') like 'int4%' then 'int'
            when replace(udt_name, '_','') like 'int%' then 'smallint'
            when replace(udt_name, '_','') like 'bool%' then 'int'
            when replace(udt_name, '_','') like 'float%' then 'numeric'
            when replace(udt_name, '_','') like 'float%' then 'numeric'
            when replace(udt_name, '_','') like 'byte%' then 'text'
            when replace(udt_name, '_','') like 'varchar%' then 'text'
            when replace(udt_name, '_','') like 'timestamp%' then 'timestamp'
            else replace(udt_name, '_','') end ||
       ' as "'||column_name||'"' select_text
from information_schema.columns 
where table_schema||'.'||table_name = 'testsatmap.calltable'
order by ordinal_position ;

  
06:32:57.812969 [debug] [MainThread]: SQL status: SELECT 5 in 0.01 seconds
06:32:57.813854 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:32:57.813928 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 as
select "call_id"::text as "call_id", 
       "call_start_epoch"::bigint as "call_start_epoch", 
       "call_duration"::int as "call_duration", 
       "customer_id"::text as "customer_id", 
       "agent_id"::text as "agent_id"
       from testsatmap.calltable;

  
06:32:57.817187 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:32:57.817685 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:32:57.817750 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:32:57.817968 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:32:57.818433 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:32:57.818496 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_exp_type_0000000000 as select call_id exp from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 limit 1
  
06:32:57.819390 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:32:57.819844 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:32:57.819905 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select replace(udt_name, '_','') dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type_0000000000' and column_name = 'exp'
  
06:32:57.823102 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
06:32:57.823582 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:32:57.823648 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:32:57.824697 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:32:57.825189 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:32:57.825255 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:32:57.825457 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:32:57.825937 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:32:57.826002 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_exp_type_0000000000 as select to_timestamp(call_start_epoch) exp from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 limit 1
  
06:32:57.827441 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:32:57.828040 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:32:57.828106 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select replace(udt_name, '_','') dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type_0000000000' and column_name = 'exp'
  
06:32:57.831227 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
06:32:57.831731 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:32:57.831797 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:32:57.832502 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:32:57.832986 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:32:57.833051 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:32:57.833243 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:32:57.833721 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:32:57.833787 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_exp_type_0000000000 as select to_timestamp(call_start_epoch + call_duration) exp from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 limit 1
  
06:32:57.834817 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:32:57.835295 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:32:57.835361 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select replace(udt_name, '_','') dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type_0000000000' and column_name = 'exp'
  
06:32:57.838628 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
06:32:57.839125 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:32:57.839190 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:32:57.839841 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:32:57.840345 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:32:57.840417 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:32:57.840620 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:32:57.841132 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:32:57.841204 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_exp_type_0000000000 as select call_duration exp from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 limit 1
  
06:32:57.842071 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:32:57.842587 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:32:57.842657 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select replace(udt_name, '_','') dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type_0000000000' and column_name = 'exp'
  
06:32:57.845790 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
06:32:57.846336 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:32:57.846410 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:32:57.847063 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:32:57.847579 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:32:57.847648 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:32:57.847960 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:32:57.848487 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:32:57.848558 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_exp_type_0000000000 as select trim(customer_id) exp from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 limit 1
  
06:32:57.849709 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:32:57.850234 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:32:57.850305 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select replace(udt_name, '_','') dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type_0000000000' and column_name = 'exp'
  
06:32:57.853513 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
06:32:57.854054 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:32:57.854128 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:32:57.854846 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:32:57.855362 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:32:57.855432 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:32:57.855632 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:32:57.856142 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:32:57.856212 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_exp_type_0000000000 as select lower(trim(agent_id)) exp from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 limit 1
  
06:32:57.857504 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:32:57.858023 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:32:57.858095 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select replace(udt_name, '_','') dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type_0000000000' and column_name = 'exp'
  
06:32:57.862332 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
06:32:57.862867 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:32:57.862937 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:32:57.863809 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:32:57.864326 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:32:57.864399 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 as
select  (call_id)::text as call_id, 
        (to_timestamp(call_start_epoch))::timestamptz as time_call_start, 
        (to_timestamp(call_start_epoch + call_duration))::timestamptz as time_call_end, 
        (call_duration)::int4 as num_duration_seconds, 
        (trim(customer_id))::text as customer_id, 
        (lower(trim(agent_id)))::text as agent_id
        from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000;

  
06:32:57.866183 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:32:57.866706 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:32:57.866776 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:32:57.867002 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:32:57.867512 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:32:57.867582 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_exp_type_0000000000 as select round(num_duration_seconds/60,2) exp from autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 limit 1
  
06:32:57.869071 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:32:57.869584 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:32:57.869654 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select replace(udt_name, '_','') dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type_0000000000' and column_name = 'exp'
  
06:32:57.874200 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
06:32:57.874944 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:32:57.875023 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:32:57.875974 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:32:57.877588 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:32:57.877668 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 cascade;
drop view if exists autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 cascade;

  
06:32:57.878803 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:32:57.879336 [info ] [MainThread]: 



create or replace view autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 as
select "call_id"::text as "call_id", 
       "call_start_epoch"::bigint as "call_start_epoch", 
       "call_duration"::int as "call_duration", 
       "customer_id"::text as "customer_id", 
       "agent_id"::text as "agent_id"
       from testsatmap.calltable;


create or replace view autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 as
select  (call_id)::text as call_id, 
        (to_timestamp(call_start_epoch))::timestamptz as time_call_start, 
        (to_timestamp(call_start_epoch + call_duration))::timestamptz as time_call_end, 
        (call_duration)::int4 as num_duration_seconds, 
        (trim(customer_id))::text as customer_id, 
        (lower(trim(agent_id)))::text as agent_id
        from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000;


drop table if exists autopie_ebpdemo.tmp_staging_fact_0000000000;
create table autopie_ebpdemo.tmp_staging_fact_0000000000 as
(
    with expression_extract_1 as
    (
        select * from autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000
    ),
    expression_extract_2 as
    (
        select  t.*,
                (round(num_duration_seconds/60,2))::numeric as num_duration_minutes
                from expression_extract_1 t
    ),
    filter__3 as
    (
        select /* filtering irrelevant records out */ *
        from expression_extract_2
        where 1=1
        and agent_id is not null
        and customer_id is not null
        and num_duration_seconds > 10
    ),
    incremental_extract__4 as
    (
        select /* retrieving incremental data - by date range only */ *
        from filter__3
        where time_call_start >= to_date('2020-01-01', 'YYYY-MM-DD')
          and time_call_start  < to_date('2021-01-01', 'YYYY-MM-DD')
    ),
    deduplication__5 as
    (
        select /* deduplicate by strategy */
               call_id
               , max(time_call_start) as time_call_start
               , max(time_call_end) as time_call_end
               , max(num_duration_seconds) as num_duration_seconds
               , max(customer_id) as customer_id
               , max(agent_id) as agent_id
               , max(num_duration_minutes) as num_duration_minutes
        from incremental_extract__4
        group by call_id 
    ),
    coarsening_6 as
    (
        select * from deduplication__5
    )
    select  t.*,
            1 autopie_run_id
    from coarsening_6 t
);

drop view if exists autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 cascade;
drop view if exists autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 cascade;


-- check if not exists already, this should run once
do $$                  
begin
if not exists
( 
    select 1 from information_schema.tables 
    where table_schema||'.'|| table_name = 'autopie_ebpdemo.obj_fact_calls'
)
then
    create table autopie_ebpdemo.obj_fact_calls as (select * from autopie_ebpdemo.tmp_staging_fact_0000000000 where 1=0);
    alter  table autopie_ebpdemo.obj_fact_calls add column row_id bigserial not null;
    alter  table autopie_ebpdemo.obj_fact_calls add primary key (call_id, time_call_end);
    --
    create index ixrid_obj_fact_calls on autopie_ebpdemo.obj_fact_calls(row_id);
end if;
end
$$;

-- upsert staging additions into the permanent fact object
delete from autopie_ebpdemo.obj_fact_calls where (call_id, time_call_end) in (select call_id, time_call_end from autopie_ebpdemo.tmp_staging_fact_0000000000);
insert into autopie_ebpdemo.obj_fact_calls select * from autopie_ebpdemo.tmp_staging_fact_0000000000;
drop table autopie_ebpdemo.tmp_staging_fact_0000000000;


06:32:57.879764 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:32:57.879835 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    



create or replace view autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 as
select "call_id"::text as "call_id", 
       "call_start_epoch"::bigint as "call_start_epoch", 
       "call_duration"::int as "call_duration", 
       "customer_id"::text as "customer_id", 
       "agent_id"::text as "agent_id"
       from testsatmap.calltable;


create or replace view autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 as
select  (call_id)::text as call_id, 
        (to_timestamp(call_start_epoch))::timestamptz as time_call_start, 
        (to_timestamp(call_start_epoch + call_duration))::timestamptz as time_call_end, 
        (call_duration)::int4 as num_duration_seconds, 
        (trim(customer_id))::text as customer_id, 
        (lower(trim(agent_id)))::text as agent_id
        from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000;


drop table if exists autopie_ebpdemo.tmp_staging_fact_0000000000;
create table autopie_ebpdemo.tmp_staging_fact_0000000000 as
(
    with expression_extract_1 as
    (
        select * from autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000
    ),
    expression_extract_2 as
    (
        select  t.*,
                (round(num_duration_seconds/60,2))::numeric as num_duration_minutes
                from expression_extract_1 t
    ),
    filter__3 as
    (
        select /* filtering irrelevant records out */ *
        from expression_extract_2
        where 1=1
        and agent_id is not null
        and customer_id is not null
        and num_duration_seconds > 10
    ),
    incremental_extract__4 as
    (
        select /* retrieving incremental data - by date range only */ *
        from filter__3
        where time_call_start >= to_date('2020-01-01', 'YYYY-MM-DD')
          and time_call_start  < to_date('2021-01-01', 'YYYY-MM-DD')
    ),
    deduplication__5 as
    (
        select /* deduplicate by strategy */
               call_id
               , max(time_call_start) as time_call_start
               , max(time_call_end) as time_call_end
               , max(num_duration_seconds) as num_duration_seconds
               , max(customer_id) as customer_id
               , max(agent_id) as agent_id
               , max(num_duration_minutes) as num_duration_minutes
        from incremental_extract__4
        group by call_id 
    ),
    coarsening_6 as
    (
        select * from deduplication__5
    )
    select  t.*,
            1 autopie_run_id
    from coarsening_6 t
);

drop view if exists autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 cascade;
drop view if exists autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 cascade;


-- check if not exists already, this should run once
do $$                  
begin
if not exists
( 
    select 1 from information_schema.tables 
    where table_schema||'.'|| table_name = 'autopie_ebpdemo.obj_fact_calls'
)
then
    create table autopie_ebpdemo.obj_fact_calls as (select * from autopie_ebpdemo.tmp_staging_fact_0000000000 where 1=0);
    alter  table autopie_ebpdemo.obj_fact_calls add column row_id bigserial not null;
    alter  table autopie_ebpdemo.obj_fact_calls add primary key (call_id, time_call_end);
    --
    create index ixrid_obj_fact_calls on autopie_ebpdemo.obj_fact_calls(row_id);
end if;
end
$$;

-- upsert staging additions into the permanent fact object
delete from autopie_ebpdemo.obj_fact_calls where (call_id, time_call_end) in (select call_id, time_call_end from autopie_ebpdemo.tmp_staging_fact_0000000000);
insert into autopie_ebpdemo.obj_fact_calls select * from autopie_ebpdemo.tmp_staging_fact_0000000000;
drop table autopie_ebpdemo.tmp_staging_fact_0000000000;


  
06:32:57.909526 [debug] [MainThread]: SQL status: DROP TABLE in 0.03 seconds
06:32:57.910284 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:32:57.910381 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    
select row_number() over (order by autopie_run_id desc) run_sequence, count(*) count_records 
  from autopie_ebpdemo.obj_fact_calls
group by autopie_run_id
order by 1 
limit 5;

  
06:32:57.911041 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
06:32:57.911708 [debug] [MainThread]: On macro_run_recipe: Close
06:32:57.912509 [debug] [MainThread]: Connection 'macro_run_recipe' was properly closed.


============================== 2022-02-20 06:32:58.991163 | 62075561-08ad-4cdd-9cba-074accb5ed00 ==============================
06:32:58.991163 [info ] [MainThread]: Running with dbt=1.0.1
06:32:58.991529 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/hassanzaheer/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, macro='run_recipe', args='{\n    "recipe_type" : "collect_fact",\n    "target_fact" : {\n        "id": "outcomes", \n        "entity_and_dims": "customer_id",\n        "date":"date_outcome"\n    },\n    "ingredients": {\n        "expression_extract": {  \n            "source_raw": "testsatmap.outcomes",\n            "expression_list": [\n                {"expression": "outcome_date", "alias": "date_outcome"},\n                {"expression": "trim(customer_id)", "alias": "customer_id"},             \n                {"expression": "outcome_code::numeric", "alias": "num_outcome_amount"}\n            ]\n        },\n        "filter_conjunctions": [\n            "num_outcome_amount > 0",\n            "customer_id is not null"\n        ],\n        "incremental_update_on": "date_outcome",\n        "deduplication": {\n            "grouping_key": "customer_id, date_outcome, num_outcome_amount",\n            "preference": "arbitrary"\n        },\n        "coarsening": {\n            "entity_and_dims": "customer_id",\n            "date_expression":"date_outcome",\n            "aggregations": [\n                {"expression": "sum(num_outcome_amount)", "alias": "sum_outcome_amount"}\n            ]\n        }\n    }\n}', defer=None, state=None, cls=<class 'dbt.task.run_operation.RunOperationTask'>, which='run-operation', rpc_method='run-operation')
06:32:58.991654 [debug] [MainThread]: Tracking: do not track
06:32:59.012579 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 2 files changed.
06:32:59.012828 [debug] [MainThread]: Partial parsing: updated file: demo_autopie://models/demo_ebp_flow/prepared_scripts/prepared_fact_calls.sql
06:32:59.012949 [debug] [MainThread]: Partial parsing: updated file: demo_autopie://models/demo_ebp_flow/prepared_scripts/prepared_fact_outcomes.sql
06:32:59.018485 [debug] [MainThread]: 1699: static parser successfully parsed demo_ebp_flow/prepared_scripts/prepared_fact_calls.sql
06:32:59.024026 [debug] [MainThread]: 1699: static parser successfully parsed demo_ebp_flow/prepared_scripts/prepared_fact_outcomes.sql
06:32:59.030158 [debug] [MainThread]: Acquiring new postgres connection "macro_run_recipe"
06:32:59.030265 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:32:59.030329 [debug] [MainThread]: On macro_run_recipe: BEGIN
06:32:59.030388 [debug] [MainThread]: Opening a new connection, currently in state init
06:32:59.034010 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
06:32:59.034095 [debug] [MainThread]: On macro_run_recipe: COMMIT
06:32:59.034155 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:32:59.034207 [debug] [MainThread]: On macro_run_recipe: COMMIT
06:32:59.034332 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
06:32:59.077665 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:32:59.077781 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select '"'||column_name||'"::'||
       case when replace(udt_name, '_','') = 'bit' then 'int'
            when replace(udt_name, '_','') like 'int8%' then 'bigint'
            when replace(udt_name, '_','') like 'int4%' then 'int'
            when replace(udt_name, '_','') like 'int%' then 'smallint'
            when replace(udt_name, '_','') like 'bool%' then 'int'
            when replace(udt_name, '_','') like 'float%' then 'numeric'
            when replace(udt_name, '_','') like 'float%' then 'numeric'
            when replace(udt_name, '_','') like 'byte%' then 'text'
            when replace(udt_name, '_','') like 'varchar%' then 'text'
            when replace(udt_name, '_','') like 'timestamp%' then 'timestamp'
            else replace(udt_name, '_','') end ||
       ' as "'||column_name||'"' select_text
from information_schema.columns 
where table_schema||'.'||table_name = 'testsatmap.outcomes'
order by ordinal_position ;

  
06:32:59.091917 [debug] [MainThread]: SQL status: SELECT 3 in 0.01 seconds
06:32:59.092754 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:32:59.092829 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 as
select "outcome_date"::date as "outcome_date", 
       "customer_id"::text as "customer_id", 
       "outcome_code"::text as "outcome_code"
       from testsatmap.outcomes;

  
06:32:59.095644 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:32:59.096166 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:32:59.096233 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:32:59.096460 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:32:59.096933 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:32:59.096999 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_exp_type_0000000000 as select outcome_date exp from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 limit 1
  
06:32:59.097905 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:32:59.098385 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:32:59.098450 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select replace(udt_name, '_','') dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type_0000000000' and column_name = 'exp'
  
06:32:59.101818 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
06:32:59.102313 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:32:59.102379 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:32:59.104500 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:32:59.105015 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:32:59.105082 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:32:59.105293 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:32:59.105872 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:32:59.105949 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_exp_type_0000000000 as select trim(customer_id) exp from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 limit 1
  
06:32:59.107143 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:32:59.107761 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:32:59.107834 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select replace(udt_name, '_','') dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type_0000000000' and column_name = 'exp'
  
06:32:59.112238 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
06:32:59.112801 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:32:59.112873 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:32:59.113746 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:32:59.114275 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:32:59.114348 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:32:59.114593 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:32:59.115119 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:32:59.115191 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_exp_type_0000000000 as select outcome_code::numeric exp from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 limit 1
  
06:32:59.116330 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:32:59.116852 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:32:59.116924 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select replace(udt_name, '_','') dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type_0000000000' and column_name = 'exp'
  
06:32:59.121350 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
06:32:59.121893 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:32:59.121965 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:32:59.122829 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:32:59.123356 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:32:59.123429 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 as
select  (outcome_date)::date as date_outcome, 
        (trim(customer_id))::text as customer_id, 
        (outcome_code::numeric)::numeric as num_outcome_amount
        from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000;

  
06:32:59.124933 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:32:59.125874 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:32:59.125949 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 cascade;
drop view if exists autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 cascade;

  
06:32:59.127063 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:32:59.127547 [info ] [MainThread]: 



create or replace view autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 as
select "outcome_date"::date as "outcome_date", 
       "customer_id"::text as "customer_id", 
       "outcome_code"::text as "outcome_code"
       from testsatmap.outcomes;


create or replace view autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 as
select  (outcome_date)::date as date_outcome, 
        (trim(customer_id))::text as customer_id, 
        (outcome_code::numeric)::numeric as num_outcome_amount
        from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000;


drop table if exists autopie_ebpdemo.tmp_staging_fact_0000000000;
create table autopie_ebpdemo.tmp_staging_fact_0000000000 as
(
    with expression_extract_1 as
    (
        select * from autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000
    ),
    expression_extract_2 as
    (
        select * from expression_extract_1
    ),
    filter__3 as
    (
        select /* filtering irrelevant records out */ *
        from expression_extract_2
        where 1=1
        and num_outcome_amount > 0
        and customer_id is not null
    ),
    incremental_extract__4 as
    (
        select /* retrieving incremental data - by date range only */ *
        from filter__3
        where date_outcome >= to_date('2020-01-01', 'YYYY-MM-DD')
          and date_outcome  < to_date('2021-01-01', 'YYYY-MM-DD')
    ),
    deduplication__5 as
    (
        select /* deduplicate by strategy */
               customer_id, date_outcome, num_outcome_amount
        from incremental_extract__4
        group by customer_id, date_outcome, num_outcome_amount 
    ),
    coarsening_6 as
    (
        select /* flatten all dimensions, fit into EAVT format */
              customer_id
              , date_outcome
              
              , sum(num_outcome_amount) as sum_outcome_amount
              from deduplication__5
        group by customer_id, date_outcome
    )
    select  t.*,
            1 autopie_run_id
    from coarsening_6 t
);

drop view if exists autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 cascade;
drop view if exists autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 cascade;


-- check if not exists already, this should run once
do $$                  
begin
if not exists
( 
    select 1 from information_schema.tables 
    where table_schema||'.'|| table_name = 'autopie_ebpdemo.obj_fact_outcomes'
)
then
    create table autopie_ebpdemo.obj_fact_outcomes as (select * from autopie_ebpdemo.tmp_staging_fact_0000000000 where 1=0);
    alter  table autopie_ebpdemo.obj_fact_outcomes add column row_id bigserial not null;
    alter  table autopie_ebpdemo.obj_fact_outcomes add primary key (customer_id, date_outcome);
    --
    create index ixrid_obj_fact_outcomes on autopie_ebpdemo.obj_fact_outcomes(row_id);
end if;
end
$$;

-- upsert staging additions into the permanent fact object
delete from autopie_ebpdemo.obj_fact_outcomes where (customer_id, date_outcome) in (select customer_id, date_outcome from autopie_ebpdemo.tmp_staging_fact_0000000000);
insert into autopie_ebpdemo.obj_fact_outcomes select * from autopie_ebpdemo.tmp_staging_fact_0000000000;
drop table autopie_ebpdemo.tmp_staging_fact_0000000000;


06:32:59.127922 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:32:59.127990 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    



create or replace view autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 as
select "outcome_date"::date as "outcome_date", 
       "customer_id"::text as "customer_id", 
       "outcome_code"::text as "outcome_code"
       from testsatmap.outcomes;


create or replace view autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 as
select  (outcome_date)::date as date_outcome, 
        (trim(customer_id))::text as customer_id, 
        (outcome_code::numeric)::numeric as num_outcome_amount
        from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000;


drop table if exists autopie_ebpdemo.tmp_staging_fact_0000000000;
create table autopie_ebpdemo.tmp_staging_fact_0000000000 as
(
    with expression_extract_1 as
    (
        select * from autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000
    ),
    expression_extract_2 as
    (
        select * from expression_extract_1
    ),
    filter__3 as
    (
        select /* filtering irrelevant records out */ *
        from expression_extract_2
        where 1=1
        and num_outcome_amount > 0
        and customer_id is not null
    ),
    incremental_extract__4 as
    (
        select /* retrieving incremental data - by date range only */ *
        from filter__3
        where date_outcome >= to_date('2020-01-01', 'YYYY-MM-DD')
          and date_outcome  < to_date('2021-01-01', 'YYYY-MM-DD')
    ),
    deduplication__5 as
    (
        select /* deduplicate by strategy */
               customer_id, date_outcome, num_outcome_amount
        from incremental_extract__4
        group by customer_id, date_outcome, num_outcome_amount 
    ),
    coarsening_6 as
    (
        select /* flatten all dimensions, fit into EAVT format */
              customer_id
              , date_outcome
              
              , sum(num_outcome_amount) as sum_outcome_amount
              from deduplication__5
        group by customer_id, date_outcome
    )
    select  t.*,
            1 autopie_run_id
    from coarsening_6 t
);

drop view if exists autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 cascade;
drop view if exists autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 cascade;


-- check if not exists already, this should run once
do $$                  
begin
if not exists
( 
    select 1 from information_schema.tables 
    where table_schema||'.'|| table_name = 'autopie_ebpdemo.obj_fact_outcomes'
)
then
    create table autopie_ebpdemo.obj_fact_outcomes as (select * from autopie_ebpdemo.tmp_staging_fact_0000000000 where 1=0);
    alter  table autopie_ebpdemo.obj_fact_outcomes add column row_id bigserial not null;
    alter  table autopie_ebpdemo.obj_fact_outcomes add primary key (customer_id, date_outcome);
    --
    create index ixrid_obj_fact_outcomes on autopie_ebpdemo.obj_fact_outcomes(row_id);
end if;
end
$$;

-- upsert staging additions into the permanent fact object
delete from autopie_ebpdemo.obj_fact_outcomes where (customer_id, date_outcome) in (select customer_id, date_outcome from autopie_ebpdemo.tmp_staging_fact_0000000000);
insert into autopie_ebpdemo.obj_fact_outcomes select * from autopie_ebpdemo.tmp_staging_fact_0000000000;
drop table autopie_ebpdemo.tmp_staging_fact_0000000000;


  
06:32:59.154897 [debug] [MainThread]: SQL status: DROP TABLE in 0.03 seconds
06:32:59.155590 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:32:59.155677 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    
select row_number() over (order by autopie_run_id desc) run_sequence, count(*) count_records 
  from autopie_ebpdemo.obj_fact_outcomes
group by autopie_run_id
order by 1 
limit 5;

  
06:32:59.156266 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
06:32:59.157023 [debug] [MainThread]: On macro_run_recipe: Close
06:32:59.157697 [debug] [MainThread]: Connection 'macro_run_recipe' was properly closed.


============================== 2022-02-20 06:33:00.237915 | 80da6275-f864-4709-8f63-5b31b4fe1841 ==============================
06:33:00.237915 [info ] [MainThread]: Running with dbt=1.0.1
06:33:00.238304 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/hassanzaheer/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, macro='run_recipe', args='{\n    "recipe_type" : "collect_fact",\n    "target_fact" : {\n        "id": "crm", \n        "entity_and_dims": "customer_id",\n        "date":"date_data"\n    },\n    "ingredients": {\n        "expression_extract": {  \n            "source_raw": "testsatmap.crm",\n            "expression_list": [\n                {"expression": "data_date", "alias": "date_data"},\n                {"expression": "trim(customer_id)",  "alias": "customer_id"},             \n                {"expression": "customer_num_attrib", "alias": "num_attrib"},\n                {"expression": "customer_cat_attrib",  "alias": "cat_attrib"}\n            ]\n        },\n        "filter_conjunctions": [\n            "customer_id is not null"\n        ],\n        "incremental_update_on": "date_data",\n        "deduplication": {\n            "grouping_key": "customer_id, date_data",\n            "preference": "arbitrary"\n        }\n    }\n}', defer=None, state=None, cls=<class 'dbt.task.run_operation.RunOperationTask'>, which='run-operation', rpc_method='run-operation')
06:33:00.238420 [debug] [MainThread]: Tracking: do not track
06:33:00.260121 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 1 files added, 1 files changed.
06:33:00.260337 [debug] [MainThread]: Partial parsing: added file: demo_autopie://models/demo_ebp_flow/prepared_scripts/prepared_fact_crm.sql
06:33:00.260470 [debug] [MainThread]: Partial parsing: updated file: demo_autopie://models/demo_ebp_flow/prepared_scripts/prepared_fact_outcomes.sql
06:33:00.265902 [debug] [MainThread]: 1699: static parser successfully parsed demo_ebp_flow/prepared_scripts/prepared_fact_crm.sql
06:33:00.271426 [debug] [MainThread]: 1699: static parser successfully parsed demo_ebp_flow/prepared_scripts/prepared_fact_outcomes.sql
06:33:00.277523 [debug] [MainThread]: Acquiring new postgres connection "macro_run_recipe"
06:33:00.277640 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:33:00.277706 [debug] [MainThread]: On macro_run_recipe: BEGIN
06:33:00.277767 [debug] [MainThread]: Opening a new connection, currently in state init
06:33:00.281374 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
06:33:00.281467 [debug] [MainThread]: On macro_run_recipe: COMMIT
06:33:00.281533 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:33:00.281589 [debug] [MainThread]: On macro_run_recipe: COMMIT
06:33:00.281715 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
06:33:00.325041 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:33:00.325163 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select '"'||column_name||'"::'||
       case when replace(udt_name, '_','') = 'bit' then 'int'
            when replace(udt_name, '_','') like 'int8%' then 'bigint'
            when replace(udt_name, '_','') like 'int4%' then 'int'
            when replace(udt_name, '_','') like 'int%' then 'smallint'
            when replace(udt_name, '_','') like 'bool%' then 'int'
            when replace(udt_name, '_','') like 'float%' then 'numeric'
            when replace(udt_name, '_','') like 'float%' then 'numeric'
            when replace(udt_name, '_','') like 'byte%' then 'text'
            when replace(udt_name, '_','') like 'varchar%' then 'text'
            when replace(udt_name, '_','') like 'timestamp%' then 'timestamp'
            else replace(udt_name, '_','') end ||
       ' as "'||column_name||'"' select_text
from information_schema.columns 
where table_schema||'.'||table_name = 'testsatmap.crm'
order by ordinal_position ;

  
06:33:00.338710 [debug] [MainThread]: SQL status: SELECT 4 in 0.01 seconds
06:33:00.339541 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:33:00.339614 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 as
select "data_date"::date as "data_date", 
       "customer_id"::text as "customer_id", 
       "customer_cat_attrib"::text as "customer_cat_attrib", 
       "customer_num_attrib"::numeric as "customer_num_attrib"
       from testsatmap.crm;

  
06:33:00.342203 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:33:00.342719 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:33:00.342785 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:33:00.343010 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:33:00.343488 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:33:00.343552 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_exp_type_0000000000 as select data_date exp from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 limit 1
  
06:33:00.344452 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:33:00.344922 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:33:00.344984 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select replace(udt_name, '_','') dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type_0000000000' and column_name = 'exp'
  
06:33:00.348301 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
06:33:00.348793 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:33:00.348856 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:33:00.349963 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:33:00.350428 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:33:00.350490 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:33:00.350744 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:33:00.351216 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:33:00.351282 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_exp_type_0000000000 as select trim(customer_id) exp from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 limit 1
  
06:33:00.352479 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:33:00.353077 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:33:00.353144 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select replace(udt_name, '_','') dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type_0000000000' and column_name = 'exp'
  
06:33:00.356491 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
06:33:00.357005 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:33:00.357071 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:33:00.357861 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:33:00.358349 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:33:00.358414 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:33:00.358623 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:33:00.359101 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:33:00.359169 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_exp_type_0000000000 as select customer_num_attrib exp from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 limit 1
  
06:33:00.360077 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:33:00.360559 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:33:00.360625 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select replace(udt_name, '_','') dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type_0000000000' and column_name = 'exp'
  
06:33:00.363815 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
06:33:00.364362 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:33:00.364434 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:33:00.365110 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:33:00.365638 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:33:00.365708 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:33:00.365919 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:33:00.366435 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:33:00.366505 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_exp_type_0000000000 as select customer_cat_attrib exp from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 limit 1
  
06:33:00.367410 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:33:00.367926 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:33:00.367995 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select replace(udt_name, '_','') dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type_0000000000' and column_name = 'exp'
  
06:33:00.371113 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
06:33:00.371656 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:33:00.371728 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:33:00.372649 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:33:00.373169 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:33:00.373240 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 as
select  (data_date)::date as date_data, 
        (trim(customer_id))::text as customer_id, 
        (customer_num_attrib)::numeric as num_attrib, 
        (customer_cat_attrib)::text as cat_attrib
        from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000;

  
06:33:00.374344 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:33:00.375485 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:33:00.375557 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 cascade;
drop view if exists autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 cascade;

  
06:33:00.376420 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:33:00.376895 [info ] [MainThread]: 



create or replace view autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 as
select "data_date"::date as "data_date", 
       "customer_id"::text as "customer_id", 
       "customer_cat_attrib"::text as "customer_cat_attrib", 
       "customer_num_attrib"::numeric as "customer_num_attrib"
       from testsatmap.crm;


create or replace view autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 as
select  (data_date)::date as date_data, 
        (trim(customer_id))::text as customer_id, 
        (customer_num_attrib)::numeric as num_attrib, 
        (customer_cat_attrib)::text as cat_attrib
        from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000;


drop table if exists autopie_ebpdemo.tmp_staging_fact_0000000000;
create table autopie_ebpdemo.tmp_staging_fact_0000000000 as
(
    with expression_extract_1 as
    (
        select * from autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000
    ),
    expression_extract_2 as
    (
        select * from expression_extract_1
    ),
    filter__3 as
    (
        select /* filtering irrelevant records out */ *
        from expression_extract_2
        where 1=1
        and customer_id is not null
    ),
    incremental_extract__4 as
    (
        select /* retrieving incremental data - by date range only */ *
        from filter__3
        where date_data >= to_date('2020-01-01', 'YYYY-MM-DD')
          and date_data  < to_date('2021-01-01', 'YYYY-MM-DD')
    ),
    deduplication__5 as
    (
        select /* deduplicate by strategy */
               customer_id, date_data
               , max(num_attrib) as num_attrib
               , max(cat_attrib) as cat_attrib
        from incremental_extract__4
        group by customer_id, date_data 
    ),
    coarsening_6 as
    (
        select * from deduplication__5
    )
    select  t.*,
            1 autopie_run_id
    from coarsening_6 t
);

drop view if exists autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 cascade;
drop view if exists autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 cascade;


-- check if not exists already, this should run once
do $$                  
begin
if not exists
( 
    select 1 from information_schema.tables 
    where table_schema||'.'|| table_name = 'autopie_ebpdemo.obj_fact_crm'
)
then
    create table autopie_ebpdemo.obj_fact_crm as (select * from autopie_ebpdemo.tmp_staging_fact_0000000000 where 1=0);
    alter  table autopie_ebpdemo.obj_fact_crm add column row_id bigserial not null;
    alter  table autopie_ebpdemo.obj_fact_crm add primary key (customer_id, date_data);
    --
    create index ixrid_obj_fact_crm on autopie_ebpdemo.obj_fact_crm(row_id);
end if;
end
$$;

-- upsert staging additions into the permanent fact object
delete from autopie_ebpdemo.obj_fact_crm where (customer_id, date_data) in (select customer_id, date_data from autopie_ebpdemo.tmp_staging_fact_0000000000);
insert into autopie_ebpdemo.obj_fact_crm select * from autopie_ebpdemo.tmp_staging_fact_0000000000;
drop table autopie_ebpdemo.tmp_staging_fact_0000000000;


06:33:00.377263 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:33:00.377332 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    



create or replace view autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 as
select "data_date"::date as "data_date", 
       "customer_id"::text as "customer_id", 
       "customer_cat_attrib"::text as "customer_cat_attrib", 
       "customer_num_attrib"::numeric as "customer_num_attrib"
       from testsatmap.crm;


create or replace view autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 as
select  (data_date)::date as date_data, 
        (trim(customer_id))::text as customer_id, 
        (customer_num_attrib)::numeric as num_attrib, 
        (customer_cat_attrib)::text as cat_attrib
        from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000;


drop table if exists autopie_ebpdemo.tmp_staging_fact_0000000000;
create table autopie_ebpdemo.tmp_staging_fact_0000000000 as
(
    with expression_extract_1 as
    (
        select * from autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000
    ),
    expression_extract_2 as
    (
        select * from expression_extract_1
    ),
    filter__3 as
    (
        select /* filtering irrelevant records out */ *
        from expression_extract_2
        where 1=1
        and customer_id is not null
    ),
    incremental_extract__4 as
    (
        select /* retrieving incremental data - by date range only */ *
        from filter__3
        where date_data >= to_date('2020-01-01', 'YYYY-MM-DD')
          and date_data  < to_date('2021-01-01', 'YYYY-MM-DD')
    ),
    deduplication__5 as
    (
        select /* deduplicate by strategy */
               customer_id, date_data
               , max(num_attrib) as num_attrib
               , max(cat_attrib) as cat_attrib
        from incremental_extract__4
        group by customer_id, date_data 
    ),
    coarsening_6 as
    (
        select * from deduplication__5
    )
    select  t.*,
            1 autopie_run_id
    from coarsening_6 t
);

drop view if exists autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 cascade;
drop view if exists autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 cascade;


-- check if not exists already, this should run once
do $$                  
begin
if not exists
( 
    select 1 from information_schema.tables 
    where table_schema||'.'|| table_name = 'autopie_ebpdemo.obj_fact_crm'
)
then
    create table autopie_ebpdemo.obj_fact_crm as (select * from autopie_ebpdemo.tmp_staging_fact_0000000000 where 1=0);
    alter  table autopie_ebpdemo.obj_fact_crm add column row_id bigserial not null;
    alter  table autopie_ebpdemo.obj_fact_crm add primary key (customer_id, date_data);
    --
    create index ixrid_obj_fact_crm on autopie_ebpdemo.obj_fact_crm(row_id);
end if;
end
$$;

-- upsert staging additions into the permanent fact object
delete from autopie_ebpdemo.obj_fact_crm where (customer_id, date_data) in (select customer_id, date_data from autopie_ebpdemo.tmp_staging_fact_0000000000);
insert into autopie_ebpdemo.obj_fact_crm select * from autopie_ebpdemo.tmp_staging_fact_0000000000;
drop table autopie_ebpdemo.tmp_staging_fact_0000000000;


  
06:33:00.402410 [debug] [MainThread]: SQL status: DROP TABLE in 0.03 seconds
06:33:00.403136 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:33:00.403229 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    
select row_number() over (order by autopie_run_id desc) run_sequence, count(*) count_records 
  from autopie_ebpdemo.obj_fact_crm
group by autopie_run_id
order by 1 
limit 5;

  
06:33:00.403838 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
06:33:00.404455 [debug] [MainThread]: On macro_run_recipe: Close
06:33:00.405142 [debug] [MainThread]: Connection 'macro_run_recipe' was properly closed.


============================== 2022-02-20 06:33:01.485434 | 5d2da309-d14b-48d0-9521-1c45f4623865 ==============================
06:33:01.485434 [info ] [MainThread]: Running with dbt=1.0.1
06:33:01.485863 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/hassanzaheer/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, macro='run_recipe', args='{\n    "recipe_type" : "collect_fact",\n    "target_fact" : {\n        "id": "dispositions", \n        "entity_and_dims": "agent_id",\n        "date":"time_disposition_made"\n    },\n    "ingredients": {\n        "expression_extract": {  \n            "source_raw": "testsatmap.calldispositions",\n            "expression_list": [\n                {"expression": "to_timestamp(disposition_epoch)", "alias": "time_disposition_made"},\n                {"expression": "trim(customer_id)",  "alias": "customer_id"},             \n                {"expression": "lower(trim(agent_id))",  "alias": "agent_id"},\n                {"expression": "lower(trim(disp_code))",  "alias": "cat_disposition"}\n            ]\n        },\n        "filter_conjunctions": [\n            "agent_id is not null",\n            "customer_id is not null",\n            "cat_disposition in (\'k\', \'m\', \'a\')"\n        ],\n        "incremental_update_on": "time_disposition_made",\n        "deduplication": {\n            "grouping_key": "agent_id, cat_disposition, time_disposition_made",\n            "preference": "arbitrary"\n        },\n        "coarsening": {\n            "entity_and_dims": "agent_id",\n            "date_expression":"time_disposition_made",\n            "aggregations": [\n                {"expression": "max(customer_id)", "alias": "customer_id"},\n                {"expression": "sum(case when cat_disposition = \'k\' then 1 else 0 end)", "alias": "flg_k_disp_made"},\n                {"expression": "sum(case when cat_disposition = \'m\' then 1 else 0 end)", "alias": "flg_m_disp_made"},\n                {"expression": "sum(case when cat_disposition = \'a\' then 1 else 0 end)", "alias": "flg_a_disp_made"}\n            ]\n        }\n    }\n}', defer=None, state=None, cls=<class 'dbt.task.run_operation.RunOperationTask'>, which='run-operation', rpc_method='run-operation')
06:33:01.486001 [debug] [MainThread]: Tracking: do not track
06:33:01.506590 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 1 files added, 1 files changed.
06:33:01.506795 [debug] [MainThread]: Partial parsing: added file: demo_autopie://models/demo_ebp_flow/prepared_scripts/prepared_fact_dispositions.sql
06:33:01.506935 [debug] [MainThread]: Partial parsing: updated file: demo_autopie://models/demo_ebp_flow/prepared_scripts/prepared_fact_crm.sql
06:33:01.512467 [debug] [MainThread]: 1699: static parser successfully parsed demo_ebp_flow/prepared_scripts/prepared_fact_dispositions.sql
06:33:01.518344 [debug] [MainThread]: 1699: static parser successfully parsed demo_ebp_flow/prepared_scripts/prepared_fact_crm.sql
06:33:01.525261 [debug] [MainThread]: Acquiring new postgres connection "macro_run_recipe"
06:33:01.525407 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:33:01.525482 [debug] [MainThread]: On macro_run_recipe: BEGIN
06:33:01.525550 [debug] [MainThread]: Opening a new connection, currently in state init
06:33:01.531414 [debug] [MainThread]: SQL status: BEGIN in 0.01 seconds
06:33:01.531519 [debug] [MainThread]: On macro_run_recipe: COMMIT
06:33:01.531582 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:33:01.531637 [debug] [MainThread]: On macro_run_recipe: COMMIT
06:33:01.531818 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
06:33:01.575179 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:33:01.575301 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select '"'||column_name||'"::'||
       case when replace(udt_name, '_','') = 'bit' then 'int'
            when replace(udt_name, '_','') like 'int8%' then 'bigint'
            when replace(udt_name, '_','') like 'int4%' then 'int'
            when replace(udt_name, '_','') like 'int%' then 'smallint'
            when replace(udt_name, '_','') like 'bool%' then 'int'
            when replace(udt_name, '_','') like 'float%' then 'numeric'
            when replace(udt_name, '_','') like 'float%' then 'numeric'
            when replace(udt_name, '_','') like 'byte%' then 'text'
            when replace(udt_name, '_','') like 'varchar%' then 'text'
            when replace(udt_name, '_','') like 'timestamp%' then 'timestamp'
            else replace(udt_name, '_','') end ||
       ' as "'||column_name||'"' select_text
from information_schema.columns 
where table_schema||'.'||table_name = 'testsatmap.calldispositions'
order by ordinal_position ;

  
06:33:01.590760 [debug] [MainThread]: SQL status: SELECT 4 in 0.02 seconds
06:33:01.591651 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:33:01.591729 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 as
select "disposition_epoch"::bigint as "disposition_epoch", 
       "customer_id"::text as "customer_id", 
       "agent_id"::text as "agent_id", 
       "disp_code"::text as "disp_code"
       from testsatmap.calldispositions;

  
06:33:01.596308 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:33:01.596827 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:33:01.596894 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:33:01.597136 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:33:01.597618 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:33:01.597686 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_exp_type_0000000000 as select to_timestamp(disposition_epoch) exp from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 limit 1
  
06:33:01.598714 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:33:01.599226 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:33:01.599293 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select replace(udt_name, '_','') dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type_0000000000' and column_name = 'exp'
  
06:33:01.602711 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
06:33:01.603270 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:33:01.603341 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:33:01.604461 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:33:01.604965 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:33:01.605035 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:33:01.605234 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:33:01.605730 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:33:01.605797 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_exp_type_0000000000 as select trim(customer_id) exp from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 limit 1
  
06:33:01.606942 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:33:01.607570 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:33:01.607637 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select replace(udt_name, '_','') dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type_0000000000' and column_name = 'exp'
  
06:33:01.610825 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
06:33:01.611381 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:33:01.611453 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:33:01.612147 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:33:01.612679 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:33:01.612751 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:33:01.612960 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:33:01.613484 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:33:01.613555 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_exp_type_0000000000 as select lower(trim(agent_id)) exp from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 limit 1
  
06:33:01.614766 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:33:01.615288 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:33:01.615360 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select replace(udt_name, '_','') dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type_0000000000' and column_name = 'exp'
  
06:33:01.618821 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
06:33:01.619372 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:33:01.619443 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:33:01.620139 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:33:01.620662 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:33:01.620733 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:33:01.620937 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:33:01.621456 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:33:01.621527 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_exp_type_0000000000 as select lower(trim(disp_code)) exp from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 limit 1
  
06:33:01.622401 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:33:01.622924 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:33:01.622997 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select replace(udt_name, '_','') dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type_0000000000' and column_name = 'exp'
  
06:33:01.626363 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
06:33:01.626904 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:33:01.626975 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:33:01.627689 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:33:01.628213 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:33:01.628282 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 as
select  (to_timestamp(disposition_epoch))::timestamptz as time_disposition_made, 
        (trim(customer_id))::text as customer_id, 
        (lower(trim(agent_id)))::text as agent_id, 
        (lower(trim(disp_code)))::text as cat_disposition
        from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000;

  
06:33:01.629736 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:33:01.630861 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:33:01.630942 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 cascade;
drop view if exists autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 cascade;

  
06:33:01.632134 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:33:01.632629 [info ] [MainThread]: 



create or replace view autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 as
select "disposition_epoch"::bigint as "disposition_epoch", 
       "customer_id"::text as "customer_id", 
       "agent_id"::text as "agent_id", 
       "disp_code"::text as "disp_code"
       from testsatmap.calldispositions;


create or replace view autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 as
select  (to_timestamp(disposition_epoch))::timestamptz as time_disposition_made, 
        (trim(customer_id))::text as customer_id, 
        (lower(trim(agent_id)))::text as agent_id, 
        (lower(trim(disp_code)))::text as cat_disposition
        from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000;


drop table if exists autopie_ebpdemo.tmp_staging_fact_0000000000;
create table autopie_ebpdemo.tmp_staging_fact_0000000000 as
(
    with expression_extract_1 as
    (
        select * from autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000
    ),
    expression_extract_2 as
    (
        select * from expression_extract_1
    ),
    filter__3 as
    (
        select /* filtering irrelevant records out */ *
        from expression_extract_2
        where 1=1
        and agent_id is not null
        and customer_id is not null
        and cat_disposition in ('k', 'm', 'a')
    ),
    incremental_extract__4 as
    (
        select /* retrieving incremental data - by date range only */ *
        from filter__3
        where time_disposition_made >= to_date('2020-01-01', 'YYYY-MM-DD')
          and time_disposition_made  < to_date('2021-01-01', 'YYYY-MM-DD')
    ),
    deduplication__5 as
    (
        select /* deduplicate by strategy */
               agent_id, cat_disposition, time_disposition_made
               , max(customer_id) as customer_id
        from incremental_extract__4
        group by agent_id, cat_disposition, time_disposition_made 
    ),
    coarsening_6 as
    (
        select /* flatten all dimensions, fit into EAVT format */
              agent_id
              , time_disposition_made
              
              , max(customer_id) as customer_id
              , sum(case when cat_disposition = 'k' then 1 else 0 end) as flg_k_disp_made
              , sum(case when cat_disposition = 'm' then 1 else 0 end) as flg_m_disp_made
              , sum(case when cat_disposition = 'a' then 1 else 0 end) as flg_a_disp_made
              from deduplication__5
        group by agent_id, time_disposition_made
    )
    select  t.*,
            1 autopie_run_id
    from coarsening_6 t
);

drop view if exists autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 cascade;
drop view if exists autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 cascade;


-- check if not exists already, this should run once
do $$                  
begin
if not exists
( 
    select 1 from information_schema.tables 
    where table_schema||'.'|| table_name = 'autopie_ebpdemo.obj_fact_dispositions'
)
then
    create table autopie_ebpdemo.obj_fact_dispositions as (select * from autopie_ebpdemo.tmp_staging_fact_0000000000 where 1=0);
    alter  table autopie_ebpdemo.obj_fact_dispositions add column row_id bigserial not null;
    alter  table autopie_ebpdemo.obj_fact_dispositions add primary key (agent_id, time_disposition_made);
    --
    create index ixrid_obj_fact_dispositions on autopie_ebpdemo.obj_fact_dispositions(row_id);
end if;
end
$$;

-- upsert staging additions into the permanent fact object
delete from autopie_ebpdemo.obj_fact_dispositions where (agent_id, time_disposition_made) in (select agent_id, time_disposition_made from autopie_ebpdemo.tmp_staging_fact_0000000000);
insert into autopie_ebpdemo.obj_fact_dispositions select * from autopie_ebpdemo.tmp_staging_fact_0000000000;
drop table autopie_ebpdemo.tmp_staging_fact_0000000000;


06:33:01.633030 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:33:01.633103 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    



create or replace view autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 as
select "disposition_epoch"::bigint as "disposition_epoch", 
       "customer_id"::text as "customer_id", 
       "agent_id"::text as "agent_id", 
       "disp_code"::text as "disp_code"
       from testsatmap.calldispositions;


create or replace view autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 as
select  (to_timestamp(disposition_epoch))::timestamptz as time_disposition_made, 
        (trim(customer_id))::text as customer_id, 
        (lower(trim(agent_id)))::text as agent_id, 
        (lower(trim(disp_code)))::text as cat_disposition
        from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000;


drop table if exists autopie_ebpdemo.tmp_staging_fact_0000000000;
create table autopie_ebpdemo.tmp_staging_fact_0000000000 as
(
    with expression_extract_1 as
    (
        select * from autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000
    ),
    expression_extract_2 as
    (
        select * from expression_extract_1
    ),
    filter__3 as
    (
        select /* filtering irrelevant records out */ *
        from expression_extract_2
        where 1=1
        and agent_id is not null
        and customer_id is not null
        and cat_disposition in ('k', 'm', 'a')
    ),
    incremental_extract__4 as
    (
        select /* retrieving incremental data - by date range only */ *
        from filter__3
        where time_disposition_made >= to_date('2020-01-01', 'YYYY-MM-DD')
          and time_disposition_made  < to_date('2021-01-01', 'YYYY-MM-DD')
    ),
    deduplication__5 as
    (
        select /* deduplicate by strategy */
               agent_id, cat_disposition, time_disposition_made
               , max(customer_id) as customer_id
        from incremental_extract__4
        group by agent_id, cat_disposition, time_disposition_made 
    ),
    coarsening_6 as
    (
        select /* flatten all dimensions, fit into EAVT format */
              agent_id
              , time_disposition_made
              
              , max(customer_id) as customer_id
              , sum(case when cat_disposition = 'k' then 1 else 0 end) as flg_k_disp_made
              , sum(case when cat_disposition = 'm' then 1 else 0 end) as flg_m_disp_made
              , sum(case when cat_disposition = 'a' then 1 else 0 end) as flg_a_disp_made
              from deduplication__5
        group by agent_id, time_disposition_made
    )
    select  t.*,
            1 autopie_run_id
    from coarsening_6 t
);

drop view if exists autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 cascade;
drop view if exists autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 cascade;


-- check if not exists already, this should run once
do $$                  
begin
if not exists
( 
    select 1 from information_schema.tables 
    where table_schema||'.'|| table_name = 'autopie_ebpdemo.obj_fact_dispositions'
)
then
    create table autopie_ebpdemo.obj_fact_dispositions as (select * from autopie_ebpdemo.tmp_staging_fact_0000000000 where 1=0);
    alter  table autopie_ebpdemo.obj_fact_dispositions add column row_id bigserial not null;
    alter  table autopie_ebpdemo.obj_fact_dispositions add primary key (agent_id, time_disposition_made);
    --
    create index ixrid_obj_fact_dispositions on autopie_ebpdemo.obj_fact_dispositions(row_id);
end if;
end
$$;

-- upsert staging additions into the permanent fact object
delete from autopie_ebpdemo.obj_fact_dispositions where (agent_id, time_disposition_made) in (select agent_id, time_disposition_made from autopie_ebpdemo.tmp_staging_fact_0000000000);
insert into autopie_ebpdemo.obj_fact_dispositions select * from autopie_ebpdemo.tmp_staging_fact_0000000000;
drop table autopie_ebpdemo.tmp_staging_fact_0000000000;


  
06:33:01.659464 [debug] [MainThread]: SQL status: DROP TABLE in 0.03 seconds
06:33:01.660220 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:33:01.660316 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    
select row_number() over (order by autopie_run_id desc) run_sequence, count(*) count_records 
  from autopie_ebpdemo.obj_fact_dispositions
group by autopie_run_id
order by 1 
limit 5;

  
06:33:01.660931 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
06:33:01.661551 [debug] [MainThread]: On macro_run_recipe: Close
06:33:01.662335 [debug] [MainThread]: Connection 'macro_run_recipe' was properly closed.


============================== 2022-02-20 06:34:10.309691 | a0e7e392-559e-4583-9598-524cde09b6e4 ==============================
06:34:10.309691 [info ] [MainThread]: Running with dbt=1.0.1
06:34:10.310053 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/hassanzaheer/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, macro='run_recipe', args='{\n    "recipe_type" : "collect_fact",\n    "target_fact" : {\n        "id": "calls", \n        "entity_and_dims": "call_id",\n        "date":"time_call_end"\n    },\n    "ingredients": {\n        "expression_extract": {  \n            "source_raw": "testsatmap.calltable",\n            "expression_list": [\n                {"expression": "call_id", "alias": "call_id"},\n                {"expression": "to_timestamp(call_start_epoch)", "alias": "time_call_start"},\n                {"expression": "to_timestamp(call_start_epoch + call_duration)", "alias": "time_call_end"},\n                {"expression": "call_duration", "alias": "num_duration_seconds"},\n                {"expression": "trim(customer_id)",  "alias": "customer_id"},\n                {"expression": "lower(trim(agent_id))",  "alias": "agent_id"}\n            ]\n        },\n        "expression_extract_outer": {  \n            "expression_list": [\n                {"expression": "round(num_duration_seconds/60,2)", "alias": "num_duration_minutes"}\n            ]\n        },\n        "filter_conjunctions": [\n            "agent_id is not null",\n            "customer_id is not null",\n            "num_duration_seconds > 10"\n        ],\n        "incremental_update_on": "time_call_start",\n        "deduplication": {\n            "grouping_key": "call_id",\n            "preference": "arbitrary"\n        }\n    }\n}', defer=None, state=None, cls=<class 'dbt.task.run_operation.RunOperationTask'>, which='run-operation', rpc_method='run-operation')
06:34:10.310170 [debug] [MainThread]: Tracking: do not track
06:34:10.331831 [debug] [MainThread]: Partial parsing enabled: 4 files deleted, 1 files added, 0 files changed.
06:34:10.332043 [debug] [MainThread]: Partial parsing: added file: demo_autopie://models/demo_ebp_flow/prepared_scripts/phase1_fact_calls.sql
06:34:10.332117 [debug] [MainThread]: Partial parsing: deleted file: demo_autopie://models/demo_ebp_flow/prepared_scripts/prepared_fact_calls.sql
06:34:10.332178 [debug] [MainThread]: Partial parsing: deleted file: demo_autopie://models/demo_ebp_flow/prepared_scripts/prepared_fact_dispositions.sql
06:34:10.332235 [debug] [MainThread]: Partial parsing: deleted file: demo_autopie://models/demo_ebp_flow/prepared_scripts/prepared_fact_outcomes.sql
06:34:10.332289 [debug] [MainThread]: Partial parsing: deleted file: demo_autopie://models/demo_ebp_flow/prepared_scripts/prepared_fact_crm.sql
06:34:10.337728 [debug] [MainThread]: 1699: static parser successfully parsed demo_ebp_flow/prepared_scripts/phase1_fact_calls.sql
06:34:10.348453 [debug] [MainThread]: Acquiring new postgres connection "macro_run_recipe"
06:34:10.348570 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:34:10.348639 [debug] [MainThread]: On macro_run_recipe: BEGIN
06:34:10.348699 [debug] [MainThread]: Opening a new connection, currently in state init
06:34:10.381902 [debug] [MainThread]: SQL status: BEGIN in 0.03 seconds
06:34:10.382057 [debug] [MainThread]: On macro_run_recipe: COMMIT
06:34:10.382138 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:34:10.382208 [debug] [MainThread]: On macro_run_recipe: COMMIT
06:34:10.382421 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
06:34:10.428621 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:34:10.428780 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select '"'||column_name||'"::'||
       case when replace(udt_name, '_','') = 'bit' then 'int'
            when replace(udt_name, '_','') like 'int8%' then 'bigint'
            when replace(udt_name, '_','') like 'int4%' then 'int'
            when replace(udt_name, '_','') like 'int%' then 'smallint'
            when replace(udt_name, '_','') like 'bool%' then 'int'
            when replace(udt_name, '_','') like 'float%' then 'numeric'
            when replace(udt_name, '_','') like 'float%' then 'numeric'
            when replace(udt_name, '_','') like 'byte%' then 'text'
            when replace(udt_name, '_','') like 'varchar%' then 'text'
            when replace(udt_name, '_','') like 'timestamp%' then 'timestamp'
            else replace(udt_name, '_','') end ||
       ' as "'||column_name||'"' select_text
from information_schema.columns 
where table_schema||'.'||table_name = 'testsatmap.calltable'
order by ordinal_position ;

  
06:34:10.443056 [debug] [MainThread]: SQL status: SELECT 5 in 0.01 seconds
06:34:10.443918 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:34:10.443998 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 as
select "call_id"::text as "call_id", 
       "call_start_epoch"::bigint as "call_start_epoch", 
       "call_duration"::int as "call_duration", 
       "customer_id"::text as "customer_id", 
       "agent_id"::text as "agent_id"
       from testsatmap.calltable;

  
06:34:10.447430 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:34:10.447956 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:34:10.448029 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:34:10.448255 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:34:10.448735 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:34:10.448800 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_exp_type_0000000000 as select call_id exp from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 limit 1
  
06:34:10.449732 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:34:10.450209 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:34:10.450272 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select replace(udt_name, '_','') dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type_0000000000' and column_name = 'exp'
  
06:34:10.454226 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
06:34:10.454774 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:34:10.454842 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:34:10.455991 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:34:10.456484 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:34:10.456553 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:34:10.456751 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:34:10.457237 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:34:10.457303 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_exp_type_0000000000 as select to_timestamp(call_start_epoch) exp from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 limit 1
  
06:34:10.458248 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:34:10.458855 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:34:10.458924 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select replace(udt_name, '_','') dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type_0000000000' and column_name = 'exp'
  
06:34:10.462335 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
06:34:10.462843 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:34:10.462909 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:34:10.463608 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:34:10.464100 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:34:10.464167 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:34:10.464373 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:34:10.464852 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:34:10.464918 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_exp_type_0000000000 as select to_timestamp(call_start_epoch + call_duration) exp from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 limit 1
  
06:34:10.466113 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:34:10.466600 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:34:10.466666 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select replace(udt_name, '_','') dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type_0000000000' and column_name = 'exp'
  
06:34:10.470028 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
06:34:10.470571 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:34:10.470642 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:34:10.471403 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:34:10.471950 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:34:10.472021 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:34:10.472221 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:34:10.472756 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:34:10.472828 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_exp_type_0000000000 as select call_duration exp from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 limit 1
  
06:34:10.473705 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:34:10.474226 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:34:10.474302 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select replace(udt_name, '_','') dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type_0000000000' and column_name = 'exp'
  
06:34:10.477542 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
06:34:10.478095 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:34:10.478166 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:34:10.478832 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:34:10.479358 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:34:10.479428 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:34:10.479739 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:34:10.480270 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:34:10.480341 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_exp_type_0000000000 as select trim(customer_id) exp from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 limit 1
  
06:34:10.481764 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:34:10.482286 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:34:10.482357 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select replace(udt_name, '_','') dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type_0000000000' and column_name = 'exp'
  
06:34:10.486720 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
06:34:10.487267 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:34:10.487338 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:34:10.488205 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:34:10.488727 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:34:10.488798 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:34:10.489038 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:34:10.489555 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:34:10.489626 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_exp_type_0000000000 as select lower(trim(agent_id)) exp from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 limit 1
  
06:34:10.490825 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:34:10.491347 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:34:10.491440 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select replace(udt_name, '_','') dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type_0000000000' and column_name = 'exp'
  
06:34:10.495563 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
06:34:10.496110 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:34:10.496182 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:34:10.496998 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:34:10.497566 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:34:10.497641 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 as
select  (call_id)::text as call_id, 
        (to_timestamp(call_start_epoch))::timestamptz as time_call_start, 
        (to_timestamp(call_start_epoch + call_duration))::timestamptz as time_call_end, 
        (call_duration)::int4 as num_duration_seconds, 
        (trim(customer_id))::text as customer_id, 
        (lower(trim(agent_id)))::text as agent_id
        from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000;

  
06:34:10.499150 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:34:10.499721 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:34:10.499796 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:34:10.500082 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:34:10.500643 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:34:10.500724 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_exp_type_0000000000 as select round(num_duration_seconds/60,2) exp from autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 limit 1
  
06:34:10.502379 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:34:10.502952 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:34:10.503044 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select replace(udt_name, '_','') dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type_0000000000' and column_name = 'exp'
  
06:34:10.507808 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
06:34:10.508570 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:34:10.508652 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:34:10.509614 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:34:10.511257 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:34:10.511337 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 cascade;
drop view if exists autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 cascade;

  
06:34:10.512498 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:34:10.513034 [info ] [MainThread]: 



create or replace view autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 as
select "call_id"::text as "call_id", 
       "call_start_epoch"::bigint as "call_start_epoch", 
       "call_duration"::int as "call_duration", 
       "customer_id"::text as "customer_id", 
       "agent_id"::text as "agent_id"
       from testsatmap.calltable;


create or replace view autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 as
select  (call_id)::text as call_id, 
        (to_timestamp(call_start_epoch))::timestamptz as time_call_start, 
        (to_timestamp(call_start_epoch + call_duration))::timestamptz as time_call_end, 
        (call_duration)::int4 as num_duration_seconds, 
        (trim(customer_id))::text as customer_id, 
        (lower(trim(agent_id)))::text as agent_id
        from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000;


drop table if exists autopie_ebpdemo.tmp_staging_fact_0000000000;
create table autopie_ebpdemo.tmp_staging_fact_0000000000 as
(
    with expression_extract_1 as
    (
        select * from autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000
    ),
    expression_extract_2 as
    (
        select  t.*,
                (round(num_duration_seconds/60,2))::numeric as num_duration_minutes
                from expression_extract_1 t
    ),
    filter__3 as
    (
        select /* filtering irrelevant records out */ *
        from expression_extract_2
        where 1=1
        and agent_id is not null
        and customer_id is not null
        and num_duration_seconds > 10
    ),
    incremental_extract__4 as
    (
        select /* retrieving incremental data - by date range only */ *
        from filter__3
        where time_call_start >= to_date('2020-01-01', 'YYYY-MM-DD')
          and time_call_start  < to_date('2021-01-01', 'YYYY-MM-DD')
    ),
    deduplication__5 as
    (
        select /* deduplicate by strategy */
               call_id
               , max(time_call_start) as time_call_start
               , max(time_call_end) as time_call_end
               , max(num_duration_seconds) as num_duration_seconds
               , max(customer_id) as customer_id
               , max(agent_id) as agent_id
               , max(num_duration_minutes) as num_duration_minutes
        from incremental_extract__4
        group by call_id 
    ),
    coarsening_6 as
    (
        select * from deduplication__5
    )
    select  t.*,
            1 autopie_run_id
    from coarsening_6 t
);

drop view if exists autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 cascade;
drop view if exists autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 cascade;


-- check if not exists already, this should run once
do $$                  
begin
if not exists
( 
    select 1 from information_schema.tables 
    where table_schema||'.'|| table_name = 'autopie_ebpdemo.obj_fact_calls'
)
then
    create table autopie_ebpdemo.obj_fact_calls as (select * from autopie_ebpdemo.tmp_staging_fact_0000000000 where 1=0);
    alter  table autopie_ebpdemo.obj_fact_calls add column row_id bigserial not null;
    alter  table autopie_ebpdemo.obj_fact_calls add primary key (call_id, time_call_end);
    --
    create index ixrid_obj_fact_calls on autopie_ebpdemo.obj_fact_calls(row_id);
end if;
end
$$;

-- upsert staging additions into the permanent fact object
delete from autopie_ebpdemo.obj_fact_calls where (call_id, time_call_end) in (select call_id, time_call_end from autopie_ebpdemo.tmp_staging_fact_0000000000);
insert into autopie_ebpdemo.obj_fact_calls select * from autopie_ebpdemo.tmp_staging_fact_0000000000;
drop table autopie_ebpdemo.tmp_staging_fact_0000000000;


06:34:10.513460 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:34:10.513533 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    



create or replace view autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 as
select "call_id"::text as "call_id", 
       "call_start_epoch"::bigint as "call_start_epoch", 
       "call_duration"::int as "call_duration", 
       "customer_id"::text as "customer_id", 
       "agent_id"::text as "agent_id"
       from testsatmap.calltable;


create or replace view autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 as
select  (call_id)::text as call_id, 
        (to_timestamp(call_start_epoch))::timestamptz as time_call_start, 
        (to_timestamp(call_start_epoch + call_duration))::timestamptz as time_call_end, 
        (call_duration)::int4 as num_duration_seconds, 
        (trim(customer_id))::text as customer_id, 
        (lower(trim(agent_id)))::text as agent_id
        from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000;


drop table if exists autopie_ebpdemo.tmp_staging_fact_0000000000;
create table autopie_ebpdemo.tmp_staging_fact_0000000000 as
(
    with expression_extract_1 as
    (
        select * from autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000
    ),
    expression_extract_2 as
    (
        select  t.*,
                (round(num_duration_seconds/60,2))::numeric as num_duration_minutes
                from expression_extract_1 t
    ),
    filter__3 as
    (
        select /* filtering irrelevant records out */ *
        from expression_extract_2
        where 1=1
        and agent_id is not null
        and customer_id is not null
        and num_duration_seconds > 10
    ),
    incremental_extract__4 as
    (
        select /* retrieving incremental data - by date range only */ *
        from filter__3
        where time_call_start >= to_date('2020-01-01', 'YYYY-MM-DD')
          and time_call_start  < to_date('2021-01-01', 'YYYY-MM-DD')
    ),
    deduplication__5 as
    (
        select /* deduplicate by strategy */
               call_id
               , max(time_call_start) as time_call_start
               , max(time_call_end) as time_call_end
               , max(num_duration_seconds) as num_duration_seconds
               , max(customer_id) as customer_id
               , max(agent_id) as agent_id
               , max(num_duration_minutes) as num_duration_minutes
        from incremental_extract__4
        group by call_id 
    ),
    coarsening_6 as
    (
        select * from deduplication__5
    )
    select  t.*,
            1 autopie_run_id
    from coarsening_6 t
);

drop view if exists autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 cascade;
drop view if exists autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 cascade;


-- check if not exists already, this should run once
do $$                  
begin
if not exists
( 
    select 1 from information_schema.tables 
    where table_schema||'.'|| table_name = 'autopie_ebpdemo.obj_fact_calls'
)
then
    create table autopie_ebpdemo.obj_fact_calls as (select * from autopie_ebpdemo.tmp_staging_fact_0000000000 where 1=0);
    alter  table autopie_ebpdemo.obj_fact_calls add column row_id bigserial not null;
    alter  table autopie_ebpdemo.obj_fact_calls add primary key (call_id, time_call_end);
    --
    create index ixrid_obj_fact_calls on autopie_ebpdemo.obj_fact_calls(row_id);
end if;
end
$$;

-- upsert staging additions into the permanent fact object
delete from autopie_ebpdemo.obj_fact_calls where (call_id, time_call_end) in (select call_id, time_call_end from autopie_ebpdemo.tmp_staging_fact_0000000000);
insert into autopie_ebpdemo.obj_fact_calls select * from autopie_ebpdemo.tmp_staging_fact_0000000000;
drop table autopie_ebpdemo.tmp_staging_fact_0000000000;


  
06:34:10.543005 [debug] [MainThread]: SQL status: DROP TABLE in 0.03 seconds
06:34:10.543779 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:34:10.543873 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    
select row_number() over (order by autopie_run_id desc) run_sequence, count(*) count_records 
  from autopie_ebpdemo.obj_fact_calls
group by autopie_run_id
order by 1 
limit 5;

  
06:34:10.544508 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
06:34:10.545168 [debug] [MainThread]: On macro_run_recipe: Close
06:34:10.545982 [debug] [MainThread]: Connection 'macro_run_recipe' was properly closed.


============================== 2022-02-20 06:34:11.631620 | b3f86b23-5b36-42f3-ab67-67de440e958a ==============================
06:34:11.631620 [info ] [MainThread]: Running with dbt=1.0.1
06:34:11.631988 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/hassanzaheer/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, macro='run_recipe', args='{\n    "recipe_type" : "collect_fact",\n    "target_fact" : {\n        "id": "outcomes", \n        "entity_and_dims": "customer_id",\n        "date":"date_outcome"\n    },\n    "ingredients": {\n        "expression_extract": {  \n            "source_raw": "testsatmap.outcomes",\n            "expression_list": [\n                {"expression": "outcome_date", "alias": "date_outcome"},\n                {"expression": "trim(customer_id)", "alias": "customer_id"},             \n                {"expression": "outcome_code::numeric", "alias": "num_outcome_amount"}\n            ]\n        },\n        "filter_conjunctions": [\n            "num_outcome_amount > 0",\n            "customer_id is not null"\n        ],\n        "incremental_update_on": "date_outcome",\n        "deduplication": {\n            "grouping_key": "customer_id, date_outcome, num_outcome_amount",\n            "preference": "arbitrary"\n        },\n        "coarsening": {\n            "entity_and_dims": "customer_id",\n            "date_expression":"date_outcome",\n            "aggregations": [\n                {"expression": "sum(num_outcome_amount)", "alias": "sum_outcome_amount"}\n            ]\n        }\n    }\n}', defer=None, state=None, cls=<class 'dbt.task.run_operation.RunOperationTask'>, which='run-operation', rpc_method='run-operation')
06:34:11.632120 [debug] [MainThread]: Tracking: do not track
06:34:11.652721 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 1 files added, 1 files changed.
06:34:11.652944 [debug] [MainThread]: Partial parsing: added file: demo_autopie://models/demo_ebp_flow/prepared_scripts/phase1_fact_outcomes.sql
06:34:11.653078 [debug] [MainThread]: Partial parsing: updated file: demo_autopie://models/demo_ebp_flow/prepared_scripts/phase1_fact_calls.sql
06:34:11.658615 [debug] [MainThread]: 1699: static parser successfully parsed demo_ebp_flow/prepared_scripts/phase1_fact_outcomes.sql
06:34:11.664112 [debug] [MainThread]: 1699: static parser successfully parsed demo_ebp_flow/prepared_scripts/phase1_fact_calls.sql
06:34:11.670205 [debug] [MainThread]: Acquiring new postgres connection "macro_run_recipe"
06:34:11.670306 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:34:11.670375 [debug] [MainThread]: On macro_run_recipe: BEGIN
06:34:11.670436 [debug] [MainThread]: Opening a new connection, currently in state init
06:34:11.674026 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
06:34:11.674122 [debug] [MainThread]: On macro_run_recipe: COMMIT
06:34:11.674183 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:34:11.674237 [debug] [MainThread]: On macro_run_recipe: COMMIT
06:34:11.674359 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
06:34:11.717572 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:34:11.717687 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select '"'||column_name||'"::'||
       case when replace(udt_name, '_','') = 'bit' then 'int'
            when replace(udt_name, '_','') like 'int8%' then 'bigint'
            when replace(udt_name, '_','') like 'int4%' then 'int'
            when replace(udt_name, '_','') like 'int%' then 'smallint'
            when replace(udt_name, '_','') like 'bool%' then 'int'
            when replace(udt_name, '_','') like 'float%' then 'numeric'
            when replace(udt_name, '_','') like 'float%' then 'numeric'
            when replace(udt_name, '_','') like 'byte%' then 'text'
            when replace(udt_name, '_','') like 'varchar%' then 'text'
            when replace(udt_name, '_','') like 'timestamp%' then 'timestamp'
            else replace(udt_name, '_','') end ||
       ' as "'||column_name||'"' select_text
from information_schema.columns 
where table_schema||'.'||table_name = 'testsatmap.outcomes'
order by ordinal_position ;

  
06:34:11.731484 [debug] [MainThread]: SQL status: SELECT 3 in 0.01 seconds
06:34:11.732277 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:34:11.732346 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 as
select "outcome_date"::date as "outcome_date", 
       "customer_id"::text as "customer_id", 
       "outcome_code"::text as "outcome_code"
       from testsatmap.outcomes;

  
06:34:11.735930 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:34:11.736480 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:34:11.736550 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:34:11.736812 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:34:11.737309 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:34:11.737377 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_exp_type_0000000000 as select outcome_date exp from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 limit 1
  
06:34:11.738586 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:34:11.739086 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:34:11.739153 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select replace(udt_name, '_','') dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type_0000000000' and column_name = 'exp'
  
06:34:11.744145 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
06:34:11.744840 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:34:11.744926 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:34:11.746403 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:34:11.746913 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:34:11.746981 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:34:11.747269 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:34:11.747751 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:34:11.747817 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_exp_type_0000000000 as select trim(customer_id) exp from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 limit 1
  
06:34:11.753622 [debug] [MainThread]: SQL status: CREATE VIEW in 0.01 seconds
06:34:11.754310 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:34:11.754384 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select replace(udt_name, '_','') dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type_0000000000' and column_name = 'exp'
  
06:34:11.757675 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
06:34:11.758227 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:34:11.758300 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:34:11.759043 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:34:11.759572 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:34:11.759644 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:34:11.759849 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:34:11.760363 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:34:11.760437 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_exp_type_0000000000 as select outcome_code::numeric exp from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 limit 1
  
06:34:11.761338 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:34:11.761861 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:34:11.761932 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select replace(udt_name, '_','') dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type_0000000000' and column_name = 'exp'
  
06:34:11.765093 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
06:34:11.765639 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:34:11.765711 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:34:11.766371 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:34:11.766892 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:34:11.766964 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 as
select  (outcome_date)::date as date_outcome, 
        (trim(customer_id))::text as customer_id, 
        (outcome_code::numeric)::numeric as num_outcome_amount
        from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000;

  
06:34:11.767936 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:34:11.768887 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:34:11.768959 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 cascade;
drop view if exists autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 cascade;

  
06:34:11.770057 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:34:11.770524 [info ] [MainThread]: 



create or replace view autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 as
select "outcome_date"::date as "outcome_date", 
       "customer_id"::text as "customer_id", 
       "outcome_code"::text as "outcome_code"
       from testsatmap.outcomes;


create or replace view autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 as
select  (outcome_date)::date as date_outcome, 
        (trim(customer_id))::text as customer_id, 
        (outcome_code::numeric)::numeric as num_outcome_amount
        from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000;


drop table if exists autopie_ebpdemo.tmp_staging_fact_0000000000;
create table autopie_ebpdemo.tmp_staging_fact_0000000000 as
(
    with expression_extract_1 as
    (
        select * from autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000
    ),
    expression_extract_2 as
    (
        select * from expression_extract_1
    ),
    filter__3 as
    (
        select /* filtering irrelevant records out */ *
        from expression_extract_2
        where 1=1
        and num_outcome_amount > 0
        and customer_id is not null
    ),
    incremental_extract__4 as
    (
        select /* retrieving incremental data - by date range only */ *
        from filter__3
        where date_outcome >= to_date('2020-01-01', 'YYYY-MM-DD')
          and date_outcome  < to_date('2021-01-01', 'YYYY-MM-DD')
    ),
    deduplication__5 as
    (
        select /* deduplicate by strategy */
               customer_id, date_outcome, num_outcome_amount
        from incremental_extract__4
        group by customer_id, date_outcome, num_outcome_amount 
    ),
    coarsening_6 as
    (
        select /* flatten all dimensions, fit into EAVT format */
              customer_id
              , date_outcome
              
              , sum(num_outcome_amount) as sum_outcome_amount
              from deduplication__5
        group by customer_id, date_outcome
    )
    select  t.*,
            1 autopie_run_id
    from coarsening_6 t
);

drop view if exists autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 cascade;
drop view if exists autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 cascade;


-- check if not exists already, this should run once
do $$                  
begin
if not exists
( 
    select 1 from information_schema.tables 
    where table_schema||'.'|| table_name = 'autopie_ebpdemo.obj_fact_outcomes'
)
then
    create table autopie_ebpdemo.obj_fact_outcomes as (select * from autopie_ebpdemo.tmp_staging_fact_0000000000 where 1=0);
    alter  table autopie_ebpdemo.obj_fact_outcomes add column row_id bigserial not null;
    alter  table autopie_ebpdemo.obj_fact_outcomes add primary key (customer_id, date_outcome);
    --
    create index ixrid_obj_fact_outcomes on autopie_ebpdemo.obj_fact_outcomes(row_id);
end if;
end
$$;

-- upsert staging additions into the permanent fact object
delete from autopie_ebpdemo.obj_fact_outcomes where (customer_id, date_outcome) in (select customer_id, date_outcome from autopie_ebpdemo.tmp_staging_fact_0000000000);
insert into autopie_ebpdemo.obj_fact_outcomes select * from autopie_ebpdemo.tmp_staging_fact_0000000000;
drop table autopie_ebpdemo.tmp_staging_fact_0000000000;


06:34:11.770904 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:34:11.770974 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    



create or replace view autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 as
select "outcome_date"::date as "outcome_date", 
       "customer_id"::text as "customer_id", 
       "outcome_code"::text as "outcome_code"
       from testsatmap.outcomes;


create or replace view autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 as
select  (outcome_date)::date as date_outcome, 
        (trim(customer_id))::text as customer_id, 
        (outcome_code::numeric)::numeric as num_outcome_amount
        from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000;


drop table if exists autopie_ebpdemo.tmp_staging_fact_0000000000;
create table autopie_ebpdemo.tmp_staging_fact_0000000000 as
(
    with expression_extract_1 as
    (
        select * from autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000
    ),
    expression_extract_2 as
    (
        select * from expression_extract_1
    ),
    filter__3 as
    (
        select /* filtering irrelevant records out */ *
        from expression_extract_2
        where 1=1
        and num_outcome_amount > 0
        and customer_id is not null
    ),
    incremental_extract__4 as
    (
        select /* retrieving incremental data - by date range only */ *
        from filter__3
        where date_outcome >= to_date('2020-01-01', 'YYYY-MM-DD')
          and date_outcome  < to_date('2021-01-01', 'YYYY-MM-DD')
    ),
    deduplication__5 as
    (
        select /* deduplicate by strategy */
               customer_id, date_outcome, num_outcome_amount
        from incremental_extract__4
        group by customer_id, date_outcome, num_outcome_amount 
    ),
    coarsening_6 as
    (
        select /* flatten all dimensions, fit into EAVT format */
              customer_id
              , date_outcome
              
              , sum(num_outcome_amount) as sum_outcome_amount
              from deduplication__5
        group by customer_id, date_outcome
    )
    select  t.*,
            1 autopie_run_id
    from coarsening_6 t
);

drop view if exists autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 cascade;
drop view if exists autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 cascade;


-- check if not exists already, this should run once
do $$                  
begin
if not exists
( 
    select 1 from information_schema.tables 
    where table_schema||'.'|| table_name = 'autopie_ebpdemo.obj_fact_outcomes'
)
then
    create table autopie_ebpdemo.obj_fact_outcomes as (select * from autopie_ebpdemo.tmp_staging_fact_0000000000 where 1=0);
    alter  table autopie_ebpdemo.obj_fact_outcomes add column row_id bigserial not null;
    alter  table autopie_ebpdemo.obj_fact_outcomes add primary key (customer_id, date_outcome);
    --
    create index ixrid_obj_fact_outcomes on autopie_ebpdemo.obj_fact_outcomes(row_id);
end if;
end
$$;

-- upsert staging additions into the permanent fact object
delete from autopie_ebpdemo.obj_fact_outcomes where (customer_id, date_outcome) in (select customer_id, date_outcome from autopie_ebpdemo.tmp_staging_fact_0000000000);
insert into autopie_ebpdemo.obj_fact_outcomes select * from autopie_ebpdemo.tmp_staging_fact_0000000000;
drop table autopie_ebpdemo.tmp_staging_fact_0000000000;


  
06:34:11.792599 [debug] [MainThread]: SQL status: DROP TABLE in 0.02 seconds
06:34:11.793359 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:34:11.793451 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    
select row_number() over (order by autopie_run_id desc) run_sequence, count(*) count_records 
  from autopie_ebpdemo.obj_fact_outcomes
group by autopie_run_id
order by 1 
limit 5;

  
06:34:11.794047 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
06:34:11.794828 [debug] [MainThread]: On macro_run_recipe: Close
06:34:11.795535 [debug] [MainThread]: Connection 'macro_run_recipe' was properly closed.


============================== 2022-02-20 06:34:12.871535 | 5452de3f-d934-4f7c-9e04-1cb6a07dfb00 ==============================
06:34:12.871535 [info ] [MainThread]: Running with dbt=1.0.1
06:34:12.871898 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/hassanzaheer/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, macro='run_recipe', args='{\n    "recipe_type" : "collect_fact",\n    "target_fact" : {\n        "id": "crm", \n        "entity_and_dims": "customer_id",\n        "date":"date_data"\n    },\n    "ingredients": {\n        "expression_extract": {  \n            "source_raw": "testsatmap.crm",\n            "expression_list": [\n                {"expression": "data_date", "alias": "date_data"},\n                {"expression": "trim(customer_id)",  "alias": "customer_id"},             \n                {"expression": "customer_num_attrib", "alias": "num_attrib"},\n                {"expression": "customer_cat_attrib",  "alias": "cat_attrib"}\n            ]\n        },\n        "filter_conjunctions": [\n            "customer_id is not null"\n        ],\n        "incremental_update_on": "date_data",\n        "deduplication": {\n            "grouping_key": "customer_id, date_data",\n            "preference": "arbitrary"\n        }\n    }\n}', defer=None, state=None, cls=<class 'dbt.task.run_operation.RunOperationTask'>, which='run-operation', rpc_method='run-operation')
06:34:12.872016 [debug] [MainThread]: Tracking: do not track
06:34:12.891570 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 1 files added, 1 files changed.
06:34:12.891794 [debug] [MainThread]: Partial parsing: added file: demo_autopie://models/demo_ebp_flow/prepared_scripts/phase1_fact_crm.sql
06:34:12.891927 [debug] [MainThread]: Partial parsing: updated file: demo_autopie://models/demo_ebp_flow/prepared_scripts/phase1_fact_outcomes.sql
06:34:12.897419 [debug] [MainThread]: 1699: static parser successfully parsed demo_ebp_flow/prepared_scripts/phase1_fact_crm.sql
06:34:12.902953 [debug] [MainThread]: 1699: static parser successfully parsed demo_ebp_flow/prepared_scripts/phase1_fact_outcomes.sql
06:34:12.909003 [debug] [MainThread]: Acquiring new postgres connection "macro_run_recipe"
06:34:12.909111 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:34:12.909175 [debug] [MainThread]: On macro_run_recipe: BEGIN
06:34:12.909237 [debug] [MainThread]: Opening a new connection, currently in state init
06:34:12.914625 [debug] [MainThread]: SQL status: BEGIN in 0.01 seconds
06:34:12.914713 [debug] [MainThread]: On macro_run_recipe: COMMIT
06:34:12.914770 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:34:12.914823 [debug] [MainThread]: On macro_run_recipe: COMMIT
06:34:12.914995 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
06:34:12.958227 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:34:12.958362 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select '"'||column_name||'"::'||
       case when replace(udt_name, '_','') = 'bit' then 'int'
            when replace(udt_name, '_','') like 'int8%' then 'bigint'
            when replace(udt_name, '_','') like 'int4%' then 'int'
            when replace(udt_name, '_','') like 'int%' then 'smallint'
            when replace(udt_name, '_','') like 'bool%' then 'int'
            when replace(udt_name, '_','') like 'float%' then 'numeric'
            when replace(udt_name, '_','') like 'float%' then 'numeric'
            when replace(udt_name, '_','') like 'byte%' then 'text'
            when replace(udt_name, '_','') like 'varchar%' then 'text'
            when replace(udt_name, '_','') like 'timestamp%' then 'timestamp'
            else replace(udt_name, '_','') end ||
       ' as "'||column_name||'"' select_text
from information_schema.columns 
where table_schema||'.'||table_name = 'testsatmap.crm'
order by ordinal_position ;

  
06:34:12.972687 [debug] [MainThread]: SQL status: SELECT 4 in 0.01 seconds
06:34:12.973535 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:34:12.973607 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 as
select "data_date"::date as "data_date", 
       "customer_id"::text as "customer_id", 
       "customer_cat_attrib"::text as "customer_cat_attrib", 
       "customer_num_attrib"::numeric as "customer_num_attrib"
       from testsatmap.crm;

  
06:34:12.976858 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:34:12.977353 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:34:12.977419 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:34:12.977646 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:34:12.978108 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:34:12.978170 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_exp_type_0000000000 as select data_date exp from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 limit 1
  
06:34:12.979087 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:34:12.979540 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:34:12.979603 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select replace(udt_name, '_','') dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type_0000000000' and column_name = 'exp'
  
06:34:12.982884 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
06:34:12.983420 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:34:12.983491 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:34:12.984598 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:34:12.985099 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:34:12.985168 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:34:12.985369 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:34:12.985847 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:34:12.985912 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_exp_type_0000000000 as select trim(customer_id) exp from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 limit 1
  
06:34:12.987327 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:34:12.987928 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:34:12.987995 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select replace(udt_name, '_','') dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type_0000000000' and column_name = 'exp'
  
06:34:12.992613 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
06:34:12.993121 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:34:12.993187 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:34:12.994111 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:34:12.994587 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:34:12.994666 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:34:12.994900 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:34:12.995375 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:34:12.995440 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_exp_type_0000000000 as select customer_num_attrib exp from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 limit 1
  
06:34:12.996600 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:34:12.997081 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:34:12.997153 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select replace(udt_name, '_','') dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type_0000000000' and column_name = 'exp'
  
06:34:13.001476 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
06:34:13.002016 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:34:13.002090 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:34:13.002818 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:34:13.003342 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:34:13.003412 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:34:13.003616 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:34:13.004128 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:34:13.004202 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_exp_type_0000000000 as select customer_cat_attrib exp from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 limit 1
  
06:34:13.005052 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:34:13.005568 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:34:13.005638 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select replace(udt_name, '_','') dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type_0000000000' and column_name = 'exp'
  
06:34:13.008895 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
06:34:13.009432 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:34:13.009502 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:34:13.010210 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:34:13.010727 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:34:13.010799 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 as
select  (data_date)::date as date_data, 
        (trim(customer_id))::text as customer_id, 
        (customer_num_attrib)::numeric as num_attrib, 
        (customer_cat_attrib)::text as cat_attrib
        from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000;

  
06:34:13.012214 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:34:13.013320 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:34:13.013391 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 cascade;
drop view if exists autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 cascade;

  
06:34:13.014319 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:34:13.014803 [info ] [MainThread]: 



create or replace view autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 as
select "data_date"::date as "data_date", 
       "customer_id"::text as "customer_id", 
       "customer_cat_attrib"::text as "customer_cat_attrib", 
       "customer_num_attrib"::numeric as "customer_num_attrib"
       from testsatmap.crm;


create or replace view autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 as
select  (data_date)::date as date_data, 
        (trim(customer_id))::text as customer_id, 
        (customer_num_attrib)::numeric as num_attrib, 
        (customer_cat_attrib)::text as cat_attrib
        from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000;


drop table if exists autopie_ebpdemo.tmp_staging_fact_0000000000;
create table autopie_ebpdemo.tmp_staging_fact_0000000000 as
(
    with expression_extract_1 as
    (
        select * from autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000
    ),
    expression_extract_2 as
    (
        select * from expression_extract_1
    ),
    filter__3 as
    (
        select /* filtering irrelevant records out */ *
        from expression_extract_2
        where 1=1
        and customer_id is not null
    ),
    incremental_extract__4 as
    (
        select /* retrieving incremental data - by date range only */ *
        from filter__3
        where date_data >= to_date('2020-01-01', 'YYYY-MM-DD')
          and date_data  < to_date('2021-01-01', 'YYYY-MM-DD')
    ),
    deduplication__5 as
    (
        select /* deduplicate by strategy */
               customer_id, date_data
               , max(num_attrib) as num_attrib
               , max(cat_attrib) as cat_attrib
        from incremental_extract__4
        group by customer_id, date_data 
    ),
    coarsening_6 as
    (
        select * from deduplication__5
    )
    select  t.*,
            1 autopie_run_id
    from coarsening_6 t
);

drop view if exists autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 cascade;
drop view if exists autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 cascade;


-- check if not exists already, this should run once
do $$                  
begin
if not exists
( 
    select 1 from information_schema.tables 
    where table_schema||'.'|| table_name = 'autopie_ebpdemo.obj_fact_crm'
)
then
    create table autopie_ebpdemo.obj_fact_crm as (select * from autopie_ebpdemo.tmp_staging_fact_0000000000 where 1=0);
    alter  table autopie_ebpdemo.obj_fact_crm add column row_id bigserial not null;
    alter  table autopie_ebpdemo.obj_fact_crm add primary key (customer_id, date_data);
    --
    create index ixrid_obj_fact_crm on autopie_ebpdemo.obj_fact_crm(row_id);
end if;
end
$$;

-- upsert staging additions into the permanent fact object
delete from autopie_ebpdemo.obj_fact_crm where (customer_id, date_data) in (select customer_id, date_data from autopie_ebpdemo.tmp_staging_fact_0000000000);
insert into autopie_ebpdemo.obj_fact_crm select * from autopie_ebpdemo.tmp_staging_fact_0000000000;
drop table autopie_ebpdemo.tmp_staging_fact_0000000000;


06:34:13.015168 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:34:13.015240 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    



create or replace view autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 as
select "data_date"::date as "data_date", 
       "customer_id"::text as "customer_id", 
       "customer_cat_attrib"::text as "customer_cat_attrib", 
       "customer_num_attrib"::numeric as "customer_num_attrib"
       from testsatmap.crm;


create or replace view autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 as
select  (data_date)::date as date_data, 
        (trim(customer_id))::text as customer_id, 
        (customer_num_attrib)::numeric as num_attrib, 
        (customer_cat_attrib)::text as cat_attrib
        from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000;


drop table if exists autopie_ebpdemo.tmp_staging_fact_0000000000;
create table autopie_ebpdemo.tmp_staging_fact_0000000000 as
(
    with expression_extract_1 as
    (
        select * from autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000
    ),
    expression_extract_2 as
    (
        select * from expression_extract_1
    ),
    filter__3 as
    (
        select /* filtering irrelevant records out */ *
        from expression_extract_2
        where 1=1
        and customer_id is not null
    ),
    incremental_extract__4 as
    (
        select /* retrieving incremental data - by date range only */ *
        from filter__3
        where date_data >= to_date('2020-01-01', 'YYYY-MM-DD')
          and date_data  < to_date('2021-01-01', 'YYYY-MM-DD')
    ),
    deduplication__5 as
    (
        select /* deduplicate by strategy */
               customer_id, date_data
               , max(num_attrib) as num_attrib
               , max(cat_attrib) as cat_attrib
        from incremental_extract__4
        group by customer_id, date_data 
    ),
    coarsening_6 as
    (
        select * from deduplication__5
    )
    select  t.*,
            1 autopie_run_id
    from coarsening_6 t
);

drop view if exists autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 cascade;
drop view if exists autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 cascade;


-- check if not exists already, this should run once
do $$                  
begin
if not exists
( 
    select 1 from information_schema.tables 
    where table_schema||'.'|| table_name = 'autopie_ebpdemo.obj_fact_crm'
)
then
    create table autopie_ebpdemo.obj_fact_crm as (select * from autopie_ebpdemo.tmp_staging_fact_0000000000 where 1=0);
    alter  table autopie_ebpdemo.obj_fact_crm add column row_id bigserial not null;
    alter  table autopie_ebpdemo.obj_fact_crm add primary key (customer_id, date_data);
    --
    create index ixrid_obj_fact_crm on autopie_ebpdemo.obj_fact_crm(row_id);
end if;
end
$$;

-- upsert staging additions into the permanent fact object
delete from autopie_ebpdemo.obj_fact_crm where (customer_id, date_data) in (select customer_id, date_data from autopie_ebpdemo.tmp_staging_fact_0000000000);
insert into autopie_ebpdemo.obj_fact_crm select * from autopie_ebpdemo.tmp_staging_fact_0000000000;
drop table autopie_ebpdemo.tmp_staging_fact_0000000000;


  
06:34:13.040741 [debug] [MainThread]: SQL status: DROP TABLE in 0.03 seconds
06:34:13.041440 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:34:13.041529 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    
select row_number() over (order by autopie_run_id desc) run_sequence, count(*) count_records 
  from autopie_ebpdemo.obj_fact_crm
group by autopie_run_id
order by 1 
limit 5;

  
06:34:13.042162 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
06:34:13.042757 [debug] [MainThread]: On macro_run_recipe: Close
06:34:13.043508 [debug] [MainThread]: Connection 'macro_run_recipe' was properly closed.


============================== 2022-02-20 06:34:14.124053 | 2d8fe206-04db-4337-aaf7-c369cb61fd9c ==============================
06:34:14.124053 [info ] [MainThread]: Running with dbt=1.0.1
06:34:14.124483 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/hassanzaheer/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, macro='run_recipe', args='{\n    "recipe_type" : "collect_fact",\n    "target_fact" : {\n        "id": "dispositions", \n        "entity_and_dims": "agent_id",\n        "date":"time_disposition_made"\n    },\n    "ingredients": {\n        "expression_extract": {  \n            "source_raw": "testsatmap.calldispositions",\n            "expression_list": [\n                {"expression": "to_timestamp(disposition_epoch)", "alias": "time_disposition_made"},\n                {"expression": "trim(customer_id)",  "alias": "customer_id"},             \n                {"expression": "lower(trim(agent_id))",  "alias": "agent_id"},\n                {"expression": "lower(trim(disp_code))",  "alias": "cat_disposition"}\n            ]\n        },\n        "filter_conjunctions": [\n            "agent_id is not null",\n            "customer_id is not null",\n            "cat_disposition in (\'k\', \'m\', \'a\')"\n        ],\n        "incremental_update_on": "time_disposition_made",\n        "deduplication": {\n            "grouping_key": "agent_id, cat_disposition, time_disposition_made",\n            "preference": "arbitrary"\n        },\n        "coarsening": {\n            "entity_and_dims": "agent_id",\n            "date_expression":"time_disposition_made",\n            "aggregations": [\n                {"expression": "max(customer_id)", "alias": "customer_id"},\n                {"expression": "sum(case when cat_disposition = \'k\' then 1 else 0 end)", "alias": "flg_k_disp_made"},\n                {"expression": "sum(case when cat_disposition = \'m\' then 1 else 0 end)", "alias": "flg_m_disp_made"},\n                {"expression": "sum(case when cat_disposition = \'a\' then 1 else 0 end)", "alias": "flg_a_disp_made"}\n            ]\n        }\n    }\n}', defer=None, state=None, cls=<class 'dbt.task.run_operation.RunOperationTask'>, which='run-operation', rpc_method='run-operation')
06:34:14.124608 [debug] [MainThread]: Tracking: do not track
06:34:14.147121 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 1 files added, 1 files changed.
06:34:14.147328 [debug] [MainThread]: Partial parsing: added file: demo_autopie://models/demo_ebp_flow/prepared_scripts/phase1_fact_dispositions.sql
06:34:14.147452 [debug] [MainThread]: Partial parsing: updated file: demo_autopie://models/demo_ebp_flow/prepared_scripts/phase1_fact_crm.sql
06:34:14.152953 [debug] [MainThread]: 1699: static parser successfully parsed demo_ebp_flow/prepared_scripts/phase1_fact_dispositions.sql
06:34:14.158432 [debug] [MainThread]: 1699: static parser successfully parsed demo_ebp_flow/prepared_scripts/phase1_fact_crm.sql
06:34:14.164618 [debug] [MainThread]: Acquiring new postgres connection "macro_run_recipe"
06:34:14.164742 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:34:14.164810 [debug] [MainThread]: On macro_run_recipe: BEGIN
06:34:14.164876 [debug] [MainThread]: Opening a new connection, currently in state init
06:34:14.170463 [debug] [MainThread]: SQL status: BEGIN in 0.01 seconds
06:34:14.170555 [debug] [MainThread]: On macro_run_recipe: COMMIT
06:34:14.170612 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:34:14.170664 [debug] [MainThread]: On macro_run_recipe: COMMIT
06:34:14.170833 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
06:34:14.214042 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:34:14.214158 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select '"'||column_name||'"::'||
       case when replace(udt_name, '_','') = 'bit' then 'int'
            when replace(udt_name, '_','') like 'int8%' then 'bigint'
            when replace(udt_name, '_','') like 'int4%' then 'int'
            when replace(udt_name, '_','') like 'int%' then 'smallint'
            when replace(udt_name, '_','') like 'bool%' then 'int'
            when replace(udt_name, '_','') like 'float%' then 'numeric'
            when replace(udt_name, '_','') like 'float%' then 'numeric'
            when replace(udt_name, '_','') like 'byte%' then 'text'
            when replace(udt_name, '_','') like 'varchar%' then 'text'
            when replace(udt_name, '_','') like 'timestamp%' then 'timestamp'
            else replace(udt_name, '_','') end ||
       ' as "'||column_name||'"' select_text
from information_schema.columns 
where table_schema||'.'||table_name = 'testsatmap.calldispositions'
order by ordinal_position ;

  
06:34:14.227705 [debug] [MainThread]: SQL status: SELECT 4 in 0.01 seconds
06:34:14.228540 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:34:14.228610 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 as
select "disposition_epoch"::bigint as "disposition_epoch", 
       "customer_id"::text as "customer_id", 
       "agent_id"::text as "agent_id", 
       "disp_code"::text as "disp_code"
       from testsatmap.calldispositions;

  
06:34:14.231729 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:34:14.232283 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:34:14.232358 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:34:14.232592 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:34:14.233105 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:34:14.233173 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_exp_type_0000000000 as select to_timestamp(disposition_epoch) exp from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 limit 1
  
06:34:14.234298 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:34:14.234796 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:34:14.234863 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select replace(udt_name, '_','') dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type_0000000000' and column_name = 'exp'
  
06:34:14.238319 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
06:34:14.238835 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:34:14.238903 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:34:14.239974 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:34:14.240463 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:34:14.240531 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:34:14.240728 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:34:14.241205 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:34:14.241271 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_exp_type_0000000000 as select trim(customer_id) exp from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 limit 1
  
06:34:14.242322 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:34:14.242921 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:34:14.242988 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select replace(udt_name, '_','') dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type_0000000000' and column_name = 'exp'
  
06:34:14.246386 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
06:34:14.246945 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:34:14.247015 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:34:14.247726 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:34:14.248213 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:34:14.248280 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:34:14.248480 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:34:14.248960 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:34:14.249026 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_exp_type_0000000000 as select lower(trim(agent_id)) exp from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 limit 1
  
06:34:14.250196 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:34:14.250718 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:34:14.250792 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select replace(udt_name, '_','') dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type_0000000000' and column_name = 'exp'
  
06:34:14.254060 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
06:34:14.254604 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:34:14.254675 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:34:14.255416 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:34:14.255937 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:34:14.256007 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:34:14.256211 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:34:14.256723 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:34:14.256795 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_exp_type_0000000000 as select lower(trim(disp_code)) exp from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 limit 1
  
06:34:14.257696 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:34:14.258220 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:34:14.258291 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select replace(udt_name, '_','') dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type_0000000000' and column_name = 'exp'
  
06:34:14.261424 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
06:34:14.261971 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:34:14.262043 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
06:34:14.262730 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:34:14.263249 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:34:14.263317 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 as
select  (to_timestamp(disposition_epoch))::timestamptz as time_disposition_made, 
        (trim(customer_id))::text as customer_id, 
        (lower(trim(agent_id)))::text as agent_id, 
        (lower(trim(disp_code)))::text as cat_disposition
        from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000;

  
06:34:14.264949 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
06:34:14.266039 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:34:14.266110 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 cascade;
drop view if exists autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 cascade;

  
06:34:14.267792 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
06:34:14.268284 [info ] [MainThread]: 



create or replace view autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 as
select "disposition_epoch"::bigint as "disposition_epoch", 
       "customer_id"::text as "customer_id", 
       "agent_id"::text as "agent_id", 
       "disp_code"::text as "disp_code"
       from testsatmap.calldispositions;


create or replace view autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 as
select  (to_timestamp(disposition_epoch))::timestamptz as time_disposition_made, 
        (trim(customer_id))::text as customer_id, 
        (lower(trim(agent_id)))::text as agent_id, 
        (lower(trim(disp_code)))::text as cat_disposition
        from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000;


drop table if exists autopie_ebpdemo.tmp_staging_fact_0000000000;
create table autopie_ebpdemo.tmp_staging_fact_0000000000 as
(
    with expression_extract_1 as
    (
        select * from autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000
    ),
    expression_extract_2 as
    (
        select * from expression_extract_1
    ),
    filter__3 as
    (
        select /* filtering irrelevant records out */ *
        from expression_extract_2
        where 1=1
        and agent_id is not null
        and customer_id is not null
        and cat_disposition in ('k', 'm', 'a')
    ),
    incremental_extract__4 as
    (
        select /* retrieving incremental data - by date range only */ *
        from filter__3
        where time_disposition_made >= to_date('2020-01-01', 'YYYY-MM-DD')
          and time_disposition_made  < to_date('2021-01-01', 'YYYY-MM-DD')
    ),
    deduplication__5 as
    (
        select /* deduplicate by strategy */
               agent_id, cat_disposition, time_disposition_made
               , max(customer_id) as customer_id
        from incremental_extract__4
        group by agent_id, cat_disposition, time_disposition_made 
    ),
    coarsening_6 as
    (
        select /* flatten all dimensions, fit into EAVT format */
              agent_id
              , time_disposition_made
              
              , max(customer_id) as customer_id
              , sum(case when cat_disposition = 'k' then 1 else 0 end) as flg_k_disp_made
              , sum(case when cat_disposition = 'm' then 1 else 0 end) as flg_m_disp_made
              , sum(case when cat_disposition = 'a' then 1 else 0 end) as flg_a_disp_made
              from deduplication__5
        group by agent_id, time_disposition_made
    )
    select  t.*,
            1 autopie_run_id
    from coarsening_6 t
);

drop view if exists autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 cascade;
drop view if exists autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 cascade;


-- check if not exists already, this should run once
do $$                  
begin
if not exists
( 
    select 1 from information_schema.tables 
    where table_schema||'.'|| table_name = 'autopie_ebpdemo.obj_fact_dispositions'
)
then
    create table autopie_ebpdemo.obj_fact_dispositions as (select * from autopie_ebpdemo.tmp_staging_fact_0000000000 where 1=0);
    alter  table autopie_ebpdemo.obj_fact_dispositions add column row_id bigserial not null;
    alter  table autopie_ebpdemo.obj_fact_dispositions add primary key (agent_id, time_disposition_made);
    --
    create index ixrid_obj_fact_dispositions on autopie_ebpdemo.obj_fact_dispositions(row_id);
end if;
end
$$;

-- upsert staging additions into the permanent fact object
delete from autopie_ebpdemo.obj_fact_dispositions where (agent_id, time_disposition_made) in (select agent_id, time_disposition_made from autopie_ebpdemo.tmp_staging_fact_0000000000);
insert into autopie_ebpdemo.obj_fact_dispositions select * from autopie_ebpdemo.tmp_staging_fact_0000000000;
drop table autopie_ebpdemo.tmp_staging_fact_0000000000;


06:34:14.268675 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:34:14.268753 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    



create or replace view autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 as
select "disposition_epoch"::bigint as "disposition_epoch", 
       "customer_id"::text as "customer_id", 
       "agent_id"::text as "agent_id", 
       "disp_code"::text as "disp_code"
       from testsatmap.calldispositions;


create or replace view autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 as
select  (to_timestamp(disposition_epoch))::timestamptz as time_disposition_made, 
        (trim(customer_id))::text as customer_id, 
        (lower(trim(agent_id)))::text as agent_id, 
        (lower(trim(disp_code)))::text as cat_disposition
        from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000;


drop table if exists autopie_ebpdemo.tmp_staging_fact_0000000000;
create table autopie_ebpdemo.tmp_staging_fact_0000000000 as
(
    with expression_extract_1 as
    (
        select * from autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000
    ),
    expression_extract_2 as
    (
        select * from expression_extract_1
    ),
    filter__3 as
    (
        select /* filtering irrelevant records out */ *
        from expression_extract_2
        where 1=1
        and agent_id is not null
        and customer_id is not null
        and cat_disposition in ('k', 'm', 'a')
    ),
    incremental_extract__4 as
    (
        select /* retrieving incremental data - by date range only */ *
        from filter__3
        where time_disposition_made >= to_date('2020-01-01', 'YYYY-MM-DD')
          and time_disposition_made  < to_date('2021-01-01', 'YYYY-MM-DD')
    ),
    deduplication__5 as
    (
        select /* deduplicate by strategy */
               agent_id, cat_disposition, time_disposition_made
               , max(customer_id) as customer_id
        from incremental_extract__4
        group by agent_id, cat_disposition, time_disposition_made 
    ),
    coarsening_6 as
    (
        select /* flatten all dimensions, fit into EAVT format */
              agent_id
              , time_disposition_made
              
              , max(customer_id) as customer_id
              , sum(case when cat_disposition = 'k' then 1 else 0 end) as flg_k_disp_made
              , sum(case when cat_disposition = 'm' then 1 else 0 end) as flg_m_disp_made
              , sum(case when cat_disposition = 'a' then 1 else 0 end) as flg_a_disp_made
              from deduplication__5
        group by agent_id, time_disposition_made
    )
    select  t.*,
            1 autopie_run_id
    from coarsening_6 t
);

drop view if exists autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 cascade;
drop view if exists autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 cascade;


-- check if not exists already, this should run once
do $$                  
begin
if not exists
( 
    select 1 from information_schema.tables 
    where table_schema||'.'|| table_name = 'autopie_ebpdemo.obj_fact_dispositions'
)
then
    create table autopie_ebpdemo.obj_fact_dispositions as (select * from autopie_ebpdemo.tmp_staging_fact_0000000000 where 1=0);
    alter  table autopie_ebpdemo.obj_fact_dispositions add column row_id bigserial not null;
    alter  table autopie_ebpdemo.obj_fact_dispositions add primary key (agent_id, time_disposition_made);
    --
    create index ixrid_obj_fact_dispositions on autopie_ebpdemo.obj_fact_dispositions(row_id);
end if;
end
$$;

-- upsert staging additions into the permanent fact object
delete from autopie_ebpdemo.obj_fact_dispositions where (agent_id, time_disposition_made) in (select agent_id, time_disposition_made from autopie_ebpdemo.tmp_staging_fact_0000000000);
insert into autopie_ebpdemo.obj_fact_dispositions select * from autopie_ebpdemo.tmp_staging_fact_0000000000;
drop table autopie_ebpdemo.tmp_staging_fact_0000000000;


  
06:34:14.295373 [debug] [MainThread]: SQL status: DROP TABLE in 0.03 seconds
06:34:14.296140 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
06:34:14.296234 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    
select row_number() over (order by autopie_run_id desc) run_sequence, count(*) count_records 
  from autopie_ebpdemo.obj_fact_dispositions
group by autopie_run_id
order by 1 
limit 5;

  
06:34:14.296806 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
06:34:14.297417 [debug] [MainThread]: On macro_run_recipe: Close
06:34:14.298183 [debug] [MainThread]: Connection 'macro_run_recipe' was properly closed.


============================== 2022-02-20 09:06:55.408189 | 1508c578-3ac1-49d0-a294-0c8c6aa3f4ff ==============================
09:06:55.408189 [info ] [MainThread]: Running with dbt=1.0.1
09:06:55.408627 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/hassanzaheer/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, macro='run_recipe', args='{\n    "recipe_type" : "collect_fact",\n    "target_fact" : {\n        "id": "calls", \n        "entity_and_dims": "call_id",\n        "date":"time_call_end"\n    },\n    "ingredients": {\n        "expression_extract": {  \n            "source_raw": "testsatmap.calltable",\n            "expression_list": [\n                {"expression": "call_id", "alias": "call_id"},\n                {"expression": "to_timestamp(call_start_epoch)", "alias": "time_call_start"},\n                {"expression": "to_timestamp(call_start_epoch + call_duration)", "alias": "time_call_end"},\n                {"expression": "call_duration", "alias": "num_duration_seconds"},\n                {"expression": "trim(customer_id)",  "alias": "customer_id"},\n                {"expression": "lower(trim(agent_id))",  "alias": "agent_id"}\n            ]\n        },\n        "expression_extract_outer": {  \n            "expression_list": [\n                {"expression": "round(num_duration_seconds/60,2)", "alias": "num_duration_minutes"}\n            ]\n        },\n        "filter_conjunctions": [\n            "agent_id is not null",\n            "customer_id is not null",\n            "num_duration_seconds > 10"\n        ],\n        "incremental_update_on": "time_call_start",\n        "deduplication": {\n            "grouping_key": "call_id",\n            "preference": "arbitrary"\n        }\n    }\n}', defer=None, state=None, cls=<class 'dbt.task.run_operation.RunOperationTask'>, which='run-operation', rpc_method='run-operation')
09:06:55.408733 [debug] [MainThread]: Tracking: do not track
09:06:55.432013 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 2 files changed.
09:06:55.432262 [debug] [MainThread]: Partial parsing: updated file: demo_autopie://models/demo_ebp_flow/prepared_scripts/phase1_fact_calls.sql
09:06:55.432383 [debug] [MainThread]: Partial parsing: updated file: demo_autopie://models/demo_ebp_flow/prepared_scripts/phase1_fact_dispositions.sql
09:06:55.437799 [debug] [MainThread]: 1699: static parser successfully parsed demo_ebp_flow/prepared_scripts/phase1_fact_calls.sql
09:06:55.443265 [debug] [MainThread]: 1699: static parser successfully parsed demo_ebp_flow/prepared_scripts/phase1_fact_dispositions.sql
09:06:55.449417 [debug] [MainThread]: Acquiring new postgres connection "macro_run_recipe"
09:06:55.449521 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:06:55.449589 [debug] [MainThread]: On macro_run_recipe: BEGIN
09:06:55.449649 [debug] [MainThread]: Opening a new connection, currently in state init
09:06:55.477644 [debug] [MainThread]: SQL status: BEGIN in 0.03 seconds
09:06:55.477750 [debug] [MainThread]: On macro_run_recipe: COMMIT
09:06:55.477818 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:06:55.477882 [debug] [MainThread]: On macro_run_recipe: COMMIT
09:06:55.478031 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
09:06:55.523615 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:06:55.523765 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select '"'||column_name||'"::'||
       case when replace(udt_name, '_','') = 'bit' then 'int'
            when replace(udt_name, '_','') like 'int8%' then 'bigint'
            when replace(udt_name, '_','') like 'int4%' then 'int'
            when replace(udt_name, '_','') like 'int%' then 'smallint'
            when replace(udt_name, '_','') like 'bool%' then 'int'
            when replace(udt_name, '_','') like 'float%' then 'numeric'
            when replace(udt_name, '_','') like 'float%' then 'numeric'
            when replace(udt_name, '_','') like 'byte%' then 'text'
            when replace(udt_name, '_','') like 'varchar%' then 'text'
            when replace(udt_name, '_','') like 'timestamp%' then 'timestamp'
            else replace(udt_name, '_','') end ||
       ' as "'||column_name||'"' select_text
from information_schema.columns 
where table_schema||'.'||table_name = 'testsatmap.calltable'
order by ordinal_position ;

  
09:06:55.546051 [debug] [MainThread]: SQL status: SELECT 5 in 0.02 seconds
09:06:55.546940 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:06:55.547020 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 as
select "call_id"::text as "call_id", 
       "call_start_epoch"::bigint as "call_start_epoch", 
       "call_duration"::int as "call_duration", 
       "customer_id"::text as "customer_id", 
       "agent_id"::text as "agent_id"
       from testsatmap.calltable;

  
09:06:55.549165 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
09:06:55.549703 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:06:55.549773 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
09:06:55.549977 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
09:06:55.550479 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:06:55.550547 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_exp_type_0000000000 as select call_id exp from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 limit 1
  
09:06:55.551341 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
09:06:55.551836 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:06:55.551902 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select replace(udt_name, '_','') dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type_0000000000' and column_name = 'exp'
  
09:06:55.554448 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
09:06:55.554959 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:06:55.555025 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
09:06:55.556126 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
09:06:55.556661 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:06:55.556732 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
09:06:55.556921 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
09:06:55.557438 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:06:55.557510 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_exp_type_0000000000 as select to_timestamp(call_start_epoch) exp from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 limit 1
  
09:06:55.558955 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
09:06:55.559611 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:06:55.559684 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select replace(udt_name, '_','') dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type_0000000000' and column_name = 'exp'
  
09:06:55.562720 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
09:06:55.563274 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:06:55.563346 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
09:06:55.564010 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
09:06:55.564536 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:06:55.564607 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
09:06:55.564806 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
09:06:55.565325 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:06:55.565395 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_exp_type_0000000000 as select to_timestamp(call_start_epoch + call_duration) exp from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 limit 1
  
09:06:55.566996 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
09:06:55.567538 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:06:55.567609 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select replace(udt_name, '_','') dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type_0000000000' and column_name = 'exp'
  
09:06:55.571092 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
09:06:55.571635 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:06:55.571706 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
09:06:55.572402 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
09:06:55.572926 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:06:55.572996 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
09:06:55.573196 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
09:06:55.573707 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:06:55.573777 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_exp_type_0000000000 as select call_duration exp from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 limit 1
  
09:06:55.574637 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
09:06:55.575155 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:06:55.575225 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select replace(udt_name, '_','') dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type_0000000000' and column_name = 'exp'
  
09:06:55.578352 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
09:06:55.578894 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:06:55.578964 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
09:06:55.579651 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
09:06:55.580170 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:06:55.580246 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
09:06:55.580550 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
09:06:55.581079 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:06:55.581151 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_exp_type_0000000000 as select trim(customer_id) exp from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 limit 1
  
09:06:55.582749 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
09:06:55.583270 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:06:55.583341 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select replace(udt_name, '_','') dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type_0000000000' and column_name = 'exp'
  
09:06:55.586406 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
09:06:55.586951 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:06:55.587025 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
09:06:55.587652 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
09:06:55.588222 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:06:55.588299 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
09:06:55.588507 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
09:06:55.589067 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:06:55.589144 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_exp_type_0000000000 as select lower(trim(agent_id)) exp from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 limit 1
  
09:06:55.590283 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
09:06:55.590848 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:06:55.590924 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select replace(udt_name, '_','') dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type_0000000000' and column_name = 'exp'
  
09:06:55.594019 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
09:06:55.594612 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:06:55.594688 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
09:06:55.595365 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
09:06:55.595933 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:06:55.596009 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 as
select  (call_id)::text as call_id, 
        (to_timestamp(call_start_epoch))::timestamptz as time_call_start, 
        (to_timestamp(call_start_epoch + call_duration))::timestamptz as time_call_end, 
        (call_duration)::int4 as num_duration_seconds, 
        (trim(customer_id))::text as customer_id, 
        (lower(trim(agent_id)))::text as agent_id
        from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000;

  
09:06:55.597384 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
09:06:55.597948 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:06:55.598024 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
09:06:55.598232 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
09:06:55.598786 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:06:55.598864 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_exp_type_0000000000 as select round(num_duration_seconds/60,2) exp from autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 limit 1
  
09:06:55.600584 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
09:06:55.601147 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:06:55.601224 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select replace(udt_name, '_','') dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type_0000000000' and column_name = 'exp'
  
09:06:55.604596 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
09:06:55.605312 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:06:55.605390 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
09:06:55.606249 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
09:06:55.607868 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:06:55.607948 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 cascade;
drop view if exists autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 cascade;

  
09:06:55.609030 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
09:06:55.609564 [info ] [MainThread]: 



create or replace view autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 as
select "call_id"::text as "call_id", 
       "call_start_epoch"::bigint as "call_start_epoch", 
       "call_duration"::int as "call_duration", 
       "customer_id"::text as "customer_id", 
       "agent_id"::text as "agent_id"
       from testsatmap.calltable;


create or replace view autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 as
select  (call_id)::text as call_id, 
        (to_timestamp(call_start_epoch))::timestamptz as time_call_start, 
        (to_timestamp(call_start_epoch + call_duration))::timestamptz as time_call_end, 
        (call_duration)::int4 as num_duration_seconds, 
        (trim(customer_id))::text as customer_id, 
        (lower(trim(agent_id)))::text as agent_id
        from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000;


drop table if exists autopie_ebpdemo.tmp_staging_fact_0000000000;
create table autopie_ebpdemo.tmp_staging_fact_0000000000 as
(
    with expression_extract_1 as
    (
        select * from autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000
    ),
    expression_extract_2 as
    (
        select  t.*,
                (round(num_duration_seconds/60,2))::numeric as num_duration_minutes
                from expression_extract_1 t
    ),
    filter__3 as
    (
        select /* filtering irrelevant records out */ *
        from expression_extract_2
        where 1=1
        and agent_id is not null
        and customer_id is not null
        and num_duration_seconds > 10
    ),
    incremental_extract__4 as
    (
        select /* retrieving incremental data - by date range only */ *
        from filter__3
        where time_call_start >= to_date('2020-01-01', 'YYYY-MM-DD')
          and time_call_start  < to_date('2021-01-01', 'YYYY-MM-DD')
    ),
    deduplication__5 as
    (
        select /* deduplicate by strategy */
               call_id
               , max(time_call_start) as time_call_start
               , max(time_call_end) as time_call_end
               , max(num_duration_seconds) as num_duration_seconds
               , max(customer_id) as customer_id
               , max(agent_id) as agent_id
               , max(num_duration_minutes) as num_duration_minutes
        from incremental_extract__4
        group by call_id 
    ),
    coarsening_6 as
    (
        select * from deduplication__5
    )
    select  t.*,
            1 autopie_run_id
    from coarsening_6 t
);

drop view if exists autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 cascade;
drop view if exists autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 cascade;


-- check if not exists already, this should run once
do $$                  
begin
if not exists
( 
    select 1 from information_schema.tables 
    where table_schema||'.'|| table_name = 'autopie_ebpdemo.obj_fact_calls'
)
then
    create table autopie_ebpdemo.obj_fact_calls as (select * from autopie_ebpdemo.tmp_staging_fact_0000000000 where 1=0);
    alter  table autopie_ebpdemo.obj_fact_calls add column row_id bigserial not null;
    alter  table autopie_ebpdemo.obj_fact_calls add primary key (call_id, time_call_end);
    --
    create index ixrid_obj_fact_calls on autopie_ebpdemo.obj_fact_calls(row_id);
end if;
end
$$;

-- upsert staging additions into the permanent fact object
delete from autopie_ebpdemo.obj_fact_calls where (call_id, time_call_end) in (select call_id, time_call_end from autopie_ebpdemo.tmp_staging_fact_0000000000);
insert into autopie_ebpdemo.obj_fact_calls select * from autopie_ebpdemo.tmp_staging_fact_0000000000;
drop table autopie_ebpdemo.tmp_staging_fact_0000000000;


09:06:55.609991 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:06:55.610067 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    



create or replace view autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 as
select "call_id"::text as "call_id", 
       "call_start_epoch"::bigint as "call_start_epoch", 
       "call_duration"::int as "call_duration", 
       "customer_id"::text as "customer_id", 
       "agent_id"::text as "agent_id"
       from testsatmap.calltable;


create or replace view autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 as
select  (call_id)::text as call_id, 
        (to_timestamp(call_start_epoch))::timestamptz as time_call_start, 
        (to_timestamp(call_start_epoch + call_duration))::timestamptz as time_call_end, 
        (call_duration)::int4 as num_duration_seconds, 
        (trim(customer_id))::text as customer_id, 
        (lower(trim(agent_id)))::text as agent_id
        from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000;


drop table if exists autopie_ebpdemo.tmp_staging_fact_0000000000;
create table autopie_ebpdemo.tmp_staging_fact_0000000000 as
(
    with expression_extract_1 as
    (
        select * from autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000
    ),
    expression_extract_2 as
    (
        select  t.*,
                (round(num_duration_seconds/60,2))::numeric as num_duration_minutes
                from expression_extract_1 t
    ),
    filter__3 as
    (
        select /* filtering irrelevant records out */ *
        from expression_extract_2
        where 1=1
        and agent_id is not null
        and customer_id is not null
        and num_duration_seconds > 10
    ),
    incremental_extract__4 as
    (
        select /* retrieving incremental data - by date range only */ *
        from filter__3
        where time_call_start >= to_date('2020-01-01', 'YYYY-MM-DD')
          and time_call_start  < to_date('2021-01-01', 'YYYY-MM-DD')
    ),
    deduplication__5 as
    (
        select /* deduplicate by strategy */
               call_id
               , max(time_call_start) as time_call_start
               , max(time_call_end) as time_call_end
               , max(num_duration_seconds) as num_duration_seconds
               , max(customer_id) as customer_id
               , max(agent_id) as agent_id
               , max(num_duration_minutes) as num_duration_minutes
        from incremental_extract__4
        group by call_id 
    ),
    coarsening_6 as
    (
        select * from deduplication__5
    )
    select  t.*,
            1 autopie_run_id
    from coarsening_6 t
);

drop view if exists autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 cascade;
drop view if exists autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 cascade;


-- check if not exists already, this should run once
do $$                  
begin
if not exists
( 
    select 1 from information_schema.tables 
    where table_schema||'.'|| table_name = 'autopie_ebpdemo.obj_fact_calls'
)
then
    create table autopie_ebpdemo.obj_fact_calls as (select * from autopie_ebpdemo.tmp_staging_fact_0000000000 where 1=0);
    alter  table autopie_ebpdemo.obj_fact_calls add column row_id bigserial not null;
    alter  table autopie_ebpdemo.obj_fact_calls add primary key (call_id, time_call_end);
    --
    create index ixrid_obj_fact_calls on autopie_ebpdemo.obj_fact_calls(row_id);
end if;
end
$$;

-- upsert staging additions into the permanent fact object
delete from autopie_ebpdemo.obj_fact_calls where (call_id, time_call_end) in (select call_id, time_call_end from autopie_ebpdemo.tmp_staging_fact_0000000000);
insert into autopie_ebpdemo.obj_fact_calls select * from autopie_ebpdemo.tmp_staging_fact_0000000000;
drop table autopie_ebpdemo.tmp_staging_fact_0000000000;


  
09:06:55.640309 [debug] [MainThread]: SQL status: DROP TABLE in 0.03 seconds
09:06:55.641124 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:06:55.641226 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    
select row_number() over (order by autopie_run_id desc) run_sequence, count(*) count_records 
  from autopie_ebpdemo.obj_fact_calls
group by autopie_run_id
order by 1 
limit 5;

  
09:06:55.641873 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
09:06:55.642543 [debug] [MainThread]: On macro_run_recipe: Close
09:06:55.643359 [debug] [MainThread]: Connection 'macro_run_recipe' was properly closed.


============================== 2022-02-20 09:06:56.721876 | 499cb101-dd44-4426-88b9-3c16c915a695 ==============================
09:06:56.721876 [info ] [MainThread]: Running with dbt=1.0.1
09:06:56.722264 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/hassanzaheer/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, macro='run_recipe', args='{\n    "recipe_type" : "collect_fact",\n    "target_fact" : {\n        "id": "outcomes", \n        "entity_and_dims": "customer_id",\n        "date":"date_outcome"\n    },\n    "ingredients": {\n        "expression_extract": {  \n            "source_raw": "testsatmap.outcomes",\n            "expression_list": [\n                {"expression": "outcome_date", "alias": "date_outcome"},\n                {"expression": "trim(customer_id)", "alias": "customer_id"},             \n                {"expression": "outcome_code::numeric", "alias": "num_outcome_amount"}\n            ]\n        },\n        "filter_conjunctions": [\n            "num_outcome_amount > 0",\n            "customer_id is not null"\n        ],\n        "incremental_update_on": "date_outcome",\n        "deduplication": {\n            "grouping_key": "customer_id, date_outcome, num_outcome_amount",\n            "preference": "arbitrary"\n        },\n        "coarsening": {\n            "entity_and_dims": "customer_id",\n            "date_expression":"date_outcome",\n            "aggregations": [\n                {"expression": "sum(num_outcome_amount)", "alias": "sum_outcome_amount"}\n            ]\n        }\n    }\n}', defer=None, state=None, cls=<class 'dbt.task.run_operation.RunOperationTask'>, which='run-operation', rpc_method='run-operation')
09:06:56.722377 [debug] [MainThread]: Tracking: do not track
09:06:56.741665 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 2 files changed.
09:06:56.741925 [debug] [MainThread]: Partial parsing: updated file: demo_autopie://models/demo_ebp_flow/prepared_scripts/phase1_fact_calls.sql
09:06:56.742049 [debug] [MainThread]: Partial parsing: updated file: demo_autopie://models/demo_ebp_flow/prepared_scripts/phase1_fact_outcomes.sql
09:06:56.747577 [debug] [MainThread]: 1699: static parser successfully parsed demo_ebp_flow/prepared_scripts/phase1_fact_calls.sql
09:06:56.753069 [debug] [MainThread]: 1699: static parser successfully parsed demo_ebp_flow/prepared_scripts/phase1_fact_outcomes.sql
09:06:56.759233 [debug] [MainThread]: Acquiring new postgres connection "macro_run_recipe"
09:06:56.759333 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:06:56.759397 [debug] [MainThread]: On macro_run_recipe: BEGIN
09:06:56.759459 [debug] [MainThread]: Opening a new connection, currently in state init
09:06:56.763976 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
09:06:56.764092 [debug] [MainThread]: On macro_run_recipe: COMMIT
09:06:56.764156 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:06:56.764216 [debug] [MainThread]: On macro_run_recipe: COMMIT
09:06:56.764393 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
09:06:56.807810 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:06:56.807933 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select '"'||column_name||'"::'||
       case when replace(udt_name, '_','') = 'bit' then 'int'
            when replace(udt_name, '_','') like 'int8%' then 'bigint'
            when replace(udt_name, '_','') like 'int4%' then 'int'
            when replace(udt_name, '_','') like 'int%' then 'smallint'
            when replace(udt_name, '_','') like 'bool%' then 'int'
            when replace(udt_name, '_','') like 'float%' then 'numeric'
            when replace(udt_name, '_','') like 'float%' then 'numeric'
            when replace(udt_name, '_','') like 'byte%' then 'text'
            when replace(udt_name, '_','') like 'varchar%' then 'text'
            when replace(udt_name, '_','') like 'timestamp%' then 'timestamp'
            else replace(udt_name, '_','') end ||
       ' as "'||column_name||'"' select_text
from information_schema.columns 
where table_schema||'.'||table_name = 'testsatmap.outcomes'
order by ordinal_position ;

  
09:06:56.821737 [debug] [MainThread]: SQL status: SELECT 3 in 0.01 seconds
09:06:56.822554 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:06:56.822630 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 as
select "outcome_date"::date as "outcome_date", 
       "customer_id"::text as "customer_id", 
       "outcome_code"::text as "outcome_code"
       from testsatmap.outcomes;

  
09:06:56.825203 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
09:06:56.825715 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:06:56.825782 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
09:06:56.826003 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
09:06:56.826479 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:06:56.826544 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_exp_type_0000000000 as select outcome_date exp from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 limit 1
  
09:06:56.827889 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
09:06:56.828367 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:06:56.828429 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select replace(udt_name, '_','') dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type_0000000000' and column_name = 'exp'
  
09:06:56.831961 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
09:06:56.832451 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:06:56.832515 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
09:06:56.833528 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
09:06:56.834008 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:06:56.834070 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
09:06:56.834265 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
09:06:56.834724 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:06:56.834787 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_exp_type_0000000000 as select trim(customer_id) exp from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 limit 1
  
09:06:56.835667 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
09:06:56.836267 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:06:56.836337 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select replace(udt_name, '_','') dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type_0000000000' and column_name = 'exp'
  
09:06:56.839418 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
09:06:56.839935 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:06:56.840001 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
09:06:56.840663 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
09:06:56.841156 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:06:56.841224 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
09:06:56.841422 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
09:06:56.841907 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:06:56.841980 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_exp_type_0000000000 as select outcome_code::numeric exp from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 limit 1
  
09:06:56.843051 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
09:06:56.843575 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:06:56.843645 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select replace(udt_name, '_','') dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type_0000000000' and column_name = 'exp'
  
09:06:56.846768 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
09:06:56.847315 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:06:56.847385 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
09:06:56.848006 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
09:06:56.848530 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:06:56.848601 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 as
select  (outcome_date)::date as date_outcome, 
        (trim(customer_id))::text as customer_id, 
        (outcome_code::numeric)::numeric as num_outcome_amount
        from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000;

  
09:06:56.849510 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
09:06:56.850457 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:06:56.850531 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 cascade;
drop view if exists autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 cascade;

  
09:06:56.851377 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
09:06:56.851870 [info ] [MainThread]: 



create or replace view autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 as
select "outcome_date"::date as "outcome_date", 
       "customer_id"::text as "customer_id", 
       "outcome_code"::text as "outcome_code"
       from testsatmap.outcomes;


create or replace view autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 as
select  (outcome_date)::date as date_outcome, 
        (trim(customer_id))::text as customer_id, 
        (outcome_code::numeric)::numeric as num_outcome_amount
        from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000;


drop table if exists autopie_ebpdemo.tmp_staging_fact_0000000000;
create table autopie_ebpdemo.tmp_staging_fact_0000000000 as
(
    with expression_extract_1 as
    (
        select * from autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000
    ),
    expression_extract_2 as
    (
        select * from expression_extract_1
    ),
    filter__3 as
    (
        select /* filtering irrelevant records out */ *
        from expression_extract_2
        where 1=1
        and num_outcome_amount > 0
        and customer_id is not null
    ),
    incremental_extract__4 as
    (
        select /* retrieving incremental data - by date range only */ *
        from filter__3
        where date_outcome >= to_date('2020-01-01', 'YYYY-MM-DD')
          and date_outcome  < to_date('2021-01-01', 'YYYY-MM-DD')
    ),
    deduplication__5 as
    (
        select /* deduplicate by strategy */
               customer_id, date_outcome, num_outcome_amount
        from incremental_extract__4
        group by customer_id, date_outcome, num_outcome_amount 
    ),
    coarsening_6 as
    (
        select /* flatten all dimensions, fit into EAVT format */
              customer_id
              , date_outcome
              
              , sum(num_outcome_amount) as sum_outcome_amount
              from deduplication__5
        group by customer_id, date_outcome
    )
    select  t.*,
            1 autopie_run_id
    from coarsening_6 t
);

drop view if exists autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 cascade;
drop view if exists autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 cascade;


-- check if not exists already, this should run once
do $$                  
begin
if not exists
( 
    select 1 from information_schema.tables 
    where table_schema||'.'|| table_name = 'autopie_ebpdemo.obj_fact_outcomes'
)
then
    create table autopie_ebpdemo.obj_fact_outcomes as (select * from autopie_ebpdemo.tmp_staging_fact_0000000000 where 1=0);
    alter  table autopie_ebpdemo.obj_fact_outcomes add column row_id bigserial not null;
    alter  table autopie_ebpdemo.obj_fact_outcomes add primary key (customer_id, date_outcome);
    --
    create index ixrid_obj_fact_outcomes on autopie_ebpdemo.obj_fact_outcomes(row_id);
end if;
end
$$;

-- upsert staging additions into the permanent fact object
delete from autopie_ebpdemo.obj_fact_outcomes where (customer_id, date_outcome) in (select customer_id, date_outcome from autopie_ebpdemo.tmp_staging_fact_0000000000);
insert into autopie_ebpdemo.obj_fact_outcomes select * from autopie_ebpdemo.tmp_staging_fact_0000000000;
drop table autopie_ebpdemo.tmp_staging_fact_0000000000;


09:06:56.852254 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:06:56.852321 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    



create or replace view autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 as
select "outcome_date"::date as "outcome_date", 
       "customer_id"::text as "customer_id", 
       "outcome_code"::text as "outcome_code"
       from testsatmap.outcomes;


create or replace view autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 as
select  (outcome_date)::date as date_outcome, 
        (trim(customer_id))::text as customer_id, 
        (outcome_code::numeric)::numeric as num_outcome_amount
        from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000;


drop table if exists autopie_ebpdemo.tmp_staging_fact_0000000000;
create table autopie_ebpdemo.tmp_staging_fact_0000000000 as
(
    with expression_extract_1 as
    (
        select * from autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000
    ),
    expression_extract_2 as
    (
        select * from expression_extract_1
    ),
    filter__3 as
    (
        select /* filtering irrelevant records out */ *
        from expression_extract_2
        where 1=1
        and num_outcome_amount > 0
        and customer_id is not null
    ),
    incremental_extract__4 as
    (
        select /* retrieving incremental data - by date range only */ *
        from filter__3
        where date_outcome >= to_date('2020-01-01', 'YYYY-MM-DD')
          and date_outcome  < to_date('2021-01-01', 'YYYY-MM-DD')
    ),
    deduplication__5 as
    (
        select /* deduplicate by strategy */
               customer_id, date_outcome, num_outcome_amount
        from incremental_extract__4
        group by customer_id, date_outcome, num_outcome_amount 
    ),
    coarsening_6 as
    (
        select /* flatten all dimensions, fit into EAVT format */
              customer_id
              , date_outcome
              
              , sum(num_outcome_amount) as sum_outcome_amount
              from deduplication__5
        group by customer_id, date_outcome
    )
    select  t.*,
            1 autopie_run_id
    from coarsening_6 t
);

drop view if exists autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 cascade;
drop view if exists autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 cascade;


-- check if not exists already, this should run once
do $$                  
begin
if not exists
( 
    select 1 from information_schema.tables 
    where table_schema||'.'|| table_name = 'autopie_ebpdemo.obj_fact_outcomes'
)
then
    create table autopie_ebpdemo.obj_fact_outcomes as (select * from autopie_ebpdemo.tmp_staging_fact_0000000000 where 1=0);
    alter  table autopie_ebpdemo.obj_fact_outcomes add column row_id bigserial not null;
    alter  table autopie_ebpdemo.obj_fact_outcomes add primary key (customer_id, date_outcome);
    --
    create index ixrid_obj_fact_outcomes on autopie_ebpdemo.obj_fact_outcomes(row_id);
end if;
end
$$;

-- upsert staging additions into the permanent fact object
delete from autopie_ebpdemo.obj_fact_outcomes where (customer_id, date_outcome) in (select customer_id, date_outcome from autopie_ebpdemo.tmp_staging_fact_0000000000);
insert into autopie_ebpdemo.obj_fact_outcomes select * from autopie_ebpdemo.tmp_staging_fact_0000000000;
drop table autopie_ebpdemo.tmp_staging_fact_0000000000;


  
09:06:56.880213 [debug] [MainThread]: SQL status: DROP TABLE in 0.03 seconds
09:06:56.880945 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:06:56.881034 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    
select row_number() over (order by autopie_run_id desc) run_sequence, count(*) count_records 
  from autopie_ebpdemo.obj_fact_outcomes
group by autopie_run_id
order by 1 
limit 5;

  
09:06:56.881656 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
09:06:56.882430 [debug] [MainThread]: On macro_run_recipe: Close
09:06:56.883100 [debug] [MainThread]: Connection 'macro_run_recipe' was properly closed.


============================== 2022-02-20 09:06:57.961675 | 57648d4b-be99-4bf9-b070-b8f9e0d63e85 ==============================
09:06:57.961675 [info ] [MainThread]: Running with dbt=1.0.1
09:06:57.962069 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/hassanzaheer/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, macro='run_recipe', args='{\n    "recipe_type" : "collect_fact",\n    "target_fact" : {\n        "id": "crm", \n        "entity_and_dims": "customer_id",\n        "date":"date_data"\n    },\n    "ingredients": {\n        "expression_extract": {  \n            "source_raw": "testsatmap.crm",\n            "expression_list": [\n                {"expression": "data_date", "alias": "date_data"},\n                {"expression": "trim(customer_id)",  "alias": "customer_id"},             \n                {"expression": "customer_num_attrib", "alias": "num_attrib"},\n                {"expression": "customer_cat_attrib",  "alias": "cat_attrib"}\n            ]\n        },\n        "filter_conjunctions": [\n            "customer_id is not null"\n        ],\n        "incremental_update_on": "date_data",\n        "deduplication": {\n            "grouping_key": "customer_id, date_data",\n            "preference": "arbitrary"\n        }\n    }\n}', defer=None, state=None, cls=<class 'dbt.task.run_operation.RunOperationTask'>, which='run-operation', rpc_method='run-operation')
09:06:57.962166 [debug] [MainThread]: Tracking: do not track
09:06:57.982192 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 2 files changed.
09:06:57.982455 [debug] [MainThread]: Partial parsing: updated file: demo_autopie://models/demo_ebp_flow/prepared_scripts/phase1_fact_outcomes.sql
09:06:57.982581 [debug] [MainThread]: Partial parsing: updated file: demo_autopie://models/demo_ebp_flow/prepared_scripts/phase1_fact_crm.sql
09:06:57.988053 [debug] [MainThread]: 1699: static parser successfully parsed demo_ebp_flow/prepared_scripts/phase1_fact_outcomes.sql
09:06:57.993483 [debug] [MainThread]: 1699: static parser successfully parsed demo_ebp_flow/prepared_scripts/phase1_fact_crm.sql
09:06:57.999689 [debug] [MainThread]: Acquiring new postgres connection "macro_run_recipe"
09:06:57.999794 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:06:57.999860 [debug] [MainThread]: On macro_run_recipe: BEGIN
09:06:57.999921 [debug] [MainThread]: Opening a new connection, currently in state init
09:06:58.005376 [debug] [MainThread]: SQL status: BEGIN in 0.01 seconds
09:06:58.005474 [debug] [MainThread]: On macro_run_recipe: COMMIT
09:06:58.005538 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:06:58.005592 [debug] [MainThread]: On macro_run_recipe: COMMIT
09:06:58.005765 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
09:06:58.049138 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:06:58.049256 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select '"'||column_name||'"::'||
       case when replace(udt_name, '_','') = 'bit' then 'int'
            when replace(udt_name, '_','') like 'int8%' then 'bigint'
            when replace(udt_name, '_','') like 'int4%' then 'int'
            when replace(udt_name, '_','') like 'int%' then 'smallint'
            when replace(udt_name, '_','') like 'bool%' then 'int'
            when replace(udt_name, '_','') like 'float%' then 'numeric'
            when replace(udt_name, '_','') like 'float%' then 'numeric'
            when replace(udt_name, '_','') like 'byte%' then 'text'
            when replace(udt_name, '_','') like 'varchar%' then 'text'
            when replace(udt_name, '_','') like 'timestamp%' then 'timestamp'
            else replace(udt_name, '_','') end ||
       ' as "'||column_name||'"' select_text
from information_schema.columns 
where table_schema||'.'||table_name = 'testsatmap.crm'
order by ordinal_position ;

  
09:06:58.062164 [debug] [MainThread]: SQL status: SELECT 4 in 0.01 seconds
09:06:58.062981 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:06:58.063049 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 as
select "data_date"::date as "data_date", 
       "customer_id"::text as "customer_id", 
       "customer_cat_attrib"::text as "customer_cat_attrib", 
       "customer_num_attrib"::numeric as "customer_num_attrib"
       from testsatmap.crm;

  
09:06:58.066232 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
09:06:58.066729 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:06:58.066792 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
09:06:58.067018 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
09:06:58.067474 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:06:58.067533 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_exp_type_0000000000 as select data_date exp from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 limit 1
  
09:06:58.068471 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
09:06:58.068924 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:06:58.068984 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select replace(udt_name, '_','') dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type_0000000000' and column_name = 'exp'
  
09:06:58.072504 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
09:06:58.073015 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:06:58.073080 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
09:06:58.074148 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
09:06:58.074656 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:06:58.074720 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
09:06:58.074962 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
09:06:58.075465 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:06:58.075529 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_exp_type_0000000000 as select trim(customer_id) exp from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 limit 1
  
09:06:58.076175 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
09:06:58.076780 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:06:58.076846 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select replace(udt_name, '_','') dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type_0000000000' and column_name = 'exp'
  
09:06:58.079879 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
09:06:58.080392 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:06:58.080456 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
09:06:58.081340 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
09:06:58.081828 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:06:58.081891 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
09:06:58.082092 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
09:06:58.082571 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:06:58.082634 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_exp_type_0000000000 as select customer_num_attrib exp from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 limit 1
  
09:06:58.083493 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
09:06:58.083979 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:06:58.084042 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select replace(udt_name, '_','') dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type_0000000000' and column_name = 'exp'
  
09:06:58.087206 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
09:06:58.087750 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:06:58.087819 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
09:06:58.088676 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
09:06:58.089200 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:06:58.089269 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
09:06:58.089477 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
09:06:58.089990 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:06:58.090058 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_exp_type_0000000000 as select customer_cat_attrib exp from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 limit 1
  
09:06:58.090923 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
09:06:58.091442 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:06:58.091513 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select replace(udt_name, '_','') dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type_0000000000' and column_name = 'exp'
  
09:06:58.094649 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
09:06:58.095192 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:06:58.095262 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
09:06:58.095904 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
09:06:58.096423 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:06:58.096491 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 as
select  (data_date)::date as date_data, 
        (trim(customer_id))::text as customer_id, 
        (customer_num_attrib)::numeric as num_attrib, 
        (customer_cat_attrib)::text as cat_attrib
        from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000;

  
09:06:58.097862 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
09:06:58.098994 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:06:58.099068 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 cascade;
drop view if exists autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 cascade;

  
09:06:58.099937 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
09:06:58.100425 [info ] [MainThread]: 



create or replace view autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 as
select "data_date"::date as "data_date", 
       "customer_id"::text as "customer_id", 
       "customer_cat_attrib"::text as "customer_cat_attrib", 
       "customer_num_attrib"::numeric as "customer_num_attrib"
       from testsatmap.crm;


create or replace view autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 as
select  (data_date)::date as date_data, 
        (trim(customer_id))::text as customer_id, 
        (customer_num_attrib)::numeric as num_attrib, 
        (customer_cat_attrib)::text as cat_attrib
        from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000;


drop table if exists autopie_ebpdemo.tmp_staging_fact_0000000000;
create table autopie_ebpdemo.tmp_staging_fact_0000000000 as
(
    with expression_extract_1 as
    (
        select * from autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000
    ),
    expression_extract_2 as
    (
        select * from expression_extract_1
    ),
    filter__3 as
    (
        select /* filtering irrelevant records out */ *
        from expression_extract_2
        where 1=1
        and customer_id is not null
    ),
    incremental_extract__4 as
    (
        select /* retrieving incremental data - by date range only */ *
        from filter__3
        where date_data >= to_date('2020-01-01', 'YYYY-MM-DD')
          and date_data  < to_date('2021-01-01', 'YYYY-MM-DD')
    ),
    deduplication__5 as
    (
        select /* deduplicate by strategy */
               customer_id, date_data
               , max(num_attrib) as num_attrib
               , max(cat_attrib) as cat_attrib
        from incremental_extract__4
        group by customer_id, date_data 
    ),
    coarsening_6 as
    (
        select * from deduplication__5
    )
    select  t.*,
            1 autopie_run_id
    from coarsening_6 t
);

drop view if exists autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 cascade;
drop view if exists autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 cascade;


-- check if not exists already, this should run once
do $$                  
begin
if not exists
( 
    select 1 from information_schema.tables 
    where table_schema||'.'|| table_name = 'autopie_ebpdemo.obj_fact_crm'
)
then
    create table autopie_ebpdemo.obj_fact_crm as (select * from autopie_ebpdemo.tmp_staging_fact_0000000000 where 1=0);
    alter  table autopie_ebpdemo.obj_fact_crm add column row_id bigserial not null;
    alter  table autopie_ebpdemo.obj_fact_crm add primary key (customer_id, date_data);
    --
    create index ixrid_obj_fact_crm on autopie_ebpdemo.obj_fact_crm(row_id);
end if;
end
$$;

-- upsert staging additions into the permanent fact object
delete from autopie_ebpdemo.obj_fact_crm where (customer_id, date_data) in (select customer_id, date_data from autopie_ebpdemo.tmp_staging_fact_0000000000);
insert into autopie_ebpdemo.obj_fact_crm select * from autopie_ebpdemo.tmp_staging_fact_0000000000;
drop table autopie_ebpdemo.tmp_staging_fact_0000000000;


09:06:58.100799 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:06:58.100863 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    



create or replace view autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 as
select "data_date"::date as "data_date", 
       "customer_id"::text as "customer_id", 
       "customer_cat_attrib"::text as "customer_cat_attrib", 
       "customer_num_attrib"::numeric as "customer_num_attrib"
       from testsatmap.crm;


create or replace view autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 as
select  (data_date)::date as date_data, 
        (trim(customer_id))::text as customer_id, 
        (customer_num_attrib)::numeric as num_attrib, 
        (customer_cat_attrib)::text as cat_attrib
        from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000;


drop table if exists autopie_ebpdemo.tmp_staging_fact_0000000000;
create table autopie_ebpdemo.tmp_staging_fact_0000000000 as
(
    with expression_extract_1 as
    (
        select * from autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000
    ),
    expression_extract_2 as
    (
        select * from expression_extract_1
    ),
    filter__3 as
    (
        select /* filtering irrelevant records out */ *
        from expression_extract_2
        where 1=1
        and customer_id is not null
    ),
    incremental_extract__4 as
    (
        select /* retrieving incremental data - by date range only */ *
        from filter__3
        where date_data >= to_date('2020-01-01', 'YYYY-MM-DD')
          and date_data  < to_date('2021-01-01', 'YYYY-MM-DD')
    ),
    deduplication__5 as
    (
        select /* deduplicate by strategy */
               customer_id, date_data
               , max(num_attrib) as num_attrib
               , max(cat_attrib) as cat_attrib
        from incremental_extract__4
        group by customer_id, date_data 
    ),
    coarsening_6 as
    (
        select * from deduplication__5
    )
    select  t.*,
            1 autopie_run_id
    from coarsening_6 t
);

drop view if exists autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 cascade;
drop view if exists autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 cascade;


-- check if not exists already, this should run once
do $$                  
begin
if not exists
( 
    select 1 from information_schema.tables 
    where table_schema||'.'|| table_name = 'autopie_ebpdemo.obj_fact_crm'
)
then
    create table autopie_ebpdemo.obj_fact_crm as (select * from autopie_ebpdemo.tmp_staging_fact_0000000000 where 1=0);
    alter  table autopie_ebpdemo.obj_fact_crm add column row_id bigserial not null;
    alter  table autopie_ebpdemo.obj_fact_crm add primary key (customer_id, date_data);
    --
    create index ixrid_obj_fact_crm on autopie_ebpdemo.obj_fact_crm(row_id);
end if;
end
$$;

-- upsert staging additions into the permanent fact object
delete from autopie_ebpdemo.obj_fact_crm where (customer_id, date_data) in (select customer_id, date_data from autopie_ebpdemo.tmp_staging_fact_0000000000);
insert into autopie_ebpdemo.obj_fact_crm select * from autopie_ebpdemo.tmp_staging_fact_0000000000;
drop table autopie_ebpdemo.tmp_staging_fact_0000000000;


  
09:06:58.125770 [debug] [MainThread]: SQL status: DROP TABLE in 0.02 seconds
09:06:58.126501 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:06:58.126590 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    
select row_number() over (order by autopie_run_id desc) run_sequence, count(*) count_records 
  from autopie_ebpdemo.obj_fact_crm
group by autopie_run_id
order by 1 
limit 5;

  
09:06:58.127206 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
09:06:58.127811 [debug] [MainThread]: On macro_run_recipe: Close
09:06:58.128571 [debug] [MainThread]: Connection 'macro_run_recipe' was properly closed.


============================== 2022-02-20 09:06:59.204272 | d4fd4a0b-e51b-4097-a65b-3943fad1260c ==============================
09:06:59.204272 [info ] [MainThread]: Running with dbt=1.0.1
09:06:59.204662 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/hassanzaheer/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, macro='run_recipe', args='{\n    "recipe_type" : "collect_fact",\n    "target_fact" : {\n        "id": "dispositions", \n        "entity_and_dims": "agent_id",\n        "date":"time_disposition_made"\n    },\n    "ingredients": {\n        "expression_extract": {  \n            "source_raw": "testsatmap.calldispositions",\n            "expression_list": [\n                {"expression": "to_timestamp(disposition_epoch)", "alias": "time_disposition_made"},\n                {"expression": "trim(customer_id)",  "alias": "customer_id"},             \n                {"expression": "lower(trim(agent_id))",  "alias": "agent_id"},\n                {"expression": "lower(trim(disp_code))",  "alias": "cat_disposition"}\n            ]\n        },\n        "filter_conjunctions": [\n            "agent_id is not null",\n            "customer_id is not null",\n            "cat_disposition in (\'k\', \'m\', \'a\')"\n        ],\n        "incremental_update_on": "time_disposition_made",\n        "deduplication": {\n            "grouping_key": "agent_id, cat_disposition, time_disposition_made",\n            "preference": "arbitrary"\n        },\n        "coarsening": {\n            "entity_and_dims": "agent_id",\n            "date_expression":"time_disposition_made",\n            "aggregations": [\n                {"expression": "max(customer_id)", "alias": "customer_id"},\n                {"expression": "sum(case when cat_disposition = \'k\' then 1 else 0 end)", "alias": "flg_k_disp_made"},\n                {"expression": "sum(case when cat_disposition = \'m\' then 1 else 0 end)", "alias": "flg_m_disp_made"},\n                {"expression": "sum(case when cat_disposition = \'a\' then 1 else 0 end)", "alias": "flg_a_disp_made"}\n            ]\n        }\n    }\n}', defer=None, state=None, cls=<class 'dbt.task.run_operation.RunOperationTask'>, which='run-operation', rpc_method='run-operation')
09:06:59.204779 [debug] [MainThread]: Tracking: do not track
09:06:59.224637 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 2 files changed.
09:06:59.224899 [debug] [MainThread]: Partial parsing: updated file: demo_autopie://models/demo_ebp_flow/prepared_scripts/phase1_fact_dispositions.sql
09:06:59.225022 [debug] [MainThread]: Partial parsing: updated file: demo_autopie://models/demo_ebp_flow/prepared_scripts/phase1_fact_crm.sql
09:06:59.230452 [debug] [MainThread]: 1699: static parser successfully parsed demo_ebp_flow/prepared_scripts/phase1_fact_dispositions.sql
09:06:59.236337 [debug] [MainThread]: 1699: static parser successfully parsed demo_ebp_flow/prepared_scripts/phase1_fact_crm.sql
09:06:59.243298 [debug] [MainThread]: Acquiring new postgres connection "macro_run_recipe"
09:06:59.243431 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:06:59.243503 [debug] [MainThread]: On macro_run_recipe: BEGIN
09:06:59.243572 [debug] [MainThread]: Opening a new connection, currently in state init
09:06:59.249065 [debug] [MainThread]: SQL status: BEGIN in 0.01 seconds
09:06:59.249151 [debug] [MainThread]: On macro_run_recipe: COMMIT
09:06:59.249209 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:06:59.249265 [debug] [MainThread]: On macro_run_recipe: COMMIT
09:06:59.249611 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
09:06:59.293036 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:06:59.293174 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select '"'||column_name||'"::'||
       case when replace(udt_name, '_','') = 'bit' then 'int'
            when replace(udt_name, '_','') like 'int8%' then 'bigint'
            when replace(udt_name, '_','') like 'int4%' then 'int'
            when replace(udt_name, '_','') like 'int%' then 'smallint'
            when replace(udt_name, '_','') like 'bool%' then 'int'
            when replace(udt_name, '_','') like 'float%' then 'numeric'
            when replace(udt_name, '_','') like 'float%' then 'numeric'
            when replace(udt_name, '_','') like 'byte%' then 'text'
            when replace(udt_name, '_','') like 'varchar%' then 'text'
            when replace(udt_name, '_','') like 'timestamp%' then 'timestamp'
            else replace(udt_name, '_','') end ||
       ' as "'||column_name||'"' select_text
from information_schema.columns 
where table_schema||'.'||table_name = 'testsatmap.calldispositions'
order by ordinal_position ;

  
09:06:59.307109 [debug] [MainThread]: SQL status: SELECT 4 in 0.01 seconds
09:06:59.307970 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:06:59.308052 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 as
select "disposition_epoch"::bigint as "disposition_epoch", 
       "customer_id"::text as "customer_id", 
       "agent_id"::text as "agent_id", 
       "disp_code"::text as "disp_code"
       from testsatmap.calldispositions;

  
09:06:59.310575 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
09:06:59.311093 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:06:59.311161 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
09:06:59.311389 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
09:06:59.311863 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:06:59.311932 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_exp_type_0000000000 as select to_timestamp(disposition_epoch) exp from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 limit 1
  
09:06:59.312920 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
09:06:59.313396 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:06:59.313468 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select replace(udt_name, '_','') dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type_0000000000' and column_name = 'exp'
  
09:06:59.316982 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
09:06:59.317506 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:06:59.317571 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
09:06:59.318617 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
09:06:59.319098 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:06:59.319164 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
09:06:59.319353 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
09:06:59.319824 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:06:59.319888 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_exp_type_0000000000 as select trim(customer_id) exp from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 limit 1
  
09:06:59.320813 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
09:06:59.321405 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:06:59.321476 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select replace(udt_name, '_','') dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type_0000000000' and column_name = 'exp'
  
09:06:59.324594 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
09:06:59.325110 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:06:59.325181 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
09:06:59.325830 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
09:06:59.326324 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:06:59.326392 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
09:06:59.326589 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
09:06:59.327074 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:06:59.327141 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_exp_type_0000000000 as select lower(trim(agent_id)) exp from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 limit 1
  
09:06:59.328257 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
09:06:59.328739 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:06:59.328807 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select replace(udt_name, '_','') dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type_0000000000' and column_name = 'exp'
  
09:06:59.331862 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
09:06:59.332368 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:06:59.332436 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
09:06:59.333137 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
09:06:59.333623 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:06:59.333690 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
09:06:59.333881 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
09:06:59.334355 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:06:59.334422 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_exp_type_0000000000 as select lower(trim(disp_code)) exp from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 limit 1
  
09:06:59.335280 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
09:06:59.335770 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:06:59.335840 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select replace(udt_name, '_','') dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type_0000000000' and column_name = 'exp'
  
09:06:59.339583 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
09:06:59.340123 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:06:59.340199 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
09:06:59.341002 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
09:06:59.341522 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:06:59.341597 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 as
select  (to_timestamp(disposition_epoch))::timestamptz as time_disposition_made, 
        (trim(customer_id))::text as customer_id, 
        (lower(trim(agent_id)))::text as agent_id, 
        (lower(trim(disp_code)))::text as cat_disposition
        from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000;

  
09:06:59.343139 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
09:06:59.344259 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:06:59.344340 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 cascade;
drop view if exists autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 cascade;

  
09:06:59.345841 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
09:06:59.346334 [info ] [MainThread]: 



create or replace view autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 as
select "disposition_epoch"::bigint as "disposition_epoch", 
       "customer_id"::text as "customer_id", 
       "agent_id"::text as "agent_id", 
       "disp_code"::text as "disp_code"
       from testsatmap.calldispositions;


create or replace view autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 as
select  (to_timestamp(disposition_epoch))::timestamptz as time_disposition_made, 
        (trim(customer_id))::text as customer_id, 
        (lower(trim(agent_id)))::text as agent_id, 
        (lower(trim(disp_code)))::text as cat_disposition
        from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000;


drop table if exists autopie_ebpdemo.tmp_staging_fact_0000000000;
create table autopie_ebpdemo.tmp_staging_fact_0000000000 as
(
    with expression_extract_1 as
    (
        select * from autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000
    ),
    expression_extract_2 as
    (
        select * from expression_extract_1
    ),
    filter__3 as
    (
        select /* filtering irrelevant records out */ *
        from expression_extract_2
        where 1=1
        and agent_id is not null
        and customer_id is not null
        and cat_disposition in ('k', 'm', 'a')
    ),
    incremental_extract__4 as
    (
        select /* retrieving incremental data - by date range only */ *
        from filter__3
        where time_disposition_made >= to_date('2020-01-01', 'YYYY-MM-DD')
          and time_disposition_made  < to_date('2021-01-01', 'YYYY-MM-DD')
    ),
    deduplication__5 as
    (
        select /* deduplicate by strategy */
               agent_id, cat_disposition, time_disposition_made
               , max(customer_id) as customer_id
        from incremental_extract__4
        group by agent_id, cat_disposition, time_disposition_made 
    ),
    coarsening_6 as
    (
        select /* flatten all dimensions, fit into EAVT format */
              agent_id
              , time_disposition_made
              
              , max(customer_id) as customer_id
              , sum(case when cat_disposition = 'k' then 1 else 0 end) as flg_k_disp_made
              , sum(case when cat_disposition = 'm' then 1 else 0 end) as flg_m_disp_made
              , sum(case when cat_disposition = 'a' then 1 else 0 end) as flg_a_disp_made
              from deduplication__5
        group by agent_id, time_disposition_made
    )
    select  t.*,
            1 autopie_run_id
    from coarsening_6 t
);

drop view if exists autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 cascade;
drop view if exists autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 cascade;


-- check if not exists already, this should run once
do $$                  
begin
if not exists
( 
    select 1 from information_schema.tables 
    where table_schema||'.'|| table_name = 'autopie_ebpdemo.obj_fact_dispositions'
)
then
    create table autopie_ebpdemo.obj_fact_dispositions as (select * from autopie_ebpdemo.tmp_staging_fact_0000000000 where 1=0);
    alter  table autopie_ebpdemo.obj_fact_dispositions add column row_id bigserial not null;
    alter  table autopie_ebpdemo.obj_fact_dispositions add primary key (agent_id, time_disposition_made);
    --
    create index ixrid_obj_fact_dispositions on autopie_ebpdemo.obj_fact_dispositions(row_id);
end if;
end
$$;

-- upsert staging additions into the permanent fact object
delete from autopie_ebpdemo.obj_fact_dispositions where (agent_id, time_disposition_made) in (select agent_id, time_disposition_made from autopie_ebpdemo.tmp_staging_fact_0000000000);
insert into autopie_ebpdemo.obj_fact_dispositions select * from autopie_ebpdemo.tmp_staging_fact_0000000000;
drop table autopie_ebpdemo.tmp_staging_fact_0000000000;


09:06:59.346743 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:06:59.346812 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    



create or replace view autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 as
select "disposition_epoch"::bigint as "disposition_epoch", 
       "customer_id"::text as "customer_id", 
       "agent_id"::text as "agent_id", 
       "disp_code"::text as "disp_code"
       from testsatmap.calldispositions;


create or replace view autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 as
select  (to_timestamp(disposition_epoch))::timestamptz as time_disposition_made, 
        (trim(customer_id))::text as customer_id, 
        (lower(trim(agent_id)))::text as agent_id, 
        (lower(trim(disp_code)))::text as cat_disposition
        from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000;


drop table if exists autopie_ebpdemo.tmp_staging_fact_0000000000;
create table autopie_ebpdemo.tmp_staging_fact_0000000000 as
(
    with expression_extract_1 as
    (
        select * from autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000
    ),
    expression_extract_2 as
    (
        select * from expression_extract_1
    ),
    filter__3 as
    (
        select /* filtering irrelevant records out */ *
        from expression_extract_2
        where 1=1
        and agent_id is not null
        and customer_id is not null
        and cat_disposition in ('k', 'm', 'a')
    ),
    incremental_extract__4 as
    (
        select /* retrieving incremental data - by date range only */ *
        from filter__3
        where time_disposition_made >= to_date('2020-01-01', 'YYYY-MM-DD')
          and time_disposition_made  < to_date('2021-01-01', 'YYYY-MM-DD')
    ),
    deduplication__5 as
    (
        select /* deduplicate by strategy */
               agent_id, cat_disposition, time_disposition_made
               , max(customer_id) as customer_id
        from incremental_extract__4
        group by agent_id, cat_disposition, time_disposition_made 
    ),
    coarsening_6 as
    (
        select /* flatten all dimensions, fit into EAVT format */
              agent_id
              , time_disposition_made
              
              , max(customer_id) as customer_id
              , sum(case when cat_disposition = 'k' then 1 else 0 end) as flg_k_disp_made
              , sum(case when cat_disposition = 'm' then 1 else 0 end) as flg_m_disp_made
              , sum(case when cat_disposition = 'a' then 1 else 0 end) as flg_a_disp_made
              from deduplication__5
        group by agent_id, time_disposition_made
    )
    select  t.*,
            1 autopie_run_id
    from coarsening_6 t
);

drop view if exists autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 cascade;
drop view if exists autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 cascade;


-- check if not exists already, this should run once
do $$                  
begin
if not exists
( 
    select 1 from information_schema.tables 
    where table_schema||'.'|| table_name = 'autopie_ebpdemo.obj_fact_dispositions'
)
then
    create table autopie_ebpdemo.obj_fact_dispositions as (select * from autopie_ebpdemo.tmp_staging_fact_0000000000 where 1=0);
    alter  table autopie_ebpdemo.obj_fact_dispositions add column row_id bigserial not null;
    alter  table autopie_ebpdemo.obj_fact_dispositions add primary key (agent_id, time_disposition_made);
    --
    create index ixrid_obj_fact_dispositions on autopie_ebpdemo.obj_fact_dispositions(row_id);
end if;
end
$$;

-- upsert staging additions into the permanent fact object
delete from autopie_ebpdemo.obj_fact_dispositions where (agent_id, time_disposition_made) in (select agent_id, time_disposition_made from autopie_ebpdemo.tmp_staging_fact_0000000000);
insert into autopie_ebpdemo.obj_fact_dispositions select * from autopie_ebpdemo.tmp_staging_fact_0000000000;
drop table autopie_ebpdemo.tmp_staging_fact_0000000000;


  
09:06:59.373546 [debug] [MainThread]: SQL status: DROP TABLE in 0.03 seconds
09:06:59.374268 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:06:59.374358 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    
select row_number() over (order by autopie_run_id desc) run_sequence, count(*) count_records 
  from autopie_ebpdemo.obj_fact_dispositions
group by autopie_run_id
order by 1 
limit 5;

  
09:06:59.374980 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
09:06:59.375584 [debug] [MainThread]: On macro_run_recipe: Close
09:06:59.376318 [debug] [MainThread]: Connection 'macro_run_recipe' was properly closed.


============================== 2022-02-20 09:07:00.467558 | fc541a1e-2307-4043-a89a-9234513bb97c ==============================
09:07:00.467558 [info ] [MainThread]: Running with dbt=1.0.1
09:07:00.468015 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/hassanzaheer/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, macro='run_recipe', args='{\n    "recipe_type" : "blend_window",\n    "target_fact" : "calls",\n    "ingredients": {  \n        "window_expression_list": [\n            {"expression":"lead(time_call_start) over (partition by agent_id order by time_call_start)", "alias":"time_agent_next_call", "data_type":"timestamp"},\n            {"expression":"lag(time_call_start) over (partition by agent_id order by time_call_start)", "alias":"time_agent_prev_call", "data_type":"timestamp"}\n        ]\n    }\n}', defer=None, state=None, cls=<class 'dbt.task.run_operation.RunOperationTask'>, which='run-operation', rpc_method='run-operation')
09:07:00.468122 [debug] [MainThread]: Tracking: do not track
09:07:00.488805 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 1 files added, 1 files changed.
09:07:00.489037 [debug] [MainThread]: Partial parsing: added file: demo_autopie://models/demo_ebp_flow/prepared_scripts/phase2__window_next_agent.sql
09:07:00.489172 [debug] [MainThread]: Partial parsing: updated file: demo_autopie://models/demo_ebp_flow/prepared_scripts/phase1_fact_dispositions.sql
09:07:00.494604 [debug] [MainThread]: 1699: static parser successfully parsed demo_ebp_flow/prepared_scripts/phase2__window_next_agent.sql
09:07:00.500223 [debug] [MainThread]: 1699: static parser successfully parsed demo_ebp_flow/prepared_scripts/phase1_fact_dispositions.sql
09:07:00.506573 [debug] [MainThread]: Acquiring new postgres connection "macro_run_recipe"
09:07:00.506699 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:07:00.506766 [debug] [MainThread]: On macro_run_recipe: BEGIN
09:07:00.506827 [debug] [MainThread]: Opening a new connection, currently in state init
09:07:00.510843 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
09:07:00.510935 [debug] [MainThread]: On macro_run_recipe: COMMIT
09:07:00.510999 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:07:00.511056 [debug] [MainThread]: On macro_run_recipe: COMMIT
09:07:00.511176 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
09:07:00.521392 [info ] [MainThread]: 




drop table if exists autopie_ebpdemo.tmp_alter_staging_0000000000;
create table autopie_ebpdemo.tmp_alter_staging_0000000000 as
(
  select  row_id,
          /* calculate window functions on whole fact table - TODO, will optimize this */
          lead(time_call_start) over (partition by agent_id order by time_call_start) as time_agent_next_call, 
          lag(time_call_start) over (partition by agent_id order by time_call_start) as time_agent_prev_call
  from autopie_ebpdemo.obj_fact_calls
);

alter table autopie_ebpdemo.tmp_alter_staging_0000000000 add primary key (row_id);

-- check if not exists already, this should run once
do $$                  
begin
if not exists
( 
  select 1 from information_schema.columns 
  where table_schema||'.'|| table_name = 'autopie_ebpdemo.obj_fact_calls'
  and column_name = 'time_agent_next_call'
)
then
  alter table autopie_ebpdemo.obj_fact_calls add column time_agent_next_call timestamp;
end if;
end
$$;
do $$                  
begin
if not exists
( 
  select 1 from information_schema.columns 
  where table_schema||'.'|| table_name = 'autopie_ebpdemo.obj_fact_calls'
  and column_name = 'time_agent_prev_call'
)
then
  alter table autopie_ebpdemo.obj_fact_calls add column time_agent_prev_call timestamp;
end if;
end
$$;
update autopie_ebpdemo.obj_fact_calls as t
set
    time_agent_next_call = m.time_agent_next_call,
    time_agent_prev_call = m.time_agent_prev_call,
    autopie_run_id = 1
from autopie_ebpdemo.tmp_alter_staging_0000000000 m 
where t.row_id = m.row_id;

drop table autopie_ebpdemo.tmp_alter_staging_0000000000;


09:07:00.524327 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:07:00.524423 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    




drop table if exists autopie_ebpdemo.tmp_alter_staging_0000000000;
create table autopie_ebpdemo.tmp_alter_staging_0000000000 as
(
  select  row_id,
          /* calculate window functions on whole fact table - TODO, will optimize this */
          lead(time_call_start) over (partition by agent_id order by time_call_start) as time_agent_next_call, 
          lag(time_call_start) over (partition by agent_id order by time_call_start) as time_agent_prev_call
  from autopie_ebpdemo.obj_fact_calls
);

alter table autopie_ebpdemo.tmp_alter_staging_0000000000 add primary key (row_id);

-- check if not exists already, this should run once
do $$                  
begin
if not exists
( 
  select 1 from information_schema.columns 
  where table_schema||'.'|| table_name = 'autopie_ebpdemo.obj_fact_calls'
  and column_name = 'time_agent_next_call'
)
then
  alter table autopie_ebpdemo.obj_fact_calls add column time_agent_next_call timestamp;
end if;
end
$$;
do $$                  
begin
if not exists
( 
  select 1 from information_schema.columns 
  where table_schema||'.'|| table_name = 'autopie_ebpdemo.obj_fact_calls'
  and column_name = 'time_agent_prev_call'
)
then
  alter table autopie_ebpdemo.obj_fact_calls add column time_agent_prev_call timestamp;
end if;
end
$$;
update autopie_ebpdemo.obj_fact_calls as t
set
    time_agent_next_call = m.time_agent_next_call,
    time_agent_prev_call = m.time_agent_prev_call,
    autopie_run_id = 1
from autopie_ebpdemo.tmp_alter_staging_0000000000 m 
where t.row_id = m.row_id;

drop table autopie_ebpdemo.tmp_alter_staging_0000000000;


  
09:07:00.547641 [debug] [MainThread]: SQL status: DROP TABLE in 0.02 seconds
09:07:00.548524 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:07:00.548607 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    
select row_number() over (order by autopie_run_id desc) run_sequence, count(*) count_records 
  from autopie_ebpdemo.obj_fact_calls
group by autopie_run_id
order by 1
limit 5;

  
09:07:00.548975 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
09:07:00.549517 [debug] [MainThread]: On macro_run_recipe: Close
09:07:00.550129 [debug] [MainThread]: Connection 'macro_run_recipe' was properly closed.


============================== 2022-02-20 09:07:01.641410 | 06955fd5-a3ac-4b21-9cbf-0dc5bb160d39 ==============================
09:07:01.641410 [info ] [MainThread]: Running with dbt=1.0.1
09:07:01.641804 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/hassanzaheer/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, macro='run_recipe', args='{\n    "recipe_type" : "blend_join",\n    "target_fact" : "calls",\n    "source_fact" : "dispositions",\n    "ingredients": {  \n        "conjunctions": [\n            "s.agent_id = t.agent_id",\n            "s.customer_id = t.customer_id",\n            "date(s.time_disposition_made) = date(t.time_call_start)",\n            "s.time_disposition_made >= t.time_call_start - interval \'120 second\'",\n            "s.time_disposition_made <= t.time_call_end + interval \'120 second\'"\n        ],\n        "match_preferences": [\n            "case when s.time_disposition_made between t.time_call_start and t.time_call_end then 1 else 0 end",\n            "extract(epoch from greatest(s.time_disposition_made - t.time_call_end, t.time_call_start - s.time_disposition_made))::int"\n        ],\n        "matched_expressions": [\n            {"expression": "s.flg_k_disp_made"},\n            {"expression": "s.flg_m_disp_made"},\n            {"expression": "s.flg_a_disp_made"},\n            {"expression": "s.time_disposition_made"}\n        ],\n        "from_source_to_target_mapping": "best",\n        "at_target_choose_sources": "collapse",\n        "target_collapse_aggregations": [\n            {"expression": "max(flg_k_disp_made)", "alias": "flg_k_disp_made"},\n            {"expression": "max(flg_m_disp_made)", "alias": "flg_m_disp_made"},\n            {"expression": "max(flg_a_disp_made)", "alias": "flg_a_disp_made"},\n            {"expression": "min(time_disposition_made)", "alias": "time_first_disposition_made"},\n            {"expression": "max(time_disposition_made)", "alias": "time_last_disposition_made"}\n        ]\n    }\n}', defer=None, state=None, cls=<class 'dbt.task.run_operation.RunOperationTask'>, which='run-operation', rpc_method='run-operation')
09:07:01.641932 [debug] [MainThread]: Tracking: do not track
09:07:01.664211 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 1 files added, 1 files changed.
09:07:01.664459 [debug] [MainThread]: Partial parsing: added file: demo_autopie://models/demo_ebp_flow/prepared_scripts/phase2_join_disp_to_calls.sql
09:07:01.664588 [debug] [MainThread]: Partial parsing: updated file: demo_autopie://models/demo_ebp_flow/prepared_scripts/phase2__window_next_agent.sql
09:07:01.670097 [debug] [MainThread]: 1699: static parser successfully parsed demo_ebp_flow/prepared_scripts/phase2_join_disp_to_calls.sql
09:07:01.675798 [debug] [MainThread]: 1699: static parser successfully parsed demo_ebp_flow/prepared_scripts/phase2__window_next_agent.sql
09:07:01.683019 [debug] [MainThread]: Acquiring new postgres connection "macro_run_recipe"
09:07:01.683162 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:07:01.683230 [debug] [MainThread]: On macro_run_recipe: BEGIN
09:07:01.683294 [debug] [MainThread]: Opening a new connection, currently in state init
09:07:01.688178 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
09:07:01.688287 [debug] [MainThread]: On macro_run_recipe: COMMIT
09:07:01.688346 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:07:01.688400 [debug] [MainThread]: On macro_run_recipe: COMMIT
09:07:01.688521 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
09:07:01.694718 [debug] [MainThread]: Postgres adapter: Error running SQL: macro run_recipe
09:07:01.694826 [debug] [MainThread]: Postgres adapter: Rolling back transaction.
09:07:01.694922 [debug] [MainThread]: On macro_run_recipe: Close
09:07:01.695064 [error] [MainThread]: Encountered an error while running operation: Compilation Error in macro run_recipe (macros/core/run_recipe.sql)
  'compile_recipe_blend_join' is undefined
09:07:01.695245 [debug] [MainThread]: 
09:07:01.695736 [debug] [MainThread]: Connection 'macro_run_recipe' was properly closed.


============================== 2022-02-20 09:07:02.792578 | a75ff26c-33b1-4e27-ab34-f68f1af5763b ==============================
09:07:02.792578 [info ] [MainThread]: Running with dbt=1.0.1
09:07:02.792982 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/hassanzaheer/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, macro='run_recipe', args='{\n    "recipe_type" : "blend_join",\n    "target_fact" : "calls",\n    "source_fact" : "outcomes",\n    "ingredients": {\n        "conjunctions": [\n            "s.customer_id = t.customer_id",\n            "s.date_outcome >= date(t.time_call_start)"\n        ],\n        "match_preferences": [\n            "(date(t.time_call_start) - s.date_outcome)::int",\n            "(date(t.time_call_start) - t.time_call_start)::interval"\n        ],\n        "matched_expressions": [\n            {"expression": "s.sum_outcome_amount"}\n        ],\n        "from_source_to_target_mapping": "best",\n        "at_target_choose_sources": "collapse",\n        "target_collapse_aggregations": [\n            {"expression": "sum(sum_outcome_amount)", "alias": "sum_outcome_amount"}\n        ]\n    }\n}', defer=None, state=None, cls=<class 'dbt.task.run_operation.RunOperationTask'>, which='run-operation', rpc_method='run-operation')
09:07:02.793087 [debug] [MainThread]: Tracking: do not track
09:07:02.814442 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 1 files added, 1 files changed.
09:07:02.814657 [debug] [MainThread]: Partial parsing: added file: demo_autopie://models/demo_ebp_flow/prepared_scripts/phase2_join_outc_to_calls.sql
09:07:02.814788 [debug] [MainThread]: Partial parsing: updated file: demo_autopie://models/demo_ebp_flow/prepared_scripts/phase2_join_disp_to_calls.sql
09:07:02.820471 [debug] [MainThread]: 1699: static parser successfully parsed demo_ebp_flow/prepared_scripts/phase2_join_outc_to_calls.sql
09:07:02.825997 [debug] [MainThread]: 1699: static parser successfully parsed demo_ebp_flow/prepared_scripts/phase2_join_disp_to_calls.sql
09:07:02.832559 [debug] [MainThread]: Acquiring new postgres connection "macro_run_recipe"
09:07:02.832681 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:07:02.832744 [debug] [MainThread]: On macro_run_recipe: BEGIN
09:07:02.832804 [debug] [MainThread]: Opening a new connection, currently in state init
09:07:02.837749 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
09:07:02.837856 [debug] [MainThread]: On macro_run_recipe: COMMIT
09:07:02.837913 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:07:02.837966 [debug] [MainThread]: On macro_run_recipe: COMMIT
09:07:02.838086 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
09:07:02.844086 [debug] [MainThread]: Postgres adapter: Error running SQL: macro run_recipe
09:07:02.844179 [debug] [MainThread]: Postgres adapter: Rolling back transaction.
09:07:02.844257 [debug] [MainThread]: On macro_run_recipe: Close
09:07:02.844394 [error] [MainThread]: Encountered an error while running operation: Compilation Error in macro run_recipe (macros/core/run_recipe.sql)
  'compile_recipe_blend_join' is undefined
09:07:02.844552 [debug] [MainThread]: 
09:07:02.845017 [debug] [MainThread]: Connection 'macro_run_recipe' was properly closed.


============================== 2022-02-20 09:07:22.250401 | 92dfa3bb-bd4e-4a68-a609-771545a34c06 ==============================
09:07:22.250401 [info ] [MainThread]: Running with dbt=1.0.1
09:07:22.250748 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/hassanzaheer/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, macro='run_recipe', args='{\n    "recipe_type" : "collect_fact",\n    "target_fact" : {\n        "id": "calls", \n        "entity_and_dims": "call_id",\n        "date":"time_call_end"\n    },\n    "ingredients": {\n        "expression_extract": {  \n            "source_raw": "testsatmap.calltable",\n            "expression_list": [\n                {"expression": "call_id", "alias": "call_id"},\n                {"expression": "to_timestamp(call_start_epoch)", "alias": "time_call_start"},\n                {"expression": "to_timestamp(call_start_epoch + call_duration)", "alias": "time_call_end"},\n                {"expression": "call_duration", "alias": "num_duration_seconds"},\n                {"expression": "trim(customer_id)",  "alias": "customer_id"},\n                {"expression": "lower(trim(agent_id))",  "alias": "agent_id"}\n            ]\n        },\n        "expression_extract_outer": {  \n            "expression_list": [\n                {"expression": "round(num_duration_seconds/60,2)", "alias": "num_duration_minutes"}\n            ]\n        },\n        "filter_conjunctions": [\n            "agent_id is not null",\n            "customer_id is not null",\n            "num_duration_seconds > 10"\n        ],\n        "incremental_update_on": "time_call_start",\n        "deduplication": {\n            "grouping_key": "call_id",\n            "preference": "arbitrary"\n        }\n    }\n}', defer=None, state=None, cls=<class 'dbt.task.run_operation.RunOperationTask'>, which='run-operation', rpc_method='run-operation')
09:07:22.250852 [debug] [MainThread]: Tracking: do not track
09:07:22.272384 [debug] [MainThread]: Partial parsing enabled: 1 files deleted, 0 files added, 2 files changed.
09:07:22.272554 [debug] [MainThread]: Partial parsing: deleted file: demo_autopie://models/demo_ebp_flow/prepared_scripts/phase2__window_next_agent.sql
09:07:22.272722 [debug] [MainThread]: Partial parsing: updated file: demo_autopie://models/demo_ebp_flow/prepared_scripts/phase2_join_outc_to_calls.sql
09:07:22.272834 [debug] [MainThread]: Partial parsing: updated file: demo_autopie://models/demo_ebp_flow/prepared_scripts/phase1_fact_calls.sql
09:07:22.278220 [debug] [MainThread]: 1699: static parser successfully parsed demo_ebp_flow/prepared_scripts/phase2_join_outc_to_calls.sql
09:07:22.283726 [debug] [MainThread]: 1699: static parser successfully parsed demo_ebp_flow/prepared_scripts/phase1_fact_calls.sql
09:07:22.290084 [debug] [MainThread]: Acquiring new postgres connection "macro_run_recipe"
09:07:22.290190 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:07:22.290257 [debug] [MainThread]: On macro_run_recipe: BEGIN
09:07:22.290316 [debug] [MainThread]: Opening a new connection, currently in state init
09:07:22.311991 [debug] [MainThread]: SQL status: BEGIN in 0.02 seconds
09:07:22.312097 [debug] [MainThread]: On macro_run_recipe: COMMIT
09:07:22.312163 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:07:22.312223 [debug] [MainThread]: On macro_run_recipe: COMMIT
09:07:22.312405 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
09:07:22.356726 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:07:22.356839 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select '"'||column_name||'"::'||
       case when replace(udt_name, '_','') = 'bit' then 'int'
            when replace(udt_name, '_','') like 'int8%' then 'bigint'
            when replace(udt_name, '_','') like 'int4%' then 'int'
            when replace(udt_name, '_','') like 'int%' then 'smallint'
            when replace(udt_name, '_','') like 'bool%' then 'int'
            when replace(udt_name, '_','') like 'float%' then 'numeric'
            when replace(udt_name, '_','') like 'float%' then 'numeric'
            when replace(udt_name, '_','') like 'byte%' then 'text'
            when replace(udt_name, '_','') like 'varchar%' then 'text'
            when replace(udt_name, '_','') like 'timestamp%' then 'timestamp'
            else replace(udt_name, '_','') end ||
       ' as "'||column_name||'"' select_text
from information_schema.columns 
where table_schema||'.'||table_name = 'testsatmap.calltable'
order by ordinal_position ;

  
09:07:22.369460 [debug] [MainThread]: SQL status: SELECT 5 in 0.01 seconds
09:07:22.370387 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:07:22.370469 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 as
select "call_id"::text as "call_id", 
       "call_start_epoch"::bigint as "call_start_epoch", 
       "call_duration"::int as "call_duration", 
       "customer_id"::text as "customer_id", 
       "agent_id"::text as "agent_id"
       from testsatmap.calltable;

  
09:07:22.373633 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
09:07:22.374158 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:07:22.374232 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
09:07:22.374470 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
09:07:22.374938 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:07:22.375003 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_exp_type_0000000000 as select call_id exp from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 limit 1
  
09:07:22.375937 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
09:07:22.376402 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:07:22.376466 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select replace(udt_name, '_','') dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type_0000000000' and column_name = 'exp'
  
09:07:22.379647 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
09:07:22.380129 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:07:22.380192 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
09:07:22.381209 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
09:07:22.381712 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:07:22.381782 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
09:07:22.381984 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
09:07:22.382466 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:07:22.382532 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_exp_type_0000000000 as select to_timestamp(call_start_epoch) exp from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 limit 1
  
09:07:22.383494 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
09:07:22.384096 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:07:22.384164 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select replace(udt_name, '_','') dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type_0000000000' and column_name = 'exp'
  
09:07:22.387682 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
09:07:22.388194 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:07:22.388259 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
09:07:22.388929 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
09:07:22.389415 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:07:22.389478 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
09:07:22.389675 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
09:07:22.390153 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:07:22.390217 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_exp_type_0000000000 as select to_timestamp(call_start_epoch + call_duration) exp from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 limit 1
  
09:07:22.391369 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
09:07:22.391859 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:07:22.391925 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select replace(udt_name, '_','') dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type_0000000000' and column_name = 'exp'
  
09:07:22.395214 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
09:07:22.395731 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:07:22.395796 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
09:07:22.396528 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
09:07:22.397048 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:07:22.397117 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
09:07:22.397324 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
09:07:22.397837 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:07:22.397908 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_exp_type_0000000000 as select call_duration exp from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 limit 1
  
09:07:22.398739 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
09:07:22.399261 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:07:22.399330 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select replace(udt_name, '_','') dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type_0000000000' and column_name = 'exp'
  
09:07:22.402471 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
09:07:22.403019 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:07:22.403089 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
09:07:22.403721 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
09:07:22.404245 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:07:22.404316 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
09:07:22.404668 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
09:07:22.405194 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:07:22.405264 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_exp_type_0000000000 as select trim(customer_id) exp from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 limit 1
  
09:07:22.406383 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
09:07:22.406902 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:07:22.406971 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select replace(udt_name, '_','') dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type_0000000000' and column_name = 'exp'
  
09:07:22.411162 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
09:07:22.411703 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:07:22.411776 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
09:07:22.412602 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
09:07:22.413132 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:07:22.413202 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
09:07:22.413549 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
09:07:22.414061 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:07:22.414131 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_exp_type_0000000000 as select lower(trim(agent_id)) exp from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 limit 1
  
09:07:22.415556 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
09:07:22.416072 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:07:22.416140 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select replace(udt_name, '_','') dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type_0000000000' and column_name = 'exp'
  
09:07:22.420348 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
09:07:22.420883 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:07:22.420953 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
09:07:22.421647 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
09:07:22.422167 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:07:22.422235 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 as
select  (call_id)::text as call_id, 
        (to_timestamp(call_start_epoch))::timestamptz as time_call_start, 
        (to_timestamp(call_start_epoch + call_duration))::timestamptz as time_call_end, 
        (call_duration)::int4 as num_duration_seconds, 
        (trim(customer_id))::text as customer_id, 
        (lower(trim(agent_id)))::text as agent_id
        from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000;

  
09:07:22.423454 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
09:07:22.423977 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:07:22.424045 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
09:07:22.424244 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
09:07:22.424759 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:07:22.424830 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_exp_type_0000000000 as select round(num_duration_seconds/60,2) exp from autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 limit 1
  
09:07:22.426056 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
09:07:22.426582 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:07:22.426653 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select replace(udt_name, '_','') dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type_0000000000' and column_name = 'exp'
  
09:07:22.429761 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
09:07:22.430478 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:07:22.430556 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
09:07:22.431211 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
09:07:22.432821 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:07:22.432897 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 cascade;
drop view if exists autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 cascade;

  
09:07:22.433978 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
09:07:22.434514 [info ] [MainThread]: 



create or replace view autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 as
select "call_id"::text as "call_id", 
       "call_start_epoch"::bigint as "call_start_epoch", 
       "call_duration"::int as "call_duration", 
       "customer_id"::text as "customer_id", 
       "agent_id"::text as "agent_id"
       from testsatmap.calltable;


create or replace view autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 as
select  (call_id)::text as call_id, 
        (to_timestamp(call_start_epoch))::timestamptz as time_call_start, 
        (to_timestamp(call_start_epoch + call_duration))::timestamptz as time_call_end, 
        (call_duration)::int4 as num_duration_seconds, 
        (trim(customer_id))::text as customer_id, 
        (lower(trim(agent_id)))::text as agent_id
        from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000;


drop table if exists autopie_ebpdemo.tmp_staging_fact_0000000000;
create table autopie_ebpdemo.tmp_staging_fact_0000000000 as
(
    with expression_extract_1 as
    (
        select * from autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000
    ),
    expression_extract_2 as
    (
        select  t.*,
                (round(num_duration_seconds/60,2))::numeric as num_duration_minutes
                from expression_extract_1 t
    ),
    filter__3 as
    (
        select /* filtering irrelevant records out */ *
        from expression_extract_2
        where 1=1
        and agent_id is not null
        and customer_id is not null
        and num_duration_seconds > 10
    ),
    incremental_extract__4 as
    (
        select /* retrieving incremental data - by date range only */ *
        from filter__3
        where time_call_start >= to_date('2020-01-01', 'YYYY-MM-DD')
          and time_call_start  < to_date('2021-01-01', 'YYYY-MM-DD')
    ),
    deduplication__5 as
    (
        select /* deduplicate by strategy */
               call_id
               , max(time_call_start) as time_call_start
               , max(time_call_end) as time_call_end
               , max(num_duration_seconds) as num_duration_seconds
               , max(customer_id) as customer_id
               , max(agent_id) as agent_id
               , max(num_duration_minutes) as num_duration_minutes
        from incremental_extract__4
        group by call_id 
    ),
    coarsening_6 as
    (
        select * from deduplication__5
    )
    select  t.*,
            1 autopie_run_id
    from coarsening_6 t
);

drop view if exists autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 cascade;
drop view if exists autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 cascade;


-- check if not exists already, this should run once
do $$                  
begin
if not exists
( 
    select 1 from information_schema.tables 
    where table_schema||'.'|| table_name = 'autopie_ebpdemo.obj_fact_calls'
)
then
    create table autopie_ebpdemo.obj_fact_calls as (select * from autopie_ebpdemo.tmp_staging_fact_0000000000 where 1=0);
    alter  table autopie_ebpdemo.obj_fact_calls add column row_id bigserial not null;
    alter  table autopie_ebpdemo.obj_fact_calls add primary key (call_id, time_call_end);
    --
    create index ixrid_obj_fact_calls on autopie_ebpdemo.obj_fact_calls(row_id);
end if;
end
$$;

-- upsert staging additions into the permanent fact object
delete from autopie_ebpdemo.obj_fact_calls where (call_id, time_call_end) in (select call_id, time_call_end from autopie_ebpdemo.tmp_staging_fact_0000000000);
insert into autopie_ebpdemo.obj_fact_calls select * from autopie_ebpdemo.tmp_staging_fact_0000000000;
drop table autopie_ebpdemo.tmp_staging_fact_0000000000;


09:07:22.434937 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:07:22.435010 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    



create or replace view autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 as
select "call_id"::text as "call_id", 
       "call_start_epoch"::bigint as "call_start_epoch", 
       "call_duration"::int as "call_duration", 
       "customer_id"::text as "customer_id", 
       "agent_id"::text as "agent_id"
       from testsatmap.calltable;


create or replace view autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 as
select  (call_id)::text as call_id, 
        (to_timestamp(call_start_epoch))::timestamptz as time_call_start, 
        (to_timestamp(call_start_epoch + call_duration))::timestamptz as time_call_end, 
        (call_duration)::int4 as num_duration_seconds, 
        (trim(customer_id))::text as customer_id, 
        (lower(trim(agent_id)))::text as agent_id
        from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000;


drop table if exists autopie_ebpdemo.tmp_staging_fact_0000000000;
create table autopie_ebpdemo.tmp_staging_fact_0000000000 as
(
    with expression_extract_1 as
    (
        select * from autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000
    ),
    expression_extract_2 as
    (
        select  t.*,
                (round(num_duration_seconds/60,2))::numeric as num_duration_minutes
                from expression_extract_1 t
    ),
    filter__3 as
    (
        select /* filtering irrelevant records out */ *
        from expression_extract_2
        where 1=1
        and agent_id is not null
        and customer_id is not null
        and num_duration_seconds > 10
    ),
    incremental_extract__4 as
    (
        select /* retrieving incremental data - by date range only */ *
        from filter__3
        where time_call_start >= to_date('2020-01-01', 'YYYY-MM-DD')
          and time_call_start  < to_date('2021-01-01', 'YYYY-MM-DD')
    ),
    deduplication__5 as
    (
        select /* deduplicate by strategy */
               call_id
               , max(time_call_start) as time_call_start
               , max(time_call_end) as time_call_end
               , max(num_duration_seconds) as num_duration_seconds
               , max(customer_id) as customer_id
               , max(agent_id) as agent_id
               , max(num_duration_minutes) as num_duration_minutes
        from incremental_extract__4
        group by call_id 
    ),
    coarsening_6 as
    (
        select * from deduplication__5
    )
    select  t.*,
            1 autopie_run_id
    from coarsening_6 t
);

drop view if exists autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 cascade;
drop view if exists autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 cascade;


-- check if not exists already, this should run once
do $$                  
begin
if not exists
( 
    select 1 from information_schema.tables 
    where table_schema||'.'|| table_name = 'autopie_ebpdemo.obj_fact_calls'
)
then
    create table autopie_ebpdemo.obj_fact_calls as (select * from autopie_ebpdemo.tmp_staging_fact_0000000000 where 1=0);
    alter  table autopie_ebpdemo.obj_fact_calls add column row_id bigserial not null;
    alter  table autopie_ebpdemo.obj_fact_calls add primary key (call_id, time_call_end);
    --
    create index ixrid_obj_fact_calls on autopie_ebpdemo.obj_fact_calls(row_id);
end if;
end
$$;

-- upsert staging additions into the permanent fact object
delete from autopie_ebpdemo.obj_fact_calls where (call_id, time_call_end) in (select call_id, time_call_end from autopie_ebpdemo.tmp_staging_fact_0000000000);
insert into autopie_ebpdemo.obj_fact_calls select * from autopie_ebpdemo.tmp_staging_fact_0000000000;
drop table autopie_ebpdemo.tmp_staging_fact_0000000000;


  
09:07:22.458454 [debug] [MainThread]: SQL status: DROP TABLE in 0.02 seconds
09:07:22.459268 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:07:22.459373 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    
select row_number() over (order by autopie_run_id desc) run_sequence, count(*) count_records 
  from autopie_ebpdemo.obj_fact_calls
group by autopie_run_id
order by 1 
limit 5;

  
09:07:22.460037 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
09:07:22.460704 [debug] [MainThread]: On macro_run_recipe: Close
09:07:22.461507 [debug] [MainThread]: Connection 'macro_run_recipe' was properly closed.


============================== 2022-02-20 09:07:23.535302 | 70616a04-bc1f-47ca-87bb-1b5ae82ab16d ==============================
09:07:23.535302 [info ] [MainThread]: Running with dbt=1.0.1
09:07:23.535702 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/hassanzaheer/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, macro='run_recipe', args='{\n    "recipe_type" : "collect_fact",\n    "target_fact" : {\n        "id": "outcomes", \n        "entity_and_dims": "customer_id",\n        "date":"date_outcome"\n    },\n    "ingredients": {\n        "expression_extract": {  \n            "source_raw": "testsatmap.outcomes",\n            "expression_list": [\n                {"expression": "outcome_date", "alias": "date_outcome"},\n                {"expression": "trim(customer_id)", "alias": "customer_id"},             \n                {"expression": "outcome_code::numeric", "alias": "num_outcome_amount"}\n            ]\n        },\n        "filter_conjunctions": [\n            "num_outcome_amount > 0",\n            "customer_id is not null"\n        ],\n        "incremental_update_on": "date_outcome",\n        "deduplication": {\n            "grouping_key": "customer_id, date_outcome, num_outcome_amount",\n            "preference": "arbitrary"\n        },\n        "coarsening": {\n            "entity_and_dims": "customer_id",\n            "date_expression":"date_outcome",\n            "aggregations": [\n                {"expression": "sum(num_outcome_amount)", "alias": "sum_outcome_amount"}\n            ]\n        }\n    }\n}', defer=None, state=None, cls=<class 'dbt.task.run_operation.RunOperationTask'>, which='run-operation', rpc_method='run-operation')
09:07:23.535821 [debug] [MainThread]: Tracking: do not track
09:07:23.555404 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 2 files changed.
09:07:23.555650 [debug] [MainThread]: Partial parsing: updated file: demo_autopie://models/demo_ebp_flow/prepared_scripts/phase1_fact_outcomes.sql
09:07:23.555773 [debug] [MainThread]: Partial parsing: updated file: demo_autopie://models/demo_ebp_flow/prepared_scripts/phase1_fact_calls.sql
09:07:23.561224 [debug] [MainThread]: 1699: static parser successfully parsed demo_ebp_flow/prepared_scripts/phase1_fact_outcomes.sql
09:07:23.566704 [debug] [MainThread]: 1699: static parser successfully parsed demo_ebp_flow/prepared_scripts/phase1_fact_calls.sql
09:07:23.572990 [debug] [MainThread]: Acquiring new postgres connection "macro_run_recipe"
09:07:23.573097 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:07:23.573160 [debug] [MainThread]: On macro_run_recipe: BEGIN
09:07:23.573223 [debug] [MainThread]: Opening a new connection, currently in state init
09:07:23.578551 [debug] [MainThread]: SQL status: BEGIN in 0.01 seconds
09:07:23.578664 [debug] [MainThread]: On macro_run_recipe: COMMIT
09:07:23.578732 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:07:23.578790 [debug] [MainThread]: On macro_run_recipe: COMMIT
09:07:23.578967 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
09:07:23.622107 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:07:23.622222 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select '"'||column_name||'"::'||
       case when replace(udt_name, '_','') = 'bit' then 'int'
            when replace(udt_name, '_','') like 'int8%' then 'bigint'
            when replace(udt_name, '_','') like 'int4%' then 'int'
            when replace(udt_name, '_','') like 'int%' then 'smallint'
            when replace(udt_name, '_','') like 'bool%' then 'int'
            when replace(udt_name, '_','') like 'float%' then 'numeric'
            when replace(udt_name, '_','') like 'float%' then 'numeric'
            when replace(udt_name, '_','') like 'byte%' then 'text'
            when replace(udt_name, '_','') like 'varchar%' then 'text'
            when replace(udt_name, '_','') like 'timestamp%' then 'timestamp'
            else replace(udt_name, '_','') end ||
       ' as "'||column_name||'"' select_text
from information_schema.columns 
where table_schema||'.'||table_name = 'testsatmap.outcomes'
order by ordinal_position ;

  
09:07:23.636165 [debug] [MainThread]: SQL status: SELECT 3 in 0.01 seconds
09:07:23.636977 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:07:23.637051 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 as
select "outcome_date"::date as "outcome_date", 
       "customer_id"::text as "customer_id", 
       "outcome_code"::text as "outcome_code"
       from testsatmap.outcomes;

  
09:07:23.640217 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
09:07:23.640730 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:07:23.640796 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
09:07:23.641016 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
09:07:23.641501 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:07:23.641565 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_exp_type_0000000000 as select outcome_date exp from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 limit 1
  
09:07:23.642478 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
09:07:23.642953 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:07:23.643015 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select replace(udt_name, '_','') dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type_0000000000' and column_name = 'exp'
  
09:07:23.646292 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
09:07:23.646913 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:07:23.646990 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
09:07:23.648058 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
09:07:23.648578 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:07:23.648646 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
09:07:23.648848 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
09:07:23.649331 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:07:23.649398 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_exp_type_0000000000 as select trim(customer_id) exp from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 limit 1
  
09:07:23.650572 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
09:07:23.651180 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:07:23.651248 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select replace(udt_name, '_','') dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type_0000000000' and column_name = 'exp'
  
09:07:23.655845 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
09:07:23.656363 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:07:23.656429 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
09:07:23.657274 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
09:07:23.657762 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:07:23.657828 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
09:07:23.658064 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
09:07:23.658548 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:07:23.658620 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_exp_type_0000000000 as select outcome_code::numeric exp from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 limit 1
  
09:07:23.659731 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
09:07:23.660212 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:07:23.660281 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select replace(udt_name, '_','') dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type_0000000000' and column_name = 'exp'
  
09:07:23.664453 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
09:07:23.665002 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:07:23.665073 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
09:07:23.665857 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
09:07:23.666385 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:07:23.666457 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 as
select  (outcome_date)::date as date_outcome, 
        (trim(customer_id))::text as customer_id, 
        (outcome_code::numeric)::numeric as num_outcome_amount
        from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000;

  
09:07:23.667730 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
09:07:23.668661 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:07:23.668735 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 cascade;
drop view if exists autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 cascade;

  
09:07:23.669878 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
09:07:23.670368 [info ] [MainThread]: 



create or replace view autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 as
select "outcome_date"::date as "outcome_date", 
       "customer_id"::text as "customer_id", 
       "outcome_code"::text as "outcome_code"
       from testsatmap.outcomes;


create or replace view autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 as
select  (outcome_date)::date as date_outcome, 
        (trim(customer_id))::text as customer_id, 
        (outcome_code::numeric)::numeric as num_outcome_amount
        from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000;


drop table if exists autopie_ebpdemo.tmp_staging_fact_0000000000;
create table autopie_ebpdemo.tmp_staging_fact_0000000000 as
(
    with expression_extract_1 as
    (
        select * from autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000
    ),
    expression_extract_2 as
    (
        select * from expression_extract_1
    ),
    filter__3 as
    (
        select /* filtering irrelevant records out */ *
        from expression_extract_2
        where 1=1
        and num_outcome_amount > 0
        and customer_id is not null
    ),
    incremental_extract__4 as
    (
        select /* retrieving incremental data - by date range only */ *
        from filter__3
        where date_outcome >= to_date('2020-01-01', 'YYYY-MM-DD')
          and date_outcome  < to_date('2021-01-01', 'YYYY-MM-DD')
    ),
    deduplication__5 as
    (
        select /* deduplicate by strategy */
               customer_id, date_outcome, num_outcome_amount
        from incremental_extract__4
        group by customer_id, date_outcome, num_outcome_amount 
    ),
    coarsening_6 as
    (
        select /* flatten all dimensions, fit into EAVT format */
              customer_id
              , date_outcome
              
              , sum(num_outcome_amount) as sum_outcome_amount
              from deduplication__5
        group by customer_id, date_outcome
    )
    select  t.*,
            1 autopie_run_id
    from coarsening_6 t
);

drop view if exists autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 cascade;
drop view if exists autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 cascade;


-- check if not exists already, this should run once
do $$                  
begin
if not exists
( 
    select 1 from information_schema.tables 
    where table_schema||'.'|| table_name = 'autopie_ebpdemo.obj_fact_outcomes'
)
then
    create table autopie_ebpdemo.obj_fact_outcomes as (select * from autopie_ebpdemo.tmp_staging_fact_0000000000 where 1=0);
    alter  table autopie_ebpdemo.obj_fact_outcomes add column row_id bigserial not null;
    alter  table autopie_ebpdemo.obj_fact_outcomes add primary key (customer_id, date_outcome);
    --
    create index ixrid_obj_fact_outcomes on autopie_ebpdemo.obj_fact_outcomes(row_id);
end if;
end
$$;

-- upsert staging additions into the permanent fact object
delete from autopie_ebpdemo.obj_fact_outcomes where (customer_id, date_outcome) in (select customer_id, date_outcome from autopie_ebpdemo.tmp_staging_fact_0000000000);
insert into autopie_ebpdemo.obj_fact_outcomes select * from autopie_ebpdemo.tmp_staging_fact_0000000000;
drop table autopie_ebpdemo.tmp_staging_fact_0000000000;


09:07:23.670743 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:07:23.670808 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    



create or replace view autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 as
select "outcome_date"::date as "outcome_date", 
       "customer_id"::text as "customer_id", 
       "outcome_code"::text as "outcome_code"
       from testsatmap.outcomes;


create or replace view autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 as
select  (outcome_date)::date as date_outcome, 
        (trim(customer_id))::text as customer_id, 
        (outcome_code::numeric)::numeric as num_outcome_amount
        from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000;


drop table if exists autopie_ebpdemo.tmp_staging_fact_0000000000;
create table autopie_ebpdemo.tmp_staging_fact_0000000000 as
(
    with expression_extract_1 as
    (
        select * from autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000
    ),
    expression_extract_2 as
    (
        select * from expression_extract_1
    ),
    filter__3 as
    (
        select /* filtering irrelevant records out */ *
        from expression_extract_2
        where 1=1
        and num_outcome_amount > 0
        and customer_id is not null
    ),
    incremental_extract__4 as
    (
        select /* retrieving incremental data - by date range only */ *
        from filter__3
        where date_outcome >= to_date('2020-01-01', 'YYYY-MM-DD')
          and date_outcome  < to_date('2021-01-01', 'YYYY-MM-DD')
    ),
    deduplication__5 as
    (
        select /* deduplicate by strategy */
               customer_id, date_outcome, num_outcome_amount
        from incremental_extract__4
        group by customer_id, date_outcome, num_outcome_amount 
    ),
    coarsening_6 as
    (
        select /* flatten all dimensions, fit into EAVT format */
              customer_id
              , date_outcome
              
              , sum(num_outcome_amount) as sum_outcome_amount
              from deduplication__5
        group by customer_id, date_outcome
    )
    select  t.*,
            1 autopie_run_id
    from coarsening_6 t
);

drop view if exists autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 cascade;
drop view if exists autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 cascade;


-- check if not exists already, this should run once
do $$                  
begin
if not exists
( 
    select 1 from information_schema.tables 
    where table_schema||'.'|| table_name = 'autopie_ebpdemo.obj_fact_outcomes'
)
then
    create table autopie_ebpdemo.obj_fact_outcomes as (select * from autopie_ebpdemo.tmp_staging_fact_0000000000 where 1=0);
    alter  table autopie_ebpdemo.obj_fact_outcomes add column row_id bigserial not null;
    alter  table autopie_ebpdemo.obj_fact_outcomes add primary key (customer_id, date_outcome);
    --
    create index ixrid_obj_fact_outcomes on autopie_ebpdemo.obj_fact_outcomes(row_id);
end if;
end
$$;

-- upsert staging additions into the permanent fact object
delete from autopie_ebpdemo.obj_fact_outcomes where (customer_id, date_outcome) in (select customer_id, date_outcome from autopie_ebpdemo.tmp_staging_fact_0000000000);
insert into autopie_ebpdemo.obj_fact_outcomes select * from autopie_ebpdemo.tmp_staging_fact_0000000000;
drop table autopie_ebpdemo.tmp_staging_fact_0000000000;


  
09:07:23.695796 [debug] [MainThread]: SQL status: DROP TABLE in 0.02 seconds
09:07:23.696521 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:07:23.696610 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    
select row_number() over (order by autopie_run_id desc) run_sequence, count(*) count_records 
  from autopie_ebpdemo.obj_fact_outcomes
group by autopie_run_id
order by 1 
limit 5;

  
09:07:23.697248 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
09:07:23.698017 [debug] [MainThread]: On macro_run_recipe: Close
09:07:23.698705 [debug] [MainThread]: Connection 'macro_run_recipe' was properly closed.


============================== 2022-02-20 09:07:24.772973 | e6ff8776-4062-42b8-9a56-b5d30b2d8234 ==============================
09:07:24.772973 [info ] [MainThread]: Running with dbt=1.0.1
09:07:24.773330 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/hassanzaheer/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, macro='run_recipe', args='{\n    "recipe_type" : "collect_fact",\n    "target_fact" : {\n        "id": "crm", \n        "entity_and_dims": "customer_id",\n        "date":"date_data"\n    },\n    "ingredients": {\n        "expression_extract": {  \n            "source_raw": "testsatmap.crm",\n            "expression_list": [\n                {"expression": "data_date", "alias": "date_data"},\n                {"expression": "trim(customer_id)",  "alias": "customer_id"},             \n                {"expression": "customer_num_attrib", "alias": "num_attrib"},\n                {"expression": "customer_cat_attrib",  "alias": "cat_attrib"}\n            ]\n        },\n        "filter_conjunctions": [\n            "customer_id is not null"\n        ],\n        "incremental_update_on": "date_data",\n        "deduplication": {\n            "grouping_key": "customer_id, date_data",\n            "preference": "arbitrary"\n        }\n    }\n}', defer=None, state=None, cls=<class 'dbt.task.run_operation.RunOperationTask'>, which='run-operation', rpc_method='run-operation')
09:07:24.773452 [debug] [MainThread]: Tracking: do not track
09:07:24.792803 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 2 files changed.
09:07:24.793059 [debug] [MainThread]: Partial parsing: updated file: demo_autopie://models/demo_ebp_flow/prepared_scripts/phase1_fact_outcomes.sql
09:07:24.793181 [debug] [MainThread]: Partial parsing: updated file: demo_autopie://models/demo_ebp_flow/prepared_scripts/phase1_fact_crm.sql
09:07:24.798592 [debug] [MainThread]: 1699: static parser successfully parsed demo_ebp_flow/prepared_scripts/phase1_fact_outcomes.sql
09:07:24.803941 [debug] [MainThread]: 1699: static parser successfully parsed demo_ebp_flow/prepared_scripts/phase1_fact_crm.sql
09:07:24.810214 [debug] [MainThread]: Acquiring new postgres connection "macro_run_recipe"
09:07:24.810317 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:07:24.810382 [debug] [MainThread]: On macro_run_recipe: BEGIN
09:07:24.810442 [debug] [MainThread]: Opening a new connection, currently in state init
09:07:24.815137 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
09:07:24.815230 [debug] [MainThread]: On macro_run_recipe: COMMIT
09:07:24.815288 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:07:24.815340 [debug] [MainThread]: On macro_run_recipe: COMMIT
09:07:24.815511 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
09:07:24.858471 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:07:24.858589 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select '"'||column_name||'"::'||
       case when replace(udt_name, '_','') = 'bit' then 'int'
            when replace(udt_name, '_','') like 'int8%' then 'bigint'
            when replace(udt_name, '_','') like 'int4%' then 'int'
            when replace(udt_name, '_','') like 'int%' then 'smallint'
            when replace(udt_name, '_','') like 'bool%' then 'int'
            when replace(udt_name, '_','') like 'float%' then 'numeric'
            when replace(udt_name, '_','') like 'float%' then 'numeric'
            when replace(udt_name, '_','') like 'byte%' then 'text'
            when replace(udt_name, '_','') like 'varchar%' then 'text'
            when replace(udt_name, '_','') like 'timestamp%' then 'timestamp'
            else replace(udt_name, '_','') end ||
       ' as "'||column_name||'"' select_text
from information_schema.columns 
where table_schema||'.'||table_name = 'testsatmap.crm'
order by ordinal_position ;

  
09:07:24.872521 [debug] [MainThread]: SQL status: SELECT 4 in 0.01 seconds
09:07:24.873341 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:07:24.873419 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 as
select "data_date"::date as "data_date", 
       "customer_id"::text as "customer_id", 
       "customer_cat_attrib"::text as "customer_cat_attrib", 
       "customer_num_attrib"::numeric as "customer_num_attrib"
       from testsatmap.crm;

  
09:07:24.876742 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
09:07:24.877237 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:07:24.877302 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
09:07:24.877525 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
09:07:24.877987 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:07:24.878050 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_exp_type_0000000000 as select data_date exp from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 limit 1
  
09:07:24.879010 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
09:07:24.879464 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:07:24.879526 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select replace(udt_name, '_','') dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type_0000000000' and column_name = 'exp'
  
09:07:24.882944 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
09:07:24.883468 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:07:24.883542 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
09:07:24.884612 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
09:07:24.885102 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:07:24.885175 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
09:07:24.885378 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
09:07:24.885854 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:07:24.885920 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_exp_type_0000000000 as select trim(customer_id) exp from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 limit 1
  
09:07:24.886843 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
09:07:24.887456 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:07:24.887523 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select replace(udt_name, '_','') dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type_0000000000' and column_name = 'exp'
  
09:07:24.891313 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
09:07:24.891827 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:07:24.891894 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
09:07:24.892738 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
09:07:24.893223 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:07:24.893289 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
09:07:24.893518 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
09:07:24.893996 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:07:24.894062 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_exp_type_0000000000 as select customer_num_attrib exp from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 limit 1
  
09:07:24.895403 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
09:07:24.895889 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:07:24.895956 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select replace(udt_name, '_','') dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type_0000000000' and column_name = 'exp'
  
09:07:24.900255 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
09:07:24.900802 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:07:24.900876 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
09:07:24.901683 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
09:07:24.902203 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:07:24.902274 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
09:07:24.902506 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
09:07:24.903015 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:07:24.903086 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_exp_type_0000000000 as select customer_cat_attrib exp from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 limit 1
  
09:07:24.904136 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
09:07:24.904654 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:07:24.904725 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select replace(udt_name, '_','') dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type_0000000000' and column_name = 'exp'
  
09:07:24.908901 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
09:07:24.909443 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:07:24.909514 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
09:07:24.910316 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
09:07:24.910840 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:07:24.910913 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 as
select  (data_date)::date as date_data, 
        (trim(customer_id))::text as customer_id, 
        (customer_num_attrib)::numeric as num_attrib, 
        (customer_cat_attrib)::text as cat_attrib
        from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000;

  
09:07:24.912589 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
09:07:24.913705 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:07:24.913781 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 cascade;
drop view if exists autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 cascade;

  
09:07:24.914906 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
09:07:24.915390 [info ] [MainThread]: 



create or replace view autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 as
select "data_date"::date as "data_date", 
       "customer_id"::text as "customer_id", 
       "customer_cat_attrib"::text as "customer_cat_attrib", 
       "customer_num_attrib"::numeric as "customer_num_attrib"
       from testsatmap.crm;


create or replace view autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 as
select  (data_date)::date as date_data, 
        (trim(customer_id))::text as customer_id, 
        (customer_num_attrib)::numeric as num_attrib, 
        (customer_cat_attrib)::text as cat_attrib
        from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000;


drop table if exists autopie_ebpdemo.tmp_staging_fact_0000000000;
create table autopie_ebpdemo.tmp_staging_fact_0000000000 as
(
    with expression_extract_1 as
    (
        select * from autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000
    ),
    expression_extract_2 as
    (
        select * from expression_extract_1
    ),
    filter__3 as
    (
        select /* filtering irrelevant records out */ *
        from expression_extract_2
        where 1=1
        and customer_id is not null
    ),
    incremental_extract__4 as
    (
        select /* retrieving incremental data - by date range only */ *
        from filter__3
        where date_data >= to_date('2020-01-01', 'YYYY-MM-DD')
          and date_data  < to_date('2021-01-01', 'YYYY-MM-DD')
    ),
    deduplication__5 as
    (
        select /* deduplicate by strategy */
               customer_id, date_data
               , max(num_attrib) as num_attrib
               , max(cat_attrib) as cat_attrib
        from incremental_extract__4
        group by customer_id, date_data 
    ),
    coarsening_6 as
    (
        select * from deduplication__5
    )
    select  t.*,
            1 autopie_run_id
    from coarsening_6 t
);

drop view if exists autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 cascade;
drop view if exists autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 cascade;


-- check if not exists already, this should run once
do $$                  
begin
if not exists
( 
    select 1 from information_schema.tables 
    where table_schema||'.'|| table_name = 'autopie_ebpdemo.obj_fact_crm'
)
then
    create table autopie_ebpdemo.obj_fact_crm as (select * from autopie_ebpdemo.tmp_staging_fact_0000000000 where 1=0);
    alter  table autopie_ebpdemo.obj_fact_crm add column row_id bigserial not null;
    alter  table autopie_ebpdemo.obj_fact_crm add primary key (customer_id, date_data);
    --
    create index ixrid_obj_fact_crm on autopie_ebpdemo.obj_fact_crm(row_id);
end if;
end
$$;

-- upsert staging additions into the permanent fact object
delete from autopie_ebpdemo.obj_fact_crm where (customer_id, date_data) in (select customer_id, date_data from autopie_ebpdemo.tmp_staging_fact_0000000000);
insert into autopie_ebpdemo.obj_fact_crm select * from autopie_ebpdemo.tmp_staging_fact_0000000000;
drop table autopie_ebpdemo.tmp_staging_fact_0000000000;


09:07:24.915761 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:07:24.915830 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    



create or replace view autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 as
select "data_date"::date as "data_date", 
       "customer_id"::text as "customer_id", 
       "customer_cat_attrib"::text as "customer_cat_attrib", 
       "customer_num_attrib"::numeric as "customer_num_attrib"
       from testsatmap.crm;


create or replace view autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 as
select  (data_date)::date as date_data, 
        (trim(customer_id))::text as customer_id, 
        (customer_num_attrib)::numeric as num_attrib, 
        (customer_cat_attrib)::text as cat_attrib
        from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000;


drop table if exists autopie_ebpdemo.tmp_staging_fact_0000000000;
create table autopie_ebpdemo.tmp_staging_fact_0000000000 as
(
    with expression_extract_1 as
    (
        select * from autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000
    ),
    expression_extract_2 as
    (
        select * from expression_extract_1
    ),
    filter__3 as
    (
        select /* filtering irrelevant records out */ *
        from expression_extract_2
        where 1=1
        and customer_id is not null
    ),
    incremental_extract__4 as
    (
        select /* retrieving incremental data - by date range only */ *
        from filter__3
        where date_data >= to_date('2020-01-01', 'YYYY-MM-DD')
          and date_data  < to_date('2021-01-01', 'YYYY-MM-DD')
    ),
    deduplication__5 as
    (
        select /* deduplicate by strategy */
               customer_id, date_data
               , max(num_attrib) as num_attrib
               , max(cat_attrib) as cat_attrib
        from incremental_extract__4
        group by customer_id, date_data 
    ),
    coarsening_6 as
    (
        select * from deduplication__5
    )
    select  t.*,
            1 autopie_run_id
    from coarsening_6 t
);

drop view if exists autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 cascade;
drop view if exists autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 cascade;


-- check if not exists already, this should run once
do $$                  
begin
if not exists
( 
    select 1 from information_schema.tables 
    where table_schema||'.'|| table_name = 'autopie_ebpdemo.obj_fact_crm'
)
then
    create table autopie_ebpdemo.obj_fact_crm as (select * from autopie_ebpdemo.tmp_staging_fact_0000000000 where 1=0);
    alter  table autopie_ebpdemo.obj_fact_crm add column row_id bigserial not null;
    alter  table autopie_ebpdemo.obj_fact_crm add primary key (customer_id, date_data);
    --
    create index ixrid_obj_fact_crm on autopie_ebpdemo.obj_fact_crm(row_id);
end if;
end
$$;

-- upsert staging additions into the permanent fact object
delete from autopie_ebpdemo.obj_fact_crm where (customer_id, date_data) in (select customer_id, date_data from autopie_ebpdemo.tmp_staging_fact_0000000000);
insert into autopie_ebpdemo.obj_fact_crm select * from autopie_ebpdemo.tmp_staging_fact_0000000000;
drop table autopie_ebpdemo.tmp_staging_fact_0000000000;


  
09:07:24.942577 [debug] [MainThread]: SQL status: DROP TABLE in 0.03 seconds
09:07:24.943268 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:07:24.943356 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    
select row_number() over (order by autopie_run_id desc) run_sequence, count(*) count_records 
  from autopie_ebpdemo.obj_fact_crm
group by autopie_run_id
order by 1 
limit 5;

  
09:07:24.943955 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
09:07:24.944551 [debug] [MainThread]: On macro_run_recipe: Close
09:07:24.945300 [debug] [MainThread]: Connection 'macro_run_recipe' was properly closed.


============================== 2022-02-20 09:07:26.015807 | 40c166c4-4d9b-44e4-920f-7344075701e5 ==============================
09:07:26.015807 [info ] [MainThread]: Running with dbt=1.0.1
09:07:26.016201 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/hassanzaheer/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, macro='run_recipe', args='{\n    "recipe_type" : "collect_fact",\n    "target_fact" : {\n        "id": "dispositions", \n        "entity_and_dims": "agent_id",\n        "date":"time_disposition_made"\n    },\n    "ingredients": {\n        "expression_extract": {  \n            "source_raw": "testsatmap.calldispositions",\n            "expression_list": [\n                {"expression": "to_timestamp(disposition_epoch)", "alias": "time_disposition_made"},\n                {"expression": "trim(customer_id)",  "alias": "customer_id"},             \n                {"expression": "lower(trim(agent_id))",  "alias": "agent_id"},\n                {"expression": "lower(trim(disp_code))",  "alias": "cat_disposition"}\n            ]\n        },\n        "filter_conjunctions": [\n            "agent_id is not null",\n            "customer_id is not null",\n            "cat_disposition in (\'k\', \'m\', \'a\')"\n        ],\n        "incremental_update_on": "time_disposition_made",\n        "deduplication": {\n            "grouping_key": "agent_id, cat_disposition, time_disposition_made",\n            "preference": "arbitrary"\n        },\n        "coarsening": {\n            "entity_and_dims": "agent_id",\n            "date_expression":"time_disposition_made",\n            "aggregations": [\n                {"expression": "max(customer_id)", "alias": "customer_id"},\n                {"expression": "sum(case when cat_disposition = \'k\' then 1 else 0 end)", "alias": "flg_k_disp_made"},\n                {"expression": "sum(case when cat_disposition = \'m\' then 1 else 0 end)", "alias": "flg_m_disp_made"},\n                {"expression": "sum(case when cat_disposition = \'a\' then 1 else 0 end)", "alias": "flg_a_disp_made"}\n            ]\n        }\n    }\n}', defer=None, state=None, cls=<class 'dbt.task.run_operation.RunOperationTask'>, which='run-operation', rpc_method='run-operation')
09:07:26.016324 [debug] [MainThread]: Tracking: do not track
09:07:26.035841 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 2 files changed.
09:07:26.036112 [debug] [MainThread]: Partial parsing: updated file: demo_autopie://models/demo_ebp_flow/prepared_scripts/phase1_fact_dispositions.sql
09:07:26.036234 [debug] [MainThread]: Partial parsing: updated file: demo_autopie://models/demo_ebp_flow/prepared_scripts/phase1_fact_crm.sql
09:07:26.041648 [debug] [MainThread]: 1699: static parser successfully parsed demo_ebp_flow/prepared_scripts/phase1_fact_dispositions.sql
09:07:26.047193 [debug] [MainThread]: 1699: static parser successfully parsed demo_ebp_flow/prepared_scripts/phase1_fact_crm.sql
09:07:26.053520 [debug] [MainThread]: Acquiring new postgres connection "macro_run_recipe"
09:07:26.053625 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:07:26.053691 [debug] [MainThread]: On macro_run_recipe: BEGIN
09:07:26.053749 [debug] [MainThread]: Opening a new connection, currently in state init
09:07:26.058950 [debug] [MainThread]: SQL status: BEGIN in 0.01 seconds
09:07:26.059029 [debug] [MainThread]: On macro_run_recipe: COMMIT
09:07:26.059084 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:07:26.059141 [debug] [MainThread]: On macro_run_recipe: COMMIT
09:07:26.059310 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
09:07:26.102458 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:07:26.102578 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select '"'||column_name||'"::'||
       case when replace(udt_name, '_','') = 'bit' then 'int'
            when replace(udt_name, '_','') like 'int8%' then 'bigint'
            when replace(udt_name, '_','') like 'int4%' then 'int'
            when replace(udt_name, '_','') like 'int%' then 'smallint'
            when replace(udt_name, '_','') like 'bool%' then 'int'
            when replace(udt_name, '_','') like 'float%' then 'numeric'
            when replace(udt_name, '_','') like 'float%' then 'numeric'
            when replace(udt_name, '_','') like 'byte%' then 'text'
            when replace(udt_name, '_','') like 'varchar%' then 'text'
            when replace(udt_name, '_','') like 'timestamp%' then 'timestamp'
            else replace(udt_name, '_','') end ||
       ' as "'||column_name||'"' select_text
from information_schema.columns 
where table_schema||'.'||table_name = 'testsatmap.calldispositions'
order by ordinal_position ;

  
09:07:26.116517 [debug] [MainThread]: SQL status: SELECT 4 in 0.01 seconds
09:07:26.117335 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:07:26.117407 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 as
select "disposition_epoch"::bigint as "disposition_epoch", 
       "customer_id"::text as "customer_id", 
       "agent_id"::text as "agent_id", 
       "disp_code"::text as "disp_code"
       from testsatmap.calldispositions;

  
09:07:26.120058 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
09:07:26.120572 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:07:26.120636 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
09:07:26.120856 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
09:07:26.121332 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:07:26.121394 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_exp_type_0000000000 as select to_timestamp(disposition_epoch) exp from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 limit 1
  
09:07:26.122685 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
09:07:26.123154 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:07:26.123218 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select replace(udt_name, '_','') dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type_0000000000' and column_name = 'exp'
  
09:07:26.126415 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
09:07:26.126906 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:07:26.126972 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
09:07:26.128009 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
09:07:26.128490 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:07:26.128553 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
09:07:26.128744 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
09:07:26.129201 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:07:26.129261 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_exp_type_0000000000 as select trim(customer_id) exp from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 limit 1
  
09:07:26.130188 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
09:07:26.130787 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:07:26.130851 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select replace(udt_name, '_','') dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type_0000000000' and column_name = 'exp'
  
09:07:26.135477 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
09:07:26.136033 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:07:26.136102 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
09:07:26.136947 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
09:07:26.137473 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:07:26.137544 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
09:07:26.137778 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
09:07:26.138298 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:07:26.138366 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_exp_type_0000000000 as select lower(trim(agent_id)) exp from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 limit 1
  
09:07:26.139589 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
09:07:26.140114 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:07:26.140182 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select replace(udt_name, '_','') dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type_0000000000' and column_name = 'exp'
  
09:07:26.144398 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
09:07:26.144937 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:07:26.145008 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
09:07:26.146085 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
09:07:26.146605 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:07:26.146674 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
09:07:26.146906 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
09:07:26.147418 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:07:26.147487 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_exp_type_0000000000 as select lower(trim(disp_code)) exp from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 limit 1
  
09:07:26.148637 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
09:07:26.149148 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:07:26.149217 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select replace(udt_name, '_','') dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type_0000000000' and column_name = 'exp'
  
09:07:26.155145 [debug] [MainThread]: SQL status: SELECT 1 in 0.01 seconds
09:07:26.155696 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:07:26.155765 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
09:07:26.156454 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
09:07:26.156970 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:07:26.157038 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 as
select  (to_timestamp(disposition_epoch))::timestamptz as time_disposition_made, 
        (trim(customer_id))::text as customer_id, 
        (lower(trim(agent_id)))::text as agent_id, 
        (lower(trim(disp_code)))::text as cat_disposition
        from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000;

  
09:07:26.158234 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
09:07:26.159299 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:07:26.159378 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 cascade;
drop view if exists autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 cascade;

  
09:07:26.160495 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
09:07:26.160977 [info ] [MainThread]: 



create or replace view autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 as
select "disposition_epoch"::bigint as "disposition_epoch", 
       "customer_id"::text as "customer_id", 
       "agent_id"::text as "agent_id", 
       "disp_code"::text as "disp_code"
       from testsatmap.calldispositions;


create or replace view autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 as
select  (to_timestamp(disposition_epoch))::timestamptz as time_disposition_made, 
        (trim(customer_id))::text as customer_id, 
        (lower(trim(agent_id)))::text as agent_id, 
        (lower(trim(disp_code)))::text as cat_disposition
        from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000;


drop table if exists autopie_ebpdemo.tmp_staging_fact_0000000000;
create table autopie_ebpdemo.tmp_staging_fact_0000000000 as
(
    with expression_extract_1 as
    (
        select * from autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000
    ),
    expression_extract_2 as
    (
        select * from expression_extract_1
    ),
    filter__3 as
    (
        select /* filtering irrelevant records out */ *
        from expression_extract_2
        where 1=1
        and agent_id is not null
        and customer_id is not null
        and cat_disposition in ('k', 'm', 'a')
    ),
    incremental_extract__4 as
    (
        select /* retrieving incremental data - by date range only */ *
        from filter__3
        where time_disposition_made >= to_date('2020-01-01', 'YYYY-MM-DD')
          and time_disposition_made  < to_date('2021-01-01', 'YYYY-MM-DD')
    ),
    deduplication__5 as
    (
        select /* deduplicate by strategy */
               agent_id, cat_disposition, time_disposition_made
               , max(customer_id) as customer_id
        from incremental_extract__4
        group by agent_id, cat_disposition, time_disposition_made 
    ),
    coarsening_6 as
    (
        select /* flatten all dimensions, fit into EAVT format */
              agent_id
              , time_disposition_made
              
              , max(customer_id) as customer_id
              , sum(case when cat_disposition = 'k' then 1 else 0 end) as flg_k_disp_made
              , sum(case when cat_disposition = 'm' then 1 else 0 end) as flg_m_disp_made
              , sum(case when cat_disposition = 'a' then 1 else 0 end) as flg_a_disp_made
              from deduplication__5
        group by agent_id, time_disposition_made
    )
    select  t.*,
            1 autopie_run_id
    from coarsening_6 t
);

drop view if exists autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 cascade;
drop view if exists autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 cascade;


-- check if not exists already, this should run once
do $$                  
begin
if not exists
( 
    select 1 from information_schema.tables 
    where table_schema||'.'|| table_name = 'autopie_ebpdemo.obj_fact_dispositions'
)
then
    create table autopie_ebpdemo.obj_fact_dispositions as (select * from autopie_ebpdemo.tmp_staging_fact_0000000000 where 1=0);
    alter  table autopie_ebpdemo.obj_fact_dispositions add column row_id bigserial not null;
    alter  table autopie_ebpdemo.obj_fact_dispositions add primary key (agent_id, time_disposition_made);
    --
    create index ixrid_obj_fact_dispositions on autopie_ebpdemo.obj_fact_dispositions(row_id);
end if;
end
$$;

-- upsert staging additions into the permanent fact object
delete from autopie_ebpdemo.obj_fact_dispositions where (agent_id, time_disposition_made) in (select agent_id, time_disposition_made from autopie_ebpdemo.tmp_staging_fact_0000000000);
insert into autopie_ebpdemo.obj_fact_dispositions select * from autopie_ebpdemo.tmp_staging_fact_0000000000;
drop table autopie_ebpdemo.tmp_staging_fact_0000000000;


09:07:26.161378 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:07:26.161445 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    



create or replace view autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 as
select "disposition_epoch"::bigint as "disposition_epoch", 
       "customer_id"::text as "customer_id", 
       "agent_id"::text as "agent_id", 
       "disp_code"::text as "disp_code"
       from testsatmap.calldispositions;


create or replace view autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 as
select  (to_timestamp(disposition_epoch))::timestamptz as time_disposition_made, 
        (trim(customer_id))::text as customer_id, 
        (lower(trim(agent_id)))::text as agent_id, 
        (lower(trim(disp_code)))::text as cat_disposition
        from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000;


drop table if exists autopie_ebpdemo.tmp_staging_fact_0000000000;
create table autopie_ebpdemo.tmp_staging_fact_0000000000 as
(
    with expression_extract_1 as
    (
        select * from autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000
    ),
    expression_extract_2 as
    (
        select * from expression_extract_1
    ),
    filter__3 as
    (
        select /* filtering irrelevant records out */ *
        from expression_extract_2
        where 1=1
        and agent_id is not null
        and customer_id is not null
        and cat_disposition in ('k', 'm', 'a')
    ),
    incremental_extract__4 as
    (
        select /* retrieving incremental data - by date range only */ *
        from filter__3
        where time_disposition_made >= to_date('2020-01-01', 'YYYY-MM-DD')
          and time_disposition_made  < to_date('2021-01-01', 'YYYY-MM-DD')
    ),
    deduplication__5 as
    (
        select /* deduplicate by strategy */
               agent_id, cat_disposition, time_disposition_made
               , max(customer_id) as customer_id
        from incremental_extract__4
        group by agent_id, cat_disposition, time_disposition_made 
    ),
    coarsening_6 as
    (
        select /* flatten all dimensions, fit into EAVT format */
              agent_id
              , time_disposition_made
              
              , max(customer_id) as customer_id
              , sum(case when cat_disposition = 'k' then 1 else 0 end) as flg_k_disp_made
              , sum(case when cat_disposition = 'm' then 1 else 0 end) as flg_m_disp_made
              , sum(case when cat_disposition = 'a' then 1 else 0 end) as flg_a_disp_made
              from deduplication__5
        group by agent_id, time_disposition_made
    )
    select  t.*,
            1 autopie_run_id
    from coarsening_6 t
);

drop view if exists autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 cascade;
drop view if exists autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 cascade;


-- check if not exists already, this should run once
do $$                  
begin
if not exists
( 
    select 1 from information_schema.tables 
    where table_schema||'.'|| table_name = 'autopie_ebpdemo.obj_fact_dispositions'
)
then
    create table autopie_ebpdemo.obj_fact_dispositions as (select * from autopie_ebpdemo.tmp_staging_fact_0000000000 where 1=0);
    alter  table autopie_ebpdemo.obj_fact_dispositions add column row_id bigserial not null;
    alter  table autopie_ebpdemo.obj_fact_dispositions add primary key (agent_id, time_disposition_made);
    --
    create index ixrid_obj_fact_dispositions on autopie_ebpdemo.obj_fact_dispositions(row_id);
end if;
end
$$;

-- upsert staging additions into the permanent fact object
delete from autopie_ebpdemo.obj_fact_dispositions where (agent_id, time_disposition_made) in (select agent_id, time_disposition_made from autopie_ebpdemo.tmp_staging_fact_0000000000);
insert into autopie_ebpdemo.obj_fact_dispositions select * from autopie_ebpdemo.tmp_staging_fact_0000000000;
drop table autopie_ebpdemo.tmp_staging_fact_0000000000;


  
09:07:26.187378 [debug] [MainThread]: SQL status: DROP TABLE in 0.03 seconds
09:07:26.188124 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:07:26.188216 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    
select row_number() over (order by autopie_run_id desc) run_sequence, count(*) count_records 
  from autopie_ebpdemo.obj_fact_dispositions
group by autopie_run_id
order by 1 
limit 5;

  
09:07:26.188780 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
09:07:26.189387 [debug] [MainThread]: On macro_run_recipe: Close
09:07:26.190117 [debug] [MainThread]: Connection 'macro_run_recipe' was properly closed.


============================== 2022-02-20 09:07:27.272645 | 101f1cf5-651b-49eb-a14a-df27bca960ac ==============================
09:07:27.272645 [info ] [MainThread]: Running with dbt=1.0.1
09:07:27.272991 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/hassanzaheer/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, macro='run_recipe', args='{\n    "recipe_type" : "blend_window",\n    "target_fact" : "calls",\n    "ingredients": {  \n        "window_expression_list": [\n            {"expression":"lead(time_call_start) over (partition by agent_id order by time_call_start)", "alias":"time_agent_next_call", "data_type":"timestamp"},\n            {"expression":"lag(time_call_start) over (partition by agent_id order by time_call_start)", "alias":"time_agent_prev_call", "data_type":"timestamp"}\n        ]\n    }\n}', defer=None, state=None, cls=<class 'dbt.task.run_operation.RunOperationTask'>, which='run-operation', rpc_method='run-operation')
09:07:27.273102 [debug] [MainThread]: Tracking: do not track
09:07:27.293461 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 1 files added, 1 files changed.
09:07:27.293712 [debug] [MainThread]: Partial parsing: added file: demo_autopie://models/demo_ebp_flow/prepared_scripts/phase2_window_next_agent.sql
09:07:27.293845 [debug] [MainThread]: Partial parsing: updated file: demo_autopie://models/demo_ebp_flow/prepared_scripts/phase1_fact_dispositions.sql
09:07:27.299332 [debug] [MainThread]: 1699: static parser successfully parsed demo_ebp_flow/prepared_scripts/phase2_window_next_agent.sql
09:07:27.304957 [debug] [MainThread]: 1699: static parser successfully parsed demo_ebp_flow/prepared_scripts/phase1_fact_dispositions.sql
09:07:27.311448 [debug] [MainThread]: Acquiring new postgres connection "macro_run_recipe"
09:07:27.311562 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:07:27.311631 [debug] [MainThread]: On macro_run_recipe: BEGIN
09:07:27.311690 [debug] [MainThread]: Opening a new connection, currently in state init
09:07:27.315385 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
09:07:27.315476 [debug] [MainThread]: On macro_run_recipe: COMMIT
09:07:27.315533 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:07:27.315588 [debug] [MainThread]: On macro_run_recipe: COMMIT
09:07:27.315710 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
09:07:27.325943 [info ] [MainThread]: 




drop table if exists autopie_ebpdemo.tmp_alter_staging_0000000000;
create table autopie_ebpdemo.tmp_alter_staging_0000000000 as
(
  select  row_id,
          /* calculate window functions on whole fact table - TODO, will optimize this */
          lead(time_call_start) over (partition by agent_id order by time_call_start) as time_agent_next_call, 
          lag(time_call_start) over (partition by agent_id order by time_call_start) as time_agent_prev_call
  from autopie_ebpdemo.obj_fact_calls
);

alter table autopie_ebpdemo.tmp_alter_staging_0000000000 add primary key (row_id);

-- check if not exists already, this should run once
do $$                  
begin
if not exists
( 
  select 1 from information_schema.columns 
  where table_schema||'.'|| table_name = 'autopie_ebpdemo.obj_fact_calls'
  and column_name = 'time_agent_next_call'
)
then
  alter table autopie_ebpdemo.obj_fact_calls add column time_agent_next_call timestamp;
end if;
end
$$;
do $$                  
begin
if not exists
( 
  select 1 from information_schema.columns 
  where table_schema||'.'|| table_name = 'autopie_ebpdemo.obj_fact_calls'
  and column_name = 'time_agent_prev_call'
)
then
  alter table autopie_ebpdemo.obj_fact_calls add column time_agent_prev_call timestamp;
end if;
end
$$;
update autopie_ebpdemo.obj_fact_calls as t
set
    time_agent_next_call = m.time_agent_next_call,
    time_agent_prev_call = m.time_agent_prev_call,
    autopie_run_id = 1
from autopie_ebpdemo.tmp_alter_staging_0000000000 m 
where t.row_id = m.row_id;

drop table autopie_ebpdemo.tmp_alter_staging_0000000000;


09:07:27.328912 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:07:27.329012 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    




drop table if exists autopie_ebpdemo.tmp_alter_staging_0000000000;
create table autopie_ebpdemo.tmp_alter_staging_0000000000 as
(
  select  row_id,
          /* calculate window functions on whole fact table - TODO, will optimize this */
          lead(time_call_start) over (partition by agent_id order by time_call_start) as time_agent_next_call, 
          lag(time_call_start) over (partition by agent_id order by time_call_start) as time_agent_prev_call
  from autopie_ebpdemo.obj_fact_calls
);

alter table autopie_ebpdemo.tmp_alter_staging_0000000000 add primary key (row_id);

-- check if not exists already, this should run once
do $$                  
begin
if not exists
( 
  select 1 from information_schema.columns 
  where table_schema||'.'|| table_name = 'autopie_ebpdemo.obj_fact_calls'
  and column_name = 'time_agent_next_call'
)
then
  alter table autopie_ebpdemo.obj_fact_calls add column time_agent_next_call timestamp;
end if;
end
$$;
do $$                  
begin
if not exists
( 
  select 1 from information_schema.columns 
  where table_schema||'.'|| table_name = 'autopie_ebpdemo.obj_fact_calls'
  and column_name = 'time_agent_prev_call'
)
then
  alter table autopie_ebpdemo.obj_fact_calls add column time_agent_prev_call timestamp;
end if;
end
$$;
update autopie_ebpdemo.obj_fact_calls as t
set
    time_agent_next_call = m.time_agent_next_call,
    time_agent_prev_call = m.time_agent_prev_call,
    autopie_run_id = 1
from autopie_ebpdemo.tmp_alter_staging_0000000000 m 
where t.row_id = m.row_id;

drop table autopie_ebpdemo.tmp_alter_staging_0000000000;


  
09:07:27.354718 [debug] [MainThread]: SQL status: DROP TABLE in 0.03 seconds
09:07:27.355608 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:07:27.355696 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    
select row_number() over (order by autopie_run_id desc) run_sequence, count(*) count_records 
  from autopie_ebpdemo.obj_fact_calls
group by autopie_run_id
order by 1
limit 5;

  
09:07:27.356352 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
09:07:27.356873 [debug] [MainThread]: On macro_run_recipe: Close
09:07:27.357468 [debug] [MainThread]: Connection 'macro_run_recipe' was properly closed.


============================== 2022-02-20 09:07:28.446482 | 06a88a2e-784c-4442-a0c4-7ec1465046ad ==============================
09:07:28.446482 [info ] [MainThread]: Running with dbt=1.0.1
09:07:28.446846 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/hassanzaheer/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, macro='run_recipe', args='{\n    "recipe_type" : "blend_join",\n    "target_fact" : "calls",\n    "source_fact" : "dispositions",\n    "ingredients": {  \n        "conjunctions": [\n            "s.agent_id = t.agent_id",\n            "s.customer_id = t.customer_id",\n            "date(s.time_disposition_made) = date(t.time_call_start)",\n            "s.time_disposition_made >= t.time_call_start - interval \'120 second\'",\n            "s.time_disposition_made <= t.time_call_end + interval \'120 second\'"\n        ],\n        "match_preferences": [\n            "case when s.time_disposition_made between t.time_call_start and t.time_call_end then 1 else 0 end",\n            "extract(epoch from greatest(s.time_disposition_made - t.time_call_end, t.time_call_start - s.time_disposition_made))::int"\n        ],\n        "matched_expressions": [\n            {"expression": "s.flg_k_disp_made"},\n            {"expression": "s.flg_m_disp_made"},\n            {"expression": "s.flg_a_disp_made"},\n            {"expression": "s.time_disposition_made"}\n        ],\n        "from_source_to_target_mapping": "best",\n        "at_target_choose_sources": "collapse",\n        "target_collapse_aggregations": [\n            {"expression": "max(flg_k_disp_made)", "alias": "flg_k_disp_made"},\n            {"expression": "max(flg_m_disp_made)", "alias": "flg_m_disp_made"},\n            {"expression": "max(flg_a_disp_made)", "alias": "flg_a_disp_made"},\n            {"expression": "min(time_disposition_made)", "alias": "time_first_disposition_made"},\n            {"expression": "max(time_disposition_made)", "alias": "time_last_disposition_made"}\n        ]\n    }\n}', defer=None, state=None, cls=<class 'dbt.task.run_operation.RunOperationTask'>, which='run-operation', rpc_method='run-operation')
09:07:28.446952 [debug] [MainThread]: Tracking: do not track
09:07:28.467189 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 2 files changed.
09:07:28.467459 [debug] [MainThread]: Partial parsing: updated file: demo_autopie://models/demo_ebp_flow/prepared_scripts/phase2_window_next_agent.sql
09:07:28.467577 [debug] [MainThread]: Partial parsing: updated file: demo_autopie://models/demo_ebp_flow/prepared_scripts/phase2_join_disp_to_calls.sql
09:07:28.473170 [debug] [MainThread]: 1699: static parser successfully parsed demo_ebp_flow/prepared_scripts/phase2_window_next_agent.sql
09:07:28.479061 [debug] [MainThread]: 1699: static parser successfully parsed demo_ebp_flow/prepared_scripts/phase2_join_disp_to_calls.sql
09:07:28.486357 [debug] [MainThread]: Acquiring new postgres connection "macro_run_recipe"
09:07:28.486493 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:07:28.486564 [debug] [MainThread]: On macro_run_recipe: BEGIN
09:07:28.486629 [debug] [MainThread]: Opening a new connection, currently in state init
09:07:28.491707 [debug] [MainThread]: SQL status: BEGIN in 0.01 seconds
09:07:28.491789 [debug] [MainThread]: On macro_run_recipe: COMMIT
09:07:28.491846 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:07:28.491900 [debug] [MainThread]: On macro_run_recipe: COMMIT
09:07:28.492058 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
09:07:28.498167 [debug] [MainThread]: Postgres adapter: Error running SQL: macro run_recipe
09:07:28.498269 [debug] [MainThread]: Postgres adapter: Rolling back transaction.
09:07:28.498347 [debug] [MainThread]: On macro_run_recipe: Close
09:07:28.498480 [error] [MainThread]: Encountered an error while running operation: Compilation Error in macro run_recipe (macros/core/run_recipe.sql)
  'compile_recipe_blend_join' is undefined
09:07:28.498653 [debug] [MainThread]: 
09:07:28.499108 [debug] [MainThread]: Connection 'macro_run_recipe' was properly closed.


============================== 2022-02-20 09:07:29.574196 | f08345ff-31eb-455c-9da7-0c582ee43e16 ==============================
09:07:29.574196 [info ] [MainThread]: Running with dbt=1.0.1
09:07:29.574553 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/hassanzaheer/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, macro='run_recipe', args='{\n    "recipe_type" : "blend_join",\n    "target_fact" : "calls",\n    "source_fact" : "outcomes",\n    "ingredients": {\n        "conjunctions": [\n            "s.customer_id = t.customer_id",\n            "s.date_outcome >= date(t.time_call_start)"\n        ],\n        "match_preferences": [\n            "(date(t.time_call_start) - s.date_outcome)::int",\n            "(date(t.time_call_start) - t.time_call_start)::interval"\n        ],\n        "matched_expressions": [\n            {"expression": "s.sum_outcome_amount"}\n        ],\n        "from_source_to_target_mapping": "best",\n        "at_target_choose_sources": "collapse",\n        "target_collapse_aggregations": [\n            {"expression": "sum(sum_outcome_amount)", "alias": "sum_outcome_amount"}\n        ]\n    }\n}', defer=None, state=None, cls=<class 'dbt.task.run_operation.RunOperationTask'>, which='run-operation', rpc_method='run-operation')
09:07:29.574663 [debug] [MainThread]: Tracking: do not track
09:07:29.594446 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 2 files changed.
09:07:29.594714 [debug] [MainThread]: Partial parsing: updated file: demo_autopie://models/demo_ebp_flow/prepared_scripts/phase2_join_disp_to_calls.sql
09:07:29.594842 [debug] [MainThread]: Partial parsing: updated file: demo_autopie://models/demo_ebp_flow/prepared_scripts/phase2_join_outc_to_calls.sql
09:07:29.600306 [debug] [MainThread]: 1699: static parser successfully parsed demo_ebp_flow/prepared_scripts/phase2_join_disp_to_calls.sql
09:07:29.606029 [debug] [MainThread]: 1699: static parser successfully parsed demo_ebp_flow/prepared_scripts/phase2_join_outc_to_calls.sql
09:07:29.613074 [debug] [MainThread]: Acquiring new postgres connection "macro_run_recipe"
09:07:29.613220 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:07:29.613285 [debug] [MainThread]: On macro_run_recipe: BEGIN
09:07:29.613348 [debug] [MainThread]: Opening a new connection, currently in state init
09:07:29.624880 [debug] [MainThread]: SQL status: BEGIN in 0.01 seconds
09:07:29.624986 [debug] [MainThread]: On macro_run_recipe: COMMIT
09:07:29.625052 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:07:29.625108 [debug] [MainThread]: On macro_run_recipe: COMMIT
09:07:29.625263 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
09:07:29.631794 [debug] [MainThread]: Postgres adapter: Error running SQL: macro run_recipe
09:07:29.631893 [debug] [MainThread]: Postgres adapter: Rolling back transaction.
09:07:29.631974 [debug] [MainThread]: On macro_run_recipe: Close
09:07:29.632117 [error] [MainThread]: Encountered an error while running operation: Compilation Error in macro run_recipe (macros/core/run_recipe.sql)
  'compile_recipe_blend_join' is undefined
09:07:29.632284 [debug] [MainThread]: 
09:07:29.632745 [debug] [MainThread]: Connection 'macro_run_recipe' was properly closed.


============================== 2022-02-20 09:09:19.412992 | 8ace1db1-fd99-4a60-a1e4-821959bd66a0 ==============================
09:09:19.412992 [info ] [MainThread]: Running with dbt=1.0.1
09:09:19.413403 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/hassanzaheer/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, macro='run_recipe', args='{\n    "recipe_type" : "collect_fact",\n    "target_fact" : {\n        "id": "calls", \n        "entity_and_dims": "call_id",\n        "date":"time_call_end"\n    },\n    "ingredients": {\n        "expression_extract": {  \n            "source_raw": "testsatmap.calltable",\n            "expression_list": [\n                {"expression": "call_id", "alias": "call_id"},\n                {"expression": "to_timestamp(call_start_epoch)", "alias": "time_call_start"},\n                {"expression": "to_timestamp(call_start_epoch + call_duration)", "alias": "time_call_end"},\n                {"expression": "call_duration", "alias": "num_duration_seconds"},\n                {"expression": "trim(customer_id)",  "alias": "customer_id"},\n                {"expression": "lower(trim(agent_id))",  "alias": "agent_id"}\n            ]\n        },\n        "expression_extract_outer": {  \n            "expression_list": [\n                {"expression": "round(num_duration_seconds/60,2)", "alias": "num_duration_minutes"}\n            ]\n        },\n        "filter_conjunctions": [\n            "agent_id is not null",\n            "customer_id is not null",\n            "num_duration_seconds > 10"\n        ],\n        "incremental_update_on": "time_call_start",\n        "deduplication": {\n            "grouping_key": "call_id",\n            "preference": "arbitrary"\n        }\n    }\n}', defer=None, state=None, cls=<class 'dbt.task.run_operation.RunOperationTask'>, which='run-operation', rpc_method='run-operation')
09:09:19.413531 [debug] [MainThread]: Tracking: do not track
09:09:19.434281 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 1 files added, 2 files changed.
09:09:19.434502 [debug] [MainThread]: Partial parsing: added file: demo_autopie://macros/compile_recipes/compile_recipe_blend_join.sql
09:09:19.434638 [debug] [MainThread]: Partial parsing: updated file: demo_autopie://models/demo_ebp_flow/prepared_scripts/phase1_fact_calls.sql
09:09:19.434780 [debug] [MainThread]: Partial parsing: updated file: demo_autopie://models/demo_ebp_flow/prepared_scripts/phase2_join_outc_to_calls.sql
09:09:19.434861 [debug] [MainThread]: Parsing macros/compile_recipes/compile_recipe_blend_join.sql
09:09:19.464921 [debug] [MainThread]: 1699: static parser successfully parsed demo_ebp_flow/prepared_scripts/phase1_fact_calls.sql
09:09:19.469962 [debug] [MainThread]: 1699: static parser successfully parsed demo_ebp_flow/prepared_scripts/phase2_join_outc_to_calls.sql
09:09:19.476285 [debug] [MainThread]: Acquiring new postgres connection "macro_run_recipe"
09:09:19.476389 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:09:19.476455 [debug] [MainThread]: On macro_run_recipe: BEGIN
09:09:19.476516 [debug] [MainThread]: Opening a new connection, currently in state init
09:09:19.499697 [debug] [MainThread]: SQL status: BEGIN in 0.02 seconds
09:09:19.499819 [debug] [MainThread]: On macro_run_recipe: COMMIT
09:09:19.499892 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:09:19.499956 [debug] [MainThread]: On macro_run_recipe: COMMIT
09:09:19.500092 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
09:09:19.545096 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:09:19.545217 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select '"'||column_name||'"::'||
       case when replace(udt_name, '_','') = 'bit' then 'int'
            when replace(udt_name, '_','') like 'int8%' then 'bigint'
            when replace(udt_name, '_','') like 'int4%' then 'int'
            when replace(udt_name, '_','') like 'int%' then 'smallint'
            when replace(udt_name, '_','') like 'bool%' then 'int'
            when replace(udt_name, '_','') like 'float%' then 'numeric'
            when replace(udt_name, '_','') like 'float%' then 'numeric'
            when replace(udt_name, '_','') like 'byte%' then 'text'
            when replace(udt_name, '_','') like 'varchar%' then 'text'
            when replace(udt_name, '_','') like 'timestamp%' then 'timestamp'
            else replace(udt_name, '_','') end ||
       ' as "'||column_name||'"' select_text
from information_schema.columns 
where table_schema||'.'||table_name = 'testsatmap.calltable'
order by ordinal_position ;

  
09:09:19.558580 [debug] [MainThread]: SQL status: SELECT 5 in 0.01 seconds
09:09:19.559469 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:09:19.559546 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 as
select "call_id"::text as "call_id", 
       "call_start_epoch"::bigint as "call_start_epoch", 
       "call_duration"::int as "call_duration", 
       "customer_id"::text as "customer_id", 
       "agent_id"::text as "agent_id"
       from testsatmap.calltable;

  
09:09:19.562632 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
09:09:19.563146 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:09:19.563223 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
09:09:19.563452 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
09:09:19.563913 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:09:19.563984 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_exp_type_0000000000 as select call_id exp from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 limit 1
  
09:09:19.564996 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
09:09:19.565460 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:09:19.565529 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select replace(udt_name, '_','') dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type_0000000000' and column_name = 'exp'
  
09:09:19.569091 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
09:09:19.569574 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:09:19.569639 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
09:09:19.570740 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
09:09:19.571227 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:09:19.571293 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
09:09:19.571497 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
09:09:19.571977 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:09:19.572043 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_exp_type_0000000000 as select to_timestamp(call_start_epoch) exp from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 limit 1
  
09:09:19.573230 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
09:09:19.573834 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:09:19.573902 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select replace(udt_name, '_','') dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type_0000000000' and column_name = 'exp'
  
09:09:19.577191 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
09:09:19.577706 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:09:19.577772 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
09:09:19.578486 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
09:09:19.578973 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:09:19.579039 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
09:09:19.579234 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
09:09:19.579714 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:09:19.579780 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_exp_type_0000000000 as select to_timestamp(call_start_epoch + call_duration) exp from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 limit 1
  
09:09:19.580727 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
09:09:19.581208 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:09:19.581276 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select replace(udt_name, '_','') dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type_0000000000' and column_name = 'exp'
  
09:09:19.584361 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
09:09:19.584864 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:09:19.584930 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
09:09:19.585578 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
09:09:19.586087 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:09:19.586157 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
09:09:19.586361 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
09:09:19.586880 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:09:19.586950 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_exp_type_0000000000 as select call_duration exp from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 limit 1
  
09:09:19.587774 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
09:09:19.588291 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:09:19.588361 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select replace(udt_name, '_','') dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type_0000000000' and column_name = 'exp'
  
09:09:19.591441 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
09:09:19.591983 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:09:19.592059 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
09:09:19.592703 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
09:09:19.593220 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:09:19.593291 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
09:09:19.593601 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
09:09:19.594119 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:09:19.594201 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_exp_type_0000000000 as select trim(customer_id) exp from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 limit 1
  
09:09:19.595464 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
09:09:19.595995 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:09:19.596067 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select replace(udt_name, '_','') dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type_0000000000' and column_name = 'exp'
  
09:09:19.599702 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
09:09:19.600255 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:09:19.600327 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
09:09:19.601149 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
09:09:19.601673 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:09:19.601746 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
09:09:19.601980 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
09:09:19.602492 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:09:19.602563 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_exp_type_0000000000 as select lower(trim(agent_id)) exp from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 limit 1
  
09:09:19.603718 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
09:09:19.604239 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:09:19.604310 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select replace(udt_name, '_','') dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type_0000000000' and column_name = 'exp'
  
09:09:19.608446 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
09:09:19.608989 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:09:19.609061 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
09:09:19.609881 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
09:09:19.610401 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:09:19.610472 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 as
select  (call_id)::text as call_id, 
        (to_timestamp(call_start_epoch))::timestamptz as time_call_start, 
        (to_timestamp(call_start_epoch + call_duration))::timestamptz as time_call_end, 
        (call_duration)::int4 as num_duration_seconds, 
        (trim(customer_id))::text as customer_id, 
        (lower(trim(agent_id)))::text as agent_id
        from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000;

  
09:09:19.612240 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
09:09:19.612762 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:09:19.612833 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
09:09:19.613070 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
09:09:19.613583 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:09:19.613654 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_exp_type_0000000000 as select round(num_duration_seconds/60,2) exp from autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 limit 1
  
09:09:19.615026 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
09:09:19.615540 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:09:19.615611 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select replace(udt_name, '_','') dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type_0000000000' and column_name = 'exp'
  
09:09:19.619800 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
09:09:19.620533 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:09:19.620633 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
09:09:19.621455 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
09:09:19.623090 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:09:19.623172 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 cascade;
drop view if exists autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 cascade;

  
09:09:19.624215 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
09:09:19.624703 [info ] [MainThread]: 



create or replace view autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 as
select "call_id"::text as "call_id", 
       "call_start_epoch"::bigint as "call_start_epoch", 
       "call_duration"::int as "call_duration", 
       "customer_id"::text as "customer_id", 
       "agent_id"::text as "agent_id"
       from testsatmap.calltable;


create or replace view autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 as
select  (call_id)::text as call_id, 
        (to_timestamp(call_start_epoch))::timestamptz as time_call_start, 
        (to_timestamp(call_start_epoch + call_duration))::timestamptz as time_call_end, 
        (call_duration)::int4 as num_duration_seconds, 
        (trim(customer_id))::text as customer_id, 
        (lower(trim(agent_id)))::text as agent_id
        from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000;


drop table if exists autopie_ebpdemo.tmp_staging_fact_0000000000;
create table autopie_ebpdemo.tmp_staging_fact_0000000000 as
(
    with expression_extract_1 as
    (
        select * from autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000
    ),
    expression_extract_2 as
    (
        select  t.*,
                (round(num_duration_seconds/60,2))::numeric as num_duration_minutes
                from expression_extract_1 t
    ),
    filter__3 as
    (
        select /* filtering irrelevant records out */ *
        from expression_extract_2
        where 1=1
        and agent_id is not null
        and customer_id is not null
        and num_duration_seconds > 10
    ),
    incremental_extract__4 as
    (
        select /* retrieving incremental data - by date range only */ *
        from filter__3
        where time_call_start >= to_date('2020-01-01', 'YYYY-MM-DD')
          and time_call_start  < to_date('2021-01-01', 'YYYY-MM-DD')
    ),
    deduplication__5 as
    (
        select /* deduplicate by strategy */
               call_id
               , max(time_call_start) as time_call_start
               , max(time_call_end) as time_call_end
               , max(num_duration_seconds) as num_duration_seconds
               , max(customer_id) as customer_id
               , max(agent_id) as agent_id
               , max(num_duration_minutes) as num_duration_minutes
        from incremental_extract__4
        group by call_id 
    ),
    coarsening_6 as
    (
        select * from deduplication__5
    )
    select  t.*,
            1 autopie_run_id
    from coarsening_6 t
);

drop view if exists autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 cascade;
drop view if exists autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 cascade;


-- check if not exists already, this should run once
do $$                  
begin
if not exists
( 
    select 1 from information_schema.tables 
    where table_schema||'.'|| table_name = 'autopie_ebpdemo.obj_fact_calls'
)
then
    create table autopie_ebpdemo.obj_fact_calls as (select * from autopie_ebpdemo.tmp_staging_fact_0000000000 where 1=0);
    alter  table autopie_ebpdemo.obj_fact_calls add column row_id bigserial not null;
    alter  table autopie_ebpdemo.obj_fact_calls add primary key (call_id, time_call_end);
    --
    create index ixrid_obj_fact_calls on autopie_ebpdemo.obj_fact_calls(row_id);
end if;
end
$$;

-- upsert staging additions into the permanent fact object
delete from autopie_ebpdemo.obj_fact_calls where (call_id, time_call_end) in (select call_id, time_call_end from autopie_ebpdemo.tmp_staging_fact_0000000000);
insert into autopie_ebpdemo.obj_fact_calls select * from autopie_ebpdemo.tmp_staging_fact_0000000000;
drop table autopie_ebpdemo.tmp_staging_fact_0000000000;


09:09:19.625095 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:09:19.625164 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    



create or replace view autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 as
select "call_id"::text as "call_id", 
       "call_start_epoch"::bigint as "call_start_epoch", 
       "call_duration"::int as "call_duration", 
       "customer_id"::text as "customer_id", 
       "agent_id"::text as "agent_id"
       from testsatmap.calltable;


create or replace view autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 as
select  (call_id)::text as call_id, 
        (to_timestamp(call_start_epoch))::timestamptz as time_call_start, 
        (to_timestamp(call_start_epoch + call_duration))::timestamptz as time_call_end, 
        (call_duration)::int4 as num_duration_seconds, 
        (trim(customer_id))::text as customer_id, 
        (lower(trim(agent_id)))::text as agent_id
        from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000;


drop table if exists autopie_ebpdemo.tmp_staging_fact_0000000000;
create table autopie_ebpdemo.tmp_staging_fact_0000000000 as
(
    with expression_extract_1 as
    (
        select * from autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000
    ),
    expression_extract_2 as
    (
        select  t.*,
                (round(num_duration_seconds/60,2))::numeric as num_duration_minutes
                from expression_extract_1 t
    ),
    filter__3 as
    (
        select /* filtering irrelevant records out */ *
        from expression_extract_2
        where 1=1
        and agent_id is not null
        and customer_id is not null
        and num_duration_seconds > 10
    ),
    incremental_extract__4 as
    (
        select /* retrieving incremental data - by date range only */ *
        from filter__3
        where time_call_start >= to_date('2020-01-01', 'YYYY-MM-DD')
          and time_call_start  < to_date('2021-01-01', 'YYYY-MM-DD')
    ),
    deduplication__5 as
    (
        select /* deduplicate by strategy */
               call_id
               , max(time_call_start) as time_call_start
               , max(time_call_end) as time_call_end
               , max(num_duration_seconds) as num_duration_seconds
               , max(customer_id) as customer_id
               , max(agent_id) as agent_id
               , max(num_duration_minutes) as num_duration_minutes
        from incremental_extract__4
        group by call_id 
    ),
    coarsening_6 as
    (
        select * from deduplication__5
    )
    select  t.*,
            1 autopie_run_id
    from coarsening_6 t
);

drop view if exists autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 cascade;
drop view if exists autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 cascade;


-- check if not exists already, this should run once
do $$                  
begin
if not exists
( 
    select 1 from information_schema.tables 
    where table_schema||'.'|| table_name = 'autopie_ebpdemo.obj_fact_calls'
)
then
    create table autopie_ebpdemo.obj_fact_calls as (select * from autopie_ebpdemo.tmp_staging_fact_0000000000 where 1=0);
    alter  table autopie_ebpdemo.obj_fact_calls add column row_id bigserial not null;
    alter  table autopie_ebpdemo.obj_fact_calls add primary key (call_id, time_call_end);
    --
    create index ixrid_obj_fact_calls on autopie_ebpdemo.obj_fact_calls(row_id);
end if;
end
$$;

-- upsert staging additions into the permanent fact object
delete from autopie_ebpdemo.obj_fact_calls where (call_id, time_call_end) in (select call_id, time_call_end from autopie_ebpdemo.tmp_staging_fact_0000000000);
insert into autopie_ebpdemo.obj_fact_calls select * from autopie_ebpdemo.tmp_staging_fact_0000000000;
drop table autopie_ebpdemo.tmp_staging_fact_0000000000;


  
09:09:19.652621 [debug] [MainThread]: SQL status: DROP TABLE in 0.03 seconds
09:09:19.653408 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:09:19.653507 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    
select row_number() over (order by autopie_run_id desc) run_sequence, count(*) count_records 
  from autopie_ebpdemo.obj_fact_calls
group by autopie_run_id
order by 1 
limit 5;

  
09:09:19.654167 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
09:09:19.654843 [debug] [MainThread]: On macro_run_recipe: Close
09:09:19.655660 [debug] [MainThread]: Connection 'macro_run_recipe' was properly closed.


============================== 2022-02-20 09:09:20.733679 | 3f78ac8e-0225-4b9e-bb93-24bedc39a856 ==============================
09:09:20.733679 [info ] [MainThread]: Running with dbt=1.0.1
09:09:20.734059 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/hassanzaheer/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, macro='run_recipe', args='{\n    "recipe_type" : "collect_fact",\n    "target_fact" : {\n        "id": "outcomes", \n        "entity_and_dims": "customer_id",\n        "date":"date_outcome"\n    },\n    "ingredients": {\n        "expression_extract": {  \n            "source_raw": "testsatmap.outcomes",\n            "expression_list": [\n                {"expression": "outcome_date", "alias": "date_outcome"},\n                {"expression": "trim(customer_id)", "alias": "customer_id"},             \n                {"expression": "outcome_code::numeric", "alias": "num_outcome_amount"}\n            ]\n        },\n        "filter_conjunctions": [\n            "num_outcome_amount > 0",\n            "customer_id is not null"\n        ],\n        "incremental_update_on": "date_outcome",\n        "deduplication": {\n            "grouping_key": "customer_id, date_outcome, num_outcome_amount",\n            "preference": "arbitrary"\n        },\n        "coarsening": {\n            "entity_and_dims": "customer_id",\n            "date_expression":"date_outcome",\n            "aggregations": [\n                {"expression": "sum(num_outcome_amount)", "alias": "sum_outcome_amount"}\n            ]\n        }\n    }\n}', defer=None, state=None, cls=<class 'dbt.task.run_operation.RunOperationTask'>, which='run-operation', rpc_method='run-operation')
09:09:20.734164 [debug] [MainThread]: Tracking: do not track
09:09:20.753692 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 2 files changed.
09:09:20.753950 [debug] [MainThread]: Partial parsing: updated file: demo_autopie://models/demo_ebp_flow/prepared_scripts/phase1_fact_calls.sql
09:09:20.754108 [debug] [MainThread]: Partial parsing: updated file: demo_autopie://models/demo_ebp_flow/prepared_scripts/phase1_fact_outcomes.sql
09:09:20.759589 [debug] [MainThread]: 1699: static parser successfully parsed demo_ebp_flow/prepared_scripts/phase1_fact_calls.sql
09:09:20.765012 [debug] [MainThread]: 1699: static parser successfully parsed demo_ebp_flow/prepared_scripts/phase1_fact_outcomes.sql
09:09:20.771337 [debug] [MainThread]: Acquiring new postgres connection "macro_run_recipe"
09:09:20.771435 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:09:20.771500 [debug] [MainThread]: On macro_run_recipe: BEGIN
09:09:20.771561 [debug] [MainThread]: Opening a new connection, currently in state init
09:09:20.775123 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
09:09:20.775216 [debug] [MainThread]: On macro_run_recipe: COMMIT
09:09:20.775277 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:09:20.775329 [debug] [MainThread]: On macro_run_recipe: COMMIT
09:09:20.775451 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
09:09:20.818576 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:09:20.818695 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select '"'||column_name||'"::'||
       case when replace(udt_name, '_','') = 'bit' then 'int'
            when replace(udt_name, '_','') like 'int8%' then 'bigint'
            when replace(udt_name, '_','') like 'int4%' then 'int'
            when replace(udt_name, '_','') like 'int%' then 'smallint'
            when replace(udt_name, '_','') like 'bool%' then 'int'
            when replace(udt_name, '_','') like 'float%' then 'numeric'
            when replace(udt_name, '_','') like 'float%' then 'numeric'
            when replace(udt_name, '_','') like 'byte%' then 'text'
            when replace(udt_name, '_','') like 'varchar%' then 'text'
            when replace(udt_name, '_','') like 'timestamp%' then 'timestamp'
            else replace(udt_name, '_','') end ||
       ' as "'||column_name||'"' select_text
from information_schema.columns 
where table_schema||'.'||table_name = 'testsatmap.outcomes'
order by ordinal_position ;

  
09:09:20.831684 [debug] [MainThread]: SQL status: SELECT 3 in 0.01 seconds
09:09:20.832470 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:09:20.832543 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 as
select "outcome_date"::date as "outcome_date", 
       "customer_id"::text as "customer_id", 
       "outcome_code"::text as "outcome_code"
       from testsatmap.outcomes;

  
09:09:20.835217 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
09:09:20.835742 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:09:20.835812 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
09:09:20.836040 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
09:09:20.836535 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:09:20.836602 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_exp_type_0000000000 as select outcome_date exp from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 limit 1
  
09:09:20.837497 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
09:09:20.837989 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:09:20.838055 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select replace(udt_name, '_','') dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type_0000000000' and column_name = 'exp'
  
09:09:20.841756 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
09:09:20.842279 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:09:20.842345 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
09:09:20.843707 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
09:09:20.844198 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:09:20.844263 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
09:09:20.844462 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
09:09:20.844945 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:09:20.845014 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_exp_type_0000000000 as select trim(customer_id) exp from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 limit 1
  
09:09:20.845934 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
09:09:20.846543 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:09:20.846616 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select replace(udt_name, '_','') dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type_0000000000' and column_name = 'exp'
  
09:09:20.849802 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
09:09:20.850326 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:09:20.850393 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
09:09:20.851078 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
09:09:20.851563 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:09:20.851630 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
09:09:20.851822 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
09:09:20.852300 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:09:20.852366 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_exp_type_0000000000 as select outcome_code::numeric exp from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 limit 1
  
09:09:20.853237 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
09:09:20.853722 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:09:20.853787 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select replace(udt_name, '_','') dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type_0000000000' and column_name = 'exp'
  
09:09:20.856910 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
09:09:20.857459 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:09:20.857531 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
09:09:20.858180 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
09:09:20.858700 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:09:20.858773 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 as
select  (outcome_date)::date as date_outcome, 
        (trim(customer_id))::text as customer_id, 
        (outcome_code::numeric)::numeric as num_outcome_amount
        from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000;

  
09:09:20.859960 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
09:09:20.860880 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:09:20.860952 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 cascade;
drop view if exists autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 cascade;

  
09:09:20.861826 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
09:09:20.862313 [info ] [MainThread]: 



create or replace view autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 as
select "outcome_date"::date as "outcome_date", 
       "customer_id"::text as "customer_id", 
       "outcome_code"::text as "outcome_code"
       from testsatmap.outcomes;


create or replace view autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 as
select  (outcome_date)::date as date_outcome, 
        (trim(customer_id))::text as customer_id, 
        (outcome_code::numeric)::numeric as num_outcome_amount
        from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000;


drop table if exists autopie_ebpdemo.tmp_staging_fact_0000000000;
create table autopie_ebpdemo.tmp_staging_fact_0000000000 as
(
    with expression_extract_1 as
    (
        select * from autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000
    ),
    expression_extract_2 as
    (
        select * from expression_extract_1
    ),
    filter__3 as
    (
        select /* filtering irrelevant records out */ *
        from expression_extract_2
        where 1=1
        and num_outcome_amount > 0
        and customer_id is not null
    ),
    incremental_extract__4 as
    (
        select /* retrieving incremental data - by date range only */ *
        from filter__3
        where date_outcome >= to_date('2020-01-01', 'YYYY-MM-DD')
          and date_outcome  < to_date('2021-01-01', 'YYYY-MM-DD')
    ),
    deduplication__5 as
    (
        select /* deduplicate by strategy */
               customer_id, date_outcome, num_outcome_amount
        from incremental_extract__4
        group by customer_id, date_outcome, num_outcome_amount 
    ),
    coarsening_6 as
    (
        select /* flatten all dimensions, fit into EAVT format */
              customer_id
              , date_outcome
              
              , sum(num_outcome_amount) as sum_outcome_amount
              from deduplication__5
        group by customer_id, date_outcome
    )
    select  t.*,
            1 autopie_run_id
    from coarsening_6 t
);

drop view if exists autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 cascade;
drop view if exists autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 cascade;


-- check if not exists already, this should run once
do $$                  
begin
if not exists
( 
    select 1 from information_schema.tables 
    where table_schema||'.'|| table_name = 'autopie_ebpdemo.obj_fact_outcomes'
)
then
    create table autopie_ebpdemo.obj_fact_outcomes as (select * from autopie_ebpdemo.tmp_staging_fact_0000000000 where 1=0);
    alter  table autopie_ebpdemo.obj_fact_outcomes add column row_id bigserial not null;
    alter  table autopie_ebpdemo.obj_fact_outcomes add primary key (customer_id, date_outcome);
    --
    create index ixrid_obj_fact_outcomes on autopie_ebpdemo.obj_fact_outcomes(row_id);
end if;
end
$$;

-- upsert staging additions into the permanent fact object
delete from autopie_ebpdemo.obj_fact_outcomes where (customer_id, date_outcome) in (select customer_id, date_outcome from autopie_ebpdemo.tmp_staging_fact_0000000000);
insert into autopie_ebpdemo.obj_fact_outcomes select * from autopie_ebpdemo.tmp_staging_fact_0000000000;
drop table autopie_ebpdemo.tmp_staging_fact_0000000000;


09:09:20.862689 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:09:20.862758 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    



create or replace view autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 as
select "outcome_date"::date as "outcome_date", 
       "customer_id"::text as "customer_id", 
       "outcome_code"::text as "outcome_code"
       from testsatmap.outcomes;


create or replace view autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 as
select  (outcome_date)::date as date_outcome, 
        (trim(customer_id))::text as customer_id, 
        (outcome_code::numeric)::numeric as num_outcome_amount
        from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000;


drop table if exists autopie_ebpdemo.tmp_staging_fact_0000000000;
create table autopie_ebpdemo.tmp_staging_fact_0000000000 as
(
    with expression_extract_1 as
    (
        select * from autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000
    ),
    expression_extract_2 as
    (
        select * from expression_extract_1
    ),
    filter__3 as
    (
        select /* filtering irrelevant records out */ *
        from expression_extract_2
        where 1=1
        and num_outcome_amount > 0
        and customer_id is not null
    ),
    incremental_extract__4 as
    (
        select /* retrieving incremental data - by date range only */ *
        from filter__3
        where date_outcome >= to_date('2020-01-01', 'YYYY-MM-DD')
          and date_outcome  < to_date('2021-01-01', 'YYYY-MM-DD')
    ),
    deduplication__5 as
    (
        select /* deduplicate by strategy */
               customer_id, date_outcome, num_outcome_amount
        from incremental_extract__4
        group by customer_id, date_outcome, num_outcome_amount 
    ),
    coarsening_6 as
    (
        select /* flatten all dimensions, fit into EAVT format */
              customer_id
              , date_outcome
              
              , sum(num_outcome_amount) as sum_outcome_amount
              from deduplication__5
        group by customer_id, date_outcome
    )
    select  t.*,
            1 autopie_run_id
    from coarsening_6 t
);

drop view if exists autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 cascade;
drop view if exists autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 cascade;


-- check if not exists already, this should run once
do $$                  
begin
if not exists
( 
    select 1 from information_schema.tables 
    where table_schema||'.'|| table_name = 'autopie_ebpdemo.obj_fact_outcomes'
)
then
    create table autopie_ebpdemo.obj_fact_outcomes as (select * from autopie_ebpdemo.tmp_staging_fact_0000000000 where 1=0);
    alter  table autopie_ebpdemo.obj_fact_outcomes add column row_id bigserial not null;
    alter  table autopie_ebpdemo.obj_fact_outcomes add primary key (customer_id, date_outcome);
    --
    create index ixrid_obj_fact_outcomes on autopie_ebpdemo.obj_fact_outcomes(row_id);
end if;
end
$$;

-- upsert staging additions into the permanent fact object
delete from autopie_ebpdemo.obj_fact_outcomes where (customer_id, date_outcome) in (select customer_id, date_outcome from autopie_ebpdemo.tmp_staging_fact_0000000000);
insert into autopie_ebpdemo.obj_fact_outcomes select * from autopie_ebpdemo.tmp_staging_fact_0000000000;
drop table autopie_ebpdemo.tmp_staging_fact_0000000000;


  
09:09:20.886606 [debug] [MainThread]: SQL status: DROP TABLE in 0.02 seconds
09:09:20.887307 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:09:20.887398 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    
select row_number() over (order by autopie_run_id desc) run_sequence, count(*) count_records 
  from autopie_ebpdemo.obj_fact_outcomes
group by autopie_run_id
order by 1 
limit 5;

  
09:09:20.888018 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
09:09:20.888790 [debug] [MainThread]: On macro_run_recipe: Close
09:09:20.889447 [debug] [MainThread]: Connection 'macro_run_recipe' was properly closed.


============================== 2022-02-20 09:09:21.976153 | de42caa9-a18a-4b32-8d27-03c833611c8b ==============================
09:09:21.976153 [info ] [MainThread]: Running with dbt=1.0.1
09:09:21.976519 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/hassanzaheer/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, macro='run_recipe', args='{\n    "recipe_type" : "collect_fact",\n    "target_fact" : {\n        "id": "crm", \n        "entity_and_dims": "customer_id",\n        "date":"date_data"\n    },\n    "ingredients": {\n        "expression_extract": {  \n            "source_raw": "testsatmap.crm",\n            "expression_list": [\n                {"expression": "data_date", "alias": "date_data"},\n                {"expression": "trim(customer_id)",  "alias": "customer_id"},             \n                {"expression": "customer_num_attrib", "alias": "num_attrib"},\n                {"expression": "customer_cat_attrib",  "alias": "cat_attrib"}\n            ]\n        },\n        "filter_conjunctions": [\n            "customer_id is not null"\n        ],\n        "incremental_update_on": "date_data",\n        "deduplication": {\n            "grouping_key": "customer_id, date_data",\n            "preference": "arbitrary"\n        }\n    }\n}', defer=None, state=None, cls=<class 'dbt.task.run_operation.RunOperationTask'>, which='run-operation', rpc_method='run-operation')
09:09:21.976623 [debug] [MainThread]: Tracking: do not track
09:09:21.996954 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 2 files changed.
09:09:21.997194 [debug] [MainThread]: Partial parsing: updated file: demo_autopie://models/demo_ebp_flow/prepared_scripts/phase1_fact_crm.sql
09:09:21.997344 [debug] [MainThread]: Partial parsing: updated file: demo_autopie://models/demo_ebp_flow/prepared_scripts/phase1_fact_outcomes.sql
09:09:22.002751 [debug] [MainThread]: 1699: static parser successfully parsed demo_ebp_flow/prepared_scripts/phase1_fact_crm.sql
09:09:22.008310 [debug] [MainThread]: 1699: static parser successfully parsed demo_ebp_flow/prepared_scripts/phase1_fact_outcomes.sql
09:09:22.014785 [debug] [MainThread]: Acquiring new postgres connection "macro_run_recipe"
09:09:22.014888 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:09:22.014957 [debug] [MainThread]: On macro_run_recipe: BEGIN
09:09:22.015020 [debug] [MainThread]: Opening a new connection, currently in state init
09:09:22.020069 [debug] [MainThread]: SQL status: BEGIN in 0.01 seconds
09:09:22.020156 [debug] [MainThread]: On macro_run_recipe: COMMIT
09:09:22.020213 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:09:22.020265 [debug] [MainThread]: On macro_run_recipe: COMMIT
09:09:22.020434 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
09:09:22.063642 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:09:22.063764 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select '"'||column_name||'"::'||
       case when replace(udt_name, '_','') = 'bit' then 'int'
            when replace(udt_name, '_','') like 'int8%' then 'bigint'
            when replace(udt_name, '_','') like 'int4%' then 'int'
            when replace(udt_name, '_','') like 'int%' then 'smallint'
            when replace(udt_name, '_','') like 'bool%' then 'int'
            when replace(udt_name, '_','') like 'float%' then 'numeric'
            when replace(udt_name, '_','') like 'float%' then 'numeric'
            when replace(udt_name, '_','') like 'byte%' then 'text'
            when replace(udt_name, '_','') like 'varchar%' then 'text'
            when replace(udt_name, '_','') like 'timestamp%' then 'timestamp'
            else replace(udt_name, '_','') end ||
       ' as "'||column_name||'"' select_text
from information_schema.columns 
where table_schema||'.'||table_name = 'testsatmap.crm'
order by ordinal_position ;

  
09:09:22.076790 [debug] [MainThread]: SQL status: SELECT 4 in 0.01 seconds
09:09:22.077590 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:09:22.077661 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 as
select "data_date"::date as "data_date", 
       "customer_id"::text as "customer_id", 
       "customer_cat_attrib"::text as "customer_cat_attrib", 
       "customer_num_attrib"::numeric as "customer_num_attrib"
       from testsatmap.crm;

  
09:09:22.080274 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
09:09:22.080777 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:09:22.080845 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
09:09:22.081062 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
09:09:22.081518 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:09:22.081580 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_exp_type_0000000000 as select data_date exp from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 limit 1
  
09:09:22.082445 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
09:09:22.082902 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:09:22.082964 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select replace(udt_name, '_','') dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type_0000000000' and column_name = 'exp'
  
09:09:22.086600 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
09:09:22.087113 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:09:22.087183 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
09:09:22.088540 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
09:09:22.089066 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:09:22.089142 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
09:09:22.089360 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
09:09:22.089844 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:09:22.089913 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_exp_type_0000000000 as select trim(customer_id) exp from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 limit 1
  
09:09:22.090848 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
09:09:22.091467 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:09:22.091537 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select replace(udt_name, '_','') dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type_0000000000' and column_name = 'exp'
  
09:09:22.095038 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
09:09:22.095579 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:09:22.095646 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
09:09:22.096358 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
09:09:22.096852 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:09:22.096918 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
09:09:22.097120 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
09:09:22.097603 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:09:22.097670 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_exp_type_0000000000 as select customer_num_attrib exp from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 limit 1
  
09:09:22.098530 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
09:09:22.099012 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:09:22.099078 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select replace(udt_name, '_','') dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type_0000000000' and column_name = 'exp'
  
09:09:22.102375 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
09:09:22.102926 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:09:22.102998 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
09:09:22.103710 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
09:09:22.104237 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:09:22.104308 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
09:09:22.104520 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
09:09:22.105034 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:09:22.105106 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_exp_type_0000000000 as select customer_cat_attrib exp from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 limit 1
  
09:09:22.106542 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
09:09:22.107062 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:09:22.107132 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select replace(udt_name, '_','') dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type_0000000000' and column_name = 'exp'
  
09:09:22.110389 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
09:09:22.110931 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:09:22.111030 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
09:09:22.111710 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
09:09:22.112232 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:09:22.112305 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 as
select  (data_date)::date as date_data, 
        (trim(customer_id))::text as customer_id, 
        (customer_num_attrib)::numeric as num_attrib, 
        (customer_cat_attrib)::text as cat_attrib
        from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000;

  
09:09:22.113428 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
09:09:22.114538 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:09:22.114610 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 cascade;
drop view if exists autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 cascade;

  
09:09:22.115484 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
09:09:22.115978 [info ] [MainThread]: 



create or replace view autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 as
select "data_date"::date as "data_date", 
       "customer_id"::text as "customer_id", 
       "customer_cat_attrib"::text as "customer_cat_attrib", 
       "customer_num_attrib"::numeric as "customer_num_attrib"
       from testsatmap.crm;


create or replace view autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 as
select  (data_date)::date as date_data, 
        (trim(customer_id))::text as customer_id, 
        (customer_num_attrib)::numeric as num_attrib, 
        (customer_cat_attrib)::text as cat_attrib
        from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000;


drop table if exists autopie_ebpdemo.tmp_staging_fact_0000000000;
create table autopie_ebpdemo.tmp_staging_fact_0000000000 as
(
    with expression_extract_1 as
    (
        select * from autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000
    ),
    expression_extract_2 as
    (
        select * from expression_extract_1
    ),
    filter__3 as
    (
        select /* filtering irrelevant records out */ *
        from expression_extract_2
        where 1=1
        and customer_id is not null
    ),
    incremental_extract__4 as
    (
        select /* retrieving incremental data - by date range only */ *
        from filter__3
        where date_data >= to_date('2020-01-01', 'YYYY-MM-DD')
          and date_data  < to_date('2021-01-01', 'YYYY-MM-DD')
    ),
    deduplication__5 as
    (
        select /* deduplicate by strategy */
               customer_id, date_data
               , max(num_attrib) as num_attrib
               , max(cat_attrib) as cat_attrib
        from incremental_extract__4
        group by customer_id, date_data 
    ),
    coarsening_6 as
    (
        select * from deduplication__5
    )
    select  t.*,
            1 autopie_run_id
    from coarsening_6 t
);

drop view if exists autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 cascade;
drop view if exists autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 cascade;


-- check if not exists already, this should run once
do $$                  
begin
if not exists
( 
    select 1 from information_schema.tables 
    where table_schema||'.'|| table_name = 'autopie_ebpdemo.obj_fact_crm'
)
then
    create table autopie_ebpdemo.obj_fact_crm as (select * from autopie_ebpdemo.tmp_staging_fact_0000000000 where 1=0);
    alter  table autopie_ebpdemo.obj_fact_crm add column row_id bigserial not null;
    alter  table autopie_ebpdemo.obj_fact_crm add primary key (customer_id, date_data);
    --
    create index ixrid_obj_fact_crm on autopie_ebpdemo.obj_fact_crm(row_id);
end if;
end
$$;

-- upsert staging additions into the permanent fact object
delete from autopie_ebpdemo.obj_fact_crm where (customer_id, date_data) in (select customer_id, date_data from autopie_ebpdemo.tmp_staging_fact_0000000000);
insert into autopie_ebpdemo.obj_fact_crm select * from autopie_ebpdemo.tmp_staging_fact_0000000000;
drop table autopie_ebpdemo.tmp_staging_fact_0000000000;


09:09:22.116343 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:09:22.116409 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    



create or replace view autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 as
select "data_date"::date as "data_date", 
       "customer_id"::text as "customer_id", 
       "customer_cat_attrib"::text as "customer_cat_attrib", 
       "customer_num_attrib"::numeric as "customer_num_attrib"
       from testsatmap.crm;


create or replace view autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 as
select  (data_date)::date as date_data, 
        (trim(customer_id))::text as customer_id, 
        (customer_num_attrib)::numeric as num_attrib, 
        (customer_cat_attrib)::text as cat_attrib
        from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000;


drop table if exists autopie_ebpdemo.tmp_staging_fact_0000000000;
create table autopie_ebpdemo.tmp_staging_fact_0000000000 as
(
    with expression_extract_1 as
    (
        select * from autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000
    ),
    expression_extract_2 as
    (
        select * from expression_extract_1
    ),
    filter__3 as
    (
        select /* filtering irrelevant records out */ *
        from expression_extract_2
        where 1=1
        and customer_id is not null
    ),
    incremental_extract__4 as
    (
        select /* retrieving incremental data - by date range only */ *
        from filter__3
        where date_data >= to_date('2020-01-01', 'YYYY-MM-DD')
          and date_data  < to_date('2021-01-01', 'YYYY-MM-DD')
    ),
    deduplication__5 as
    (
        select /* deduplicate by strategy */
               customer_id, date_data
               , max(num_attrib) as num_attrib
               , max(cat_attrib) as cat_attrib
        from incremental_extract__4
        group by customer_id, date_data 
    ),
    coarsening_6 as
    (
        select * from deduplication__5
    )
    select  t.*,
            1 autopie_run_id
    from coarsening_6 t
);

drop view if exists autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 cascade;
drop view if exists autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 cascade;


-- check if not exists already, this should run once
do $$                  
begin
if not exists
( 
    select 1 from information_schema.tables 
    where table_schema||'.'|| table_name = 'autopie_ebpdemo.obj_fact_crm'
)
then
    create table autopie_ebpdemo.obj_fact_crm as (select * from autopie_ebpdemo.tmp_staging_fact_0000000000 where 1=0);
    alter  table autopie_ebpdemo.obj_fact_crm add column row_id bigserial not null;
    alter  table autopie_ebpdemo.obj_fact_crm add primary key (customer_id, date_data);
    --
    create index ixrid_obj_fact_crm on autopie_ebpdemo.obj_fact_crm(row_id);
end if;
end
$$;

-- upsert staging additions into the permanent fact object
delete from autopie_ebpdemo.obj_fact_crm where (customer_id, date_data) in (select customer_id, date_data from autopie_ebpdemo.tmp_staging_fact_0000000000);
insert into autopie_ebpdemo.obj_fact_crm select * from autopie_ebpdemo.tmp_staging_fact_0000000000;
drop table autopie_ebpdemo.tmp_staging_fact_0000000000;


  
09:09:22.142614 [debug] [MainThread]: SQL status: DROP TABLE in 0.03 seconds
09:09:22.143321 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:09:22.143409 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    
select row_number() over (order by autopie_run_id desc) run_sequence, count(*) count_records 
  from autopie_ebpdemo.obj_fact_crm
group by autopie_run_id
order by 1 
limit 5;

  
09:09:22.143964 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
09:09:22.144575 [debug] [MainThread]: On macro_run_recipe: Close
09:09:22.145340 [debug] [MainThread]: Connection 'macro_run_recipe' was properly closed.


============================== 2022-02-20 09:09:23.220070 | d1528c00-fa07-44b0-9837-2c194d16a7a5 ==============================
09:09:23.220070 [info ] [MainThread]: Running with dbt=1.0.1
09:09:23.220452 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/hassanzaheer/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, macro='run_recipe', args='{\n    "recipe_type" : "collect_fact",\n    "target_fact" : {\n        "id": "dispositions", \n        "entity_and_dims": "agent_id",\n        "date":"time_disposition_made"\n    },\n    "ingredients": {\n        "expression_extract": {  \n            "source_raw": "testsatmap.calldispositions",\n            "expression_list": [\n                {"expression": "to_timestamp(disposition_epoch)", "alias": "time_disposition_made"},\n                {"expression": "trim(customer_id)",  "alias": "customer_id"},             \n                {"expression": "lower(trim(agent_id))",  "alias": "agent_id"},\n                {"expression": "lower(trim(disp_code))",  "alias": "cat_disposition"}\n            ]\n        },\n        "filter_conjunctions": [\n            "agent_id is not null",\n            "customer_id is not null",\n            "cat_disposition in (\'k\', \'m\', \'a\')"\n        ],\n        "incremental_update_on": "time_disposition_made",\n        "deduplication": {\n            "grouping_key": "agent_id, cat_disposition, time_disposition_made",\n            "preference": "arbitrary"\n        },\n        "coarsening": {\n            "entity_and_dims": "agent_id",\n            "date_expression":"time_disposition_made",\n            "aggregations": [\n                {"expression": "max(customer_id)", "alias": "customer_id"},\n                {"expression": "sum(case when cat_disposition = \'k\' then 1 else 0 end)", "alias": "flg_k_disp_made"},\n                {"expression": "sum(case when cat_disposition = \'m\' then 1 else 0 end)", "alias": "flg_m_disp_made"},\n                {"expression": "sum(case when cat_disposition = \'a\' then 1 else 0 end)", "alias": "flg_a_disp_made"}\n            ]\n        }\n    }\n}', defer=None, state=None, cls=<class 'dbt.task.run_operation.RunOperationTask'>, which='run-operation', rpc_method='run-operation')
09:09:23.220561 [debug] [MainThread]: Tracking: do not track
09:09:23.240603 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 2 files changed.
09:09:23.240855 [debug] [MainThread]: Partial parsing: updated file: demo_autopie://models/demo_ebp_flow/prepared_scripts/phase1_fact_crm.sql
09:09:23.241008 [debug] [MainThread]: Partial parsing: updated file: demo_autopie://models/demo_ebp_flow/prepared_scripts/phase1_fact_dispositions.sql
09:09:23.246419 [debug] [MainThread]: 1699: static parser successfully parsed demo_ebp_flow/prepared_scripts/phase1_fact_crm.sql
09:09:23.251837 [debug] [MainThread]: 1699: static parser successfully parsed demo_ebp_flow/prepared_scripts/phase1_fact_dispositions.sql
09:09:23.258244 [debug] [MainThread]: Acquiring new postgres connection "macro_run_recipe"
09:09:23.258343 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:09:23.258411 [debug] [MainThread]: On macro_run_recipe: BEGIN
09:09:23.258474 [debug] [MainThread]: Opening a new connection, currently in state init
09:09:23.262588 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
09:09:23.262696 [debug] [MainThread]: On macro_run_recipe: COMMIT
09:09:23.262763 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:09:23.262823 [debug] [MainThread]: On macro_run_recipe: COMMIT
09:09:23.262999 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
09:09:23.306374 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:09:23.306504 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select '"'||column_name||'"::'||
       case when replace(udt_name, '_','') = 'bit' then 'int'
            when replace(udt_name, '_','') like 'int8%' then 'bigint'
            when replace(udt_name, '_','') like 'int4%' then 'int'
            when replace(udt_name, '_','') like 'int%' then 'smallint'
            when replace(udt_name, '_','') like 'bool%' then 'int'
            when replace(udt_name, '_','') like 'float%' then 'numeric'
            when replace(udt_name, '_','') like 'float%' then 'numeric'
            when replace(udt_name, '_','') like 'byte%' then 'text'
            when replace(udt_name, '_','') like 'varchar%' then 'text'
            when replace(udt_name, '_','') like 'timestamp%' then 'timestamp'
            else replace(udt_name, '_','') end ||
       ' as "'||column_name||'"' select_text
from information_schema.columns 
where table_schema||'.'||table_name = 'testsatmap.calldispositions'
order by ordinal_position ;

  
09:09:23.320241 [debug] [MainThread]: SQL status: SELECT 4 in 0.01 seconds
09:09:23.321079 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:09:23.321152 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 as
select "disposition_epoch"::bigint as "disposition_epoch", 
       "customer_id"::text as "customer_id", 
       "agent_id"::text as "agent_id", 
       "disp_code"::text as "disp_code"
       from testsatmap.calldispositions;

  
09:09:23.324402 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
09:09:23.324906 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:09:23.324973 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
09:09:23.325199 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
09:09:23.325680 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:09:23.325744 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_exp_type_0000000000 as select to_timestamp(disposition_epoch) exp from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 limit 1
  
09:09:23.326799 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
09:09:23.327267 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:09:23.327334 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select replace(udt_name, '_','') dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type_0000000000' and column_name = 'exp'
  
09:09:23.330875 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
09:09:23.331386 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:09:23.331450 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
09:09:23.332489 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
09:09:23.332973 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:09:23.333036 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
09:09:23.333234 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
09:09:23.333698 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:09:23.333764 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_exp_type_0000000000 as select trim(customer_id) exp from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 limit 1
  
09:09:23.334659 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
09:09:23.335265 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:09:23.335335 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select replace(udt_name, '_','') dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type_0000000000' and column_name = 'exp'
  
09:09:23.338440 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
09:09:23.338949 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:09:23.339015 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
09:09:23.339920 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
09:09:23.340405 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:09:23.340470 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
09:09:23.340670 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
09:09:23.341147 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:09:23.341213 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_exp_type_0000000000 as select lower(trim(agent_id)) exp from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 limit 1
  
09:09:23.342367 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
09:09:23.342867 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:09:23.342932 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select replace(udt_name, '_','') dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type_0000000000' and column_name = 'exp'
  
09:09:23.347218 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
09:09:23.347716 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:09:23.347788 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
09:09:23.348623 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
09:09:23.349101 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:09:23.349165 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
09:09:23.349386 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
09:09:23.349884 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:09:23.349953 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_exp_type_0000000000 as select lower(trim(disp_code)) exp from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 limit 1
  
09:09:23.351129 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
09:09:23.351639 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:09:23.351709 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    select replace(udt_name, '_','') dt from information_schema.columns where table_schema||'.'||table_name = 'autopie_ebpdemo.tmp_exp_type_0000000000' and column_name = 'exp'
  
09:09:23.356180 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
09:09:23.356749 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:09:23.356823 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_exp_type_0000000000 cascade
  
09:09:23.357711 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
09:09:23.358231 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:09:23.358301 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    create or replace view autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 as
select  (to_timestamp(disposition_epoch))::timestamptz as time_disposition_made, 
        (trim(customer_id))::text as customer_id, 
        (lower(trim(agent_id)))::text as agent_id, 
        (lower(trim(disp_code)))::text as cat_disposition
        from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000;

  
09:09:23.360328 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
09:09:23.361387 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:09:23.361462 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    drop view if exists autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 cascade;
drop view if exists autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 cascade;

  
09:09:23.362708 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
09:09:23.363200 [info ] [MainThread]: 



create or replace view autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 as
select "disposition_epoch"::bigint as "disposition_epoch", 
       "customer_id"::text as "customer_id", 
       "agent_id"::text as "agent_id", 
       "disp_code"::text as "disp_code"
       from testsatmap.calldispositions;


create or replace view autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 as
select  (to_timestamp(disposition_epoch))::timestamptz as time_disposition_made, 
        (trim(customer_id))::text as customer_id, 
        (lower(trim(agent_id)))::text as agent_id, 
        (lower(trim(disp_code)))::text as cat_disposition
        from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000;


drop table if exists autopie_ebpdemo.tmp_staging_fact_0000000000;
create table autopie_ebpdemo.tmp_staging_fact_0000000000 as
(
    with expression_extract_1 as
    (
        select * from autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000
    ),
    expression_extract_2 as
    (
        select * from expression_extract_1
    ),
    filter__3 as
    (
        select /* filtering irrelevant records out */ *
        from expression_extract_2
        where 1=1
        and agent_id is not null
        and customer_id is not null
        and cat_disposition in ('k', 'm', 'a')
    ),
    incremental_extract__4 as
    (
        select /* retrieving incremental data - by date range only */ *
        from filter__3
        where time_disposition_made >= to_date('2020-01-01', 'YYYY-MM-DD')
          and time_disposition_made  < to_date('2021-01-01', 'YYYY-MM-DD')
    ),
    deduplication__5 as
    (
        select /* deduplicate by strategy */
               agent_id, cat_disposition, time_disposition_made
               , max(customer_id) as customer_id
        from incremental_extract__4
        group by agent_id, cat_disposition, time_disposition_made 
    ),
    coarsening_6 as
    (
        select /* flatten all dimensions, fit into EAVT format */
              agent_id
              , time_disposition_made
              
              , max(customer_id) as customer_id
              , sum(case when cat_disposition = 'k' then 1 else 0 end) as flg_k_disp_made
              , sum(case when cat_disposition = 'm' then 1 else 0 end) as flg_m_disp_made
              , sum(case when cat_disposition = 'a' then 1 else 0 end) as flg_a_disp_made
              from deduplication__5
        group by agent_id, time_disposition_made
    )
    select  t.*,
            1 autopie_run_id
    from coarsening_6 t
);

drop view if exists autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 cascade;
drop view if exists autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 cascade;


-- check if not exists already, this should run once
do $$                  
begin
if not exists
( 
    select 1 from information_schema.tables 
    where table_schema||'.'|| table_name = 'autopie_ebpdemo.obj_fact_dispositions'
)
then
    create table autopie_ebpdemo.obj_fact_dispositions as (select * from autopie_ebpdemo.tmp_staging_fact_0000000000 where 1=0);
    alter  table autopie_ebpdemo.obj_fact_dispositions add column row_id bigserial not null;
    alter  table autopie_ebpdemo.obj_fact_dispositions add primary key (agent_id, time_disposition_made);
    --
    create index ixrid_obj_fact_dispositions on autopie_ebpdemo.obj_fact_dispositions(row_id);
end if;
end
$$;

-- upsert staging additions into the permanent fact object
delete from autopie_ebpdemo.obj_fact_dispositions where (agent_id, time_disposition_made) in (select agent_id, time_disposition_made from autopie_ebpdemo.tmp_staging_fact_0000000000);
insert into autopie_ebpdemo.obj_fact_dispositions select * from autopie_ebpdemo.tmp_staging_fact_0000000000;
drop table autopie_ebpdemo.tmp_staging_fact_0000000000;


09:09:23.363598 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:09:23.363666 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    



create or replace view autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 as
select "disposition_epoch"::bigint as "disposition_epoch", 
       "customer_id"::text as "customer_id", 
       "agent_id"::text as "agent_id", 
       "disp_code"::text as "disp_code"
       from testsatmap.calldispositions;


create or replace view autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 as
select  (to_timestamp(disposition_epoch))::timestamptz as time_disposition_made, 
        (trim(customer_id))::text as customer_id, 
        (lower(trim(agent_id)))::text as agent_id, 
        (lower(trim(disp_code)))::text as cat_disposition
        from autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000;


drop table if exists autopie_ebpdemo.tmp_staging_fact_0000000000;
create table autopie_ebpdemo.tmp_staging_fact_0000000000 as
(
    with expression_extract_1 as
    (
        select * from autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000
    ),
    expression_extract_2 as
    (
        select * from expression_extract_1
    ),
    filter__3 as
    (
        select /* filtering irrelevant records out */ *
        from expression_extract_2
        where 1=1
        and agent_id is not null
        and customer_id is not null
        and cat_disposition in ('k', 'm', 'a')
    ),
    incremental_extract__4 as
    (
        select /* retrieving incremental data - by date range only */ *
        from filter__3
        where time_disposition_made >= to_date('2020-01-01', 'YYYY-MM-DD')
          and time_disposition_made  < to_date('2021-01-01', 'YYYY-MM-DD')
    ),
    deduplication__5 as
    (
        select /* deduplicate by strategy */
               agent_id, cat_disposition, time_disposition_made
               , max(customer_id) as customer_id
        from incremental_extract__4
        group by agent_id, cat_disposition, time_disposition_made 
    ),
    coarsening_6 as
    (
        select /* flatten all dimensions, fit into EAVT format */
              agent_id
              , time_disposition_made
              
              , max(customer_id) as customer_id
              , sum(case when cat_disposition = 'k' then 1 else 0 end) as flg_k_disp_made
              , sum(case when cat_disposition = 'm' then 1 else 0 end) as flg_m_disp_made
              , sum(case when cat_disposition = 'a' then 1 else 0 end) as flg_a_disp_made
              from deduplication__5
        group by agent_id, time_disposition_made
    )
    select  t.*,
            1 autopie_run_id
    from coarsening_6 t
);

drop view if exists autopie_ebpdemo.tmp_staging_view_source_extract_0_0000000000 cascade;
drop view if exists autopie_ebpdemo.tmp_staging_view_expression_extract_1_0000000000 cascade;


-- check if not exists already, this should run once
do $$                  
begin
if not exists
( 
    select 1 from information_schema.tables 
    where table_schema||'.'|| table_name = 'autopie_ebpdemo.obj_fact_dispositions'
)
then
    create table autopie_ebpdemo.obj_fact_dispositions as (select * from autopie_ebpdemo.tmp_staging_fact_0000000000 where 1=0);
    alter  table autopie_ebpdemo.obj_fact_dispositions add column row_id bigserial not null;
    alter  table autopie_ebpdemo.obj_fact_dispositions add primary key (agent_id, time_disposition_made);
    --
    create index ixrid_obj_fact_dispositions on autopie_ebpdemo.obj_fact_dispositions(row_id);
end if;
end
$$;

-- upsert staging additions into the permanent fact object
delete from autopie_ebpdemo.obj_fact_dispositions where (agent_id, time_disposition_made) in (select agent_id, time_disposition_made from autopie_ebpdemo.tmp_staging_fact_0000000000);
insert into autopie_ebpdemo.obj_fact_dispositions select * from autopie_ebpdemo.tmp_staging_fact_0000000000;
drop table autopie_ebpdemo.tmp_staging_fact_0000000000;


  
09:09:23.391181 [debug] [MainThread]: SQL status: DROP TABLE in 0.03 seconds
09:09:23.391888 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:09:23.391974 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    
select row_number() over (order by autopie_run_id desc) run_sequence, count(*) count_records 
  from autopie_ebpdemo.obj_fact_dispositions
group by autopie_run_id
order by 1 
limit 5;

  
09:09:23.392586 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
09:09:23.393188 [debug] [MainThread]: On macro_run_recipe: Close
09:09:23.393915 [debug] [MainThread]: Connection 'macro_run_recipe' was properly closed.


============================== 2022-02-20 09:09:24.470661 | 8bcda9c2-6486-49bb-918d-3c6590dc0c7a ==============================
09:09:24.470661 [info ] [MainThread]: Running with dbt=1.0.1
09:09:24.471033 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/hassanzaheer/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, macro='run_recipe', args='{\n    "recipe_type" : "blend_window",\n    "target_fact" : "calls",\n    "ingredients": {  \n        "window_expression_list": [\n            {"expression":"lead(time_call_start) over (partition by agent_id order by time_call_start)", "alias":"time_agent_next_call", "data_type":"timestamp"},\n            {"expression":"lag(time_call_start) over (partition by agent_id order by time_call_start)", "alias":"time_agent_prev_call", "data_type":"timestamp"}\n        ]\n    }\n}', defer=None, state=None, cls=<class 'dbt.task.run_operation.RunOperationTask'>, which='run-operation', rpc_method='run-operation')
09:09:24.471142 [debug] [MainThread]: Tracking: do not track
09:09:24.492078 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 2 files changed.
09:09:24.492328 [debug] [MainThread]: Partial parsing: updated file: demo_autopie://models/demo_ebp_flow/prepared_scripts/phase1_fact_dispositions.sql
09:09:24.492487 [debug] [MainThread]: Partial parsing: updated file: demo_autopie://models/demo_ebp_flow/prepared_scripts/phase2_window_next_agent.sql
09:09:24.497936 [debug] [MainThread]: 1699: static parser successfully parsed demo_ebp_flow/prepared_scripts/phase1_fact_dispositions.sql
09:09:24.503313 [debug] [MainThread]: 1699: static parser successfully parsed demo_ebp_flow/prepared_scripts/phase2_window_next_agent.sql
09:09:24.509637 [debug] [MainThread]: Acquiring new postgres connection "macro_run_recipe"
09:09:24.509739 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:09:24.509804 [debug] [MainThread]: On macro_run_recipe: BEGIN
09:09:24.509862 [debug] [MainThread]: Opening a new connection, currently in state init
09:09:24.514461 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
09:09:24.514570 [debug] [MainThread]: On macro_run_recipe: COMMIT
09:09:24.514635 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:09:24.514692 [debug] [MainThread]: On macro_run_recipe: COMMIT
09:09:24.514864 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
09:09:24.524994 [info ] [MainThread]: 




drop table if exists autopie_ebpdemo.tmp_alter_staging_0000000000;
create table autopie_ebpdemo.tmp_alter_staging_0000000000 as
(
  select  row_id,
          /* calculate window functions on whole fact table - TODO, will optimize this */
          lead(time_call_start) over (partition by agent_id order by time_call_start) as time_agent_next_call, 
          lag(time_call_start) over (partition by agent_id order by time_call_start) as time_agent_prev_call
  from autopie_ebpdemo.obj_fact_calls
);

alter table autopie_ebpdemo.tmp_alter_staging_0000000000 add primary key (row_id);

-- check if not exists already, this should run once
do $$                  
begin
if not exists
( 
  select 1 from information_schema.columns 
  where table_schema||'.'|| table_name = 'autopie_ebpdemo.obj_fact_calls'
  and column_name = 'time_agent_next_call'
)
then
  alter table autopie_ebpdemo.obj_fact_calls add column time_agent_next_call timestamp;
end if;
end
$$;
do $$                  
begin
if not exists
( 
  select 1 from information_schema.columns 
  where table_schema||'.'|| table_name = 'autopie_ebpdemo.obj_fact_calls'
  and column_name = 'time_agent_prev_call'
)
then
  alter table autopie_ebpdemo.obj_fact_calls add column time_agent_prev_call timestamp;
end if;
end
$$;
update autopie_ebpdemo.obj_fact_calls as t
set
    time_agent_next_call = m.time_agent_next_call,
    time_agent_prev_call = m.time_agent_prev_call,
    autopie_run_id = 1
from autopie_ebpdemo.tmp_alter_staging_0000000000 m 
where t.row_id = m.row_id;

drop table autopie_ebpdemo.tmp_alter_staging_0000000000;


09:09:24.527922 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:09:24.528014 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    




drop table if exists autopie_ebpdemo.tmp_alter_staging_0000000000;
create table autopie_ebpdemo.tmp_alter_staging_0000000000 as
(
  select  row_id,
          /* calculate window functions on whole fact table - TODO, will optimize this */
          lead(time_call_start) over (partition by agent_id order by time_call_start) as time_agent_next_call, 
          lag(time_call_start) over (partition by agent_id order by time_call_start) as time_agent_prev_call
  from autopie_ebpdemo.obj_fact_calls
);

alter table autopie_ebpdemo.tmp_alter_staging_0000000000 add primary key (row_id);

-- check if not exists already, this should run once
do $$                  
begin
if not exists
( 
  select 1 from information_schema.columns 
  where table_schema||'.'|| table_name = 'autopie_ebpdemo.obj_fact_calls'
  and column_name = 'time_agent_next_call'
)
then
  alter table autopie_ebpdemo.obj_fact_calls add column time_agent_next_call timestamp;
end if;
end
$$;
do $$                  
begin
if not exists
( 
  select 1 from information_schema.columns 
  where table_schema||'.'|| table_name = 'autopie_ebpdemo.obj_fact_calls'
  and column_name = 'time_agent_prev_call'
)
then
  alter table autopie_ebpdemo.obj_fact_calls add column time_agent_prev_call timestamp;
end if;
end
$$;
update autopie_ebpdemo.obj_fact_calls as t
set
    time_agent_next_call = m.time_agent_next_call,
    time_agent_prev_call = m.time_agent_prev_call,
    autopie_run_id = 1
from autopie_ebpdemo.tmp_alter_staging_0000000000 m 
where t.row_id = m.row_id;

drop table autopie_ebpdemo.tmp_alter_staging_0000000000;


  
09:09:24.554218 [debug] [MainThread]: SQL status: DROP TABLE in 0.03 seconds
09:09:24.555091 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:09:24.555180 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    
select row_number() over (order by autopie_run_id desc) run_sequence, count(*) count_records 
  from autopie_ebpdemo.obj_fact_calls
group by autopie_run_id
order by 1
limit 5;

  
09:09:24.555602 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
09:09:24.556178 [debug] [MainThread]: On macro_run_recipe: Close
09:09:24.556811 [debug] [MainThread]: Connection 'macro_run_recipe' was properly closed.


============================== 2022-02-20 09:09:25.628790 | 4b066cca-33b4-4c9b-91be-1db77181f5a7 ==============================
09:09:25.628790 [info ] [MainThread]: Running with dbt=1.0.1
09:09:25.629116 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/hassanzaheer/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, macro='run_recipe', args='{\n    "recipe_type" : "blend_join",\n    "target_fact" : "calls",\n    "source_fact" : "dispositions",\n    "ingredients": {  \n        "conjunctions": [\n            "s.agent_id = t.agent_id",\n            "s.customer_id = t.customer_id",\n            "date(s.time_disposition_made) = date(t.time_call_start)",\n            "s.time_disposition_made >= t.time_call_start - interval \'120 second\'",\n            "s.time_disposition_made <= t.time_call_end + interval \'120 second\'"\n        ],\n        "match_preferences": [\n            "case when s.time_disposition_made between t.time_call_start and t.time_call_end then 1 else 0 end",\n            "extract(epoch from greatest(s.time_disposition_made - t.time_call_end, t.time_call_start - s.time_disposition_made))::int"\n        ],\n        "matched_expressions": [\n            {"expression": "s.flg_k_disp_made"},\n            {"expression": "s.flg_m_disp_made"},\n            {"expression": "s.flg_a_disp_made"},\n            {"expression": "s.time_disposition_made"}\n        ],\n        "from_source_to_target_mapping": "best",\n        "at_target_choose_sources": "collapse",\n        "target_collapse_aggregations": [\n            {"expression": "max(flg_k_disp_made)", "alias": "flg_k_disp_made"},\n            {"expression": "max(flg_m_disp_made)", "alias": "flg_m_disp_made"},\n            {"expression": "max(flg_a_disp_made)", "alias": "flg_a_disp_made"},\n            {"expression": "min(time_disposition_made)", "alias": "time_first_disposition_made"},\n            {"expression": "max(time_disposition_made)", "alias": "time_last_disposition_made"}\n        ]\n    }\n}', defer=None, state=None, cls=<class 'dbt.task.run_operation.RunOperationTask'>, which='run-operation', rpc_method='run-operation')
09:09:25.629231 [debug] [MainThread]: Tracking: do not track
09:09:25.649923 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 2 files changed.
09:09:25.650180 [debug] [MainThread]: Partial parsing: updated file: demo_autopie://models/demo_ebp_flow/prepared_scripts/phase2_join_disp_to_calls.sql
09:09:25.650331 [debug] [MainThread]: Partial parsing: updated file: demo_autopie://models/demo_ebp_flow/prepared_scripts/phase2_window_next_agent.sql
09:09:25.655766 [debug] [MainThread]: 1699: static parser successfully parsed demo_ebp_flow/prepared_scripts/phase2_join_disp_to_calls.sql
09:09:25.661215 [debug] [MainThread]: 1699: static parser successfully parsed demo_ebp_flow/prepared_scripts/phase2_window_next_agent.sql
09:09:25.667537 [debug] [MainThread]: Acquiring new postgres connection "macro_run_recipe"
09:09:25.667635 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:09:25.667703 [debug] [MainThread]: On macro_run_recipe: BEGIN
09:09:25.667768 [debug] [MainThread]: Opening a new connection, currently in state init
09:09:25.673135 [debug] [MainThread]: SQL status: BEGIN in 0.01 seconds
09:09:25.673227 [debug] [MainThread]: On macro_run_recipe: COMMIT
09:09:25.673284 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:09:25.673338 [debug] [MainThread]: On macro_run_recipe: COMMIT
09:09:25.673509 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
09:09:25.695665 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:09:25.695759 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    
drop view if exists autopie_ebpdemo.tmp_dtype_view_base_0000000000 cascade;
create or replace view autopie_ebpdemo.tmp_dtype_view_base_0000000000 as
select  -- attributes to be propagated
        s.flg_k_disp_made,
        s.flg_m_disp_made,
        s.flg_a_disp_made,
        s.time_disposition_made
from autopie_ebpdemo.obj_fact_calls t
join autopie_ebpdemo.obj_fact_dispositions s on 1=0;
drop view if exists autopie_ebpdemo.tmp_dtype_view_collapse_0000000000 cascade;
create or replace view autopie_ebpdemo.tmp_dtype_view_collapse_0000000000 as
select
		max(flg_k_disp_made) as flg_k_disp_made,
		max(flg_m_disp_made) as flg_m_disp_made,
		max(flg_a_disp_made) as flg_a_disp_made,
		min(time_disposition_made) as time_first_disposition_made,
		max(time_disposition_made) as time_last_disposition_made
from autopie_ebpdemo.tmp_dtype_view_base_0000000000

  
09:09:25.701535 [debug] [MainThread]: SQL status: CREATE VIEW in 0.01 seconds
09:09:25.702241 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:09:25.702309 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    
select column_name alias, 
       case when replace(udt_name, '_','') = 'bit' then 'int'
            when replace(udt_name, '_','') like 'int8%' then 'bigint'
            when replace(udt_name, '_','') like 'int4%' then 'int'
            when replace(udt_name, '_','') like 'int%' then 'smallint'
            when replace(udt_name, '_','') like 'bool%' then 'int'
            when replace(udt_name, '_','') like 'float%' then 'numeric'
            when replace(udt_name, '_','') like 'float%' then 'numeric'
            when replace(udt_name, '_','') like 'byte%' then 'text'
            when replace(udt_name, '_','') like 'varchar%' then 'text'
            when replace(udt_name, '_','') like 'timestamp%' then 'timestamp'
            else replace(udt_name, '_','') end data_type
from information_schema.columns
where table_schema||'.'||table_name =

'autopie_ebpdemo.tmp_dtype_view_base_0000000000'
order by ordinal_position;

  
09:09:25.713233 [debug] [MainThread]: SQL status: SELECT 4 in 0.01 seconds
09:09:25.713771 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:09:25.713837 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    
select column_name alias, 
       case when replace(udt_name, '_','') = 'bit' then 'int'
            when replace(udt_name, '_','') like 'int8%' then 'bigint'
            when replace(udt_name, '_','') like 'int4%' then 'int'
            when replace(udt_name, '_','') like 'int%' then 'smallint'
            when replace(udt_name, '_','') like 'bool%' then 'int'
            when replace(udt_name, '_','') like 'float%' then 'numeric'
            when replace(udt_name, '_','') like 'float%' then 'numeric'
            when replace(udt_name, '_','') like 'byte%' then 'text'
            when replace(udt_name, '_','') like 'varchar%' then 'text'
            when replace(udt_name, '_','') like 'timestamp%' then 'timestamp'
            else replace(udt_name, '_','') end data_type
from information_schema.columns
where table_schema||'.'||table_name =

'autopie_ebpdemo.tmp_dtype_view_collapse_0000000000'
order by ordinal_position;

  
09:09:25.717151 [debug] [MainThread]: SQL status: SELECT 5 in 0.0 seconds
09:09:25.717649 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:09:25.717713 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    
drop view if exists autopie_ebpdemo.tmp_dtype_view_base_0000000000 cascade;
drop view if exists autopie_ebpdemo.tmp_dtype_view_collapse_0000000000 cascade;

  
09:09:25.719527 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
09:09:25.720175 [info ] [MainThread]: 














drop table if exists autopie_ebpdemo.tmp_target_affected_0000000000;
create table autopie_ebpdemo.tmp_target_affected_0000000000 as
(
    select t.row_id
    from autopie_ebpdemo.obj_fact_calls t
    where exists
    ( 
        select 1
        from autopie_ebpdemo.obj_fact_dispositions s
        where s.autopie_run_id = 1
        and s.agent_id = t.agent_id
        and s.customer_id = t.customer_id
        and date(s.time_disposition_made) = date(t.time_call_start)
        and s.time_disposition_made >= t.time_call_start - interval '120 second'
        and s.time_disposition_made <= t.time_call_end + interval '120 second'
    )
);

alter table autopie_ebpdemo.tmp_target_affected_0000000000 add primary key (row_id);

drop table if exists autopie_ebpdemo.tmp_pre_join_0000000000;
create table autopie_ebpdemo.tmp_pre_join_0000000000 as
(
    with compute_preference_scoring as
    (
        -- for each source scan potential targets, pick one by preference
        select  s.row_id s_row_id, t.row_id t_row_id,
                -- scores, bigger is more preferred
                case when s.time_disposition_made between t.time_call_start and t.time_call_end then 1 else 0 end as pref_score_1,
                extract(epoch from greatest(s.time_disposition_made - t.time_call_end, t.time_call_start - s.time_disposition_made))::int as pref_score_2,
                -- attributes to be propagated
                s.flg_k_disp_made,
                s.flg_m_disp_made,
                s.flg_a_disp_made,
                s.time_disposition_made
        from autopie_ebpdemo.obj_fact_calls t
        join autopie_ebpdemo.tmp_target_affected_0000000000 a
        on t.row_id = a.row_id
        join autopie_ebpdemo.obj_fact_dispositions s 
        on 1=1
        and s.agent_id = t.agent_id
        and s.customer_id = t.customer_id
        and date(s.time_disposition_made) = date(t.time_call_start)
        and s.time_disposition_made >= t.time_call_start - interval '120 second'
        and s.time_disposition_made <= t.time_call_end + interval '120 second'    
    ),
    pick_best_target as
    (
        select  s_row_id,
                -- collapse source expressions arbitrarily
                max(flg_k_disp_made) as flg_k_disp_made,
                max(flg_m_disp_made) as flg_m_disp_made,
                max(flg_a_disp_made) as flg_a_disp_made,
                max(time_disposition_made) as time_disposition_made, 
                max(pref_score_1) as pref_score_1, 
                max(pref_score_2) as pref_score_2,
                -- prefer best targets id
                (array_agg(t_row_id order by  pref_score_1 desc, pref_score_2 desc))[1] t_row_id
        from compute_preference_scoring
        group by s_row_id
    ),
    target_collapse as
    (
		select  t_row_id
				, max(flg_k_disp_made) as flg_k_disp_made
				, max(flg_m_disp_made) as flg_m_disp_made
				, max(flg_a_disp_made) as flg_a_disp_made
				, min(time_disposition_made) as time_first_disposition_made
				, max(time_disposition_made) as time_last_disposition_made
		from pick_best_target
		group by t_row_id       
    )
    select * from target_collapse
);

alter table autopie_ebpdemo.tmp_pre_join_0000000000 add primary key (t_row_id);

-- this should be done only once if new slot is missing

do $$                  
begin
if not exists
( 
    select 1 from information_schema.columns 
    where table_schema||'.'|| table_name = 'autopie_ebpdemo.obj_fact_calls'
    and column_name = 'flg_k_disp_made'
)
then
    alter table autopie_ebpdemo.obj_fact_calls add column flg_k_disp_made bigint;
end if;
end
$$;


do $$                  
begin
if not exists
( 
    select 1 from information_schema.columns 
    where table_schema||'.'|| table_name = 'autopie_ebpdemo.obj_fact_calls'
    and column_name = 'flg_m_disp_made'
)
then
    alter table autopie_ebpdemo.obj_fact_calls add column flg_m_disp_made bigint;
end if;
end
$$;


do $$                  
begin
if not exists
( 
    select 1 from information_schema.columns 
    where table_schema||'.'|| table_name = 'autopie_ebpdemo.obj_fact_calls'
    and column_name = 'flg_a_disp_made'
)
then
    alter table autopie_ebpdemo.obj_fact_calls add column flg_a_disp_made bigint;
end if;
end
$$;


do $$                  
begin
if not exists
( 
    select 1 from information_schema.columns 
    where table_schema||'.'|| table_name = 'autopie_ebpdemo.obj_fact_calls'
    and column_name = 'time_first_disposition_made'
)
then
    alter table autopie_ebpdemo.obj_fact_calls add column time_first_disposition_made timestamp;
end if;
end
$$;


do $$                  
begin
if not exists
( 
    select 1 from information_schema.columns 
    where table_schema||'.'|| table_name = 'autopie_ebpdemo.obj_fact_calls'
    and column_name = 'time_last_disposition_made'
)
then
    alter table autopie_ebpdemo.obj_fact_calls add column time_last_disposition_made timestamp;
end if;
end
$$;



update autopie_ebpdemo.obj_fact_calls as t
set
    flg_k_disp_made = m.flg_k_disp_made,
    flg_m_disp_made = m.flg_m_disp_made,
    flg_a_disp_made = m.flg_a_disp_made,
    time_first_disposition_made = m.time_first_disposition_made,
    time_last_disposition_made = m.time_last_disposition_made, 
    autopie_run_id = 1
from autopie_ebpdemo.tmp_pre_join_0000000000 m 
where t.row_id = m.t_row_id;

drop table if exists autopie_ebpdemo.tmp_pre_join_0000000000;
drop table if exists autopie_ebpdemo.tmp_target_affected_0000000000;


09:09:25.720591 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:09:25.720654 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    














drop table if exists autopie_ebpdemo.tmp_target_affected_0000000000;
create table autopie_ebpdemo.tmp_target_affected_0000000000 as
(
    select t.row_id
    from autopie_ebpdemo.obj_fact_calls t
    where exists
    ( 
        select 1
        from autopie_ebpdemo.obj_fact_dispositions s
        where s.autopie_run_id = 1
        and s.agent_id = t.agent_id
        and s.customer_id = t.customer_id
        and date(s.time_disposition_made) = date(t.time_call_start)
        and s.time_disposition_made >= t.time_call_start - interval '120 second'
        and s.time_disposition_made <= t.time_call_end + interval '120 second'
    )
);

alter table autopie_ebpdemo.tmp_target_affected_0000000000 add primary key (row_id);

drop table if exists autopie_ebpdemo.tmp_pre_join_0000000000;
create table autopie_ebpdemo.tmp_pre_join_0000000000 as
(
    with compute_preference_scoring as
    (
        -- for each source scan potential targets, pick one by preference
        select  s.row_id s_row_id, t.row_id t_row_id,
                -- scores, bigger is more preferred
                case when s.time_disposition_made between t.time_call_start and t.time_call_end then 1 else 0 end as pref_score_1,
                extract(epoch from greatest(s.time_disposition_made - t.time_call_end, t.time_call_start - s.time_disposition_made))::int as pref_score_2,
                -- attributes to be propagated
                s.flg_k_disp_made,
                s.flg_m_disp_made,
                s.flg_a_disp_made,
                s.time_disposition_made
        from autopie_ebpdemo.obj_fact_calls t
        join autopie_ebpdemo.tmp_target_affected_0000000000 a
        on t.row_id = a.row_id
        join autopie_ebpdemo.obj_fact_dispositions s 
        on 1=1
        and s.agent_id = t.agent_id
        and s.customer_id = t.customer_id
        and date(s.time_disposition_made) = date(t.time_call_start)
        and s.time_disposition_made >= t.time_call_start - interval '120 second'
        and s.time_disposition_made <= t.time_call_end + interval '120 second'    
    ),
    pick_best_target as
    (
        select  s_row_id,
                -- collapse source expressions arbitrarily
                max(flg_k_disp_made) as flg_k_disp_made,
                max(flg_m_disp_made) as flg_m_disp_made,
                max(flg_a_disp_made) as flg_a_disp_made,
                max(time_disposition_made) as time_disposition_made, 
                max(pref_score_1) as pref_score_1, 
                max(pref_score_2) as pref_score_2,
                -- prefer best targets id
                (array_agg(t_row_id order by  pref_score_1 desc, pref_score_2 desc))[1] t_row_id
        from compute_preference_scoring
        group by s_row_id
    ),
    target_collapse as
    (
		select  t_row_id
				, max(flg_k_disp_made) as flg_k_disp_made
				, max(flg_m_disp_made) as flg_m_disp_made
				, max(flg_a_disp_made) as flg_a_disp_made
				, min(time_disposition_made) as time_first_disposition_made
				, max(time_disposition_made) as time_last_disposition_made
		from pick_best_target
		group by t_row_id       
    )
    select * from target_collapse
);

alter table autopie_ebpdemo.tmp_pre_join_0000000000 add primary key (t_row_id);

-- this should be done only once if new slot is missing

do $$                  
begin
if not exists
( 
    select 1 from information_schema.columns 
    where table_schema||'.'|| table_name = 'autopie_ebpdemo.obj_fact_calls'
    and column_name = 'flg_k_disp_made'
)
then
    alter table autopie_ebpdemo.obj_fact_calls add column flg_k_disp_made bigint;
end if;
end
$$;


do $$                  
begin
if not exists
( 
    select 1 from information_schema.columns 
    where table_schema||'.'|| table_name = 'autopie_ebpdemo.obj_fact_calls'
    and column_name = 'flg_m_disp_made'
)
then
    alter table autopie_ebpdemo.obj_fact_calls add column flg_m_disp_made bigint;
end if;
end
$$;


do $$                  
begin
if not exists
( 
    select 1 from information_schema.columns 
    where table_schema||'.'|| table_name = 'autopie_ebpdemo.obj_fact_calls'
    and column_name = 'flg_a_disp_made'
)
then
    alter table autopie_ebpdemo.obj_fact_calls add column flg_a_disp_made bigint;
end if;
end
$$;


do $$                  
begin
if not exists
( 
    select 1 from information_schema.columns 
    where table_schema||'.'|| table_name = 'autopie_ebpdemo.obj_fact_calls'
    and column_name = 'time_first_disposition_made'
)
then
    alter table autopie_ebpdemo.obj_fact_calls add column time_first_disposition_made timestamp;
end if;
end
$$;


do $$                  
begin
if not exists
( 
    select 1 from information_schema.columns 
    where table_schema||'.'|| table_name = 'autopie_ebpdemo.obj_fact_calls'
    and column_name = 'time_last_disposition_made'
)
then
    alter table autopie_ebpdemo.obj_fact_calls add column time_last_disposition_made timestamp;
end if;
end
$$;



update autopie_ebpdemo.obj_fact_calls as t
set
    flg_k_disp_made = m.flg_k_disp_made,
    flg_m_disp_made = m.flg_m_disp_made,
    flg_a_disp_made = m.flg_a_disp_made,
    time_first_disposition_made = m.time_first_disposition_made,
    time_last_disposition_made = m.time_last_disposition_made, 
    autopie_run_id = 1
from autopie_ebpdemo.tmp_pre_join_0000000000 m 
where t.row_id = m.t_row_id;

drop table if exists autopie_ebpdemo.tmp_pre_join_0000000000;
drop table if exists autopie_ebpdemo.tmp_target_affected_0000000000;


  
09:09:25.742930 [debug] [MainThread]: SQL status: DROP TABLE in 0.02 seconds
09:09:25.743756 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:09:25.743844 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    
select row_number() over (order by autopie_run_id desc) run_sequence, count(*) count_records 
  from autopie_ebpdemo.obj_fact_calls
group by autopie_run_id
order by 1
limit 5;

  
09:09:25.744214 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
09:09:25.744774 [debug] [MainThread]: On macro_run_recipe: Close
09:09:25.745723 [debug] [MainThread]: Connection 'macro_run_recipe' was properly closed.


============================== 2022-02-20 09:09:26.817807 | 42508b2f-f717-4cd5-9f3b-5f8b7a459b7a ==============================
09:09:26.817807 [info ] [MainThread]: Running with dbt=1.0.1
09:09:26.818160 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/hassanzaheer/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, macro='run_recipe', args='{\n    "recipe_type" : "blend_join",\n    "target_fact" : "calls",\n    "source_fact" : "outcomes",\n    "ingredients": {\n        "conjunctions": [\n            "s.customer_id = t.customer_id",\n            "s.date_outcome >= date(t.time_call_start)"\n        ],\n        "match_preferences": [\n            "(date(t.time_call_start) - s.date_outcome)::int",\n            "(date(t.time_call_start) - t.time_call_start)::interval"\n        ],\n        "matched_expressions": [\n            {"expression": "s.sum_outcome_amount"}\n        ],\n        "from_source_to_target_mapping": "best",\n        "at_target_choose_sources": "collapse",\n        "target_collapse_aggregations": [\n            {"expression": "sum(sum_outcome_amount)", "alias": "sum_outcome_amount"}\n        ]\n    }\n}', defer=None, state=None, cls=<class 'dbt.task.run_operation.RunOperationTask'>, which='run-operation', rpc_method='run-operation')
09:09:26.818266 [debug] [MainThread]: Tracking: do not track
09:09:26.838028 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 2 files changed.
09:09:26.838282 [debug] [MainThread]: Partial parsing: updated file: demo_autopie://models/demo_ebp_flow/prepared_scripts/phase2_join_outc_to_calls.sql
09:09:26.838440 [debug] [MainThread]: Partial parsing: updated file: demo_autopie://models/demo_ebp_flow/prepared_scripts/phase2_join_disp_to_calls.sql
09:09:26.843855 [debug] [MainThread]: 1699: static parser successfully parsed demo_ebp_flow/prepared_scripts/phase2_join_outc_to_calls.sql
09:09:26.849273 [debug] [MainThread]: 1699: static parser successfully parsed demo_ebp_flow/prepared_scripts/phase2_join_disp_to_calls.sql
09:09:26.855640 [debug] [MainThread]: Acquiring new postgres connection "macro_run_recipe"
09:09:26.855752 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:09:26.855815 [debug] [MainThread]: On macro_run_recipe: BEGIN
09:09:26.855873 [debug] [MainThread]: Opening a new connection, currently in state init
09:09:26.860993 [debug] [MainThread]: SQL status: BEGIN in 0.01 seconds
09:09:26.861100 [debug] [MainThread]: On macro_run_recipe: COMMIT
09:09:26.861165 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:09:26.861223 [debug] [MainThread]: On macro_run_recipe: COMMIT
09:09:26.861566 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
09:09:26.883955 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:09:26.884054 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    
drop view if exists autopie_ebpdemo.tmp_dtype_view_base_0000000000 cascade;
create or replace view autopie_ebpdemo.tmp_dtype_view_base_0000000000 as
select  -- attributes to be propagated
        s.sum_outcome_amount
from autopie_ebpdemo.obj_fact_calls t
join autopie_ebpdemo.obj_fact_outcomes s on 1=0;
drop view if exists autopie_ebpdemo.tmp_dtype_view_collapse_0000000000 cascade;
create or replace view autopie_ebpdemo.tmp_dtype_view_collapse_0000000000 as
select
		sum(sum_outcome_amount) as sum_outcome_amount
from autopie_ebpdemo.tmp_dtype_view_base_0000000000

  
09:09:26.888976 [debug] [MainThread]: SQL status: CREATE VIEW in 0.0 seconds
09:09:26.889703 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:09:26.889769 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    
select column_name alias, 
       case when replace(udt_name, '_','') = 'bit' then 'int'
            when replace(udt_name, '_','') like 'int8%' then 'bigint'
            when replace(udt_name, '_','') like 'int4%' then 'int'
            when replace(udt_name, '_','') like 'int%' then 'smallint'
            when replace(udt_name, '_','') like 'bool%' then 'int'
            when replace(udt_name, '_','') like 'float%' then 'numeric'
            when replace(udt_name, '_','') like 'float%' then 'numeric'
            when replace(udt_name, '_','') like 'byte%' then 'text'
            when replace(udt_name, '_','') like 'varchar%' then 'text'
            when replace(udt_name, '_','') like 'timestamp%' then 'timestamp'
            else replace(udt_name, '_','') end data_type
from information_schema.columns
where table_schema||'.'||table_name =

'autopie_ebpdemo.tmp_dtype_view_base_0000000000'
order by ordinal_position;

  
09:09:26.901406 [debug] [MainThread]: SQL status: SELECT 1 in 0.01 seconds
09:09:26.901922 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:09:26.901988 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    
select column_name alias, 
       case when replace(udt_name, '_','') = 'bit' then 'int'
            when replace(udt_name, '_','') like 'int8%' then 'bigint'
            when replace(udt_name, '_','') like 'int4%' then 'int'
            when replace(udt_name, '_','') like 'int%' then 'smallint'
            when replace(udt_name, '_','') like 'bool%' then 'int'
            when replace(udt_name, '_','') like 'float%' then 'numeric'
            when replace(udt_name, '_','') like 'float%' then 'numeric'
            when replace(udt_name, '_','') like 'byte%' then 'text'
            when replace(udt_name, '_','') like 'varchar%' then 'text'
            when replace(udt_name, '_','') like 'timestamp%' then 'timestamp'
            else replace(udt_name, '_','') end data_type
from information_schema.columns
where table_schema||'.'||table_name =

'autopie_ebpdemo.tmp_dtype_view_collapse_0000000000'
order by ordinal_position;

  
09:09:26.905615 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
09:09:26.906098 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:09:26.906161 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    
drop view if exists autopie_ebpdemo.tmp_dtype_view_base_0000000000 cascade;
drop view if exists autopie_ebpdemo.tmp_dtype_view_collapse_0000000000 cascade;

  
09:09:26.907615 [debug] [MainThread]: SQL status: DROP VIEW in 0.0 seconds
09:09:26.908217 [info ] [MainThread]: 














drop table if exists autopie_ebpdemo.tmp_target_affected_0000000000;
create table autopie_ebpdemo.tmp_target_affected_0000000000 as
(
    select t.row_id
    from autopie_ebpdemo.obj_fact_calls t
    where exists
    ( 
        select 1
        from autopie_ebpdemo.obj_fact_outcomes s
        where s.autopie_run_id = 1
        and s.customer_id = t.customer_id
        and s.date_outcome >= date(t.time_call_start)
    )
);

alter table autopie_ebpdemo.tmp_target_affected_0000000000 add primary key (row_id);

drop table if exists autopie_ebpdemo.tmp_pre_join_0000000000;
create table autopie_ebpdemo.tmp_pre_join_0000000000 as
(
    with compute_preference_scoring as
    (
        -- for each source scan potential targets, pick one by preference
        select  s.row_id s_row_id, t.row_id t_row_id,
                -- scores, bigger is more preferred
                (date(t.time_call_start) - s.date_outcome)::int as pref_score_1,
                (date(t.time_call_start) - t.time_call_start)::interval as pref_score_2,
                -- attributes to be propagated
                s.sum_outcome_amount
        from autopie_ebpdemo.obj_fact_calls t
        join autopie_ebpdemo.tmp_target_affected_0000000000 a
        on t.row_id = a.row_id
        join autopie_ebpdemo.obj_fact_outcomes s 
        on 1=1
        and s.customer_id = t.customer_id
        and s.date_outcome >= date(t.time_call_start)    
    ),
    pick_best_target as
    (
        select  s_row_id,
                -- collapse source expressions arbitrarily
                max(sum_outcome_amount) as sum_outcome_amount, 
                max(pref_score_1) as pref_score_1, 
                max(pref_score_2) as pref_score_2,
                -- prefer best targets id
                (array_agg(t_row_id order by  pref_score_1 desc, pref_score_2 desc))[1] t_row_id
        from compute_preference_scoring
        group by s_row_id
    ),
    target_collapse as
    (
		select  t_row_id
				, sum(sum_outcome_amount) as sum_outcome_amount
		from pick_best_target
		group by t_row_id       
    )
    select * from target_collapse
);

alter table autopie_ebpdemo.tmp_pre_join_0000000000 add primary key (t_row_id);

-- this should be done only once if new slot is missing

do $$                  
begin
if not exists
( 
    select 1 from information_schema.columns 
    where table_schema||'.'|| table_name = 'autopie_ebpdemo.obj_fact_calls'
    and column_name = 'sum_outcome_amount'
)
then
    alter table autopie_ebpdemo.obj_fact_calls add column sum_outcome_amount numeric;
end if;
end
$$;



update autopie_ebpdemo.obj_fact_calls as t
set
    sum_outcome_amount = m.sum_outcome_amount, 
    autopie_run_id = 1
from autopie_ebpdemo.tmp_pre_join_0000000000 m 
where t.row_id = m.t_row_id;

drop table if exists autopie_ebpdemo.tmp_pre_join_0000000000;
drop table if exists autopie_ebpdemo.tmp_target_affected_0000000000;


09:09:26.908533 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:09:26.908594 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    














drop table if exists autopie_ebpdemo.tmp_target_affected_0000000000;
create table autopie_ebpdemo.tmp_target_affected_0000000000 as
(
    select t.row_id
    from autopie_ebpdemo.obj_fact_calls t
    where exists
    ( 
        select 1
        from autopie_ebpdemo.obj_fact_outcomes s
        where s.autopie_run_id = 1
        and s.customer_id = t.customer_id
        and s.date_outcome >= date(t.time_call_start)
    )
);

alter table autopie_ebpdemo.tmp_target_affected_0000000000 add primary key (row_id);

drop table if exists autopie_ebpdemo.tmp_pre_join_0000000000;
create table autopie_ebpdemo.tmp_pre_join_0000000000 as
(
    with compute_preference_scoring as
    (
        -- for each source scan potential targets, pick one by preference
        select  s.row_id s_row_id, t.row_id t_row_id,
                -- scores, bigger is more preferred
                (date(t.time_call_start) - s.date_outcome)::int as pref_score_1,
                (date(t.time_call_start) - t.time_call_start)::interval as pref_score_2,
                -- attributes to be propagated
                s.sum_outcome_amount
        from autopie_ebpdemo.obj_fact_calls t
        join autopie_ebpdemo.tmp_target_affected_0000000000 a
        on t.row_id = a.row_id
        join autopie_ebpdemo.obj_fact_outcomes s 
        on 1=1
        and s.customer_id = t.customer_id
        and s.date_outcome >= date(t.time_call_start)    
    ),
    pick_best_target as
    (
        select  s_row_id,
                -- collapse source expressions arbitrarily
                max(sum_outcome_amount) as sum_outcome_amount, 
                max(pref_score_1) as pref_score_1, 
                max(pref_score_2) as pref_score_2,
                -- prefer best targets id
                (array_agg(t_row_id order by  pref_score_1 desc, pref_score_2 desc))[1] t_row_id
        from compute_preference_scoring
        group by s_row_id
    ),
    target_collapse as
    (
		select  t_row_id
				, sum(sum_outcome_amount) as sum_outcome_amount
		from pick_best_target
		group by t_row_id       
    )
    select * from target_collapse
);

alter table autopie_ebpdemo.tmp_pre_join_0000000000 add primary key (t_row_id);

-- this should be done only once if new slot is missing

do $$                  
begin
if not exists
( 
    select 1 from information_schema.columns 
    where table_schema||'.'|| table_name = 'autopie_ebpdemo.obj_fact_calls'
    and column_name = 'sum_outcome_amount'
)
then
    alter table autopie_ebpdemo.obj_fact_calls add column sum_outcome_amount numeric;
end if;
end
$$;



update autopie_ebpdemo.obj_fact_calls as t
set
    sum_outcome_amount = m.sum_outcome_amount, 
    autopie_run_id = 1
from autopie_ebpdemo.tmp_pre_join_0000000000 m 
where t.row_id = m.t_row_id;

drop table if exists autopie_ebpdemo.tmp_pre_join_0000000000;
drop table if exists autopie_ebpdemo.tmp_target_affected_0000000000;


  
09:09:26.923621 [debug] [MainThread]: SQL status: DROP TABLE in 0.01 seconds
09:09:26.924211 [debug] [MainThread]: Using postgres connection "macro_run_recipe"
09:09:26.924284 [debug] [MainThread]: On macro_run_recipe: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "demo_autopie", "target_name": "dev", "connection_name": "macro_run_recipe"} */

    
select row_number() over (order by autopie_run_id desc) run_sequence, count(*) count_records 
  from autopie_ebpdemo.obj_fact_calls
group by autopie_run_id
order by 1
limit 5;

  
09:09:26.924620 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
09:09:26.925295 [debug] [MainThread]: On macro_run_recipe: Close
09:09:26.926215 [debug] [MainThread]: Connection 'macro_run_recipe' was properly closed.
